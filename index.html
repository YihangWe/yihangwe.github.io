<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yihangwe.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。">
<meta property="og:type" content="website">
<meta property="og:title" content="EthanWeee">
<meta property="og:url" content="https://yihangwe.github.io/index.html">
<meta property="og:site_name" content="EthanWeee">
<meta property="og:description" content="聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Yihang Wei">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://yihangwe.github.io/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>EthanWeee</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">EthanWeee</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://yihangwe.github.io/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/04/06/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Review%20Report%20-%20Managing%20Cold%20Data%20in%20a%20Memory-Optimized%20Database/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yihang Wei">
      <meta itemprop="description" content="聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EthanWeee">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/04/06/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Review%20Report%20-%20Managing%20Cold%20Data%20in%20a%20Memory-Optimized%20Database/" class="post-title-link" itemprop="url">Managing Cold Data in a Memory-Optimized Database</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-04-06 00:00:00" itemprop="dateCreated datePublished" datetime="2025-04-06T00:00:00-07:00">2025-04-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-05-31 23:04:49" itemprop="dateModified" datetime="2025-05-31T23:04:49-07:00">2025-05-31</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/" itemprop="url" rel="index"><span itemprop="name">高级数据存储</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>The paper addresses 2 problems:</p>
<ol>
<li>How to migrate records to and from the cold store.</li>
<li>How to read and update records in the cold store in a transactionally consistent manner.</li>
</ol>
<p>The paper provides 3 novel ideas and elaborates the proposed approach for the implementation of each idea:</p>
<ol>
<li>A unified interface that hides the physical location of a record to higher layer: the collaboration among cold store, access filters, private cache, and update memo.</li>
<li>Minimizing the overhead caused by accessing secondary storage: each transaction has its own private cache.</li>
<li>Seamless migration between hot and cold stores: the system performs migration using insert and delete operations in a transaction.</li>
</ol>
<p>Analytical and experimental findings: The paper evaluates the performance of Siberia on both the YCSB Benchmark and Multi-step read&#x2F;update workload, showing the following conclusions. With realistic client delay, the throughput loss is only 3%. Even under extreme cold access data rate, the in-memory Siberia machinery results in a low performance loss. When live migration is active, the system’s performance remains stable. The overhead of accessing the memo is expensive, which means that memo cleaning is important for improving performance. For read-only transactions at realistic cold data access rates of 5% and 10%, the performance losses are 7% and 14% respectively, which are acceptable. For update-only transactions, 5% cold data updates lead to 8% throughput loss, 10% cold data update rates lead to 13% throughput loss, which are also acceptable. For the YCSB workload, as the access skew decreases and the memory to database size ratio increases, performance degrades, and read-heavy workloads exhibit lower abort rates for transactions at higher skew rates compared to write-heavy workloads.</p>
<h1 id="Paper-Strength"><a href="#Paper-Strength" class="headerlink" title="Paper Strength"></a>Paper Strength</h1><ul>
<li>The paper provides a comprehensive literature review. In the HEKATON STORAGE AND INDEXING section, the paper briefly outlines the index and data storage structure of HEKATON and its read and update operations based on MVCC. In the RELATED WORK section, the paper analyzes how existing database systems handle cold data, explaining that Hyper manages cold data using virtual pages, Stoica et al propose separating hot and cold data into different memory locations. Finally, the paper describes the working principle of Anti-caching and highlights its 2 drawbacks: limited space savings and repeated execution.</li>
<li>The paper provides a detailed description of the working principles after integrating SIBERIA into HEKATON. It presents the workflow of 2 transactions used during data migration to the cold store. Insert and update operations ensure that data is placed into the hot store to avoid the overhead of checking the cold store. Delete and read operations utilize notices in the update memo to perform concurrency control and conflict detection. Cold store cleaning is also driven by the update memo, which enables the timely removal of records from the cold store that are no longer visible to any active transactions. Furthermore, validation leverages the notices in the update memo as well and computes TsBoundSer to ensure the correctness of serializable transactions, thereby enhancing phantom detection.</li>
<li>The paper presents the relatively comprehensive experiment. The experiments are based on the YCSB Benchmark and Multi-step read&#x2F;update workload, which allow for testing Siberia’s performance under different workloads. Moreover, the paper evaluates the pure in-memory overhead of Siberia, the overhead of running live migration, and the overhead of the update memo on the path to accessing a cold record. Furthermore, under the YCSB workload, it demonstrates the relationship among workload skew, memory to database size ratios, and workload performance.</li>
</ul>
<h1 id="Paper-Weakness"><a href="#Paper-Weakness" class="headerlink" title="Paper Weakness"></a>Paper Weakness</h1><ul>
<li>The paper does not describe the process of integrating Siberia in HEKATON at the code level, but only mentions integration at the level of data processing and storage mechanisms. It details the cold data migration process and explains how update memo notices in the insert, delete, read, and update operations work in collaboration with HEKATON’s versioning and concurrency control. However, the paper does not address how Siberia is integrated into HEKATON at the code level, such as by identifying core functions, code segments, and the corresponding modifications. This omission makes it difficult for readers to easily re-achieve the Siberia. Therefore, the paper should at least provide an outline of the code modifications.</li>
<li>In the Synthetic End-to-End Workload section, the paper does not discuss the throughput loss under moderate to high cold data access rates. The paper only presents the throughput loss at 5% and 10% cold data access rates, claiming these are realistic cold data access rates. First, the paper fails to explain which report or literature supports that 5% and 10% are “realistic cold data access rates” in the Read-Only Transactions section. Second, we assume the above data is accurate, but the paper does not describes how the throughput loss changes when cold data access rates exceed 10%. This omission prevents readers from gaining a comprehensive understanding of the performance of handling workload in Siberia. Therefore, the paper should explain how the realistic cold data access rates were determined and describe the changes in throughput loss under moderate to high cold data access rates.</li>
<li>The paper does not discuss Siberia’s performance limitations or the conditions under which its performance might degenerate, despite the Experiments section showcasing impressive performance. It is possible that such impressive performance comes at the cost of high hardware utilization such as high CPU usage. Alternatively, while integrating Siberia in HEKATON may enhance the handling of hot and cold data, it could potentially compromise some of HEKATON’s original features. Therefore, the paper should clarify the situations under which Siberia’s performance may degenerate.</li>
</ul>
<p>Reference: <a target="_blank" rel="noopener" href="https://www.vldb.org/pvldb/vol7/p931-eldawy.pdf">https://www.vldb.org/pvldb/vol7/p931-eldawy.pdf</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://yihangwe.github.io/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/03/18/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Review%20Report%20-%20TicToc/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yihang Wei">
      <meta itemprop="description" content="聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EthanWeee">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/03/18/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Review%20Report%20-%20TicToc/" class="post-title-link" itemprop="url">TicToc</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-03-18 00:00:00" itemprop="dateCreated datePublished" datetime="2025-03-18T00:00:00-07:00">2025-03-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-05-31 23:02:32" itemprop="dateModified" datetime="2025-05-31T23:02:32-07:00">2025-05-31</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/" itemprop="url" rel="index"><span itemprop="name">高级数据存储</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>The paper addresses 1 problem:</p>
<ol>
<li>How to design an efficient concurrency control algorithm to improve scalability of OLTP DBMSs in the multi-core environment?</li>
</ol>
<p>The paper provides 4 novel ideas and elaborates the proposed approach for the implementation of each idea:</p>
<ol>
<li>TicToc algorithm: Implemented on top of OCC, it ensures a transaction’s timestamp will be calculated lazily at the commit time based on tuples this transaction process, which will improve the parallelism as well.</li>
<li>No-wait locking in validation phase: If a transaction fails to acquire a lock for a tuple in the write set, the validation phase will be aborted immediately. TicToc will restarts this phase after a period of time.</li>
<li>Preemptive aborts: Based on an approximate commit timestamp together with the local rts and wts, it is possible to determine whether to abort a transaction before locking the tuples in its write set.</li>
<li>Timestamp history: When a read tuple’s local rts is lower than the commit_ts and its wts differs from the latest wts, further inspection of the tuple’s history buffer is conducted to decide whether to start the validation phase.</li>
</ol>
<p>Analytical and experimental findings: The paper compares five algorithms: TicToc, Silo, HEKATON, DL_DETECT, and NO_WAIT. In the TPC-C results, with 4 warehouses, TicToc achieves the highest throughput and a lower abort rate than Silo. As the number of warehouses increases, TicToc’s throughput is eventually surpassed by Silo around 80 warehouses, but its abort rate remains lower than that of Silo. In the YCSB results, when processing read-only transactions, TicToc’s throughput is close to Silo’s and higher than that of the other algorithms; for read-write transactions under medium contention, TicToc maintains throughput similar to SIlo’s while its abort rate is significantly lower than those of Silo, HEKATON, and NO_WAIT; under high contention conditions, TicToc’s throughput far surpasses that of Silo, although its abort rate becomes more close to Silo’s. Tests for optimization indicate that most of the performance improvements come from the no-wait and preemptive aborts. Furthermore, TicToc’s timestamp growth rate is substantially lower than that of TS_ALLOC. When the isolation level is lower, TicToc shows improved throughput and a reduced abort rate, but the degree of these changes is not as pronounced compared to the other algorithms.</p>
<h1 id="Paper-Strength"><a href="#Paper-Strength" class="headerlink" title="Paper Strength"></a>Paper Strength</h1><ul>
<li>The paper provides a clear description of the background knowledge and the problem to be addressed. It elaborates on the weaknesses of the 2PL strategy and highlights that the T&#x2F;O strategy, such as MVCC and OCC, has gradually become mainstream. It then points out that the centralized timestamp allocator and the CPU’s cache coherence protocol in traditional T&#x2F;O algorithms have led to a timestamp allocation bottleneck. Moreover, all the hardware solutions mentioned in the paper fail to perfectly align with the architecture of most modern CPUs, and their performance remains suboptimal even if implemented. Furthermore, the paper briefly describes the execution phases of OCC and introduces 2 optimized approaches based on OCC, that is DTA and Silo, and highlights that both solutions still suffer from scalability bottlenecks. In order to tackle these problems, the paper presents TicToc algorithm.</li>
<li>The paper provides code, charts, and an example for the core processes of the TicToc algorithm, enabling readers to quickly understand the implementation details and workflow. In Section 3.2, the paper presents pseudocode for the Read Phase, Validation Phase, and Write Phase, which clearly illustrates the design considerations in addressing conflicts in concurrent and parallel scenarios and the decentralized timestamp assignment. In Section 3.6, the paper demonstrates the structure used for storing read and write timestamps and, through pseudocode, effectively presents a solution to the potential overflow problem of the delta attribute. Moreover, in Section 3.3, the paper provides an example of interleaved transaction execution, accompanied by a bar chart, clearly displaying TicToc’s high flexibility and performance in handling concurrency and parallelism challenges.</li>
<li>The paper presents a comprehensive experiment of TicToc on DBx1000. It assesses TicToc’s performance in both TPC-C and YCSB scenarios, comparing throughput and abort rate under various contention levels and different numbers of warehouses, with Silo, HEKATON, DL_DETECT, and NO_WAIT. The paper also evaluates TicToc optimizations, emphasizing the contributions of the no-wait and pre-abort to performance improvements. Moreover, the paper compares TicToc’s timestamp growth rate and linear timestamp growth rate, and the differences in throughput and abort rate between TicToc and other 4 algorithms under different isolation levels.</li>
</ul>
<h1 id="Paper-Weakness"><a href="#Paper-Weakness" class="headerlink" title="Paper Weakness"></a>Paper Weakness</h1><ul>
<li>The paper does not show the process of integrating the TicToc into DBx1000. As a concurrency control algorithm, TicToc must be interfaced with other key components such as transactions, indexes, and logs, which involves a considerable amount of work. However, the paper fails to address this aspect, thereby preventing readers from easily re-achieving the algorithm. Therefore, the paper should at least provide a brief outline of the necessary steps to help readers implement this functionality.</li>
<li>The paper’s experiments fail to demonstrate the general applicability of the TicToc across a range of databases. The evaluation was conducted only in the DBx1000 environment, thereby only substantiating TicToc’s high performance within DBx1000. But many commercially available databases, such as SQL Server and MySQL etc., exhibit distinct characteristics under varying workloads, which could potentially lead to different performance when using TicToc. However, the paper is entirely silent on this aspect. Therefore, the paper should also incorporate integration and testing of TicToc on these mainstream databases.</li>
<li>The paper fails to provide code or explanations for certain key concepts in the critical OPTIMIZATIONS section. According to the experimental results, the no-wait and preemptive aborts lead to significant performance improvements. However, the OPTIMIZATIONS section does not present any relevant code. For instance, in the No-Wait Locking in Validation Phase section, the paper does not clarify what thrashing problems mean in the given context, nor does it showcase the code for the no-wait or highlight its modifications relative to the original TicToc implementation. Therefore, the paper should include the optimization code and explanations for concepts.</li>
</ul>
<p>Reference: <a target="_blank" rel="noopener" href="https://people.csail.mit.edu/sanchez/papers/2016.tictoc.sigmod.pdf">https://people.csail.mit.edu/sanchez/papers/2016.tictoc.sigmod.pdf</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://yihangwe.github.io/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/03/02/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Review%20Report%20-%20Adaptive%20Execution%20of%20Compiled%20Queries/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yihang Wei">
      <meta itemprop="description" content="聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EthanWeee">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/03/02/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Review%20Report%20-%20Adaptive%20Execution%20of%20Compiled%20Queries/" class="post-title-link" itemprop="url">Adaptive Execution of Compiled Queries</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-03-02 00:00:00" itemprop="dateCreated datePublished" datetime="2025-03-02T00:00:00-08:00">2025-03-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-05-31 23:01:14" itemprop="dateModified" datetime="2025-05-31T23:01:14-07:00">2025-05-31</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/" itemprop="url" rel="index"><span itemprop="name">高级数据存储</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>The paper addresses 3 problems:</p>
<ol>
<li>How to reduce the compilation time of complex but fast queries?</li>
<li>How to reduce the compilation time of extremely large queries?</li>
<li>How to reduce the compilation time of the first incoming query?</li>
</ol>
<p>The paper provides 2 novel ideas and elaborates the proposed approach for the implementation of each idea:</p>
<ol>
<li>Adaptive execution: For a specific query pipeline, the paper tracks the progress of worker threads, predicts the remaining workload duration under 3 execution modes based on the overall state of all threads in the pipeline, and finally selects the mode with the shortest duration to apply to all threads.</li>
<li>Fast bytecode interpretation: Based on register machine, the paper implements linear-time liveness computation through processing basic blocks in intervals and using algorithms such as the disjoint set and path compression, which optimizes register allocation further. Furthermore, the bytecode interpreter behaves equivalently to the generated machine code, ensuring seamless switching between interpretation and machine code.</li>
</ol>
<p>Analytical and experimental findings: For different scale factors, adaptive execution can switch to the mode with the optimal performance, ensuring the lowest execution time compared to other static mode selections. For action, adaptive execution can immediately start to process pipeline morsels on all available worker threads and dynamically switch modes for pipelines with heavy workloads, allowing it to finish queries 10%, 40%, and 80% faster than its competitors. While interpreted code is slower than compiled code, it is faster than PostgreSQL and scales as well as compiled code when using multiple cores. Furthermore, the byte interpreter scales perfectly and can process the large query in a short time.</p>
<h1 id="Paper-Strength"><a href="#Paper-Strength" class="headerlink" title="Paper Strength"></a>Paper Strength</h1><ul>
<li>The paper provides a clear and detailed description of the problem to be addressed. In Section II, it presents the multi-step process of a SQL query in HyPer through a flowchart, highlighting that the LLVM compilation tasks takes the majority of the overall execution time. By comparing the compilation and execution times of different execution modes on TPC-H Query 1 on scale factor 1, the paper introduces the trade-off between interpreters and compilers, demonstrating that different execution modes can be applied to different parts of the same query. Furthermore, the paper analyzes the largest TPC-H and TPC-DS queries, concluding that compilation time grows super-linearly with the query size.</li>
<li>The paper provides a comprehensive literature review. In Section VI, it references experimental results from other papers on compilation time, concluding that compiling to LLVM IR is faster than compiling to C. Based on the personal experience, the paper highlights that query compilation latency becomes a major problem in production environments, this makes adaptive execution a crucial component for making query compilation truly practical. It then explores the feasibility of integrating adaptive execution into database systems such as MemSQL, LegoBase, and Microsoft Hekaton. Furthermore, the paper demonstrates the advantages of adaptive execution over automatic plan caching, i.e. the ability to re-optimize queries on every execution. Finally, the paper discusses the similarities and differences between adaptive execution and execution engines in programming languages, such as JVM, V8, and CLR.</li>
<li>The paper achieves significant improvements, the linear-time liveness computation. The traditional solution for computing the liveness of each block individually usually takes $O(n^2)$ runtime. However, the paper proposes a linear-time algorithm. The algorithm labels all basic blocks in reverse postorder and organizes them into a dominator tree, which allows interpreter to determine the relationships of basic blocks in $O(1)$ time and paves the way for identifying loops. It identifies the innermost enclosing loop of each basic block by using the disjoint set with path compression, and, based on the the distribution of basic blocks related to the definition and uses of a certain value, determines the lifetime of that value. The low cost of the computation is primarily attributed to the appropriate data structures.</li>
</ul>
<h1 id="Paper-Weakness"><a href="#Paper-Weakness" class="headerlink" title="Paper Weakness"></a>Paper Weakness</h1><ul>
<li>The paper does not provide a clear explanation of the basic concepts. In Section II, it does not explain the meaning of latency and throughput in the context of HyPer, nor the relationship between them, so readers may not realize the significance of the tradeoff and possibly do not understand how performance improvements in later experimental results are achieved. For example, readers might not figure out why interpreters can achieve very low latency by sacrificing throughput. Therefore, the paper should explain these concepts.</li>
<li>The paper’s experiments are not comprehensive enough. As a core component in data processing and storage, adaptive execution framework is only shown to have an advantage in execution time, while experiments demonstrating its physical device utilization, stability and fault recovery performance are lacking. These metrics are also critical in evaluating the overall performance of the framework. For example, for the same set of queries, if the execution time is short but the CPU and memory usage are extremely high, or if the probability of throwing an exception is high and a large amount of time is required for fault recovery, then the framework still has room for improvement. Therefore, the paper should include experimental results for these metrics.</li>
<li>The paper does not provide a detailed explanation of how to translate into VM code. In Section IV-B, the paper mentions that subsumed instructions will not be translated, but it does not specify which types of instructions are subsumed or in what manner they are subsumed. These omissions can confuse readers and hinder their understanding of the translation pseudocode. Therefore, the paper should explain principles behind subsumed instructions.</li>
</ul>
<p>Reference: <a target="_blank" rel="noopener" href="https://db.in.tum.de/~leis/papers/adaptiveexecution.pdf">https://db.in.tum.de/~leis/papers/adaptiveexecution.pdf</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://yihangwe.github.io/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/02/11/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Review%20Report%20-%20Orca/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yihang Wei">
      <meta itemprop="description" content="聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EthanWeee">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/02/11/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Review%20Report%20-%20Orca/" class="post-title-link" itemprop="url">Orca - A Modular Query Optimizer Architecture for Big Data</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-02-11 00:00:00" itemprop="dateCreated datePublished" datetime="2025-02-11T00:00:00-08:00">2025-02-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-05-31 23:05:29" itemprop="dateModified" datetime="2025-05-31T23:05:29-07:00">2025-05-31</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/" itemprop="url" rel="index"><span itemprop="name">高级数据存储</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>The paper addresses 2 problems:</p>
<ol>
<li>How to design a query optimizer that can handle big data and complex analytical queries while ensuring the generation of efficient query plans.</li>
<li>Exploring the application of advanced query optimization theories in production environments.</li>
</ol>
<p>The paper provides 4 novel ideas and elaborates the proposed approach for the implementation of each idea:</p>
<ol>
<li>Decoupling the optimizer from the DB systems through DXL: Different DB systems need to implement 3 translators, Query2DXL, MD Provider, and DXL2Plan, to support Orca.</li>
<li>Use Memo and Group Hash Tables to optimize: Each group in the Memo stores all logically equivalent group expressions for a given operation, including enforcer operators. The group hash tables record the optimal implementation for each optimization request, i.e., the best group expressions. During query optimization, by retrieving the best group expression (best GExprs) corresponding to a given optimization request for each group and its child groups, these best GExprs are linked together to form the best execution plan.</li>
<li>Implementing the parallel query optimization with jobs dependency graph and job queues: If a group is currently processing an optimization job, other jobs will be placed in a queue to wait. Once the job is completed, its results can be utilized by subsequent jobs.</li>
<li>Developed efficient tools for testing: AMPERe is used to catch errors and generate dump files for later replaying to debug. TAQO samples plans uniformly based on the optimization requests’ linkage structure and evaluates the optimizer’s accuracy by calculating the correlation score between the ranking of sampled plans based on estimated costs and their ranking based on actual costs.</li>
</ol>
<p>Analytical and experimental findings: Based on the TPC-DS Benchmark, a limited set of queries was used to test GPDB legacy query optimizer (111 queries, MPP) and Orca, as well as Impala (31 queries, Hadoop), Stinger (19 queries, Hadoop), Presto (12 queries, Hadoop) and HAWQ. The results concluded that Orca matched or outperformed the GPDB optimizer in 80% of query executions. For 14 queries, Orca achieved a speed-up ratio of at least 1000× compared to the GPDB optimizer. Presto failed to process any TPC-DS queries under all test conditions, and query execution performance on HAWQ was generally superior to that on Impala and Stinger.</p>
<h1 id="Paper-Strength"><a href="#Paper-Strength" class="headerlink" title="Paper Strength"></a>Paper Strength</h1><ul>
<li>The paper provides a comprehensive literature review and covers the prerequisite knowledge needed to understand Orca. In the PRELIMINARIES, the paper briefly analyzes GPDB and explains its 3 core components: master, segments, and the interconnect layer, explains how SQL and query optimizers have been integrated into big data processing components such as Hadoop. Furthermore, it analyzes the advantages of the HAWQ architecture which is optimized by Orca compared to Impala and Presto. In the RELATED WORK, the paper introduces Volcano and Cascades, highlighting that Cascades offers greater flexibility than Volcano, then discusses various query optimizer implementations for big data in MPP databases, such as PDW and SCOPE. Finally, the paper reviews existing efforts to integrate SQL with Hadoop, such as converting queries into MapReduce jobs (Hive) and co-location of DBMS and Hadoop technologies (Hadapt).</li>
<li>The paper presents highly valuable solutions for query optimization on big data: DXL and Parallel Query Optimization. Different DBs only need to implement their own Query2DXL and DXL2Plan translators to achieve compatibility with Orca, giving Orca the potential to be adapted to any existing database system. To satisfy the core requirement of big data, concurrent processing, Orca constructs an optimization jobs dependency graph to determine the dependencies between jobs. Parent jobs can only be executed after their child jobs are completed, while independent jobs can run in parallel. For handling resource contention, Orca places incoming jobs in a job queue, where they wait until the running job is finished. These waiting jobs can then leverage the results generated by the completed jobs.</li>
<li>The paper elaborates steps of Orca’s optimization in the QUERY OPTIMIZATION section. In the Exploration phase, Orca creates logically equivalent expressions and deduplicates them using the Memo. In the Statistics Derivation phase, Orca estimates the cardinality and data skew for Memo groups. In the Implementation phase, Orca generates physical implementations of logical expressions. In the Optimization phase, multiple execution plans are generated, incorporating enforcer operators when necessary. The cost model is then used to select the execution plan with the lowest cost. These details effectively help readers gain a high-level understanding of Orca’s working principles.</li>
</ul>
<h1 id="Paper-Weakness"><a href="#Paper-Weakness" class="headerlink" title="Paper Weakness"></a>Paper Weakness</h1><ul>
<li>The paper lacks a description of how execution plan costs are computed during the Optimization phase. Specifically, there is a complete absence of discussion on the cost model, which should be a core functionality of Orca. This is particularly crucial when dealing with big data and a shared-nothing architecture, where the cost model here may differ from the Selinger’s cost model by incorporating coordination and communication across multiple worker nodes and need to account for network bandwidth. I recommend that the paper include a detailed description of the cost model and discuss its behavior in both monolithic and distributed DB systems.</li>
<li>The paper’s experimental evaluation for MPP databases is based on a limited dataset. Orca was only compared against the GPDB legacy query optimizer using 119 queries. Both the number of queries and the number of MPP database optimizer being compared are insufficient to convincingly demonstrate Orca’s advantages over other MPP database optimizers. Therefore, the experiment should conduct comparisons with a broader range of MPP databases, such as Amazon Redshift and Teradata Aster, to provide a more comprehensive evaluation.</li>
<li>The paper’s experiments do not reflect Orca’s hardware utilization, such as CPU usage, memory consumption, etc. Orca will possibly be used in a shared-nothing architecture, it will run across multiple servers. However, in the production environment, these servers will be not dedicated solely to Orca, other processes including databases that Orca will optimize is going to be probably running on the same server where Orca will be. If Orca has excessively high CPU or memory usage, it could negatively impact those databases’ query execution and the performance of other applications. This effect could accumulate across multiple servers, leading to significant performance degradation. Therefore, the paper should also include an evaluation of Orca’s hardware resource consumption.</li>
</ul>
<p>Reference: <a target="_blank" rel="noopener" href="https://dl.acm.org/doi/10.1145/2588555.2595637">https://dl.acm.org/doi/10.1145/2588555.2595637</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://yihangwe.github.io/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/01/25/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/OLTP%20%E7%B4%A2%E5%BC%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yihang Wei">
      <meta itemprop="description" content="聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EthanWeee">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/01/25/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/OLTP%20%E7%B4%A2%E5%BC%95/" class="post-title-link" itemprop="url">OLTP 索引</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-01-25 00:00:00" itemprop="dateCreated datePublished" datetime="2025-01-25T00:00:00-08:00">2025-01-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-06-13 18:28:30" itemprop="dateModified" datetime="2025-06-13T18:28:30-07:00">2025-06-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/" itemprop="url" rel="index"><span itemprop="name">高级数据存储</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="B-Tree"><a href="#B-Tree" class="headerlink" title="B+Tree"></a>B+Tree</h1><p>B+Tree 通过宽而浅的多路平衡结构，以及对页级 IO、顺序访问、并发保护和崩溃恢复的深度优化，完美契合 OLTP 系统对<strong>低延迟点查找</strong>、<strong>高并发访问</strong>和<strong>安全写入</strong>的严格要求，因此成为主流关系型数据库（MySQL、PostgreSQL、Oracle 等）在 OLTP 场景中最常用的索引实现。</p>
<p><strong>性能特点</strong></p>
<ol>
<li><strong>O(log n) 查找复杂度</strong>：树高 ≈ logₘ N，当 m 很大时，即使 N 达到亿级，树高也通常只有 3～4 层，单次查找只需 3～4 次磁盘／页访问。</li>
<li><strong>磁盘友好</strong>：每个节点对应一个（或多个）磁盘页（页大小常见 4 KB、8 KB），节点内存储大量键／指针，充分利用页读取的预读和缓存特性，减少 IO。</li>
<li><strong>顺序访问高效</strong>：叶子节点通过链表串联，做范围查询（e.g. WHERE key BETWEEN A AND B）时，只要从第一个叶子开始，顺序遍历链表即可，不必回溯到内节点，再次查找。</li>
<li><strong>并发控制</strong>：在多事务并发访问时，对节点（页）加共享或独占的轻量级锁（latch），确保在结构调整（分裂／合并）期间不会破坏其他事务的读取或写入视图。</li>
<li><strong>安全写入</strong>：配合 <strong>WAL</strong> 或 <strong>双写缓冲</strong> 机制，即使在页分裂或更新过程中发生崩溃，也能借助日志或双写页恢复到一致状态，不会丢失或损坏索引结构。</li>
</ol>
<p><strong>各种 Latch 实现方式的比较</strong></p>
<table>
<thead>
<tr>
<th><strong>实现方式</strong></th>
<th><strong>原理与特点</strong></th>
<th><strong>适用场景</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>Test-and-Set Spinlock</strong></td>
<td>原子地执行一条 test and set 操作：读—改—写一个标志位<br />若已被占用，则不断自旋（busy-wait）直到释放<br />实现简单、开销低（无系统调用）</td>
<td>持有时间极短、线程数少、CPU 空闲时可快速获得锁</td>
</tr>
<tr>
<td><strong>Blocking OS Mutex</strong></td>
<td>调用操作系统的互斥锁原语（如 pthread_mutex）<br />若锁被占用，线程进入睡眠（阻塞），由内核调度唤醒</td>
<td>线程可能长时间等待、锁竞争激烈、无法一直自旋时</td>
</tr>
<tr>
<td><strong>Adaptive Spinlock</strong></td>
<td>结合自旋与阻塞：先自旋若干次（避免短期冲突），超时后再阻塞<br />在多核系统上可减少线程睡眠、上下文切换开销</td>
<td>对临界区长度不稳定、短时冲突多长时冲突时都需兼顾</td>
</tr>
<tr>
<td><strong>Queue-based Spinlock</strong></td>
<td>基于队列（如 MCS、CLH）组织申请线程<br />自旋在各自本地节点上，避免全局自旋总线抖动<br />公平性好，防止饥饿</td>
<td>高并发竞争场景，需要严格 FIFO 公平性</td>
</tr>
<tr>
<td><strong>Reader-Writer Locks</strong></td>
<td>区分读锁（shared）与写锁（exclusive）<br />允许多个读者并行、写者独占<br />可基于自旋或阻塞实现</td>
<td>读多写少场景，如 B+Tree 查找（多数是读），偶尔分裂&#x2F;合并（写）</td>
</tr>
</tbody></table>
<p><strong>Test-and-Set Spinlock 的实现</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">std::atomic_flag latch;</span><br><span class="line">…</span><br><span class="line"><span class="keyword">while</span> (latch.<span class="built_in">test_and_set</span>(...)) &#123;</span><br><span class="line">    <span class="comment">// Yield? Abort? Retry?</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>以上代码中，<code>test_and_set</code> 是一个原子指令：读取锁标志，置 1，并返回旧值。如果返回值表明锁已被占用，线程就在 while 循环中不断自旋重试。</p>
<p><strong>优点</strong></p>
<ul>
<li><strong>极低的延迟</strong>：一次原子 CPU 指令即可完成加／解锁，若临界区非常短，开销远小于一次系统调用。</li>
<li><strong>实现简单</strong>：依赖硬件指令，无需操作系统介入。</li>
</ul>
<p><strong>缺点</strong></p>
<ul>
<li><strong>忙等</strong>：自旋期间 CPU 一直在循环，占用周期，却不做实质性工作。</li>
<li><strong>总线抖动</strong>：多核同时自旋会争抢同一缓存行，导致缓存一致性流量剧增。</li>
<li><strong>可扩展性差</strong>：并发度一高就容易产生严重争用，甚至导致某些线程长期拿不到锁（饥饿）。这种情况在多机器／多核环境下更为明显：TaS 自旋锁会导致耗费大量总线带宽，甚至在远程节点上更容易饿死。</li>
</ul>
<h1 id="Latch-Coupling"><a href="#Latch-Coupling" class="headerlink" title="Latch Coupling"></a>Latch Coupling</h1><p>在遍历 B+Tree（从根到叶）过程中，始终维持一条“锁链”：</p>
<ol>
<li>加锁当前节点；</li>
<li>在确定要访问的子节点加锁后，再释放父节点的锁。</li>
</ol>
<p>保证任何时刻，对正在操作路径上的节点都有锁保护，避免结构变化（分裂&#x2F;合并）导致的不一致访问。</p>
<p>思考：</p>
<p>为什么要锁父节点？</p>
<p>避免并发操作导致子节点增删时引发的父节点分裂或合并，从而避免多线程访问到不一致的数据。</p>
<blockquote>
<p>[!NOTE]</p>
<p><strong>何时可以释放父节点锁？</strong></p>
<p>当子节点被判定为“安全”（safe）时，父节点锁可提前释放：</p>
<ul>
<li><strong>插入场景</strong>：子节点没有达到最大容量，插入后不会触发分裂；</li>
<li><strong>删除场景</strong>：子节点删除后依旧保持超过一半的填充度，不会触发合并。</li>
</ul>
</blockquote>
<p><strong>优点</strong></p>
<ul>
<li><strong>锁粒度细化</strong>：仅对正在操作的节点及其立即父节点加锁，其他分支无关节点不受影响</li>
<li><strong>提高并发度</strong>：减少持锁时间，其他事务可以更快地访问不同的子树</li>
</ul>
<p><strong>缺点</strong></p>
<ul>
<li><strong>频繁的锁操作</strong>：每向下一层移动，都要做一次 lock(child) + unlock(parent)，系统调用和内核开销不可忽视</li>
<li><strong>层次深度敏感</strong>：树越深，锁–解锁次数越多；在高并发或极深树结构中，延迟和 CPU 开销上升明显</li>
</ul>
<p>Read Path 中：</p>
<ol>
<li>在根节点加读锁；</li>
<li>定位到要访问的下层子节点；</li>
<li>对该子节点加读锁；</li>
<li>释放其父节点的读锁；</li>
<li>重复 2–4，直到到达叶节点并完成读取。</li>
</ol>
<p>Write Path 中：</p>
<ol>
<li>在根节点加写锁；</li>
<li>定位到要访问的下层子节点；</li>
<li>对子节点加写锁；</li>
<li>检查子节点是否安全：<ul>
<li><strong>插入时</strong>：子节点未满（不会触发分裂）；</li>
<li><strong>删除时</strong>：删除后填充度仍 &gt;&#x3D; 50%（不会触发合并）；</li>
</ul>
</li>
<li>如果安全，释放所有祖先节点的写锁，仅保留子节点锁往下继续；</li>
<li>若不安全，则继续在上层保留必要锁，直至完成分裂&#x2F;合并，再逐级释放。</li>
</ol>
<p>示例 1：搜索数据 23（示例中 B+ 树变化的顺序是从上到下，从左到右）</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_oltp_indexing_lock_coup_search.drawio.png" alt="img"></p>
<p>示例 2：删除数据 44</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_oltp_indexing_lock_coup_delete.drawio.png" alt="img"></p>
<p>示例 3：插入 40</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_oltp_indexing_lock_coup_insert.drawio.png" alt="img"></p>
<h1 id="重要观察"><a href="#重要观察" class="headerlink" title="重要观察"></a>重要观察</h1><p>传统的 B+Tree 是为慢磁盘／页式存储优化的，而在纯内存数据库中，我们可以选用更 CPU 缓存友好、指针开销更小、分支因子更灵活的数据结构。比如：</p>
<p><strong>Adaptive Radix Tree (ART)</strong></p>
<p>一种基于 Radix-Trie（前缀树）的变体，根据子节点数动态压缩节点类型（4／16／48／256 分支），兼顾空间与速度。</p>
<p><strong>优势</strong>：</p>
<ul>
<li>存储密度极高；按 key 前缀快速定位，指针跳转少</li>
<li>支持前缀查询，范围查询也只需一次遍历即可顺序扫描叶子</li>
<li>插入／删除时节点扩张／收缩成本低</li>
</ul>
<p>适用于对内存利用率敏感、需要高吞吐点查和范围查的 OLTP 场景。</p>
<p><strong>Bw-Tree（Latch-Free）</strong></p>
<p>微软提出的无锁 B+Tree，核心是 delta record 日志链 + 原子 CAS 更新，所有结构修改都追加写入 LSN，读者通过多版本链合并视图。</p>
<p><strong>优势</strong>：</p>
<ul>
<li>无全局锁或页级 latch，天然适合超高并发写入；</li>
<li>写热点变为对内存日志的追加，分裂／合并操作也只是更新 delta。</li>
</ul>
<p>适用于写密集型、高并发事务环境。</p>
<p><strong>Masstree</strong></p>
<p>结合了 B+Tree 与 Trie 的优点，对多列复合键可层级拆分，且各层使用紧凑数组存储。</p>
<p><strong>优势</strong>：</p>
<ul>
<li>支持多列复合索引，Trie 能快速跳过公共前缀</li>
<li>使用 per-node lock-coupling + optimistic read 提升并发性能</li>
</ul>
<p>适用于典型 KV 或多字段查找场景。</p>
<p>之后的内容会重点介绍 Bw-Tree。</p>
<h1 id="Bw-Tree"><a href="#Bw-Tree" class="headerlink" title="Bw-Tree"></a>Bw-Tree</h1><p>BW-Tree 是微软 Hekaton 内存数据库中用于 OLTP 场景的无锁索引结构。它通过增量记录（delta record）和映射表（mapping table）两大核心机制，实现了对 B+Tree 操作的完全无锁化。</p>
<p><strong>Delta 机制：无就地更新</strong></p>
<ul>
<li><p><strong>增量链</strong>：每次对某个页的插入、删除、分裂等修改，都不是直接改写页本身，而是在映射表条目后面追加一个小的 delta 节点，记录本次的修改操作。</p>
</li>
<li><p><strong>好处</strong></p>
<ul>
<li><strong>无锁安全</strong>：对页的修改仅是往链尾追加，不会破坏其他读者正在访问的旧版本数据。</li>
<li><strong>减少缓存抖动</strong>：不改写原页，旧页仍然稳定驻留在 CPU 缓存中，新 delta 追加只影响少量缓存行。</li>
</ul>
</li>
<li><p><strong>读取时合并视图</strong></p>
<p>读者先通过映射表定位基础页（base page），然后顺着 delta 链向前合并各个 change record，最终得到当前一致性视图。</p>
</li>
</ul>
<p><strong>Mapping Table：页指针的原子替换</strong></p>
<ul>
<li><strong>映射表结构</strong>：类似于页 ID → 页物理地址（或页链表头节点）的一个数组／哈希表。每个索引页（或叶子页）在映射表中有一条定长条目。</li>
<li><strong>CAS 原子切换</strong><ul>
<li>当需要分裂一个 leaf page 或合并多个 delta 到一个新的 consolidated page 时，只需在映射表中对该页条目执行一次 <strong>Compare-And-Swap</strong> 操作。</li>
<li>线程安全、无锁：所有并发读者只要先读一次映射表，就能看到分裂前或分裂后的整块页内容；中间状态对读者透明。</li>
</ul>
</li>
</ul>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_oltp_indexing_bwtree_structure.drawio.png" alt="img"></p>
<p>上图中，绿色的虚线箭头是逻辑指针，黑色的实线箭头是物理指针。</p>
<p>物理指针的用途：</p>
<ul>
<li>在直接访问数据的场景中使用，提供快速访问能力。</li>
<li>通常用于叶子节点内部或数据页的局部操作。</li>
</ul>
<p>逻辑指针的用途：</p>
<ul>
<li>在节点之间（特别是父子节点之间）的连接中使用，提供动态调整的灵活性。</li>
<li>逻辑指针指向的是映射表中的条目，映射表将逻辑指针解析为实际的物理位置。</li>
<li>节点分裂或合并时，映射表更新物理位置，而逻辑指针保持不变。</li>
</ul>
<p>思考：</p>
<p>为什么节点之间用 logical pointer 连起来？</p>
<p>在 BW-Tree 中，当某个子节点发生分裂或合并等变化时，只需要在映射表中更新该节点的 Page ID 对应的物理地址，一定程度上和父节点进行解耦。</p>
<p>父节点里存的只是 Page ID（逻辑指针），因此父节点无需做物理修改或大范围加锁，这样极大提升了并发能力和更新效率。</p>
<p><strong>更新与搜索（Delta Updates &amp; Search）</strong></p>
<p>每次对页的更新操作都会产生一个新的 delta 节点，该节点通过物理指针指向基页（base page），之后通过 CAS 操作将原来从映射表指向基页的物理指针指向新的 delta 节点。</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_oltp_indexing_update_cas.drawio.png" alt="img"></p>
<p>思考：</p>
<p>为什么 delta 节点使用 physical pointer 指向基页？</p>
<p><strong>物理指针一旦写入即不可变</strong>，读者沿着物理地址可以无歧义地遍历历史记录节点，即便映射表后续对该 Page ID 做了 CAS 更新也不影响已追加的 Delta 链的正确合并和回放。而逻辑指针（Page ID）会随映射表更新而变化，若 Delta 节点也存逻辑指针，就无法区分应访问旧页还是新页；物理指针则始终指向原有的内存位置，确保版本链的完整性和一致性。</p>
<p>并发更新是怎么进行的？</p>
<p>秉持着先来先服务的理念，后到的操作则会被驳回或者重试，从而避免两个 delta 节点指向同一个下层节点。</p>
<p>下图中，我们假设 <code>DELETE K8</code> 先来，那么 <code>INSERT K6</code> 就会被驳回或重试。</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_oltp_indexing_content_update.drawio.png" alt="img"></p>
<blockquote>
<p>[!NOTE]</p>
<p>在并发更新场景下，上图的竞争中通常会加锁。</p>
</blockquote>
<p>之后如果要搜索的话，流程如下：</p>
<ol>
<li>从根到叶，像常规 B+Tree 那样遍历；</li>
<li>定位到叶子页后，检查映射表指向；</li>
<li>如果映射表指向 Delta 链：<ol>
<li>自上而下遍历 Delta 链，对每个 Record（Insert&#x2F;Delete）检查：<ol>
<li>若 Record 的键等于查询键，则：<ol>
<li>如果是 <strong>Delete</strong> 类型，说明该键已被删除，搜索可提前返回不存在；</li>
<li>如果是 <strong>Insert</strong> 类型，说明该键最新就在此处，立即返回对应的值；</li>
</ol>
</li>
</ol>
</li>
<li>如果遍历完整个 Delta 链都没命中，再回退到 Base Page；</li>
</ol>
</li>
<li>否则，或 Delta 链未命中：<ol>
<li><strong>对 Base Page 执行二分查找</strong>（就像普通 B+Tree 的叶页内搜索那样）；</li>
<li>若在 Base Page 中找到该键且未被后续的 Delete 覆盖，即返回对应记录；否则返回不存在。</li>
</ol>
</li>
</ol>
<p><strong>合并与清理（Consolidation&#x2F;Garbage Collection）</strong></p>
<ul>
<li>随着 delta 不断追加，链条会变长，读者合并成本上升。</li>
<li><strong>后台合并线程</strong>会定期：<ol>
<li>扫描映射表，选取 delta 链过长或更新频繁的页；</li>
<li>将所有 delta 应用到一个新建的基础页，生成新的 base page；</li>
<li>用 CAS 原子地在映射表中替换旧页指针；</li>
<li>将旧的 base page + delta 链标记为可回收。</li>
</ol>
</li>
</ul>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_oltp_indexing_consolidation.drawio.png" alt="img"></p>
<p>合并完成后，我们会把 old page 2 放入一个池子中，便于之后的复用。</p>
<p>思考：</p>
<p>在合并的过程中，如果执行了大量的操作，那是怎么处理的？</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_oltp_indexing_consolidate_1.drawio.png" alt="img"></p>
<p>上图中，合并期间加入的 delta 节点会一开始指向 INSERT K5，待合并完成后这些节点会指向 new page 2。</p>
<p><strong>结构变更</strong></p>
<p><strong>Split Delta Record</strong></p>
<p>表示将基页中一部分键范围（key range）移动到了另一个页面，并使用逻辑指针指向新的页面。</p>
<p><strong>Separator Delta Record</strong></p>
<p>提供一种快捷路径，用于告诉父节点：应该在哪个键范围中查找已经被拆分出来的新页面。</p>
<p>以上两个组件会带来如下优势：</p>
<ol>
<li><strong>位置变化无需修改 BW-Tree 索引结构</strong>：一旦某个页面的位置发生变化，只需修改 mapping table 即可，无需更改 BW-Tree 上层结构中的索引节点。这是因为 BW-Tree 的索引项记录的是页面的 page id，而非物理地址。这样避免了传统 B-Tree 中频繁重建索引的开销。</li>
<li><strong>页面大小灵活，提升空间与性能利用率</strong>：mapping table 中的 page 大小不必固定为如 8KB 这类块对齐的大小。可以根据业务需要进行更细粒度的划分或合并，从而减少因空间浪费或合并而产生的额外写放大。</li>
<li><strong>解耦内存与存储结构，便于系统各层独立优化</strong>：BW-Tree 通过逻辑页和 mapping table 的机制，将存储管理与内存结构解耦。这样使得存储层可以专注于持久化效率优化，而内存层则可专注于读写性能与并发控制，彼此互不干扰，从而实现系统整体性能提升。</li>
</ol>
<p>假设 BW-Tree 中的 page 3 发生分裂，具体分裂步骤如下：</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_oltp_indexing_bw_SMO.drawio.png" alt="img"></p>
<p>需要注意，一个 split delta record 就对应要创建一个 separator delta record，多个 separator delta record 也会形成跟之前一样的 delta record 链。</p>
<p>在以上的节点分裂过程中，无需加锁，而且不论何时都可以访问到对应的节点，不会出现空指针异常。</p>
<p>思考：</p>
<p>为什么 split delta 节点指向 page 3 的是物理指针，而不是逻辑指针呢？</p>
<p>跟之前的 delta record 通过物理指针指向基页的原理是一样的。</p>
<blockquote>
<p>[!NOTE]</p>
<p>Split 节点同时使用物理和逻辑指针，既可以保证老的读操作（可能还在访问旧的物理页 3）不受影响，又能让新的读写操作访问到新的页面 5 上去。</p>
</blockquote>
<p><strong>关键观察</strong></p>
<p>在每一层节点上进行查找时，若缓存中没有相应数据，就会发生 <strong>cache miss</strong>，导致额外的内存访问延迟，尤其是当树高较大时，每层都有潜在的 miss。</p>
<p>传统设计中，内部节点和叶节点大多存于随机内存地址，查找时经常会产生多次 cache miss。</p>
<p><strong>如何减少 Cache Miss？</strong></p>
<ol>
<li><p><strong>节点预取</strong></p>
<ul>
<li><p>硬件级预取：CPU 的硬件预取器可以根据访问模式（如 stride 或 stream）提前将相邻缓存行加载到缓存中。</p>
</li>
<li><p>软件或路径预取：在树的搜索路径上提前发起预取，例如先加载 root，再预测加载下层 child 块 。</p>
</li>
</ul>
</li>
<li><p><strong>缓存友好型节点结构</strong></p>
<ul>
<li>调整节点大小至多个缓存行，让一个节点的多个缓存行能并行预取，减少单节点内部的 miss 数量。</li>
</ul>
</li>
<li><p><strong>增加树扇出，降低树高</strong></p>
<ul>
<li>增大节点容量（存更多键&#x2F;指针）可以减少树的高度，也就减少访问叶子需访问的层数，从而降低总体 cache miss 数量 。</li>
</ul>
</li>
<li><p><strong>避免路径中的重复访问</strong></p>
<ul>
<li>可记录较热的路径节点，实现快速访问。</li>
</ul>
</li>
<li><p><strong>批量预加载</strong></p>
<ul>
<li>对于范围扫描或批量插入，可以一次性预加载整颗叶子区域，从 root 之后连续加载所有相关叶子节点，提高顺序访问的 cache 命中率。</li>
</ul>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Yihang Wei</p>
  <div class="site-description" itemprop="description">聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">35</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yihang Wei</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
<script src="https://cdn.jsdelivr.net/npm/darkmode-js@1.5.7/lib/darkmode-js.min.js"></script>

<script>
var options = {
  bottom: '50%',
  right: '32px',
  left: 'unset',
  time: '0.5s',
  mixColor: '#fff',
  backgroundColor: '#fff',
  buttonColorDark: '#100f2c',
  buttonColorLight: '#fff',
  saveInCookies: true,
  label: '明暗',
  autoMatchOsTheme: true
}
const darkmode = new Darkmode(options);
window.darkmode = darkmode;
darkmode.showWidget();
</script>

</body>
</html>
