<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>CAMP</title>
    <url>/undefined/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/2024/10/31/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/CAMP/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h1 id="Greedy-Dual-Size-GDS-algorithm"><a href="#Greedy-Dual-Size-GDS-algorithm" class="headerlink" title="Greedy Dual Size (GDS) algorithm"></a>Greedy Dual Size (GDS) algorithm</h1><p>Key Concepts:</p>
<ol>
<li><strong>Variable Size and Cost</strong>:<ul>
<li>Unlike simple algorithms that treat all objects equally, GDS takes into account:<ul>
<li><strong>Size of the object</strong> (<code>size(p)</code>): Larger objects take up more space in memory.</li>
<li><strong>Cost of the object</strong> (<code>cost(p)</code>): This can represent factors like time to retrieve the object, computational effort, or other resource usage.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Score H(p)</strong>:<ul>
<li>Each key-value pair ppp in the cache is assigned a score H(p). This score reflects the <strong>benefit of keeping the object</strong> in memory and is calculated using:<ul>
<li>A <strong>global parameter L</strong>, which adjusts dynamically based on cache state.</li>
<li>The <strong>size(p)</strong> of the object.</li>
<li>The <strong>cost(p)</strong> associated with the object.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Eviction Strategy</strong>:<ul>
<li>When the cache is full, and a new object needs to be added, GDS removes the object with the <strong>lowest score H(p)</strong>. This process continues until there is enough space for the new object.</li>
</ul>
</li>
</ol>
<h2 id="Proposition-1"><a href="#Proposition-1" class="headerlink" title="Proposition 1"></a>Proposition 1</h2><p><strong>L is non-decreasing over time.</strong></p>
<ul>
<li>The global parameter L, which reflects the minimum priority H(p) among all key-value pairs in the KVS, will either stay the same or increase with each operation. This ensures stability and helps prioritize eviction decisions consistently.</li>
</ul>
<p>For any key-value pair ppp in the KVS, the relationship holds:</p>
<p><strong>L ≤ H(p) ≤ L + cost(p) &#x2F; size(p)</strong></p>
<ul>
<li>H(p), the priority of p, always lies between the global minimum L and L + cost(p) &#x2F; size(p), ensuring H(p) reflects both its retrieval cost and size relative to other elements.</li>
</ul>
<p><strong>Intuition Behind Proposition 1:</strong></p>
<ul>
<li>As L increases over time (reflecting the minimum H(p)), less recently used or less “valuable” pairs become increasingly likely to be evicted. This ensures that newer and higher-priority pairs stay in the KVS longer.</li>
</ul>
<p><strong>Key Insights from Proposition 1:</strong></p>
<ol>
<li><strong>Delayed Eviction:</strong><ul>
<li>When p is requested again while in memory, its H(p) increases to L + cost(p) &#x2F; size(p), delaying its eviction.</li>
</ul>
</li>
<li><strong>Impact of Cost-to-Size Ratio:</strong><ul>
<li>Pairs with higher cost(p) &#x2F; size(p) stay longer in the KVS. For example, if one pair’s ratio is c times another’s, it will stay approximately c times longer.</li>
</ul>
</li>
</ol>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/chart3.png" alt="img"></p>
<h2 id="Key-Points-in-the-Diagram"><a href="#Key-Points-in-the-Diagram" class="headerlink" title="Key Points in the Diagram"></a>Key Points in the Diagram</h2><ol>
<li><strong>Cost-to-Size Ratios</strong>:<ol>
<li>Key-value pairs are grouped into <strong>queues</strong> according to their cost-to-size ratio.</li>
<li>Each queue corresponds to a specific cost-to-size ratio.</li>
</ol>
</li>
<li><strong>Grouping by Ratio</strong>:<ol>
<li>Within each queue, key-value pairs are managed using the <strong>Least Recently Used (LRU)</strong> strategy.</li>
</ol>
</li>
<li><strong>Priority Management</strong>:<ol>
<li>The <strong>priority (H-value)</strong> of a key-value pair is based on: <strong>H(p) &#x3D; L + cost(p) &#x2F; size(p)</strong><ol>
<li>L: The global non-decreasing variable.</li>
<li>cost(p) &#x2F; size(p): The cost-to-size ratio of the key-value pair.</li>
</ol>
</li>
</ol>
</li>
<li><strong>Efficient Eviction</strong>:<ol>
<li>CAMP maintains a <strong>heap</strong> that points to the <strong>head of each queue</strong>, storing the minimum H(p) from every queue.</li>
<li>To identify the next key-value pair for eviction:<ol>
<li><strong>The algorithm checks the heap to find the queue with the smallest H(p).</strong></li>
<li><strong>It then evicts the key-value pair at the front of that queue (i.e., the least recently used pair in that cost-to-size group).</strong></li>
</ol>
</li>
</ol>
</li>
</ol>
<h2 id="Rounding-in-CAMP"><a href="#Rounding-in-CAMP" class="headerlink" title="Rounding in CAMP"></a>Rounding in CAMP</h2><p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/bg_bm_rounding.png" alt="img"></p>
<ol>
<li><strong>Purpose</strong>: To improve performance, CAMP <strong>reduces the number of LRU queues</strong> by grouping key-value pairs with <strong>similar cost-to-size ratios</strong> into the same queue.</li>
<li><strong>Key Idea</strong>: Preserve the most significant bits proportional to the value’s size.</li>
</ol>
<h2 id="Proposition-2-Explanation-of-Rounding-and-Distinct-Values"><a href="#Proposition-2-Explanation-of-Rounding-and-Distinct-Values" class="headerlink" title="Proposition 2: Explanation of Rounding and Distinct Values"></a>Proposition 2: Explanation of Rounding and Distinct Values</h2><h3 id="Implications"><a href="#Implications" class="headerlink" title="Implications"></a>Implications</h3><ol>
<li><p><strong>Trade-Off Between Precision and Efficiency</strong>:</p>
<ul>
<li><p>A higher p preserves more precision but increases the number of distinct values (and thus computational complexity).</p>
</li>
<li><p>Lower p reduces the number of distinct values, making CAMP more efficient but less precise.</p>
</li>
</ul>
</li>
<li><p><strong>Rounding Efficiency</strong>:</p>
<ul>
<li>By limiting the number of distinct values, CAMP minimizes the number of LRU queues, reducing overhead while still approximating GDS closely.</li>
</ul>
</li>
</ol>
<h2 id="Proposition-3-Competitive-Ratio-of-CAMP"><a href="#Proposition-3-Competitive-Ratio-of-CAMP" class="headerlink" title="Proposition 3: Competitive Ratio of CAMP"></a>Proposition 3: Competitive Ratio of CAMP</h2><h3 id="Practical-Implications"><a href="#Practical-Implications" class="headerlink" title="Practical Implications"></a>Practical Implications</h3><ol>
<li><p><strong>Precision ppp</strong>:</p>
<ul>
<li><p>The smaller the ϵ (higher ppp), the closer CAMP approximates GDS.</p>
</li>
<li><p>For sufficiently large p, CAMP performs nearly as well as GDS.</p>
</li>
</ul>
</li>
<li><p><strong>Trade-off</strong>:</p>
<ul>
<li>Higher p increases precision but also increases the number of distinct cost-to-size ratios and computational overhead.</li>
</ul>
</li>
</ol>
<h3 id="CAMP’s-Improvement-Over-GDS"><a href="#CAMP’s-Improvement-Over-GDS" class="headerlink" title="CAMP’s Improvement Over GDS:"></a>CAMP’s Improvement Over GDS:</h3><ol>
<li><strong>Approximation:</strong> CAMP simplifies H(p) by <strong>rounding</strong> the cost-to-size ratio, reducing the precision but making the algorithm more efficient.</li>
<li><strong>Grouping:</strong> Key-value pairs are <strong>grouped</strong> by similar cost-to-size ratios, reducing the number of queues and simplifying priority management.</li>
<li><strong>Tie-Breaking:</strong> CAMP uses <strong>LRU within each group</strong> to determine the eviction order, making it computationally cheaper.</li>
</ol>
<h3 id="Figure-4-Heap-Node-Visits"><a href="#Figure-4-Heap-Node-Visits" class="headerlink" title="Figure 4: Heap Node Visits"></a>Figure 4: Heap Node Visits</h3><p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/chart4.png" alt="img"></p>
<p>This figure compares the number of heap node visits for GDS and CAMP as a function of cache size:</p>
<ol>
<li><p><strong>GDS</strong>:</p>
<ul>
<li><p><strong>Heap size equals the total number of key-value pairs in the cache.</strong></p>
</li>
<li><p>Every heap update (insertion, deletion, or priority change) requires visiting O(log⁡n) nodes, where n is the number of cache entries.</p>
</li>
<li><p>As cache size increases, GDS’s overhead grows significantly.</p>
</li>
</ul>
</li>
<li><p><strong>CAMP</strong>:</p>
<ul>
<li><p><strong>Heap size equals the number of non-empty LRU queues, which is much smaller than the total number of cache entries.</strong></p>
</li>
<li><p>Heap updates occur only when:</p>
<ul>
<li><p>The priority of the head of an LRU queue changes.</p>
</li>
<li><p>A new LRU queue is created.</p>
</li>
</ul>
</li>
<li><p>As cache size increases, the number of non-empty LRU queues remains relatively constant, resulting in fewer heap updates.</p>
</li>
</ul>
</li>
</ol>
<h1 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h1><p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/chart5.png" alt="img"></p>
<p><strong>(a) Cost-Miss Ratio vs Precision</strong></p>
<ul>
<li><strong>横轴</strong>：精度（Precision），从低到高。</li>
<li><strong>纵轴</strong>：成本未命中比（Cost-Miss Ratio）。</li>
<li><strong>结果</strong>：<ul>
<li>不同的缓存大小比（0.01、0.1 和 0.3）在较低精度下表现一致。</li>
<li>提高精度后，成本未命中比没有显著变化。</li>
<li>说明即使使用较低精度，CAMP 的成本未命中比也能接近 GDS（标准实现）。</li>
</ul>
</li>
</ul>
<p><strong>(b) LRU Queues vs Precision</strong></p>
<ul>
<li><strong>横轴</strong>：精度（Precision）。</li>
<li><strong>纵轴</strong>：CAMP 维护的非空 LRU 队列数量。</li>
<li><strong>结果</strong>：<ul>
<li><strong>低精度</strong>（1-5）：CAMP 维持稳定的少量 LRU 队列（约 5 个）。</li>
<li><strong>高精度</strong>（&gt;10）：队列数增加，尤其是在较大的缓存大小比（如 1.0）下。</li>
<li><strong>结论</strong>：<ul>
<li>在较低精度下，CAMP 能保持较低的计算开销，同时维持高效的队列管理。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>(c) Cost-Miss Ratio vs Cache Size Ratio</strong></p>
<ul>
<li><strong>横轴</strong>：缓存大小比（Cache Size Ratio），即缓存大小与 trace 文件中唯一键值对总大小的比值。</li>
<li><strong>纵轴</strong>：成本未命中比（Cost-Miss Ratio）。</li>
<li><strong>结果</strong>：<ul>
<li><strong>CAMP</strong>：<ul>
<li>在所有缓存大小下，成本未命中比最低。</li>
<li>说明 CAMP 在高成本键值对管理上更具效率。</li>
</ul>
</li>
<li><strong>Pooled LRU</strong>：<ul>
<li>在较小缓存下表现稍差，但随着缓存增加，接近 CAMP。</li>
</ul>
</li>
<li><strong>LRU</strong>：<ul>
<li>成本未命中比始终最高。</li>
</ul>
</li>
<li><strong>结论</strong>：<ul>
<li>CAMP 优于 LRU 和 Pooled LRU，尤其是在小缓存下。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>(d) Miss Rate vs Cache Size Ratio</strong></p>
<ul>
<li><strong>横轴</strong>：缓存大小比（Cache Size Ratio）。</li>
<li><strong>纵轴</strong>：未命中率（Miss Rate）。</li>
<li><strong>结果</strong>：<ul>
<li><strong>CAMP</strong>：<ul>
<li>未命中率显著低于 LRU 和 Pooled LRU，尤其在小缓存下表现最优。</li>
</ul>
</li>
<li><strong>Pooled LRU</strong>：<ul>
<li>未命中率随着缓存增大而下降，但始终高于 CAMP。</li>
<li>最低成本池（cheapest pool）未命中率接近 100%，次低成本池未命中率达到 65%。</li>
</ul>
</li>
<li><strong>LRU</strong>：<ul>
<li>始终高于 CAMP 和 Pooled LRU。</li>
</ul>
</li>
<li><strong>结论</strong>：<ul>
<li>CAMP 在多种缓存大小下都保持较低的未命中率，且比 Pooled LRU 更均衡。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="CAMP-的适应能力：访问模式变化的分析"><a href="#CAMP-的适应能力：访问模式变化的分析" class="headerlink" title="CAMP 的适应能力：访问模式变化的分析"></a>CAMP 的适应能力：访问模式变化的分析</h1><p>实验设置：</p>
<ul>
<li>使用 10 个不同的 trace 文件，每个文件包含 400 万个键值对引用。</li>
<li>每个 trace 文件（如 TF1、TF2 等）中的请求在其结束后不会再被引用，模拟访问模式的突然变化。</li>
<li>访问模式具有倾斜分布（如 Zipf 分布），每个 trace 文件中的高成本对象可能在下一次访问中完全无效。</li>
</ul>
<p>目标：</p>
<ul>
<li>比较 <strong>CAMP</strong>、<strong>Pooled LRU</strong> 和 <strong>LRU</strong> 在不同缓存大小下对访问模式突变的适应能力。</li>
<li>评估三种算法在突然变化后清除旧的高成本键值对的效率，以及对总体性能（如成本未命中比和未命中率）的影响。</li>
</ul>
<p>不同算法的行为分析</p>
<ol>
<li><p><strong>LRU</strong>：</p>
<ul>
<li><p>按最近使用排序，当新请求的总大小超过缓存大小时清除旧数据。</p>
</li>
<li><p>当缓存大小比为 1 时，清除 TF1 数据的时间点对应于 TF3 开始请求的第一个键值对。</p>
</li>
</ul>
</li>
<li><p><strong>Pooled LRU</strong>：</p>
<ul>
<li><p>将键值对按成本分组，每组分配固定比例的缓存空间。</p>
</li>
<li><p>高成本池占据 99% 的缓存空间，因此在每个新 trace 开始时会突然清除一批旧数据。</p>
</li>
<li><p>对于缓存大小比 2&#x2F;3 或更高的情况，直到 TF4（约 800 万请求后）才会清除所有 TF1 数据。</p>
</li>
</ul>
</li>
<li><p><strong>CAMP</strong>：</p>
<ul>
<li><p>对每个成本-大小比维护 LRU 队列，这些队列的大小可以动态调整。</p>
</li>
<li><p><strong>优先淘汰较低优先级的数据，但高成本数据即使来自旧 trace，也具有一定保留优先级。</strong></p>
</li>
<li><p><strong>当新数据的总大小超过缓存时，旧 trace 的高成本数据才会被逐步清除。</strong></p>
</li>
</ul>
</li>
</ol>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/chart6.png" alt="img"></p>
<p><strong>图 6c：缓存比 0.25（小缓存）</strong></p>
<ol>
<li><p><strong>LRU</strong>：</p>
<ul>
<li><p>清除最快，仅需 <strong>2.1 万次请求</strong> 即完全清除 Trace 1 的所有键值对。</p>
</li>
<li><p>由于 LRU 优先淘汰最久未使用的数据，小缓存下表现最佳。</p>
</li>
</ul>
</li>
<li><p><strong>Pooled LRU</strong>：</p>
<ul>
<li><p>清除速度较慢，需要 <strong>13.1 万次请求</strong>。</p>
</li>
<li><p>原因：Pooled LRU 按成本对键值对分组，高成本池占用较多缓存空间，导致清除滞后。</p>
</li>
</ul>
</li>
<li><p><strong>CAMP</strong>：</p>
<ul>
<li><p>初期清除速度比 Pooled LRU 更快，但最后完全清除所有键值对需到 <strong>TF3 结束（770 万次请求）</strong>。</p>
</li>
<li><p>然而，这些未被清除的 Trace 1 数据仅占缓存的 <strong>2%</strong>，说明 CAMP 优先保留了高成本键值对。</p>
</li>
</ul>
</li>
</ol>
<p><strong>图 6d：缓存比 0.75（大缓存）</strong></p>
<ol>
<li><p><strong>LRU</strong>：</p>
<ul>
<li><p>同样清除最快，几乎在 Trace 2 开始时就清除掉大部分 Trace 1 的数据。</p>
</li>
<li><p>说明即使缓存较大，LRU 仍然倾向淘汰旧数据。</p>
</li>
</ul>
</li>
<li><p><strong>Pooled LRU</strong>：</p>
<ul>
<li><p>清除延迟显著，需要 <strong>730 万次请求</strong>，接近 TF3 结束。</p>
</li>
<li><p>原因：高成本池占用过多缓存空间，延迟清除低成本和无用数据。</p>
</li>
</ul>
</li>
<li><p><strong>CAMP</strong>：</p>
<ul>
<li><p>大部分 Trace 1 数据在较早阶段被淘汰，仅保留少量最昂贵的键值对（占缓存比小于 <strong>0.6%</strong>）。</p>
</li>
<li><p>即使在 <strong>4000 万次请求</strong>后，这些高成本键值对仍在缓存中，但对整体缓存利用影响极小。</p>
</li>
</ul>
</li>
</ol>
<p>针对不同大小但成本相同的键值对，CAMP 优先保留较小的键值对，从而降低未命中率和成本未命中比。</p>
<p>针对相同大小但成本不同的键值对，CAMP 优先保留高成本键值对，在成本未命中比上显著优于其他算法。</p>
<p>与其他算法的对比：</p>
<ul>
<li><p>LRU：适用于简单场景，但无法处理成本差异。</p>
</li>
<li><p>Pooled LRU：小缓存情况下表现不错，但静态分区策略限制了其大缓存场景的效率。</p>
</li>
</ul>
<p>CAMP 的适应性：在处理多样化的成本分布时，通过动态调整和四舍五入策略，CAMP 在复杂负载下表现出更高的灵活性和效率。</p>
<h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h1><p><strong>What is the time complexity of LRU to select a victim?</strong></p>
<p><strong>O(1)</strong> because the least recently used item is always at the tail of the list.</p>
<p><strong>What is the time complexity of CAMP to select a victim?</strong></p>
<p><strong>O(logk)</strong> CAMP identifies the key-value pair with the smallest priority from the heap, deletes it and then <strong>heapifies</strong>.</p>
<p><strong>Why does CAMP do rounding using the high order bits?</strong></p>
<ul>
<li>CAMP rounds cost-to-size ratios to <strong>reduce the number of distinct ratios (or LRU queues)</strong>.</li>
<li>High-order bits are retained because they represent the <strong>most significant portion of the value</strong>, ensuring that <strong>approximate prioritization is maintained</strong>.</li>
</ul>
<p><strong>How does BG generate social networking actions that are always valid?</strong></p>
<p><strong>Pre-Validation of Actions:</strong></p>
<ul>
<li>Before generating an action, BG <strong>checks</strong> the current state of the database to ensure the action is valid. For instance:<ul>
<li>A friend request is only generated if the two users are not already friends or in a “pending” relationship.</li>
<li>A comment can only be posted on a resource if the resource exists.</li>
</ul>
</li>
</ul>
<p><strong>Avoiding Concurrent Modifications:</strong></p>
<ul>
<li>BG <strong>prevents multiple threads from concurrently modifying the same user’s state</strong>.</li>
</ul>
<p><strong>How does BG scale to a large number of nodes?</strong></p>
<p>BG employs <strong>a shared-nothing architecture</strong> with the following mechanisms to scale effectively:</p>
<ol>
<li><p><strong>Partitioning Members and Resources:</strong></p>
<ul>
<li><p>BGCoord <strong>partitions</strong> the database into <strong>logical fragments</strong>, each containing <strong>a unique subset</strong> of members, their resources, and relationships.</p>
</li>
<li><p>These fragments are assigned to individual BGClients.</p>
</li>
</ul>
</li>
<li><p><strong>Multiple BGClients:</strong></p>
<ul>
<li><p>Each BGClient operates <strong>independently</strong>, generating workloads for its assigned logical fragment.</p>
</li>
<li><p>By running <strong>multiple</strong> BGClients <strong>in parallel</strong> across different nodes, BG can scale horizontally to handle millions of requests.</p>
</li>
</ul>
</li>
<li><p><strong>D-Zipfian Distribution:</strong></p>
<ul>
<li><p>To ensure realistic and scalable workloads, BG uses a decentralized Zipfian distribution (D-Zipfian) that <strong>dynamically assigns</strong> requests to BGClients based on node performance.</p>
</li>
<li><p>Faster nodes receive a larger share of the logical fragments, ensuring even workload distribution.</p>
</li>
</ul>
</li>
<li><p><strong>Concurrency Control:</strong></p>
<ul>
<li>BG <strong>prevents simultaneous threads from issuing actions for the same user</strong>, maintaining the integrity of modeled user interactions and avoiding resource contention.</li>
</ul>
</li>
</ol>
<p><strong>True or False: BG quantifies the amount of unpredictable data produced by a data store?</strong></p>
<p>True.</p>
<p>This is achieved through:</p>
<ul>
<li><strong>Validation Phase:</strong><ul>
<li>BG uses <strong>read and write log records</strong> to detect instances where a read operation observes a value <strong>outside the acceptable range</strong>, classifying it as “unpredictable data.”</li>
</ul>
</li>
<li><strong>Metrics Collection:</strong><ul>
<li>The percentage of requests that observe unpredictable data (τ) is a key metric used to evaluate the data store’s consistency.</li>
</ul>
</li>
</ul>
<p><strong>How is BG’s SoAR different than its Socialites rating?</strong></p>
<p>SoAR (Social Action Rating): Represents the <strong>maximum throughput</strong> (actions per second) a data store can achieve while meeting a given SLA.</p>
<p>Socialites Rating: Represents the <strong>maximum number of concurrent threads</strong> <strong>(users)</strong> a data store can support while meeting the SLA.</p>
<p>Reference: <a href="https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=d6f9678772a09ca29101f5efce583960ecf53745">https://citeseerx.ist.psu.edu/document?repid=rep1&amp;type=pdf&amp;doi=d6f9678772a09ca29101f5efce583960ecf53745</a></p>
]]></content>
      <categories>
        <category>数据库系统</category>
      </categories>
  </entry>
  <entry>
    <title>BG Benchmark</title>
    <url>/undefined/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/2024/10/24/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/BG%20Benchmark/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h1 id="Data-Model-and-Performance-Metrics"><a href="#Data-Model-and-Performance-Metrics" class="headerlink" title="Data Model and Performance Metrics"></a>Data Model and Performance Metrics</h1><ol>
<li>ER Diagram and Database Design</li>
</ol>
<ul>
<li>ER Diagram (Figure 1.a):Represents entities and relationships in the BG system.<ul>
<li>Member Entity:<ul>
<li>Represents users with a registered profile, including a unique ID and a set of adjustable-length string attributes to create records of varying sizes.</li>
<li>Each user can have up to two images:<ul>
<li>Thumbnail Image: Small (in KBs), used for displaying in friend lists.</li>
<li>High-Resolution Image: Larger (hundreds of KBs or MBs), displayed when visiting a user profile.</li>
<li>Using thumbnails significantly reduces system load compared to larger images.</li>
</ul>
</li>
</ul>
</li>
<li>Friend Relationship:<ul>
<li>Captures relationships or friend requests between users. An attribute differentiates between invitations and confirmed friendships.</li>
</ul>
</li>
<li>Resource Entity:<ul>
<li>Represents user-owned items like images, questions, or documents. Resources must belong to a user and can be posted on their profile or another user’s profile.</li>
</ul>
</li>
<li>Manipulation Relationship:<ul>
<li>Manages comments and restrictions (e.g., only friends can comment on a resource).</li>
</ul>
</li>
</ul>
</li>
</ul>
<ol start="2">
<li>BG Workload and SLA (Service-Level Agreement)</li>
</ol>
<ul>
<li><p>Workload: BG supports defining workloads at the granularity of:</p>
<ul>
<li>Actions: Single operations like “view profile” or “list friends.”</li>
<li>Sessions: A sequence of related actions (e.g., browsing a profile, sending a friend request).</li>
<li>Mixed Workloads: A combination of actions and sessions.</li>
</ul>
</li>
<li><p>Service-Level Agreement (SLA):</p>
<ul>
<li>Goal: Ensures the system provides reliable performance under specified conditions.</li>
<li>Example SLA Requirements: SLA, e.g., 95% of requests to observe a response time equal to or faster than 100 msec with at most 0.1% of requests observing unpredictable data for 10 minutes.</li>
</ul>
</li>
<li><p>Metrics:</p>
<ul>
<li><strong>SoAR (Social Action Rating): Measures the highest number of actions per second that meet the SLA.</strong></li>
<li><strong>Socialites: Measures the maximum number of concurrent threads that meet the SLA, reflecting the system’s multithreading capabilities.</strong></li>
</ul>
</li>
</ul>
<ol start="3">
<li>Performance Evaluation Example</li>
</ol>
<ul>
<li>SQL-X System Performance:SQL-X is a relational database with strict ACID compliance.<ul>
<li>Initially, throughput increases with more threads.</li>
<li>Beyond a certain threshold (e.g., 4 threads), request queuing causes response times to increase, reducing SLA compliance.</li>
<li>With 32 threads, 99.94% of requests exceed the 100-millisecond SLA limit, indicating significant performance degradation.</li>
</ul>
</li>
</ul>
<ol start="4">
<li>Concurrency and Optimization in BG</li>
</ol>
<ul>
<li><p><strong>Concurrency Management:</strong></p>
<ul>
<li><strong>BG prevents two threads from emulating the same user simultaneously to realistically simulate user behavior.</strong></li>
</ul>
</li>
<li><p><strong>Unpredictable Data Handling:</strong></p>
<ul>
<li><strong>Definition: Data that is stale, inconsistent, or invalid due to system limitations or race conditions.</strong></li>
<li><strong>Validation:</strong><ul>
<li><strong>BG uses offline validation to analyze read and write logs.</strong></li>
<li><strong>It determines acceptable value ranges for data and flags any reads that fall outside these ranges as unpredictable.</strong></li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>If SoAR is zero, the data store fails to meet SLA requirements, even with a single-threaded BGClient issuing requests.</p>
</blockquote>
<h1 id="Actions"><a href="#Actions" class="headerlink" title="Actions"></a>Actions</h1><h2 id="Performance-Analysis-of-View-Profile"><a href="#Performance-Analysis-of-View-Profile" class="headerlink" title="Performance Analysis of View Profile"></a>Performance Analysis of View Profile</h2><p>Performance of VP is influenced by whether profile images are included and their sizes.</p>
<p><strong>Experiment Setup</strong>:</p>
<ul>
<li>Profile data tested with:</li>
<li><ul>
<li><strong>No images</strong>.</li>
<li><strong>2 KB thumbnails</strong> combined with profile images of <strong>2 KB, 12 KB, and 500 KB</strong> sizes.</li>
</ul>
</li>
<li>Metrics: SoAR (Social Action Rating) measures the number of VP actions per second that meet the SLA (response time ≤ 100 ms).</li>
</ul>
<p><strong>Results</strong>:</p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/experiment1.png" alt="img"></p>
<ol>
<li><p><strong>No Images</strong>:</p>
<ul>
<li>MongoDB performed the best, outperforming SQL-X and CASQL by almost 2x.</li>
</ul>
</li>
<li><p><strong>12 KB Images</strong>:</p>
<ul>
<li>SQL-X’s SoAR dropped significantly, from thousands of actions per second to only hundreds.</li>
</ul>
</li>
<li><p><strong>500 KB Images</strong>:</p>
<ul>
<li><p><strong>SQL-X failed to meet the SLA (SoAR &#x3D; 0) because transmitting large images caused significant delays.</strong></p>
</li>
<li><p>MongoDB and CASQL also experienced a decrease in SoAR but performed better than SQL-X.</p>
</li>
</ul>
</li>
</ol>
<p><strong>Role of CASQL</strong>:</p>
<ul>
<li><p><strong>CASQL outperformed SQL-X due to its caching layer (memcached):</strong></p>
<ul>
<li><p>During a warm-up phase, 500,000 requests populate the cache with key-value pairs for member profiles.</p>
</li>
<li><p>Most requests are serviced by memcached instead of SQL-X, significantly improving performance with larger images (12 KB and 500 KB).</p>
</li>
</ul>
</li>
</ul>
<h2 id="Performance-Analysis-of-List-Friends"><a href="#Performance-Analysis-of-List-Friends" class="headerlink" title="Performance Analysis of List Friends"></a><strong>Performance Analysis of List Friends</strong></h2><p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/experiment2.png" alt="img"></p>
<p><strong>1. SQL-X</strong></p>
<ul>
<li><strong>Process</strong>:<ul>
<li>Joins the <code>Friends</code> table with the <code>Members</code> table to fetch the friend list.</li>
<li>Friendship between two members is represented as a single record in the <code>Friends</code> table.</li>
</ul>
</li>
<li><strong>Performance</strong>:<ul>
<li><strong>When ϕ (number of friends) is 1000, SQL-X struggles due to the overhead of joining large tables and fails to meet SLA requirements.</strong></li>
</ul>
</li>
</ul>
<p><strong>2. CASQL</strong></p>
<ul>
<li><strong>Process</strong>:<ul>
<li>Uses a memcached caching layer to store and retrieve results of the LF action.</li>
<li>Results are cached as key-value pairs.</li>
</ul>
</li>
<li><strong>Performance</strong>:<ul>
<li>Outperforms SQL-X when ϕ is 50 or 100 by a small margin (&lt;10% improvement).</li>
<li><strong>At ϕ&#x3D;1000, memcached’s key-value size limit (1 MB) causes failures, as the data exceeds this limit.</strong></li>
<li>Adjusting memcached to support larger key-value pairs (e.g., 2 MB for 1000 friends with 2 KB thumbnails) could improve performance.</li>
</ul>
</li>
</ul>
<p><strong>3. MongoDB</strong></p>
<ul>
<li><strong>Process</strong>:<ul>
<li>Retrieves the <code>confirmedFriends</code> array from the referenced member’s document.</li>
<li>Can fetch friends’ profile documents one by one or as a batch.</li>
</ul>
</li>
<li><strong>Performance</strong>:<ul>
<li>Performs no joins, but its SLA compliance is poor for larger friend counts.</li>
<li>SoAR is zero for ϕ&#x3D;50,100,1000, as it fails to meet the 100 ms response time requirement.</li>
<li>For smaller friend lists (ϕ&#x3D;10), MongoDB achieves a SoAR of 6 actions per second.</li>
</ul>
</li>
</ul>
<h2 id="Mix-of-Read-and-Write-Actions"><a href="#Mix-of-Read-and-Write-Actions" class="headerlink" title="Mix of Read and Write Actions"></a><strong>Mix of Read and Write Actions</strong></h2><ul>
<li><strong>Purpose</strong>: Evaluates the performance of data stores under different ratios of read and write operations.</li>
<li><strong>Categories</strong>:<ul>
<li><strong>Read actions</strong>: Include operations like View Profile (VP), List Friends (LF), and View Friend Requests (VFR).</li>
<li><strong>Write actions</strong>: Modify friendship relationships and invalidate cached key-value pairs (e.g., Invite Friend, Accept Friend Request).</li>
</ul>
</li>
<li><strong>Mix Variations</strong>:<ul>
<li><strong>Very low writes (0.1%)</strong>: Dominantly read-heavy workloads.</li>
<li><strong>Low writes (1%)</strong>: Slightly higher frequency of write actions.</li>
<li><strong>High writes (10%)</strong>: Write-intensive workloads.</li>
</ul>
</li>
</ul>
<p><strong>Performance Analysis (Mix of Read and Write Actions)</strong></p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/experiment3.png" alt="img"></p>
<ul>
<li><strong>SoAR Comparison</strong>:<ul>
<li><strong>CASQL</strong> consistently achieves the highest SoAR for all write mixes due to its caching mechanism.</li>
<li><strong>MongoDB</strong> outperforms <strong>SQL-X</strong> by a factor of 3 across all workloads.</li>
</ul>
</li>
</ul>
<p><strong>Observations by Write Percentage:</strong></p>
<ol>
<li><p><strong>0.1% Writes (Read-Dominant)</strong>:</p>
<ul>
<li><p>CASQL significantly outperforms MongoDB due to efficient use of cached key-value pairs.</p>
</li>
<li><p>SQL-X lags due to the overhead of processing read actions directly from the RDBMS.</p>
</li>
</ul>
</li>
<li><p><strong>1% Writes</strong>:</p>
<ul>
<li><p>CASQL remains the best performer but shows sensitivity to increasing writes as it invalidates cached data, redirecting more queries to the RDBMS.</p>
</li>
<li><p>MongoDB maintains a consistent performance advantage over SQL-X.</p>
</li>
</ul>
</li>
<li><p><strong>10% Writes (Write-Heavy)</strong>:</p>
<ul>
<li><p><strong>CASQL slightly outperforms MongoDB, but the gap narrows due to the higher frequency of cache invalidations.</strong></p>
</li>
<li><p>SQL-X continues to struggle with write-heavy workloads due to its lack of caching.</p>
</li>
</ul>
</li>
</ol>
<h1 id="Session"><a href="#Session" class="headerlink" title="Session"></a>Session</h1><blockquote>
<p>Definition: A session is a sequence of actions performed by a socialite (user) in the social network.</p>
<p>Key Concepts:</p>
<ol>
<li>Think Time: Delay between consecutive actions within a session.</li>
<li>Inter-Arrival Time: Delay between sessions initiated by different socialites.</li>
</ol>
</blockquote>
<p><strong>Key Considerations</strong></p>
<ol>
<li><p><strong>Dependencies</strong>:</p>
<ul>
<li><p>Some sessions rely on specific database states (e.g., friends or pending requests).</p>
</li>
<li><p>For example, if m_i has no friends or pending requests, certain sessions terminate early.</p>
</li>
</ul>
</li>
<li><p><strong>Concurrency Handling</strong>:</p>
<ul>
<li><p>BG uses in-memory data structures to simulate database states and prevent conflicts (e.g., multiple threads deleting the same comment).</p>
</li>
<li><p>Ensures integrity by managing semaphores and detecting unpredictable data.</p>
</li>
</ul>
</li>
<li><p><strong>Extensibility</strong>:</p>
<ul>
<li>BG allows developers to define new sessions by combining different mixes of actions.</li>
</ul>
</li>
</ol>
<h1 id="Parallelism"><a href="#Parallelism" class="headerlink" title="Parallelism"></a>Parallelism</h1><h2 id="BG’s-Scalable-Benchmarking-Framework"><a href="#BG’s-Scalable-Benchmarking-Framework" class="headerlink" title="BG’s Scalable Benchmarking Framework"></a>BG’s Scalable Benchmarking Framework</h2><p>To address these limitations, BG employs <strong>a shared-nothing architecture</strong> with the following components:</p>
<p><strong>1. BGCoord (Coordinator)</strong></p>
<ul>
<li><strong>Role</strong>: Oversees and coordinates the benchmarking process.</li>
<li><strong>Responsibilities</strong>:<ul>
<li><strong>Computes SoAR and Socialites ratings.</strong></li>
<li><strong>Assigns workloads to BGClients and monitors their progress.</strong></li>
<li><strong>Aggregates results (e.g., response times, throughput) for visualization.</strong></li>
</ul>
</li>
<li><strong>Process</strong>:<ul>
<li><strong>Splits the workload among N BGClients.</strong></li>
<li><strong>Ensures each BGClient works independently to prevent resource contention.</strong></li>
</ul>
</li>
</ul>
<p><strong>2. BGClient</strong></p>
<ul>
<li><strong>Role</strong>: Executes tasks assigned by BGCoord.</li>
<li><strong>Responsibilities</strong>:<ul>
<li><strong>Creates a database based on BG specifications.</strong></li>
<li><strong>Simulates workload actions and computes metrics like unpredictable data volume.</strong></li>
<li><strong>Periodically reports metrics to BGCoord for aggregation.</strong></li>
</ul>
</li>
</ul>
<p><strong>3. Visualization Deck</strong></p>
<ul>
<li><strong>Role</strong>: Provides a user interface for monitoring and controlling the benchmarking process.</li>
<li><strong>Features</strong>:<ul>
<li>Allows users to configure parameters (e.g., SLA, workloads).</li>
<li>Visualizes the ratings (SoAR, Socialites) and progress of the benchmarking.</li>
</ul>
</li>
</ul>
<p><strong>Scaling with BGClients</strong></p>
<ul>
<li><strong>Fragmentation</strong>:<ul>
<li><strong>The database is split into N logical fragments, each assigned to a BGClient.</strong></li>
<li><strong>Each fragment includes unique members, friendships, and resources, ensuring no overlap between BGClients.</strong></li>
</ul>
</li>
<li><strong>Decentralized D-Zipfian Distribution</strong>:<ul>
<li><strong>Used to balance workloads across nodes with different processing speeds.</strong></li>
<li><strong>Faster nodes handle larger fragments, ensuring equal workload completion times.</strong></li>
</ul>
</li>
</ul>
<h1 id="Unpredictable-Data"><a href="#Unpredictable-Data" class="headerlink" title="Unpredictable Data"></a>Unpredictable Data</h1><p><strong>Definition</strong>: <strong>Data that is stale, inconsistent, or invalid, produced due to race conditions, dirty reads, or eventual consistency.</strong></p>
<h2 id="BG’s-Validation-Process"><a href="#BG’s-Validation-Process" class="headerlink" title="BG’s Validation Process"></a>BG’s Validation Process</h2><p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/chart1.png" alt="img"></p>
<h2 id="Validation-Implementation"><a href="#Validation-Implementation" class="headerlink" title="Validation Implementation"></a>Validation Implementation</h2><ol>
<li><strong>Log Generation</strong>:<ul>
<li><strong>BG generates read log records (observed values) and write log records (new or delta values).</strong></li>
</ul>
</li>
<li><strong>Offline Validation</strong>:<ul>
<li><strong>For each read log entry:</strong><ul>
<li><strong>BG computes a range of valid values using overlapping write logs.</strong></li>
<li><strong>If the observed value is outside this range, it is flagged as unpredictable.</strong></li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 id="Impact-of-Time-to-Live-TTL-on-Unpredictable-Data"><a href="#Impact-of-Time-to-Live-TTL-on-Unpredictable-Data" class="headerlink" title="Impact of Time-to-Live (TTL) on Unpredictable Data"></a>Impact of Time-to-Live (TTL) on Unpredictable Data</h2><p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/chart2.png" alt="img"></p>
<p><strong>Results</strong>:</p>
<ol>
<li><p><strong>Higher TTL Increases Stale Data</strong>:</p>
<ul>
<li><p>A higher TTL (e.g., 120 seconds) results in more stale key-value pairs, increasing the percentage of unpredictable data.</p>
</li>
<li><p>For T&#x3D;100T &#x3D; 100T&#x3D;100, unpredictable data is:</p>
<ul>
<li>~79.8% with TTL &#x3D; 30 seconds.</li>
<li>~98.15% with TTL &#x3D; 120 seconds.</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Performance Trade-off</strong>:</p>
<ul>
<li><p><strong>A higher TTL improves performance (fewer cache invalidations) but increases stale data.</strong></p>
</li>
<li><p><strong>Lower TTL reduces stale data but impacts cache performance.</strong></p>
</li>
</ul>
</li>
</ol>
<h1 id="Heuristic-Search-for-Rating"><a href="#Heuristic-Search-for-Rating" class="headerlink" title="Heuristic Search for Rating"></a>Heuristic Search for Rating</h1><p><strong>Why Use Heuristic Search?</strong></p>
<ul>
<li>Exhaustive search starting from T&#x3D;1 to the maximum T is time-consuming.</li>
<li>MongoDB with T&#x3D;1000 and Δ&#x3D;10 minutes would take 7 days for exhaustive testing.</li>
</ul>
<p><strong>Steps in Heuristic Search</strong>:</p>
<ol>
<li><p><strong>Doubling Strategy</strong>:</p>
<ul>
<li><p><strong>Start with T&#x3D;1, double T after each successful experiment.</strong></p>
</li>
<li><p><strong>Stop when SLA fails, narrowing down T to an interval.</strong></p>
</li>
</ul>
</li>
<li><p><strong>Binary Search</strong>:</p>
<ul>
<li><p><strong>Identify the T corresponding to max throughput within the interval.</strong></p>
</li>
<li><p><strong>Used for both SoAR (peak throughput) and Socialites (maximum concurrent threads).</strong></p>
</li>
</ul>
</li>
</ol>
<h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h1><p><strong>What system metrics does BG quantify?</strong></p>
<p><strong>SoAR (Social Action Rating):</strong></p>
<ul>
<li>The highest throughput (actions per second) that satisfies a given SLA, ensuring at least α% of requests meet the response time β, with at most τ% of requests observing unpredictable data.</li>
</ul>
<p><strong>Socialites Rating:</strong></p>
<ul>
<li>The maximum number of simultaneous threads (or users) that a data store can support while still meeting the SLA requirements.</li>
</ul>
<p><strong>Throughput</strong>:</p>
<ul>
<li>Total number of completed actions per unit of time.</li>
</ul>
<p><strong>Response Time:</strong></p>
<ul>
<li>Average or percentile-based latency for each action.</li>
</ul>
<p><strong>Unpredictable Data:</strong></p>
<ul>
<li>The percentage of actions that observe stale, inconsistent, or invalid data during execution.</li>
</ul>
<p><strong>How does BG scale to generate a large number of requests?</strong></p>
<p>BG employs <strong>a shared-nothing architecture</strong> with the following mechanisms to scale effectively:</p>
<ol>
<li><p><strong>Partitioning Members and Resources:</strong></p>
<ul>
<li><p>BGCoord <strong>partitions</strong> the database into <strong>logical fragments</strong>, each containing <strong>a unique subset</strong> of members, their resources, and relationships.</p>
</li>
<li><p>These fragments are assigned to individual BGClients.</p>
</li>
</ul>
</li>
<li><p><strong>Multiple BGClients:</strong></p>
<ul>
<li><p>Each BGClient operates <strong>independently</strong>, generating workloads for its assigned logical fragment.</p>
</li>
<li><p>By running <strong>multiple</strong> BGClients <strong>in parallel</strong> across different nodes, BG can scale horizontally to handle millions of requests.</p>
</li>
</ul>
</li>
<li><p><strong>D-Zipfian Distribution:</strong></p>
<ul>
<li><p>To ensure realistic and scalable workloads, BG uses a decentralized Zipfian distribution (D-Zipfian) that <strong>dynamically assigns</strong> requests to BGClients based on node performance.</p>
</li>
<li><p>Faster nodes receive a larger share of the logical fragments, ensuring even workload distribution.</p>
</li>
</ul>
</li>
<li><p><strong>Concurrency Control:</strong></p>
<ul>
<li>BG <strong>prevents simultaneous threads from issuing actions for the same user</strong>, maintaining the integrity of modeled user interactions and avoiding resource contention.</li>
</ul>
</li>
</ol>
<p><strong>If two modeled users, A and B, are already friends, does BG generate a friend request from A to B?</strong></p>
<p>No, BG does not generate a friend request from A to B if they are already friends.</p>
<p>Before generating a friend request, BG <strong>validates</strong> whether the relationship between A and B is pending or already confirmed. For example, in the <code>InviteFrdSession</code>, BG only selects users who have no existing “friend” or “pending” relationship with the requester to receive a new friend request.</p>
<p>Reference: <a href="https://www.cidrdb.org/cidr2013/Papers/CIDR13_Paper93.pdf">https://www.cidrdb.org/cidr2013/Papers/CIDR13_Paper93.pdf</a></p>
]]></content>
      <categories>
        <category>数据库系统</category>
      </categories>
  </entry>
  <entry>
    <title>FoundationDB</title>
    <url>/undefined/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2024/09/26/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/FoundationDB/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h1 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h1><p>FoundationDB的研究意义在于，它成功地将NoSQL的灵活性与ACID事务的强大功能结合在一起，提供了一种模块化的架构，使得各个子系统可以独立配置和扩展。这种设计不仅提高了系统的可扩展性和可用性，还增强了故障容忍能力。此外，FoundationDB采用了严格的模拟测试框架，确保了系统的稳定性和高效性，使得开发者能够快速引入和发布新特性。FoundationDB的快速恢复机制显著提高了系统的可用性，简化了软件升级和配置变更的过程，通常在几秒钟内完成。</p>
<p>The main design principles are:</p>
<ol>
<li>Divide-and-Conquer (or separation of concerns). FDB decouples the transaction management system (write path) from the distributed storage (read path) and scales them independently. Within the transaction management system, processes are assigned various roles representing different aspects of transaction management. Furthermore, cluster-wide orchestrating tasks, such as overload control and load balancing are also divided and serviced by additional heterogeneous roles.</li>
<li>Make failure a common case. For distributed systems, failure is a norm rather than an exception. To cope with failures in the transaction management system of FDB, we handle all failures through the recovery path: the transaction system proactively shuts down when it detects a failure. Thus, all failure handling is reduced to a single recovery operation, which becomes a common and well-tested code path. To improve availability, FDB strives to minimize Mean-Time-To-Recovery (MTTR). In our production clusters, the total time is usually less than five seconds.</li>
<li>Simulation testing. FDB relies on a randomized, deterministic simulation framework for testing the correctness of its distributed database. Simulation tests not only expose deep bugs, but also boost developer productivity and the code quality of FDB.</li>
</ol>
<h1 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h1><p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/FDB_arch.png" alt="img"></p>
<ul>
<li><p>The control plane is responsible for persisting critical system metadata, that is, the configuration of transaction systems, on Coordinators.</p>
<ul>
<li><p>These <strong>Coordinators</strong> form a Paxos group and elect a ClusterController.</p>
</li>
<li><p>The <strong>ClusterController</strong> monitors all servers in the cluster and recruits three processes, Sequencer, DataDistributor, and Ratekeeper, which are re-recruited if they fail or crash.</p>
</li>
<li><p>The <strong>DataDistributor</strong> is responsible for monitoring failures and balancing data among StorageServers.</p>
</li>
<li><p><strong>Ratekeeper</strong> provides overload protection for the cluster.</p>
</li>
</ul>
</li>
<li><p>The data plane is responsible for transaction processing and data storage. FDB chooses an unbundled architecture:</p>
<ul>
<li><p>A distributed transaction management system (TS) consists of a Sequencer, Proxies, and Resolvers, all of which are stateless processes.</p>
<ul>
<li><p>The Sequencer assigns a read and a commit version to each transaction.</p>
</li>
<li><p>Proxies offer MVCC read versions to clients and orchestrate transaction commits.</p>
</li>
<li><p>Resolvers check for conflicts among transactions.</p>
</li>
</ul>
</li>
<li><p>A log system (LS) stores Write-Ahead-Log (WAL) for TS, and a separate distributed storage system (SS) is used for storing data and servicing reads. The LS contains a set of LogServers and the SS has a number of StorageServers. LogServers act as replicated, sharded, distributed persistent queues, each queue storing WAL data for a StorageServer.</p>
</li>
</ul>
</li>
</ul>
<p><strong>Clients read from sharded StorageServers, so reads scale linearly with the number of StorageServers.</strong></p>
<p><strong>Writes are scaled by adding more Proxies, Resolvers, and LogServers.</strong></p>
<p>The control plane’s singleton processes (e.g., ClusterController and Sequencer) and Coordinators are not performance bottlenecks; they only perform limited metadata operations. 因为元数据操作少且简单，且与两者无关的数据读写是并行扩展的（如上面两行加粗字体所述）。</p>
<h1 id="Bootstrapping"><a href="#Bootstrapping" class="headerlink" title="Bootstrapping"></a>Bootstrapping</h1><p>FDB has no dependency on external coordination services. All user data and most system metadata (keys that start with 0xFF prefix) are stored in StorageServers. The metadata about StorageServers is persisted in LogServers, and the LogServers configuration data is stored in all Coordinators.</p>
<ol>
<li>The Coordinators are a disk Paxos group; servers attempt to become the ClusterController if one does not exist.</li>
<li>A newly elected ClusterController reads the old LS configuration from the Coordinators and spawns a new TS and LS.</li>
<li>Proxies recover system metadata from the old LS, including information about all StorageServers.</li>
<li>The Sequencer waits until the new TS finishes recovery, then writes the new LS configuration to all Coordinators. The new transaction system is then ready to accept client transactions.</li>
</ol>
<h1 id="Reconfiguration"><a href="#Reconfiguration" class="headerlink" title="Reconfiguration"></a>Reconfiguration</h1><p>The Sequencer process monitors the health of Proxies, Resolvers, and LogServers. Whenever there is a failure in the TS or LS, or the database configuration changes, the Sequencer terminates. The ClusterController detects the Sequencer failure, then recruits and bootstraps a new TS and LS. In this way, transaction processing is divided into epochs, where each epoch represents a generation of the transaction management system with its own Sequencer.</p>
<h1 id="End-to-end-transaction-processing"><a href="#End-to-end-transaction-processing" class="headerlink" title="End-to-end transaction processing"></a>End-to-end transaction processing</h1><ol>
<li><p><strong>Transaction Start and Read Operations:</strong></p>
<ul>
<li><p>A client starts a transaction by contacting a <strong>Proxy</strong> to obtain a read version (timestamp).</p>
</li>
<li><p>The <strong>Proxy</strong> requests a read version from the <strong>Sequencer</strong> that is greater than all previously issued commit versions and sends it to the client.</p>
</li>
<li><p>The client then reads from <strong>StorageServers</strong> at this specific read version.</p>
</li>
</ul>
</li>
<li><p><strong>Buffered Write Operations</strong>:</p>
<ul>
<li><p>Client writes are buffered locally and not sent to the cluster immediately.</p>
</li>
<li><p>Read-your-write semantics are preserved by combining the database lookups with the client’s uncommitted writes.</p>
</li>
</ul>
</li>
<li><p><strong>Transaction Commit</strong>:</p>
<ul>
<li><p>When the client commits, it sends the transaction data (read and write sets) to a <strong>Proxy</strong>, waiting for either a commit or abort response.</p>
</li>
<li><p>The <strong>Proxy</strong> commits a transaction in three steps:</p>
<ol>
<li><p><strong>Obtain Commit Version</strong>: The Proxy requests a commit version from the <strong>Sequencer</strong> that is larger than all current read or commit versions.</p>
</li>
<li><p><strong>Conflict Check</strong>: The Proxy sends transaction data to the partitioned <strong>Resolvers</strong>, which check for read-write conflicts. If no conflicts are found, the transaction proceeds; otherwise, it is aborted.</p>
</li>
<li><p><strong>Persist to Log Servers</strong>: The transaction is sent to <strong>LogServers</strong> for persistence, and after all LogServers acknowledge, the transaction is considered committed. The Proxy then reports the committed version to the <strong>Sequencer</strong> and sends the response back to the client.</p>
</li>
</ol>
</li>
</ul>
</li>
<li><p><strong>Applying Writes</strong>:</p>
<ul>
<li><strong>StorageServers</strong> continuously pull mutation logs from <strong>LogServers</strong> and apply the committed changes to disk.</li>
</ul>
</li>
<li><p><strong>Read-Only Transactions and Snapshot Reads</strong>:</p>
<ul>
<li><p>Read-only transactions are <strong>serializable</strong> (at the read version) and <strong>high-performance</strong> (thanks to MVCC), allowing the client to commit locally without contacting the database, which is particularly important since most transactions are read-only.</p>
</li>
<li><p><strong>Snapshot reads</strong> relax the isolation property of a transaction, reducing conflicts by allowing concurrent writes without conflicting with snapshot reads.</p>
</li>
</ul>
</li>
</ol>
<p><strong>FoundationDB (FDB) using Serializable Snapshot Isolation (SSI) by combining Optimistic Concurrency Control (OCC) with Multi-Version Concurrency Control (MVCC).</strong></p>
<h2 id="Transaction-Versions"><a href="#Transaction-Versions" class="headerlink" title="Transaction Versions"></a>Transaction Versions</h2><ul>
<li>Each transaction receives a <strong>read version</strong> and a <strong>commit version</strong> from the <strong>Sequencer</strong>.</li>
<li>The read version ensures that the transaction observes the results of all previously committed transactions, and the commit version is greater than all current read or commit versions, establishing a serial order for transactions.</li>
</ul>
<h2 id="Log-Sequence-Number-LSN"><a href="#Log-Sequence-Number-LSN" class="headerlink" title="Log Sequence Number (LSN)"></a>Log Sequence Number (LSN)</h2><ul>
<li>The <strong>commit version</strong> serves as the <strong>LSN</strong>, defining a serial history of transactions.</li>
<li>To ensure no gaps between LSNs, the Sequencer also returns the previous LSN with each commit. Both the LSN and previous LSN are sent to <strong>Resolvers</strong> and <strong>LogServers</strong> to enforce serial processing of transactions.</li>
</ul>
<h2 id="Conflict-Detection"><a href="#Conflict-Detection" class="headerlink" title="Conflict Detection"></a>Conflict Detection</h2><ul>
<li>FDB uses a lock-free conflict detection algorithm similar to <strong>write-snapshot isolation</strong>, but the commit version is chosen before conflict detection, enabling efficient batch processing of version assignments and conflict detection.</li>
<li>The key space is divided among multiple <strong>Resolvers</strong>, allowing conflict detection to be parallelized. A transaction can commit only if all Resolvers confirm no conflicts.</li>
</ul>
<h2 id="Handling-Aborted-Transactions"><a href="#Handling-Aborted-Transactions" class="headerlink" title="Handling Aborted Transactions"></a>Handling Aborted Transactions</h2><ul>
<li>If a transaction is aborted, some Resolvers may have already updated their history, leading to possible “false positive” conflicts for other transactions. However, this is rare because most transactions’ key ranges fall within one Resolver, and the effects of false positives are limited to a short MVCC window (5 seconds).</li>
</ul>
<h2 id="Efficiency-of-OCC"><a href="#Efficiency-of-OCC" class="headerlink" title="Efficiency of OCC"></a>Efficiency of OCC</h2><ul>
<li>The OCC design avoids the complexity of acquiring and releasing locks, simplifying interactions between the <strong>Transaction System (TS)</strong> and <strong>Storage Servers (SS)</strong>.</li>
<li>While OCC may result in some wasted work due to aborted transactions, FDB’s conflict rate in production is low (less than 1%), and clients can simply restart aborted transactions.</li>
</ul>
<h1 id="Logging-protocol"><a href="#Logging-protocol" class="headerlink" title="Logging protocol"></a>Logging protocol</h1><p>Commit Logging:</p>
<ul>
<li>Once a <strong>Proxy</strong> decides to commit a transaction, it sends the transaction’s changes (mutations) to the <strong>LogServers</strong> responsible for the modified key ranges. Other LogServers receive an empty message.</li>
<li>The log message includes the current and previous <strong>Log Sequence Number (LSN)</strong> from the <strong>Sequencer</strong> and the largest known committed version (KCV) of the Proxy.</li>
<li>The <strong>LogServers</strong> reply to the Proxy once the log data is durably stored. The Proxy updates its KCV if all replica LogServers acknowledge and the LSN is larger than the current KCV.</li>
</ul>
<p>Shipping Redo Logs:</p>
<ul>
<li>Shipping the redo log from LogServers to <strong>StorageServers</strong> happens in the background and is not part of the commit path, improving performance.</li>
</ul>
<p>Applying Redo Logs:</p>
<ul>
<li><strong>StorageServers</strong> apply non-durable redo logs from LogServers to an in-memory index. In most cases, this happens before any client reads are processed, ensuring low-latency multi-version reads.</li>
<li>If the requested data is not yet available on a StorageServer, the client either waits or retries at another replica. If both reads time out, the client can restart the transaction.</li>
</ul>
<p>I&#x2F;O Efficiency:</p>
<ul>
<li>Since log data is already durable on LogServers, StorageServers can buffer updates in memory and write batches to disk periodically, improving input&#x2F;output (I&#x2F;O) efficiency.</li>
</ul>
<p><strong>What if a StorageServer is lagging behind on applying the redo logs and a client requests a version of a key pair it does not have?</strong></p>
<ol>
<li>Wait for a threshold for when known-committed-version is greater than or equal to the read version</li>
<li>If timeout, the client asks another StorageServer that stores the key</li>
<li>Return error “request for a future version” (FDB error code 1009)</li>
</ol>
<p><strong>What if there is no further transaction logs to redo?</strong></p>
<ul>
<li>Without new transactions issued from the client, proxies still generate empty transactions to advance the known-committed-version</li>
<li>Known-committed-version and LSN of each transaction are sent to all LogServers (limit scalability on writes)</li>
</ul>
<h1 id="Transaction-system-recovery"><a href="#Transaction-system-recovery" class="headerlink" title="Transaction system recovery"></a>Transaction system recovery</h1><h2 id="Simplified-Recovery"><a href="#Simplified-Recovery" class="headerlink" title="Simplified Recovery"></a>Simplified Recovery</h2><ul>
<li>Unlike traditional databases that require <strong>undo log processing</strong>, FoundationDB avoids this step by making the <strong>redo log processing</strong> the same as the normal log forward path. StorageServers pull logs from LogServers and apply them in the background.</li>
</ul>
<h2 id="Failure-Detection-and-New-Transaction-System-TS"><a href="#Failure-Detection-and-New-Transaction-System-TS" class="headerlink" title="Failure Detection and New Transaction System (TS)"></a>Failure Detection and New Transaction System (TS)</h2><ul>
<li>Upon detecting a failure, a new TS is recruited. The new TS can start accepting transactions even before all old logs are fully processed. Recovery focuses on finding the end of the redo log, allowing StorageServers to asynchronously replay the logs from that point.</li>
</ul>
<h2 id="Epoch-based-Recovery"><a href="#Epoch-based-Recovery" class="headerlink" title="Epoch-based Recovery"></a>Epoch-based Recovery</h2><ul>
<li>The recovery process is handled per <strong>epoch</strong>. The <strong>ClusterController</strong> locks the old TS configuration, stops old LogServers from accepting new transactions, recruits a new set of transaction components (Sequencer, Proxies, Resolvers, and LogServers), and writes the new TS configuration to the <strong>Coordinators</strong>.</li>
<li>Stateless components like Proxies and Resolvers don’t require special recovery, but LogServers, which store committed transaction logs, must ensure all data is durable and retrievable by StorageServers.</li>
</ul>
<h2 id="Recovery-Version-RV"><a href="#Recovery-Version-RV" class="headerlink" title="Recovery Version (RV)"></a>Recovery Version (RV)</h2><ul>
<li>The recovery focuses on determining the <strong>Recovery Version (RV)</strong>, which is essentially the end of the redo log. The <strong>Sequencer</strong> collects data from the old LogServers, specifically the <strong>Durable Version (DV)</strong> (maximum LSN persisted) and <strong>KCV</strong> (maximum committed version) from each.</li>
<li>Once enough LogServers have responded, the <strong>Previous Epoch Version (PEV)</strong> is established (the maximum of all KCVs). The start version of the new epoch is <code>PEV + 1</code>, and the minimum DV becomes the <strong>RV</strong>.</li>
</ul>
<h2 id="Log-Copying-and-Healing"><a href="#Log-Copying-and-Healing" class="headerlink" title="Log Copying and Healing"></a>Log Copying and Healing</h2><ul>
<li>Logs between <code>PEV + 1</code> and RV are copied from old LogServers to the new ones to restore replication in case of LogServer failures. This copying process is lightweight since it only covers a few seconds of logs.</li>
</ul>
<h2 id="Rollback-and-Transaction-Processing"><a href="#Rollback-and-Transaction-Processing" class="headerlink" title="Rollback and Transaction Processing"></a>Rollback and Transaction Processing</h2><ul>
<li>The first transaction after recovery is a special <strong>recovery transaction</strong> that informs StorageServers of the RV, so they can discard in-memory multi-versioned data beyond the RV. StorageServers then pull data larger than the PEV from the new LogServers.</li>
<li>The rollback process simply discards in-memory multi-versioned data, as persistent data is only written to disk once it leaves the MVCC window.</li>
</ul>
<h1 id="Replication"><a href="#Replication" class="headerlink" title="Replication"></a>Replication</h1><ol>
<li><p><strong>Metadata Replication</strong>:</p>
<ul>
<li><strong>System metadata</strong> related to the control plane is stored on <strong>Coordinators</strong> using the <strong>Active Disk Paxos</strong> protocol. As long as a majority (quorum) of Coordinators are operational, the metadata can be recovered in case of failure.</li>
</ul>
</li>
<li><p><strong>Log Replication</strong>:</p>
<ul>
<li>When a <strong>Proxy</strong> writes logs to <strong>LogServers</strong>, each log record is replicated synchronously across <strong>k &#x3D; f + 1</strong> LogServers (where <strong>f</strong> is the number of allowed failures). The Proxy only sends a commit response to the client after all <strong>k</strong> LogServers have successfully persisted the log. If a LogServer fails, a transaction system recovery is triggered.</li>
</ul>
</li>
<li><p><strong>Storage Replication</strong>:</p>
<ul>
<li>Each <strong>key range (shard)</strong> is asynchronously replicated across <strong>k &#x3D; f + 1 StorageServers</strong>. These StorageServers form a <strong>team</strong>. A StorageServer typically hosts multiple shards, distributing its data across several teams. If a StorageServer fails, the <strong>DataDistributor</strong> moves the data from teams with the failed server to other healthy teams.</li>
</ul>
</li>
</ol>
<p>To prevent data loss in case of simultaneous failures, FoundationDB ensures that no more than one process in a replica group is placed within the same fault domain (e.g., a host, rack, or availability zone). As long as one process in each team is operational, no data is lost, provided at least one fault domain remains available.</p>
<h1 id="Simulation-testing"><a href="#Simulation-testing" class="headerlink" title="Simulation testing"></a>Simulation testing</h1><ol>
<li><p><strong>Deterministic Simulation</strong>:</p>
<ul>
<li><p>FoundationDB uses <strong>deterministic discrete-event simulation</strong> to test its distributed system. This simulation runs real database code along with <strong>randomized synthetic workloads</strong> and <strong>fault injection</strong> to uncover bugs.</p>
</li>
<li><p>Determinism ensures that bugs are reproducible and can be investigated thoroughly.</p>
</li>
</ul>
</li>
<li><p><strong>Fault Injection</strong>:</p>
<ul>
<li><p>The simulation tests system resilience by injecting various faults, such as <strong>machine, rack, or data center failures</strong>, network issues, disk corruption, and delays.</p>
</li>
<li><p>Randomization of these faults increases the diversity of tested states, allowing for a wide range of potential issues to be examined.</p>
</li>
<li><p><strong>“Buggification”</strong> is a technique used to deliberately introduce rare or unusual behaviors (e.g., unnecessary delays, errors) in the system to stress-test its handling of non-standard conditions.</p>
</li>
</ul>
</li>
<li><p><strong>Swarm Testing</strong>:</p>
<ul>
<li><p><strong>Swarm testing</strong> increases simulation diversity by using random cluster sizes, configurations, workloads, and fault injection parameters.</p>
</li>
<li><p>This ensures that a broad range of scenarios is covered in testing, allowing for the discovery of rare bugs.</p>
</li>
</ul>
</li>
<li><p><strong>Test Oracles</strong>:</p>
<ul>
<li><p><strong>Test oracles</strong> are built into the system to verify key properties like <strong>transaction atomicity</strong>, <strong>isolation</strong>, and <strong>recoverability</strong>. Assertions check these properties to detect failures during simulation.</p>
</li>
<li><p>They help confirm that the system’s expected behaviors are maintained, even under stressful conditions.</p>
</li>
</ul>
</li>
<li><p><strong>Bug Detection Efficiency</strong>:</p>
<ul>
<li><p>The simulation runs faster than real-time, allowing FoundationDB to quickly discover and trace bugs. The <strong>parallel</strong> nature of testing accelerates the process of finding bugs, particularly before major releases.</p>
</li>
<li><p>This approach uncovers bugs that may not appear during real-time testing, especially for issues that require long-running operations.</p>
</li>
</ul>
</li>
<li><p><strong>Limitations</strong>:</p>
<ul>
<li><p>Simulation cannot reliably detect <strong>performance issues</strong> (like imperfect load balancing).</p>
</li>
<li><p>It cannot test <strong>third-party libraries</strong> or <strong>external dependencies</strong>, focusing mainly on FoundationDB’s internal code and behaviors.</p>
</li>
</ul>
</li>
</ol>
<h1 id="Lessons-learned"><a href="#Lessons-learned" class="headerlink" title="Lessons learned"></a>Lessons learned</h1><ol>
<li><p><strong>Architecture Design</strong></p>
<ul>
<li><p><strong>Divide-and-Conquer Principle</strong>: Separating the transaction system from the storage layer allows for independent scaling and deployment of resources, enhancing both flexibility and performance.</p>
</li>
<li><p><strong>LogServers as Witness Replicas</strong>: In multi-region deployments, LogServers reduce the need for full StorageServer replicas while maintaining high availability.</p>
</li>
<li><p><strong>Role Specialization</strong>: The design enables the creation of specialized roles, like separating DataDistributor and Ratekeeper from the Sequencer, and separating Proxies into Get-Read-Version and Commit Proxies, which improves performance and makes the system extensible.</p>
</li>
<li><p><strong>Decoupling Enhances Extensibility</strong>: This design pattern allows features like replacing SQLite with RocksDB and adding new roles or functions without overhauling the entire system.</p>
</li>
</ul>
</li>
<li><p><strong>Simulation Testing</strong></p>
<ul>
<li><p><strong>High Productivity</strong>: FDB’s deterministic simulation testing enables bugs to be found and reproduced quickly. This approach has improved developer productivity and system reliability by reducing debugging time and improving test coverage.</p>
</li>
<li><p><strong>Reliability</strong>: FDB has operated without any data corruption over several years of deployment (e.g., CloudKit), thanks to rigorous simulation testing. Simulation has allowed ambitious rewrites and improvements to be made safely.</p>
</li>
<li><p><strong>Eliminating Dependencies</strong>: Simulation testing helped find bugs in external dependencies, leading to FDB replacing Apache Zookeeper with its own Paxos implementation. This change resulted in no further production bugs.</p>
</li>
</ul>
</li>
<li><p><strong>Fast Recovery</strong></p>
<ul>
<li><p><strong>Simplifies Upgrades</strong>: FDB allows fast recovery by restarting all processes simultaneously, typically within seconds, simplifying software upgrades and configuration changes. This method has been extensively tested and used in Apple’s production clusters.</p>
</li>
<li><p><strong>Bug Healing</strong>: Fast recovery can automatically resolve certain latent bugs, similar to software rejuvenation, by resetting system states.</p>
</li>
</ul>
</li>
<li><p><strong>5-Second MVCC Window</strong></p>
<ul>
<li><p><strong>Memory Efficiency</strong>: FDB uses a 5-second MVCC (Multi-Version Concurrency Control) window to limit memory usage in transaction systems and storage servers. This time window is long enough for most OLTP workloads, exposing inefficiencies if the transaction exceeds 5 seconds.</p>
</li>
<li><p><strong>TaskBucket Abstraction</strong>: Long-running processes, like backups, are broken into smaller transactions that fit within the 5-second window. FDB implements this through an abstraction called TaskBucket, which simplifies splitting large transactions into manageable jobs.</p>
</li>
</ul>
</li>
</ol>
<h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h1><p><strong>With FDB, what operations does a transaction commit perform when the transaction only reads the value of data items?</strong></p>
<ul>
<li><strong>Read Version Retrieval</strong>: The client requests a read version from a <strong>Proxy</strong> via the <strong>Sequencer</strong>, which guarantees the read version is greater than or equal to any committed version.</li>
<li><strong>Read Operation</strong>: The client reads the requested data at this specific read version from the <strong>StorageServers</strong>. The reads are served by the StorageServers, which are guaranteed to provide data consistent with the requested version.</li>
<li><strong>No Writes or Conflicts</strong>: Since the transaction is read-only, there is no write set or conflicts to check. The transaction simply ends, and no data is written or modified, meaning it does not interact with LogServers or commit any changes.</li>
<li><strong>Commit</strong>: Even though no actual commit occurs (because there’s no data change), the transaction is marked as successfully completed after the reads are done.</li>
</ul>
<p><strong>With FDB, is it possible for multiple resolvers to participate in the decision whether to commit or abort a write transaction?</strong> </p>
<p>Yes, multiple Resolvers can participate in the decision to commit or abort a write transaction in FDB. Here’s how it works:</p>
<ul>
<li><strong>Conflict Detection</strong>: When a transaction writes data, the write set (the keys it wants to write) is sent to a set of <strong>Resolvers</strong>. Each Resolver is responsible for a specific portion of the key space. Multiple Resolvers can be involved in checking the transaction’s read and write sets to detect <strong>conflicts</strong> (read-write conflicts or write-write conflicts).</li>
<li><strong>Parallel Conflict Checking</strong>: Since the key space is partitioned, different Resolvers check different key ranges in parallel. A transaction can only commit if <strong>all</strong> Resolvers agree that there are no conflicts.</li>
</ul>
<p><strong>With FDB, what if a StorageServer is lagging behind on applying the redo logs and a client requests a version of a key pair it does not have?</strong></p>
<ul>
<li><strong>Client Waits</strong>: The client can choose to wait for the StorageServer to catch up by applying the redo logs. Once the StorageServer finishes replaying the logs and reaches the required version, it can serve the requested data.</li>
<li><strong>Retry at Another Replica</strong>: If the StorageServer does not have the requested version yet, the client can try to read from another <strong>replica</strong> of the key. FDB typically stores multiple replicas of data across different StorageServers, so the client can retry the request from a replica that is up to date.</li>
<li><strong>Transaction Restart</strong>: If neither replica has the requested version or the delay is too long, the client may restart the transaction. Since FoundationDB uses <strong>MVCC (Multi-Version Concurrency Control)</strong>, restarting the transaction allows it to obtain a fresh version of the key from an up-to-date StorageServer.</li>
</ul>
<p><strong>Consider a database for students enrolling in courses and professors teaching those courses. Provide a SDM model of this database?</strong></p>
<p>Students: base concrete object class.</p>
<p>member property: student_id, name, age, email, department_id.</p>
<p>identifier: student_id.</p>
<p>Professors: base concrete object class.</p>
<p>member property: professor_id, name, age, email, department_id.</p>
<p>identifier: professor_id.</p>
<p>Courses: base concrete object class</p>
<p>member property: course_id, name, location, start_time, end_time, department_id.</p>
<p>derived member property: professor as Professors.professor_id.</p>
<p>identifier: course_id.</p>
<p>Enrollment: base duration event class.</p>
<p>member property: enrollment_id, date_of_enrollment.</p>
<p>member participant: student in Students, course in Courses.</p>
<p>identifier: enrollment_id.</p>
<p>Departments: abstract Students and Professors on common value of department_id.</p>
<p>derived member property: department_id as distinct value of (Students.department_id union Professors.department_id).</p>
<p><strong>What is the difference between a monolithic database management system and a disaggregated database management system?</strong> </p>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Monolithic DBMS</th>
<th>Disaggregated DBMS</th>
</tr>
</thead>
<tbody><tr>
<td>Architecture</td>
<td>All components tightly integrated into a single system</td>
<td>Components like storage, computation, and query processing are separated</td>
</tr>
<tr>
<td>Scalability</td>
<td>Scales through vertical scaling (adding resources to the single server)</td>
<td>Scales through horizontal scaling (independent scaling of storage and compute)</td>
</tr>
<tr>
<td>Performance Bottlenecks</td>
<td>May face bottlenecks as the system grows</td>
<td>Components are independently optimized, reducing bottlenecks</td>
</tr>
<tr>
<td>Resource Management</td>
<td>Storage and compute resources are tightly coupled, hard to manage separately</td>
<td>Storage and compute resources can be managed independently, offering flexibility</td>
</tr>
<tr>
<td>Complexity</td>
<td>Easier to deploy and manage initially, but complexity increases with scale</td>
<td>More complex to manage and coordinate different components</td>
</tr>
<tr>
<td>Cost</td>
<td>Pay for all resources, even if they are not fully utilized</td>
<td>Can optimize resource usage and costs by scaling components independently</td>
</tr>
<tr>
<td>Consistency</td>
<td>Strong data consistency due to tight integration</td>
<td>Requires additional mechanisms to ensure consistency across components</td>
</tr>
</tbody></table>
<p><strong>With Gamma and its data flow execution paradigm, how does the system know when the execution of a parallel query involving multiple operators is complete?</strong></p>
<p>Data Dependency Graph: The query execution is modeled as a directed acyclic graph (DAG), where each node represents an operator (e.g., selection, join). Data flows between operators, and the system tracks the completion of each operator based on this graph.</p>
<p>Completion Signals: Each parallel operator sends a “done” signal once it finishes processing its data partition. The system monitors these signals to determine when all operators have finished.</p>
<p>Coordinator: A central coordinator tracks the progress of parallel tasks. When all tasks report completion, the system declares the query execution as complete.</p>
<p>Reference: <a href="https://sigmodrecord.org/publications/sigmodRecord/2203/pdfs/08_fdb-zhou.pdf">https://sigmodrecord.org/publications/sigmodRecord/2203/pdfs/08_fdb-zhou.pdf</a></p>
]]></content>
      <categories>
        <category>数据库系统</category>
        <category>分布式系统</category>
      </categories>
  </entry>
  <entry>
    <title>HRPS Background</title>
    <url>/undefined/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/2024/09/12/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/HRPS%20Background/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/index_and_page.png" alt="img"></p>
<p>Each page consits of the header, the record space and a pointer array. Each slot in this array points to a record within the page.</p>
<p>A record is located by providing its page address and the slot number. The combination is called RID.</p>
<p>Life Cycle of a record:</p>
<p>Insert: Find an empty space to put it and set a slot at the very end of the page to point to it.</p>
<p>Delete: Remove the record and reclaim this space, set its slot number to null. When there are too many garbage slots, the system will drop the index structure, do reorganization on this disk page by removing all null slots, and reconstruct the index structure from scratch.</p>
<p>Non-clustered Index: the data of the disk page is independent of the bucket or leaf node of index.</p>
<p>Clustered Index: the data of the disk page resides within the bucket or leaf node of index.</p>
<p>Hash Index: the item in buckets is not ordered by the attribute value of index.</p>
<p>B+Tree Index: the item in leaf nodes is ordered by the attribute value of index.</p>
<ul>
<li>Primary Index: the data in the disk page is ordered.</li>
<li>Secondary Index: the data in the disk page is not ordered.</li>
</ul>
<p>Reference: <a href="https://www.vldb.org/conf/1990/P481.PDF">https://www.vldb.org/conf/1990/P481.PDF</a></p>
]]></content>
      <categories>
        <category>数据库系统</category>
      </categories>
  </entry>
  <entry>
    <title>Gamma</title>
    <url>/undefined/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/2024/09/05/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/Gamma/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h1 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h1><p>主要特点：</p>
<ol>
<li><strong>并行处理</strong>： Gamma 利用了分布式架构，通过将数据和计算任务分散到多个节点上并行处理，极大提高了查询性能和吞吐量。不同的节点可以同时处理不同的任务，从而加速整个系统的响应时间。</li>
<li><ul>
<li><strong>并行查询处理</strong>： Gamma 支持并行执行查询计划中的操作（如选择、投影、连接等）。系统采用流水线并行（pipelined parallelism）和分块并行（partitioned parallelism）技术来最大化资源利用率。</li>
<li><strong>流式处理（Pipelining）</strong>： Gamma 支持流式处理，即在一个操作产生部分结果时，直接将这些结果传递给下一个操作，而不是等待整个操作完成。这样可以减少内存占用，并加快查询处理速度。</li>
</ul>
</li>
<li><strong>数据分片（Declustering）</strong>： Gamma 系统通过数据分片将数据表水平拆分成多个片段，并将这些片段分布到不同的处理节点上。这种方式不仅均衡了负载，还支持并行的查询处理，避免单点瓶颈。</li>
<li><strong>动态负载均衡</strong>： Gamma 能够根据查询的工作负载，动态分配任务到不同的节点，确保整个系统的负载均衡，避免某些节点过载导致性能下降。通过监控每个节点的工作情况，Gamma 能够优化数据和任务分布。</li>
<li><strong>故障容错（Fault Tolerance）</strong>： Gamma 具有一定的故障容错能力，当某个节点出现故障时，系统可以通过冗余机制和数据复制，重新分配任务或从其他节点获取数据，避免系统中断。</li>
<li><strong>扩展性（Scalability）</strong>： Gamma 系统的设计能够随着节点的增加而线性扩展。通过增加处理节点，Gamma 可以处理更大规模的数据和更多的并发查询，保持高性能。</li>
</ol>
<p>Gamma is based on the concept of a shared-nothing architecture in which processors do not share disk drives or random access memory and can only communicate with one another by sending messages through an interconnection network. Mass storage in such an architecture is generally distributed among the processors by connecting one or more disk drives to each processor.</p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/Gamma_Arch.png" alt="Gamma 架构"></p>
<p>Reasons why the shared-nothing approach has become the architecture of choice.</p>
<ul>
<li>There is nothing to prevent the architecture from <strong>scaling</strong> to 1000s of processors unlike shared-memory machines for which scaling beyond 30-40 processors may be impossible.</li>
<li>By associating a small number of disks with each processor and distributing the tuples of each relation across the disk drives, it is possible to achieve very high aggregate I&#x2F;O bandwidths without using custom disk controllers</li>
</ul>
<p>When Gamma’s system is figuring out the best way to run a query, it uses information about how the data is divided up (partitioned). This partitioning information helps the system decide how many processors (computers) need to be involved in running the query.</p>
<ul>
<li><strong>For hash partitioning</strong>: If a table (say, “X”) is divided based on a hash function applied to a certain column (like “y”), and the query asks for records where “X.y &#x3D; some value,” <strong>the system can directly go to the specific processor that holds the data matching that value</strong>.</li>
<li><strong>For range partitioning</strong>: If the table is divided based on ranges of values for a column, <strong>the system can limit the query to only the processors that have data within the relevant range</strong>. For example, if “X” is partitioned such that one processor handles values from 1 to 100, and another handles values from 101 to 200, then a query asking for “X.y between 50 and 150” will involve only the processors that have data in those ranges.</li>
</ul>
<p>Different processes in the Gamma system work together. Here’s a simplified explanation of the main types of processes and their roles:</p>
<ol>
<li><p><strong>Catalog Manager</strong>: Acts like a “database encyclopedia,” <strong>storing all the information about data tables and structures</strong>. It ensures that data remains consistent when multiple users access the database.</p>
</li>
<li><p><strong>Query Manager</strong>: Each user gets a query manager that handles query requests. It is responsible for <strong>parsing the query, optimizing it, and generating the execution plan</strong>.</p>
</li>
<li><p><strong>Scheduler Processes</strong>: When a query is executed, the scheduler <strong>coordinates the execution steps</strong>. It activates the necessary operator processes (such as scan, selection, etc.) and ensures that all steps are performed in the correct order.</p>
</li>
<li><p><strong>Operator Processes</strong>: These processes <strong>carry out specific database operations</strong>, like filtering data or joining tables. To reduce the startup delay during query execution, some operator processes are pre-initialized when the system starts.</p>
</li>
<li><p><strong>Other Processes</strong>:</p>
<ul>
<li><p><strong>Deadlock Detection Process</strong>: Detects situations where two or more processes are stuck waiting for each other to release resources.</p>
</li>
<li><p><strong>Recovery Process</strong>: Manages data recovery after a system failure.</p>
</li>
</ul>
</li>
</ol>
<p>How the Gamma system executes database queries?</p>
<ol>
<li><strong>Query Parsing and Optimization</strong>: When a user submits a query, Gamma first parses it to understand what the query is asking for. Then, the system optimizes the query to find the most efficient way to execute it.</li>
<li><strong>Query Compilation</strong>: After optimization, the query is compiled into an “<strong>operator tree</strong>“ made up of different operations (such as scan, selection, join, etc.). This tree outlines the steps and the order in which the query will be executed.</li>
<li><strong>Single-Site vs. Multi-Site Queries</strong>: If the query only involves data on a single node (e.g., querying a small table), the system executes it directly on that node. However, if the query involves data distributed across multiple nodes (e.g., joining large tables), the system uses a “scheduler process” to coordinate the execution.</li>
<li><strong>Scheduler Coordination</strong>: The scheduler process is responsible for activating various operator processes across the nodes, such as instructing one node to scan data while another filters it. The scheduler also manages the flow of data between these operations, ensuring they happen in the correct order.</li>
<li><strong>Returning the Results</strong>: Once all operations are completed, the query results are collected and returned to the user. For queries embedded in a program, the results are passed back to the program that initiated the query.</li>
</ol>
<p>Different operations (like scanning data, filtering, joining tables, etc.) are carried out in a parallel manner. Here’s a simplified explanation:</p>
<ol>
<li><strong>Operator Processes</strong>: In Gamma, each operation in a query is handled by something called an “operator process.” For example, if the query needs to scan data from a table, filter some rows, and then join with another table, there would be separate operator processes for scanning, filtering, and joining.</li>
<li><strong>Data Flow</strong>: The data flows from one operator process to the next. For instance, the scan operator reads data from the disk and sends it to the filter operator, which then passes the filtered results to the join operator. This creates a kind of “data pipeline.”</li>
<li><strong>Split Table</strong>: Gamma uses a “split table” to decide where the data should go next. Think of it like a routing table that directs the flow of data. For example, if the data needs to be sent to multiple nodes for parallel processing, the split table helps determine which node each piece of data should go to.</li>
<li><strong>End of Processing</strong>: Once an operator finishes processing all its data, it closes its output streams and sends a signal to the scheduler process (which coordinates the whole query) to let it know that this part of the work is done.</li>
</ol>
<p>In simple terms, the operator and process structure in Gamma is like an assembly line where data moves from one step (operator) to the next, with each operator performing a specific task, and the split table guiding the data flow. This setup allows the system to process data in parallel across multiple nodes, making it much faster.</p>
<h1 id="Operators"><a href="#Operators" class="headerlink" title="Operators"></a>Operators</h1><h2 id="Selection-Operator"><a href="#Selection-Operator" class="headerlink" title="Selection Operator"></a>Selection Operator</h2><p>Data Spread Across Multiple Disks: In Gamma, data tables are split up and stored across multiple disks (this is called “declustering”). Because of this, when you want to search (select) for specific data, the system can perform the search in parallel across multiple disks.</p>
<p>Parallel Selection Process:</p>
<ul>
<li>If the search condition (predicate) matches the way the data is divided (partitioned), the system can narrow down the search to just the relevant nodes (computers with disks) that have the data. For example:</li>
<li><ul>
<li>If the data is divided using a <strong>hash or range</strong> partitioning method based on a certain attribute (like “employee ID”), and the search is also based on that attribute (e.g., “employee ID &#x3D; 123”), then the search can be directed only to the node that holds data matching that condition.</li>
<li>If the data is divided using a <strong>round-robin</strong> method (spreading data evenly across all disks) or if the search condition <strong>doesn’t match the partitioning attribute</strong>, then the system has to search on all nodes.</li>
</ul>
</li>
</ul>
<p>Performance Optimization:</p>
<ul>
<li>To make the search faster, Gamma uses a “<strong>read-ahead</strong>“ technique. This means that when it reads one page of data, it starts loading the next page at the same time, so that the processing of data can keep going without waiting for the next page to load.</li>
</ul>
<h2 id="Join-Operator"><a href="#Join-Operator" class="headerlink" title="Join Operator"></a>Join Operator</h2><p>Using Hash Partitioning: The join algorithms in Gamma are based on a concept called “buckets.” This means splitting the two tables to be joined into separate groups (buckets) that don’t overlap. The groups are created by applying a hash function to the join attribute (e.g., Employee ID), so that data with the same hash value ends up in the same bucket.</p>
<p>By partitioning the data into different buckets, each bucket contains unique data subsets, allowing parallel processing of these buckets, which speeds up the join operation. Additionally, <strong>all data with the same join attribute value is in the same bucket</strong>, making it easier to perform the join.</p>
<p>Gamma implements four different parallel join algorithms:</p>
<ul>
<li><strong>Sort-Merge Join</strong>: Joins data by sorting and merging.</li>
<li><strong>Grace Join</strong>: A distributed hash-based join algorithm.</li>
<li><strong>Simple Hash Join</strong>: A straightforward hash-based partitioning join.</li>
<li><strong>Hybrid Hash Join</strong>: A combination of different join techniques.</li>
</ul>
<p><strong>Default to Hybrid Hash Join:</strong> Research showed that the Hybrid Hash Join almost always performs the best, so Gamma uses this algorithm by default.</p>
<p>Limitations: These hash-based join algorithms can <strong>only handle equi-joins</strong> (joins with equality conditions, like “Employee ID &#x3D; Department ID”). They currently don’t support non-equi-joins (conditions like “Salary &gt; Department Budget * 2”). To address this, Gamma is working on designing a new parallel non-equi-join algorithm.</p>
<h3 id="Hybrid-Hash-Join"><a href="#Hybrid-Hash-Join" class="headerlink" title="Hybrid Hash-Join"></a>Hybrid Hash-Join</h3><ul>
<li>In the first phase, the algorithm uses a hash function to partition the inner (smaller) relation, R, into N buckets. The tuples of the first bucket are used to build an in-memory hash table while the remaining N-1 buckets are stored in temporary files. A good hash function produces just enough buckets to ensure that each bucket of tuples will be small enough to fit entirely in main memory.</li>
<li>During the second phase, relation S is partitioned using the hash function from step 1. Again, the last N-1 buckets are stored in temporary files while the tuples in the first bucket are used to immediately probe the in-memory hash table built during the first phase.</li>
<li>During the third phase, the algorithm joins the remaining N-1 buckets from relation R with their respective buckets from relation S.</li>
</ul>
<p>The join is thus broken up into a series of smaller joins; each of which hopefully can be computed without experiencing join overflow. The size of the smaller relation determines the number of buckets; this calculation is independent of the size of the larger relation.</p>
<h3 id="Parallel-version-of-Hybrid-Hash-Join"><a href="#Parallel-version-of-Hybrid-Hash-Join" class="headerlink" title="Parallel version of Hybrid Hash-Join"></a>Parallel version of Hybrid Hash-Join</h3><p>Partitioning into Buckets: The data from the two tables being joined is first divided into N buckets (small groups). The number of buckets is chosen so that each bucket can fit in the combined memory of the processors that are handling the join.</p>
<p>Storage of Buckets: Out of the N buckets, N-1 buckets are stored temporarily on disk across different disk sites, while one bucket is kept in memory for immediate processing.</p>
<p>Parallel Processing: A joining split table is used to decide which processor should handle each bucket, helping to divide the work across multiple processors. This means that <strong>different processors can work on different parts of the join at the same time</strong>, speeding up the process.</p>
<p>Overlapping Phases for Efficiency:</p>
<ul>
<li>When partitioning the <strong>first table (R)</strong> into buckets, Gamma simultaneously builds a hash table for the first bucket in memory at each processor.</li>
<li>When partitioning the <strong>second table (S)</strong>, Gamma simultaneously performs the join for the first bucket from S with the first bucket from R. This way, partitioning and joining overlap, making the process more efficient.</li>
</ul>
<p>Adjusting the Split Table for Parallel Joining: The joining split table is updated to make sure that the data from the first bucket of both tables is sent to the right processors that will perform the join. When the remaining N-1 buckets are processed, only the routing for joining is needed.</p>
<h2 id="Aggregate-Operator"><a href="#Aggregate-Operator" class="headerlink" title="Aggregate Operator"></a>Aggregate Operator</h2><p>Parallel Calculation of Partial Results: Each processor in the Gamma system calculates the aggregate result for its own portion of the data simultaneously. For example, if the goal is to calculate a sum, each processor will first compute the sum for the data it is responsible for.</p>
<p>Combining Partial Results: After calculating their partial results, the processors send these results to a central process. This central process is responsible for combining all the partial results to produce the final answer.</p>
<p>Two-Step Computation:</p>
<ul>
<li><strong>Step 1</strong>: Each processor calculates the aggregate value (e.g., sum, count) for its data partition, resulting in partial results.</li>
<li><strong>Step 2</strong>: The processors then redistribute these partial results based on the “group by” attribute. This means that the partial results for each group are collected at a single processor, where the final aggregation for that group is completed.</li>
</ul>
<h2 id="Update-Operator"><a href="#Update-Operator" class="headerlink" title="Update Operator"></a>Update Operator</h2><p>For the most part, the update operators (replace, delete, and append) are implemented using standard techniques. The only exception occurs when a replace operator modifies the partitioning attribute of a tuple. In this case, rather than writing the modified tuple back into the local fragment of the relation, the modified tuple is passed through a split table to determine which site should contain the tuple.</p>
<h1 id="Concurrency-Control"><a href="#Concurrency-Control" class="headerlink" title="Concurrency Control"></a><strong>Concurrency Control</strong></h1><p>Gamma uses a two-phase locking strategy to manage concurrency. This means that before accessing data, a process must first acquire locks (first phase), and then release the locks after completing its operations (second phase). This ensures that multiple operations do not modify the same data at the same time, preventing conflicts.</p>
<p>Gamma supports two levels of lock granularity: file-level and page-level (smaller scope). There are also five lock modes:</p>
<ul>
<li><strong>S (Shared) Lock</strong>: Allows multiple operations to read the data simultaneously.</li>
<li><strong>X (Exclusive) Lock</strong>: Only one operation can modify the data, while others must wait.</li>
<li><strong>IS, IX, and SIX Locks</strong>: Used to manage locking at larger scopes, such as entire files, allowing different combinations of read and write permissions.</li>
</ul>
<p>Each node in Gamma has its own lock manager and deadlock detector to handle local data locking. The lock manager maintains a lock table and a transaction wait-for-graph, which tracks which operations are waiting for which locks.</p>
<p>The cost of setting a lock depends on whether there is a conflict:</p>
<ul>
<li><strong>No Conflict</strong>: Takes about 100 instructions.</li>
<li><strong>With Conflict</strong>: Takes about 250 instructions because the system needs to check the wait-for-graph for deadlocks and suspend the requesting transaction using a semaphore mechanism.</li>
</ul>
<p>Gamma uses a centralized deadlock detection algorithm to handle deadlocks across nodes:</p>
<ul>
<li>Periodically (initially every second), the centralized deadlock detector requests each node’s local wait-for-graph.</li>
<li>If no deadlock is found, the detection interval is doubled (up to 60 seconds). If a deadlock is found, the interval is halved (down to 1 second).</li>
<li>The collected graphs are combined into a global wait-for-graph. If a cycle is detected in this global graph, it indicates a deadlock.</li>
</ul>
<p>When a deadlock is detected, the system will abort the transaction holding the fewest locks to free up resources quickly and allow other operations to proceed.</p>
<h1 id="Recovery-and-Log"><a href="#Recovery-and-Log" class="headerlink" title="Recovery and Log"></a>Recovery and Log</h1><p>Logging Changes:</p>
<p>When a record in the database is updated, Gamma creates a log record that notes the change. Each log record has a unique identifier called a Log Sequence Number (LSN), which includes a node number (determined when the system is set up) and a local sequence number (which keeps increasing). These log records are used for recovery if something goes wrong.</p>
<p>Log Management:</p>
<ul>
<li>The system sends log records from query processors to <strong>Log Managers</strong>, which are separate processors that organize the logs into a single stream.</li>
<li>If there are multiple Log Managers (M of them), a query processor sends its logs to one of them based on a simple formula: <strong>processor number mod M</strong>. This way, each query processor always sends its logs to the same Log Manager, making it easy to find logs later for recovery.</li>
</ul>
<p>Writing Logs to Disk:</p>
<ul>
<li>Once a “page” of log records is filled, it is saved to disk.</li>
<li>The Log Manager keeps a <strong>Flushed Log Table</strong>, which tracks the last log record written to disk for each node. This helps know which logs are safely stored.</li>
</ul>
<p>Writing Data to Disk (WAL Protocol):</p>
<ul>
<li>Before writing any changed data (a <strong>dirty page</strong>) to disk, the system checks if the corresponding log records have already been saved.</li>
<li>If the logs are saved, the data can be safely written to disk. If not, the system must first ensure the logs are written to disk before proceeding.</li>
<li>To avoid waiting too long for log confirmations, the system always tries to keep a certain number of <strong>clean buffer pages</strong> (unused pages) available.</li>
</ul>
<p>Commit and Abort Handling:</p>
<ul>
<li><strong>Commit</strong>: If a transaction completes successfully, the system sends a commit message to all the relevant Log Managers.</li>
<li><strong>Abort</strong>: If a transaction fails, an <strong>abort message</strong> is sent to all processors involved, and each processor retrieves its log records to undo the changes using the <strong>ARIES algorithm</strong>, which rolls back changes in the reverse order they occurred.</li>
</ul>
<p>Recovery Process:</p>
<ul>
<li>The system uses the <strong>ARIES algorithms</strong> for undoing changes, checkpointing, and restarting after a crash.</li>
<li><strong>Checkpointing</strong> helps the system know the most recent stable state, reducing the amount of work needed during recovery.</li>
</ul>
<h1 id="Dataflow-scheduling-technologies"><a href="#Dataflow-scheduling-technologies" class="headerlink" title="Dataflow scheduling technologies"></a>Dataflow scheduling technologies</h1><ol>
<li><strong>Data-Driven Execution Instead of Operator Control</strong>: Gamma’s dataflow scheduling lets data automatically move between operators, forming a pipeline. Each operator acts like a step on an assembly line: when data reaches the operator, it processes the data and then passes the processed results to the next operator.</li>
<li><strong>Reducing Coordination Overhead</strong>: Because of this dataflow design, the system does not need to frequently coordinate or synchronize the execution of each operator. This approach reduces the complexity and overhead of scheduling, especially when multiple operators are running in parallel, and avoids performance bottlenecks caused by waiting or synchronization.</li>
<li><strong>Inherent Support for Parallelism</strong>: Dataflow scheduling is well-suited for parallel processing because data can flow between multiple operators at the same time. For example, a query can simultaneously perform scanning, joining, and aggregation across different processors. Each operator can independently process the data it receives without waiting for other operators to finish, allowing the system to efficiently utilize the computational power of multiple processors.</li>
<li><strong>Adaptability to Dynamic Environments</strong>: During query execution, dataflow scheduling can be adjusted based on the actual system load and data characteristics. This flexibility allows the system to dynamically optimize the performance of query execution, especially for large and complex queries, by better adapting to changing query demands and system conditions.</li>
</ol>
<p>Gamma’s unique dataflow scheduling techniques allow data to flow naturally between operators, reducing the need for direct control over operations. This significantly lowers coordination overhead in multi-processor environments, enhances the system’s parallel processing capabilities, and improves the efficiency of executing complex queries.</p>
<p>In Gamma’s dataflow scheduling techniques, parallelism is extensively used to improve query execution efficiency. Here’s where and how parallelism is applied:</p>
<ol>
<li><p><strong>Parallel Execution of Operators</strong>: Queries often involve multiple operators (e.g., scan, filter, join, aggregation). With dataflow scheduling, these operators can run in parallel:</p>
<ul>
<li><p><strong>Scan and Filter in Parallel</strong>: While one processor scans a data block, another processor can be filtering the data from previous blocks.</p>
</li>
<li><p><strong>Parallel Joins</strong>: If a join operation involves large datasets distributed across different nodes, Gamma can perform the join operation on these different parts of the data simultaneously. The result of the join is computed in parallel across multiple processors.</p>
</li>
</ul>
</li>
<li><p><strong>Data Partitioning for Parallelism</strong>: The relations (data tables) are often partitioned across multiple processors in Gamma. This means that different processors can work on different partitions of the data at the same time. For example:</p>
<ul>
<li><p><strong>Partitioned Hash Joins</strong>: Data can be split into “buckets” based on a hash function, and different processors can handle the join for different buckets simultaneously.</p>
</li>
<li><p><strong>Parallel Aggregation</strong>: When computing aggregate functions (e.g., sum or average), each processor calculates a partial result for its own partition of the data, and these partial results are later combined.</p>
</li>
</ul>
</li>
</ol>
<p>In summary, parallelism in Gamma is achieved through:</p>
<ul>
<li>Distributing query operators across multiple processors.</li>
<li>Partitioning data so different processors work on different sections simultaneously.</li>
<li>Enabling multiple stages of query execution (e.g., scanning, filtering, joining) to happen concurrently.</li>
</ul>
<h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h1><p><strong>What is a fragment or a shard in Gamma?</strong> </p>
<p>A fragment or shard refers to a portion of a database relation that is horizontally partitioned across multiple disk drives.</p>
<p><strong>How does a Gamma operator know where to send its stream of records?</strong> </p>
<p>There is a structure called split table to determine where each tuple should be sent, based on the values of tuples.</p>
<p><strong>With interleaved declusttering, why not use a cluster size that includes all nodes in the system?</strong></p>
<p>If an interleaved declustteing system includes all nodes, it will become more vulnerable to failures. The failure of any two nodes could make the data inaccessible. A smaller cluster will limits the risk of complete data unavailability and balance the load.</p>
<p><strong>Hash-join is appropriate for processing equi-join predicates (Emp.dno &#x3D; Dept.dno). How can Gamma process nonequi-join predicates (Emp.Sal &gt; Dept.dno*1000) in a pipelined manner?</strong></p>
<p><strong>Range partitioning</strong>: Pre-partition the data based on ranges of values to reduce the search space.</p>
<p><strong>Broadcast join</strong>: When the smaller relation is broadcasted to all nodes, and then each node evaluates the nonequi-join predicate in parallel.</p>
<p><strong>Nested-loop join</strong>: Use a nested-loop join strategy where each tuple from one relation is compared against all tuples from the other relation.</p>
<p><strong>What is the difference between Gamma, Google MapReduce, Microsoft Dryad and Apache Flink?</strong></p>
<table>
<thead>
<tr>
<th><strong>Aspect</strong></th>
<th>Gamma</th>
<th>MapReduce</th>
<th>Dryad</th>
<th>Flink</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Primary Use</strong></td>
<td>Parallel database queries</td>
<td>Batch processing</td>
<td>Graph-based parallel computation</td>
<td>Stream and batch processing</td>
</tr>
<tr>
<td><strong>Architecture</strong></td>
<td>Shared-nothing, partitioned data</td>
<td>Cluster-based, distributed</td>
<td>DAG of tasks</td>
<td>Distributed, supports DAG</td>
</tr>
<tr>
<td><strong>Data Model</strong></td>
<td>Relational operations (SQL-like)</td>
<td>Key-value pairs</td>
<td>Data flow in DAG</td>
<td>Stream processing with state</td>
</tr>
<tr>
<td><strong>Partitioning</strong></td>
<td>Horizontal partitioning</td>
<td>Data split into chunks</td>
<td>Data partitioned across graph</td>
<td>Data partitioned into streams</td>
</tr>
<tr>
<td><strong>Fault Tolerance</strong></td>
<td>Limited</td>
<td>Checkpointing</td>
<td>Task-level recovery</td>
<td>State snapshots, exactly-once</td>
</tr>
<tr>
<td><strong>Programming</strong></td>
<td>Relational (SQL-style)</td>
<td>Functional (Map&#x2F;Reduce)</td>
<td>Sequential tasks in DAG</td>
<td>Functional, stream APIs</td>
</tr>
<tr>
<td><strong>Scalability</strong></td>
<td>Hundreds of processors</td>
<td>Horizontally across many nodes</td>
<td>Scales with more nodes</td>
<td>Highly scalable, stream and batch</td>
</tr>
<tr>
<td><strong>Use Case</strong></td>
<td>Database query processing</td>
<td>Log processing, data aggregation</td>
<td>Scientific computing</td>
<td>Real-time analytics, event processing</td>
</tr>
</tbody></table>
<p><strong>Will a version of Gamma using FLOW be more modular than its current design?</strong></p>
<p>Yes. FLOW enables more fine-grained control over the data flow and process interactions, which could simplify the addition of new operators and functionalities. It would also make the system easier to maintain and extend, as each component could be developed and optimized independently.</p>
<p>Reference: <a href="https://pages.cs.wisc.edu/~dewitt/includes/paralleldb/ieee90.pdf">https://pages.cs.wisc.edu/~dewitt/includes/paralleldb/ieee90.pdf</a></p>
]]></content>
      <categories>
        <category>数据库系统</category>
      </categories>
  </entry>
  <entry>
    <title>DynamoDB</title>
    <url>/undefined/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2024/10/03/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/DynamoDB/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><p>Amazon DynamoDB 将 Dynamo 的增量扩展能力和可预测的高性能与 SimpleDB 的易用表模型和强一致性相结合，既避免了自建大型数据库系统所带来的运维复杂性，又突破了 SimpleDB 在存储容量、请求吞吐和查询／写入延迟方面的局限；同时，DynamoDB 作为一款无服务器、全托管的 NoSQL 服务，内置自动扩缩容、安全加固和多区域复制，让开发者能够专注于业务逻辑，而无需管理底层基础设施。</p>
<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>一个 DynamoDB 表是多个条目的集合，或者具体来说是 KV 存储，每个条目由多个属性组成并且通过主键唯一标识。主键的模式在创建表时指定，主键模式包含分区键，或者分区键和排序键一起（也就是复合主键）。分区键的值总是作为内部哈希函数的输入，该哈希函数的输出和排序键的值（如果存在）共同决定该条目的存储位置（分区）。在具有复合主键的表中，多个条目可以具有相同的分区键值，但这些项目必须具有不同的排序键值。</p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/DynamoDB_KV_struct.drawio.png" alt="img"></p>
<p>DynamoDB 支持二级索引，一个表可以拥有一个或多个二级索引。二级索引允许使用除主键之外的备用键来查询表中的数据，这个备用键说白了就是二级索引键。</p>
<p>假设我们有一个游戏得分表 <code>GameScores</code>，记录玩家在不同游戏中的最高得分，表结构定义如下：</p>
<p>主表的表名是 <code>GameScores</code>，主键的设置如下：</p>
<ul>
<li>分区键：<code>UserId</code> (String)；</li>
<li>排序键：<code>GameId</code> (String)。</li>
</ul>
<p>在这种设计下，针对单个用户查询他们在某个游戏里的得分非常高效，但如果我们想要按 <strong>游戏名称</strong>（<code>GameTitle</code>）或 <strong>得分排名</strong>（<code>TopScore</code>）来查询所有玩家的成绩，就无法直接使用主键查询。</p>
<p>为满足上述查询需求，我们可以在表中添加一个全局二级索引 <code>GameTitleIndex</code>，其备用键（索引键）定义如下：</p>
<ul>
<li>索引名：<code>GameTitleIndex</code>；</li>
<li>分区键：<code>GameTitle</code> (String)；</li>
<li>排序键：<code>TopScore</code> (Number)。</li>
</ul>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/DynamoDB_opers.png" alt="img"></p>
<p>上表列出了客户端在 DynamoDB 表中读取和写入项目时可用的主要操作。任何插入、更新或删除项目的操作都可以带有一个条件，只有在该条件满足时操作才会成功。该条件判断在高并发场景中可避免多个客户端对同一项条目进行冲突性写入，例如只在某属性值符合预期时才更新。</p>
<p>此外，DynamoDB 支持 ACID 事务，使应用程序能够在更新多个项目时保证原子性、一致性、隔离性和持久性（ACID），而不会影响 DynamoDB 表的可扩展性、可用性和性能特性。</p>
<p>之前提到过，DynamoDB 表被拆分为多个分区，以满足表的吞吐量和存储需求。每个分区承载表键值范围中不重叠的一个连续区段，并在不同可用区分布多个副本，以实现高可用性和持久性。这些副本组成一个复制组，采用 Multi-Paxos 协议进行领导者选举与一致性达成。任一副本都可以发起选举，成为领导者后需定期续租，唯有领导者副本可处理写请求和强一致性读取。领导者在接收到写请求时，会生成预写日志并分发给其他副本，当多数副本将日志持久化后，才向客户端确认写入成功。DynamoDB 支持强一致性和最终一致性读取，其中任何副本都能提供最终一致性读取。若领导者被检测为失败或下线，其它副本可再次发起选举，新领导者在前领导者租约到期前不会处理写入或强一致性读取。复制组包含预写日志和以 B 树形式存储键值数据的存储副本。同时为了进一步提升可用性与持久性，复制组中还可包含仅持久化最近预写日志的日志副本，它们类似 Paxos 中的接受者，但不存储键值数据。也就是说，DynamoDB 的复制组中包含多个数据副本和多个日志副本。</p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/DynamoDB_s_replica.png" alt="img"></p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/DynamoDB_l_replica.png" alt="img"></p>
<p>DynamoDB 是由数十个微服务组成的，其中一些核心服务包括元数据服务、请求路由器服务、存储节点和自动管理服务。元数据服务存储有关表、索引以及给定表或索引的分区复制组的路由信息。请求路由器服务负责对每个请求进行授权、身份验证，并将其路由到相应的服务器。</p>
<p>所有的读取和更新请求都会被路由到承载客户数据的存储节点。请求路由器会从元数据服务中查询路由信息。所有资源创建、更新和数据定义请求则会被路由到自动管理服务。存储服务负责在一组存储节点上保存客户数据，每个存储节点会承载多个不同分区的副本。</p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/dynamodb_arch.png" alt="img"></p>
<p>在上图中，请求首先通过网络到达请求路由器（Request Router）服务，该服务依次调用认证系统进行 IAM 权限校验、查询分区元数据系统获取路由信息，并与全局准入控制（GAC）系统协作对表级吞吐进行限流，最后将请求转发至目标存储节点（Storage Node）进行数据读写操作。存储节点分布在多个可用区（AZ），采用 SSD 存储并在三个副本间使用 Paxos 算法选举主节点以提供写入一致性和读扩展能力，同时依靠副本复制实现高可用与耐久。认证系统通过 AWS IAM 服务简化身份验证与授权管理，分区元数据系统维护分区与存储节点的映射关系，而 GAC 则作为分布式令牌桶机制确保吞吐的可预测性与表级隔离。</p>
<p>这里需要强调的是，自动管理服务被构建为 DynamoDB 的中枢神经系统，它负责集群健康、分区健康、表的弹性扩缩以及所有控制平面请求的执行。该服务会持续监控所有分区的状态，并替换任何被判定为不健康（响应缓慢、无响应或运行在故障硬件上）的副本。它还会对 DynamoDB 的所有核心组件进行健康检查，并替换任何正在出现故障或已故障的硬件。例如，如果自动管理服务检测到某个存储节点不健康，它会启动恢复流程，把此前托管在该节点上的数据副本迁移或重建到其他健康的节点，以确保整个系统的复制组能够再次达到预期的副本数和健康状态。</p>
<blockquote>
<p>[!NOTE]</p>
<p>普遍意义上，控制平面是系统或网络中的大脑或指挥中心，负责管理、配置和决策，决定资源如何被创建、更新、删除以及如何路由请求；而实际的数据转发、存储和处理则由数据平面执行。控制平面通过一系列管理 API 与底层组件通信，实现对系统状态的监控、调度和恢复，从而保证整体的可用性、一致性和可扩展性。</p>
<p>因此，在 DynamoDB 中，控制平面并不仅仅指自动管理服务，而是由多种后台管理组件和它们所提供的管理 API 共同构成的一套系统。</p>
</blockquote>
<h2 id="从预配置到弹性伸缩"><a href="#从预配置到弹性伸缩" class="headerlink" title="从预配置到弹性伸缩"></a>从预配置到弹性伸缩</h2><p>在最初的 DynamoDB 版本中，开发者引入了分区的概念，以便能够动态地扩展表的容量和性能。系统最开始会将一张表切分为多个分区，使其内容能够分布到多台存储节点上，并且与这些节点的可用空间和性能相映射。当表的规模增大或访问负载上升时，系统可以进一步拆分分区并将其迁移，以实现弹性扩展。分区这一抽象证明了其极高的价值，并一直是 DynamoDB 设计的核心。</p>
<p>用户需要以读取吞吐量单位（RCU）和写入吞吐量单位（WCU）的形式，显式地指定一个表所需的吞吐量（预配置吞吐量）。对于不超过 4 KB 的条目，1 个 RCU 可每秒执行 1 次强一致性读取请求；对于不超过 1 KB 的条目，1 个 WCU 可每秒执行 1 次标准写入请求。</p>
<p>显然，早期版本将容量与性能的分配紧密耦合到各个分区，导致了若干挑战。DynamoDB 使用准入控制来确保存储节点不会过载，避免同机房中不同表的分区相互干扰，并强制执行客户所请求的吞吐量限制。</p>
<p>最初，一个表的所有存储节点共同承担准入控制的责任。每个存储节点会根据其本地所存放的分区的分配情况，独立地执行准入控制。由于一个节点通常会承载多个表的分区，系统便利用各分区的分配吞吐量来隔离不同表的工作负载。DynamoDB 会对单个分区可分配的最大吞吐量进行上限限制，同时确保某节点上所有分区的总吞吐量不超过由其存储介质物理特性所决定的该节点最大允许吞吐量。当表的整体吞吐量发生变化或分区被拆分时，系统会相应地调整各分区的分配吞吐量。若因表容量增长而拆分分区，子分区会从父分区继承并平均分配吞吐量；若因吞吐量需求增长而拆分分区，则新分区会按照表的预配置吞吐量进行分配。例如，假设某分区最大可承载 1000 WCU。创建一个具有 3200 WCU 的表时，DynamoDB 会生成 4 个分区，每个分区分配到 800 WCU；若将表的吞吐量提升至 3600 WCU，则每个分区可用吞吐量自动增至 900 WCU；若进一步提升至 6000 WCU，系统会拆分出 8 个子分区，每个分区分配到 750 WCU；若将吞吐量下调至 5000 WCU，则每个分区的吞吐量相应降至 675 WCU。</p>
<p>以上这种对各分区进行均匀吞吐量分配的做法基于如下假设：应用会均匀地访问表中各个键，且按容量拆分分区也会等比地拆分性能。但开发者发现，应用在不同时间和键范围上的访问模式常常并不均匀。当表内请求速率分布不均匀时，将分区拆分并按比例分配吞吐量，往往会导致热点区域拆分后可用性能反而低于拆分前的水平。由于吞吐量在分区层面上被静态分配和强制执行，这类非均匀工作负载偶尔会引发应用的读写请求被拒绝（即“限流”），即使整表的预配置吞吐量充足，也无法满足集中在少数键的高并发访问。</p>
<p><img src="/Users/yihangwei/blog/source/images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/DynamoDB_unbalanced_requests.drawio.png" alt="img"></p>
<p><img src="/Users/yihangwei/blog/source/images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/DynamoDB_throttling.drawio.png" alt="img"></p>
<p>在这种配置下，最常遇到的两个挑战是：<strong>热点分区</strong>（hot partitions）和<strong>吞吐量稀释</strong>（throughput dilution）。热点分区指的是访问始终集中在某些表项上的场景，这些热点可能稳定地落在某几个分区内，也可能随着时间在不同分区间跳动。吞吐量稀释则常出现在因扩容而按大小拆分分区的场景：拆分后，父分区的吞吐量被平均分配到新分区，使得每个分区的可用吞吐量降低。</p>
<p>从用户角度看，这两种情况都会导致资源被限流，使其应用在某些时段出现不可用。遭遇限流的用户往往会通过人为过度提升表的预配置吞吐量来规避问题，但这导致资源浪费、成本上升，并且难以准确估算所需性能。</p>
<p>因此，DynamoDB 在发布后不久就推出了两项改进，即突发容量和自适应容量，以解决这些问题。</p>
<h3 id="突发容量"><a href="#突发容量" class="headerlink" title="突发容量"></a>突发容量</h3><p>当开发者注意到各分区的访问模式并不均匀后，又发现并非所有分区在同一时刻都会耗尽为其分配的吞吐量。因此，为了在分区层面应对短时的工作负载高峰，DynamoDB 引入了突发（bursting）机制，其核心思想是在分区级别让应用可以按尽最大努力使用未被实时消耗的容量，以吸收短暂的访问激增。DynamoDB 会保留每个分区多达 300 秒的未使用容量，用于后续的突发性吞吐需求，这部分未用容量即称为突发容量（burst capacity）。</p>
<p><img src="/Users/yihangwei/blog/source/images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/DynamoDB_token_bucket.drawio.png" alt="img"></p>
<p>此外，为了仍然保证工作负载的隔离性，DynamoDB 要求分区只有在所在节点整体存在未用吞吐量时才能突发。系统在存储节点层面通过多组令牌桶来管理容量：每个分区对应两组桶（一个分配桶 allocated、一个突发桶 burst），整个节点还有一组节点桶 node。它们共同构成了准入控制的机制。</p>
<p>每当读或写请求到达存储节点时，系统首先检查对应分区的“分配桶”是否有剩余令牌。若有，则请求被接纳，并同时从该分区与节点级令牌桶中各扣减相应令牌。当分区分配桶中的令牌耗尽后，系统仅在<strong>分区突发桶</strong>和<strong>节点级桶</strong>均有可用令牌时，才允许继续处理（突发）请求。</p>
<p>而且，完全依据本地（本节点）令牌桶完成校验，无需跨副本通信。写请求除了检查本地突发桶和节点桶外，还需额外验证该分区其他副本所在节点的节点级令牌桶是否有余量，以保证跨副本一致性与可用性。为支持写请求的额外校验，分区的主副本会定期从各成员副本节点收集节点级令牌余量信息，并据此决定是否允许写请求突发。</p>
<h3 id="自适应容量"><a href="#自适应容量" class="headerlink" title="自适应容量"></a>自适应容量</h3><p>DynamoDB 推出了自适应容量（Adaptive Capacity）机制，专门用来应对那些持续时间比较长、突发容量救急不了的高峰期。自适应容量会持续监控所有表的预配置吞吐量和实际消耗情况；当表级别发生节流但整张表的吞吐量仍在预配置范围内时，系统会自动按比例控制算法动态提升该表中热点分区的分配吞吐量。如果表的总消耗超过预配置容量，则会相应地降低刚刚那些已接受提升的分区容量，以避免资源过度使用。自动管理服务等控制平面确保获得加速的分区被迁移到具备足够剩余能力的合适节点上，以保证性能提升能够得到支撑。与突发机制一样，自适应容量也是尽力而为的，但它能消除因访问倾斜导致的 99.99% 以上因为某几个热键访问量太高而被限流的尴尬，从而让应用跑得更稳，也更省钱。</p>
<h3 id="全局准入控制"><a href="#全局准入控制" class="headerlink" title="全局准入控制"></a>全局准入控制</h3><p>虽然 DynamoDB 通过突发和自适应容量在很大程度上缓解了非均匀访问带来的吞吐量问题，但这两种方案各有局限。突发机制仅能应对短时的流量峰值，并且依赖于节点本身还有剩余容量；自适应容量则属于被动响应，仅在检测到限流发生后才会启动，这意味着应用在此之前已经经历了短暂的不可用。两者的关键问题是：我们将分区级的容量管理紧密地和准入控制耦合起来了，而准入控制是分散在各个分区中执行的。换句话说，当用户往某个分区发请求时，这个分区自己就决定放行还是拒绝该请求。这种分区粒度的准入控制无法处理非均匀访问模式导致的热点，往往在整体容量闲置的情况下依然出现局部节流，因为每个分区的准入控制只能感知自身的吞吐量和资源使用情况。因此如果能够将准入控制从分区中剥离出来，让分区始终保持可 burst，同时又能保证不同工作负载之间的隔离，将更为高效。</p>
<p>为此，DynamoDB 用全局准入控制（Global Admission Control，GAC）取代了原有的自适应容量。GAC 依然基于令牌桶思想运行：一个中央服务持续监控全表范围内的令牌消耗情况，每个请求路由器在本地维护一个令牌桶；当应用请求到达时，先尝试从本地令牌桶中扣除令牌；当本地令牌不足时，再向 GAC 请求新的令牌。GAC 根据各路由器提交的消耗信息，动态计算并分发下一时间窗口内可用的全局令牌份额，确保即便流量集中在表中某些键上，也不会超过单个分区的最大处理能力。</p>
<p>与此同时，为了多层防护，DynamoDB 保留了分区级的令牌桶，并对其容量进行了上限限制，以防某个应用独占节点资源或过度消耗其存储节点上的吞吐量。这样，GAC 实现了跨分区的全局流量调度，而分区级令牌桶则继续在最底层保障多租户隔离。</p>
<h3 id="平衡消耗的容量"><a href="#平衡消耗的容量" class="headerlink" title="平衡消耗的容量"></a>平衡消耗的容量</h3><p>让分区始终保持突发（bursting）能力，就需要 DynamoDB 对突发容量进行有效管理。DynamoDB 在多种硬件实例类型上运行，这些实例在吞吐量和存储能力上各不相同。最新一代的存储节点上往往承载着数千个分区副本，这些分区可能完全无关联，属于不同表，甚至不同客户，而各表的访问模式也千差万别。要将这些副本安全地部署在同一节点上，又能保证可用性、稳定的性能、安全性和弹性，就必须设计出合理的分配方案。</p>
<p>如果只用预配置吞吐量，那很好办：分区数固定，按容量找机器，根本不用担心某个分区会多吃流量。但有了突发和自适应后，分区可能随时超出预设容量使用突发资源，这就意味着某些节点在短时内可能会超载，导致把多个数据分区放到同一台机器上变得棘手。</p>
<p>因此，为了在不牺牲可用性的前提下，提高节点利用率，DynamoDB 实现了一套主动均衡系统：每个存储节点独立监控其上所有分区副本的吞吐量和数据大小，一旦发现总吞吐量超过节点最大容量的阈值，就会向自动管理服务报告一批候选迁移分区。自动管理服务再为这些分区寻找新的存储节点（可在同可用区或跨可用区），确保新节点上尚未存在该分区的副本，从而将它们安全地搬迁出去，降低过度紧凑部署带来的可用性风险。</p>
<h3 id="拆分消费"><a href="#拆分消费" class="headerlink" title="拆分消费"></a>拆分消费</h3><p>DynamoDB 在引入全局准入控制和始终可突发能力后，发现当流量高度集中在某些键上时，仍可能出现节流。为此，它会根据分区的实际吞吐量自动扩展：当某个分区的消耗超过阈值时，系统会根据该分区的访问分布（而不是简单地把键范围对半拆分）选择最佳拆分点，将其分成两个子分区。这样可以更精准地将热点区域隔离出来，不过对于只针对单个键或按顺序访问整个键范围的场景，此方法并无优势；对此，DynamoDB 会自动识别并避免执行拆分操作。</p>
<h3 id="按需配置"><a href="#按需配置" class="headerlink" title="按需配置"></a>按需配置</h3><p>DynamoDB 还推出了按需表（On-Demand Tables）模式，帮助之前在本地或自建数据库上运行、需要手动配置服务器的应用解放运维负担，是一种无需用户预先规划吞吐量即可弹性扩缩的无服务器模式。按需表通过读写容量单位（RCU&#x2F;WCU）来自动弹性扩缩，系统会实时监控实际的读写请求量，并能瞬间承载到达表上的流量峰值的两倍。如果后续流量超过此前最大峰值的两倍，DynamoDB 会不断新增分区并按流量情况拆分，以保证应用不会因超出配额而被限流。全局准入控制则负责从整体上监控并保护系统，防止单个应用抢占所有资源；加上基于消耗量的智能分区调度，按需表能够高效利用节点资源，避免触及节点级别的容量上限，让应用在任何突发流量下都能平稳运行。</p>
<h1 id="Durability-and-correctness"><a href="#Durability-and-correctness" class="headerlink" title="Durability and correctness"></a>Durability and correctness</h1><h2 id="Hardware-failures"><a href="#Hardware-failures" class="headerlink" title="Hardware failures"></a>Hardware failures</h2><p>The write-ahead logs in DynamoDB are crucial for ensuring data durability and crash recovery. Each partition has three replicas that store the write-ahead logs. To enhance durability, the logs are periodically archived to Amazon S3. The unarchived logs typically amount to a few hundred megabytes.</p>
<p>In large-scale systems, hardware failures such as memory or disk failures are common. When a node fails, all replication groups hosted on that node are reduced to two copies. The process of repairing a storage replica can take several minutes, as it involves copying both the B-tree and the write-ahead logs.</p>
<p>When the system detects an unhealthy replica, the leader of the replication group adds a log replica to ensure data durability is not compromised. Since only the recent write-ahead logs need to be copied without the B-tree, adding the log replica takes just a few seconds. This quick addition helps restore the affected replication group, ensuring that the most recent writes remain highly durable.</p>
<h2 id="Silent-data-errors"><a href="#Silent-data-errors" class="headerlink" title="Silent data errors"></a>Silent data errors</h2><p>Hardware failures can cause incorrect data storage: In DynamoDB, errors may occur due to issues with storage media, CPU, or memory, and these errors are often difficult to detect.</p>
<p>Extensive use of checksums: DynamoDB maintains checksums for every log entry, message, and log file to detect silent errors and ensure data integrity during each data transfer. When messages are transmitted between nodes, checksums verify whether errors occurred during transmission.</p>
<p>Log archiving and validation: Each log file archived to S3 has a manifest that records details such as the table, partition, and data markers. Before uploading, the archiving agent performs various checks, including checksum validation, verifying that the log belongs to the correct table and partition, and ensuring that there are no gaps in the sequence numbers.</p>
<p>Multiple replica log archiving: Log archiving agents run on all three replicas. If one agent finds that a log file has already been archived, it downloads the file and compares it with the local write-ahead log to verify data integrity.</p>
<p>Checksum validation during S3 upload: Every log file and manifest file is uploaded to S3 with a content checksum. S3 verifies this checksum during the upload process to catch any errors in data transmission.</p>
<h2 id="Continuous-verification"><a href="#Continuous-verification" class="headerlink" title="Continuous verification"></a>Continuous verification</h2><p>Continuous Data Integrity Verification: DynamoDB continuously verifies data at rest to detect silent data errors and bit rot, which can occur due to hardware failures or data corruption. This is a critical defense mechanism for maintaining data reliability.</p>
<p>Scrub Process: The scrub process is central to detecting unforeseen errors. It checks two main aspects:</p>
<ul>
<li><strong>Replica Consistency</strong>: Ensures that all three replicas in a replication group have identical data.</li>
<li><strong>Archived Log Reconstruction</strong>: Rebuilds an offline replica using archived write-ahead logs from S3 and verifies that it matches the live replica.</li>
</ul>
<p>Verification Mechanism: Scrub computes checksums for the live replicas and compares them with those generated from replicas built using archived logs.</p>
<p>Defense in Depth: This mechanism ensures that live storage replicas and those rebuilt from historical logs remain consistent, providing confidence in the system’s integrity and reliability.</p>
<h2 id="Backups-and-restores"><a href="#Backups-and-restores" class="headerlink" title="Backups and restores"></a>Backups and restores</h2><p>Backup and Restore Mechanism: DynamoDB supports backup and restore to protect against logical corruption caused by bugs in customer applications. Backups and restores are built using write-ahead logs stored in S3 and do not affect table performance or availability.</p>
<p>Backup Consistency: Backups are full copies of DynamoDB tables, consistent across multiple partitions to the nearest second, and stored in Amazon S3. Data can be restored to a new DynamoDB table at any time.</p>
<p>Point-in-Time Restore: DynamoDB supports point-in-time restore, allowing customers to restore a table to any point within the last 35 days. This feature creates periodic snapshots of table partitions and stores them in S3.</p>
<p>Snapshots and Write-Ahead Logs: For point-in-time restore, DynamoDB identifies the closest snapshots to the requested time, applies the corresponding write-ahead logs, and restores the table to the desired state.</p>
<h1 id="Availability"><a href="#Availability" class="headerlink" title="Availability"></a>Availability</h1><h2 id="Write-and-consistent-read-availability"><a href="#Write-and-consistent-read-availability" class="headerlink" title="Write and consistent read availability"></a>Write and consistent read availability</h2><p>Write Availability: DynamoDB partition write availability depends on having a healthy leader and a healthy write quorum. A write quorum in DynamoDB requires two out of three replicas across different Availability Zones (AZs) to be healthy.</p>
<p>Handling Write Quorum Failures: <strong>If one replica becomes unresponsive, the leader adds a log replica, which is the fastest way to meet the quorum requirement and minimize write disruptions caused by an unhealthy quorum.</strong></p>
<p>Consistent Reads: Consistent reads are served by the leader replica. <strong>If the leader fails, other replicas detect the failure and elect a new leader to minimize disruptions to consistent read availability.</strong></p>
<p>Impact of Log Replicas: The introduction of log replicas was a significant system change. The use of the formally proven Paxos protocol provided confidence to safely implement this change, increasing system availability. DynamoDB can run millions of Paxos groups with log replicas in a single region.</p>
<p>Eventually Consistent Reads: Eventually consistent reads can be served by any of the replicas.</p>
<h2 id="Failure-detection"><a href="#Failure-detection" class="headerlink" title="Failure detection"></a>Failure detection</h2><p>New Leader Waits for Lease Expiry: A newly elected leader must wait for the old leader’s lease to expire before handling traffic, causing a few seconds of disruption where no new writes or consistent reads can be processed.</p>
<p>Importance of Leader Failure Detection: Quick and robust leader failure detection is crucial for minimizing disruptions. False positives in failure detection can lead to unnecessary leader elections, further disrupting availability.</p>
<p>Impact of Gray Network Failures: Gray network failures, such as communication issues between nodes or routers, can result in false or missed failure detections. These failures can trigger unnecessary leader elections, causing availability interruptions.</p>
<p>Improved Failure Detection Algorithm: To address the availability issues caused by gray failures, DynamoDB’s failure detection algorithm was improved. <strong>When a follower attempts to trigger a failover, it first checks with other replicas to see if they can still communicate with the leader. If they report the leader is healthy, the follower cancels the failover attempt.</strong> This change significantly reduced false leader elections and minimized availability disruptions.</p>
<h2 id="Metadata-availability"><a href="#Metadata-availability" class="headerlink" title="Metadata availability"></a>Metadata availability</h2><p>Metadata Needs for Request Routers: DynamoDB’s request routers require metadata mapping between table primary keys and storage nodes. Initially, this metadata was stored in DynamoDB, and the routers cached it locally. Although the cache hit rate was high, cache misses or cold starts caused metadata lookup traffic spikes, potentially destabilizing the system.</p>
<p>Caching Challenges: When caches failed or during cold starts, request routers frequently queried the metadata service, putting immense pressure on it and leading to cascading failures in other parts of the system.</p>
<p>Introduction of MemDS: <strong>To reduce reliance on local caches, DynamoDB introduced MemDS, a distributed in-memory data store for storing and replicating metadata.</strong> MemDS scales horizontally to handle all incoming requests and stores data in a compressed format. It uses a Perkle tree structure, combining Patricia and Merkle tree features for efficient key lookups and range queries.</p>
<p>Perkle Tree Operations: MemDS supports efficient key lookups, range queries, and special operations like floor (find the largest key ≤ given key) and ceiling (find the smallest key ≥ given key) for metadata retrieval.</p>
<p>New Partition Map Cache: DynamoDB implemented a new cache on request routers, addressing the issues of bimodal behavior. Even when a cache hit occurs, an asynchronous call is made to MemDS to refresh the cache. This ensures that MemDS consistently handles a steady volume of traffic, preventing reliance on cache hit ratios and avoiding cascading failures when caches become ineffective.</p>
<p>Partition Membership Updates: DynamoDB storage nodes, the authoritative source of partition membership data, push updates to MemDS. If a request router queries an incorrect storage node due to outdated information, the node provides updated membership data or triggers a new MemDS lookup.</p>
<h1 id="Programming-Interface"><a href="#Programming-Interface" class="headerlink" title="Programming Interface"></a>Programming Interface</h1><ol>
<li><p><strong>Key-Value Store</strong></p>
<p>DynamoDB allows users to create tables that can grow almost indefinitely. Each table is a collection of items, and each item is a collection of attributes. Each item is uniquely identified by a primary key, ensuring uniqueness within the table. DynamoDB provides a simple interface to store or retrieve items from a table or an index.</p>
</li>
<li><p><strong>Read and Write Operations</strong></p>
<p>DynamoDB operates as a key-value store, and the most common operations used by applications involve reading and writing data. These operations include:</p>
<ul>
<li><p><strong>GetItem</strong>: Retrieves an item with a given primary key.</p>
</li>
<li><p><strong>PutItem</strong>: Inserts a new item or replaces an existing one.</p>
</li>
<li><p><strong>UpdateItem</strong>: Updates an existing item, or adds it if it doesn’t exist.</p>
</li>
<li><p><strong>DeleteItem</strong>: Deletes an item from the table based on the primary key.</p>
</li>
</ul>
<p>These last three operations (PutItem, UpdateItem, and DeleteItem) are collectively referred to as writes. A write operation can optionally include conditions that must be satisfied for the operation to be executed successfully. For instance, you could specify that a PutItem operation should only succeed if the item doesn’t already exist.</p>
</li>
<li><p><strong>Transactional Operations</strong></p>
<p>DynamoDB supports transactions through two key operations:</p>
<ul>
<li><p><strong>TransactGetItems</strong>: Used for reading multiple items atomically. It retrieves the latest versions of items from one or more tables at a single point in time, ensuring consistency. If any conflicting operation is modifying an item that’s being read, the transaction will be rejected.</p>
</li>
<li><p><strong>TransactWriteItems</strong>: This is used for performing atomic writes across multiple items and tables. It allows you to create, update, or delete multiple items in one or more tables within a single atomic transaction. This ensures that either all changes happen, or none do. The operation is synchronous and idempotent (meaning it can be retried without causing duplicate effects). TransactWriteItems can include conditions on the current values of the items, and the operation is rejected if these conditions aren’t met.</p>
</li>
</ul>
</li>
</ol>
<h1 id="Transactions"><a href="#Transactions" class="headerlink" title="Transactions"></a>Transactions</h1><p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/dynamodb_txn.png" alt="img"></p>
<p><strong>Request Router (RR)</strong>:</p>
<ul>
<li>The <strong>Request Router</strong> is the first major component that handles incoming requests after they pass through the network.</li>
<li><strong>Authentication and Authorization</strong>: RR typically interacts with an <strong>Authentication System</strong> to ensure that the request is valid and the user has the proper permissions to access or modify the data.</li>
<li><strong>Routing Requests</strong>: Once a request is authenticated, the RR determines which <strong>Storage Nodes</strong> the request should be forwarded to. It uses the <strong>Metadata System</strong> to map the key(s) involved in the request to the correct storage nodes, as the data is distributed across many nodes.</li>
<li><strong>Forwarding Requests</strong>: Depending on whether the operation is a simple read&#x2F;write or part of a larger transaction, the RR may route the request directly to storage nodes or to the Transaction Coordinator.</li>
</ul>
<p><strong>Transaction Coordinator (TC)</strong>:</p>
<ul>
<li>The <strong>Transaction Coordinator</strong> plays a central role in handling transactions that span multiple items or storage nodes.</li>
<li><strong>Transaction Management</strong>: For requests that involve multiple storage nodes or require consistency (e.g., multi-item writes in a transaction), the RR forwards the request to the TC. The TC is responsible for breaking down the transaction into individual operations and coordinating these operations across the necessary storage nodes.</li>
<li><strong>Distributed Transaction Execution</strong>: The TC ensures that the operations follow the appropriate protocol (e.g., two-phase commit) to guarantee atomicity and consistency, ensuring that all parts of the transaction are either completed successfully or rolled back.</li>
<li><strong>Timestamp Assignment and Conflict Resolution</strong>: In a timestamp-based system like DynamoDB, the TC may assign timestamps to ensure the correct ordering of operations and manage any potential conflicts between concurrent transactions.</li>
</ul>
<p>In summary:</p>
<ul>
<li><strong>Request Router (RR)</strong> handles initial authentication and routing of requests to the appropriate storage nodes or transaction coordinator.</li>
<li><strong>Transaction Coordinator (TC)</strong> manages distributed transactions, ensuring data consistency and handling multi-node operations.</li>
</ul>
<h1 id="Transaction-execution"><a href="#Transaction-execution" class="headerlink" title="Transaction execution"></a>Transaction execution</h1><ol>
<li><p><strong>Transaction Routing</strong></p>
<p>All operation requests first reach a set of frontend hosts known as request routers. These routers are responsible for authenticating the requests and routing them to the appropriate storage nodes. Storage nodes are mapped based on key ranges. For transaction management, the routers forward transaction operations to transaction coordinators.</p>
<p>Transaction coordinators break down the transaction into multiple operations targeting different items and coordinate the execution of these operations across the storage nodes using a distributed protocol.</p>
</li>
<li><p><strong>Timestamp Ordering</strong></p>
<p>Each transaction is assigned a timestamp that defines its logical execution order. Multiple transaction coordinators operate in parallel, and different coordinators assign timestamps to different transactions. As long as transactions execute in the assigned order, serializability is maintained.</p>
<p>The storage nodes are responsible for ensuring that the operations on the items they manage are executed in the correct order and rejecting transactions that cannot be properly ordered.</p>
</li>
<li><p><strong>Write Transaction Protocol</strong></p>
<p>DynamoDB uses a two-phase commit protocol to ensure that the write operations within a transaction are atomic and executed in the correct order. In the prepare phase, the coordinator prepares all the write operations. If all storage nodes accept the operations, the transaction is committed; otherwise, it is canceled.</p>
<p>The storage nodes record the timestamp and metadata of each item involved in the transaction to ensure the transaction is handled correctly.</p>
</li>
<li><p><strong>Read Transaction Protocol</strong></p>
<p>Read transactions also use a two-phase protocol, but it differs from the write transaction protocol. DynamoDB designed a two-phase read protocol without write operations to avoid adding latency and costs to reads.</p>
<p>In the first phase, the coordinator reads all the items involved in the transaction, along with their Log Sequence Numbers (LSN). In the second phase, if the LSN has not changed, the read is successful; otherwise, the read is rejected.</p>
</li>
<li><p><strong>Recovery and Fault Tolerance</strong></p>
<p>If a storage node fails, the leadership role transfers to another storage node within the same replication group, with transaction metadata persistently stored and replicated across the nodes.</p>
<p>Transaction coordinator failures are more complex. Coordinators maintain a persistent record of each transaction to ensure atomicity and completeness. Recovery managers periodically scan these transaction records, looking for incomplete transactions, and reassign them to new coordinators to resume execution.</p>
</li>
</ol>
<h1 id="Two-phase-commit-2PC"><a href="#Two-phase-commit-2PC" class="headerlink" title="Two-phase commit (2PC)"></a>Two-phase commit (2PC)</h1><ol>
<li><p><strong>Prepare Phase</strong></p>
<p>In the prepare phase, the transaction coordinator (TC) is responsible for sending the transaction’s write operations to all the participating storage nodes. The coordinator breaks down the transaction into individual operations targeting specific data items and sends a prepare message to each storage node involved. This message includes:</p>
<ul>
<li><p>The transaction’s timestamp.</p>
</li>
<li><p>The transaction’s unique identifier (ID).</p>
</li>
<li><p>The specific operation to be performed on the data item (such as insert, update, or delete).</p>
</li>
</ul>
<p>Upon receiving the prepare message, each storage node evaluates whether it can accept the transaction. The storage node will accept the transaction’s write operation if all of the following conditions are met:</p>
<ul>
<li><p><strong>Preconditions</strong> are satisfied (e.g., a condition might be that the item must exist, or that it has a certain value).</p>
</li>
<li><p>The write operation does not violate any <strong>system restrictions</strong> (e.g., exceeding the maximum item size).</p>
</li>
<li><p>The transaction’s timestamp is <strong>greater than</strong> the item’s last write timestamp, indicating that this operation is the most recent.</p>
</li>
<li><p>There are no <strong>ongoing transactions</strong> attempting to write to the same item.</p>
</li>
</ul>
<p>If all participating storage nodes accept the transaction during the prepare phase, the coordinator moves to the commit phase. If any node rejects the transaction (e.g., due to a failed precondition or timestamp conflict), the transaction is canceled.</p>
</li>
<li><p><strong>Commit Phase</strong></p>
<p>Once the transaction has been accepted by all storage nodes during the prepare phase, the coordinator enters the commit phase. During this phase, the coordinator sends a commit message to all the storage nodes, instructing them to apply the write operations. Each storage node then:</p>
<ul>
<li><p>Applies the prepared write operations to the local items.</p>
</li>
<li><p>Updates the <strong>timestamp</strong> of the item to reflect the transaction’s timestamp.</p>
</li>
<li><p>Updates the timestamps of any items where preconditions were checked, even if no write operation was performed.</p>
</li>
</ul>
<p>If any node rejects the transaction during the prepare phase, the coordinator sends a cancel message to all storage nodes, instructing them to discard any prepared changes. No writes are applied, ensuring atomicity.</p>
</li>
</ol>
<h1 id="Adapting-timestamp-ordering-for-key-value-operations"><a href="#Adapting-timestamp-ordering-for-key-value-operations" class="headerlink" title="Adapting timestamp ordering for key-value operations"></a>Adapting timestamp ordering for key-value operations</h1><ol>
<li><p><strong>Individual Item Read Operations</strong></p>
<p>In DynamoDB, even if there is a prepared transaction attempting to read to a particular data item, the system still allows read operations on that item. Specifically:</p>
<ul>
<li><p><strong>Bypassing the transaction coordinator</strong>: Non-transactional <code>GetItem</code> operations are routed directly to the storage node responsible for the item, bypassing the transaction coordinator. This avoids potential transaction locks or delays.</p>
</li>
<li><p><strong>Returning the latest data immediately</strong>: The storage node immediately returns the latest committed value of the item, regardless of whether a prepared transaction may later update it.</p>
</li>
<li><p><strong>Timestamp assignment</strong>: This read operation is assigned a timestamp that is after the last write operation’s timestamp but before the prepared transaction’s commit timestamp. This ensures the read operation is serializable, meaning it is placed between the last completed write and the pending write.</p>
</li>
</ul>
</li>
<li><p><strong>Individual Item Write Operations</strong></p>
<p>In most cases, DynamoDB allows individual item write operations to be executed immediately, often before prepared transactions:</p>
<ul>
<li><p><strong>Directly routed to the storage node</strong>: Non-transactional <code>PutItem</code> and other modification operations are routed directly to the storage node, bypassing the transaction coordinator.</p>
</li>
<li><p><strong>Timestamp ordering</strong>: The storage node assigns a timestamp to the write operation that is typically earlier than any prepared transactions (since those have not yet written).</p>
</li>
<li><p><strong>Exceptions</strong>: If a prepared transaction includes a condition check on the item (e.g., checking a bank account balance), the system will not allow a new write to bypass the prepared transaction. For example, if a transaction is checking that there are enough funds to withdraw $100, a new transaction cannot make a withdrawal or delete the item during that check.</p>
</li>
</ul>
</li>
<li><p><strong>Delayed Execution of Write Operations</strong></p>
<p>In certain scenarios, the system can delay write operations instead of rejecting them:</p>
<ul>
<li><p><strong>Buffering writes</strong>: If a new write operation conflicts with a prepared transaction’s conditions (e.g., by modifying the item’s state), the storage node can buffer the write operation in a queue until the prepared transaction is complete. This prevents the need to reject the write and require the client to resubmit it.</p>
</li>
<li><p><strong>Processing buffered writes after the transaction completes</strong>: Once the prepared transaction completes (committed or canceled), the buffered write can be assigned a new timestamp and executed. Typically, the delay caused by waiting for the transaction to complete is short, so this strategy doesn’t significantly increase latency.</p>
</li>
<li><p><strong>Unconditional writes</strong>: If the storage node receives a <code>PutItem</code> or <code>DeleteItem</code> operation without any preconditions, these operations can be executed immediately. They are assigned a timestamp later than any prepared transactions, ensuring the correctness of transactions. If a previously prepared transaction is committed with an earlier timestamp, its write operations will be ignored.</p>
</li>
</ul>
</li>
<li><p><strong>Write Transactions with Older Timestamps</strong></p>
<p>DynamoDB supports accepting write transactions with older timestamps:</p>
<ul>
<li><p><strong>Handling after already committed writes</strong>: If a write transaction with an older timestamp arrives at a storage node where a later write has already been processed, the node can still accept the older transaction and mark it as prepared. If the transaction is eventually committed, its write will be ignored, as the earlier write has already been overwritten by the newer one.</p>
</li>
<li><p><strong>Exceptions for partial updates</strong>: This rule applies to full overwrites of data items (like <code>PutItem</code>), but not to partial updates (like <code>UpdateItem</code>). If the last write was a partial update, the operations must be executed in strict timestamp order to ensure correctness.</p>
</li>
</ul>
</li>
<li><p><strong>Multiple Transactions Writing to the Same Item</strong></p>
<p>DynamoDB allows multiple transactions to simultaneously prepare to write the same data item:</p>
<ul>
<li><p><strong>Simultaneous transaction preparation</strong>: For a given item, a series of transactions can enter the prepared state simultaneously, without waiting for the previous transaction to commit. This increases concurrency and allows multiple transactions to proceed in parallel.</p>
</li>
<li><p><strong>Order of transaction commits</strong>: If the write operations are full item overwrites (like <code>PutItem</code> or <code>DeleteItem</code>), the transactions can be committed in any order, as long as the last <code>PutItem</code> or <code>DeleteItem</code> operation (with the latest timestamp) is the final one executed.</p>
</li>
<li><p><strong>Restrictions for partial updates</strong>: For transactions performing partial updates (like <code>UpdateItem</code>), the transactions must be executed in timestamp order, as the final state of the item depends on the sequence of updates.</p>
</li>
</ul>
</li>
<li><p><strong>Optimized Single-Phase Read Transactions</strong></p>
<p>DynamoDB introduces optimizations for read transactions, allowing certain read transactions to be completed in a single phase without requiring a two-phase commit protocol:</p>
<ul>
<li><p><strong><code>GetItemWithTimestamp</code></strong>: Assuming storage nodes support the <code>GetItemWithTimestamp</code> operation, it allows a read timestamp to be passed as a parameter. This operation returns the latest value of the item, provided its last write timestamp is earlier than the given read timestamp and any prepared transactions have timestamps later than the read timestamp; otherwise, the request is rejected.</p>
</li>
<li><p><strong>Single-phase completion of read transactions</strong>: When a read transaction involves multiple items, the transaction coordinator issues <code>GetItemWithTimestamp</code> requests for each item and buffers the returned values. If all storage nodes accept the requests without conflict, the coordinator can return the buffered values to the client, completing the transaction. If any node rejects the request, the read transaction fails.</p>
</li>
<li><p><strong>Serialization issues</strong>: This optimization is optimistic but can lead to potential serialization issues. If a storage node later accepts a write with a timestamp earlier than a previously executed read transaction, it may cause the transaction to be non-serializable. To avoid this, storage nodes need to track both the last read and write timestamps for each item. Future write transactions must ensure that their timestamps are later than the last read&#x2F;write timestamps of all the items they modify.</p>
</li>
</ul>
</li>
<li><p><strong>Optimizations for Single-Partition Write Transactions</strong></p>
<p>DynamoDB further optimizes write transactions that involve multiple items within a single partition, allowing them to be completed in a single phase without a two-phase commit protocol:</p>
<ul>
<li><p><strong>Single-partition transaction processing</strong>: If all the items being written in a transaction reside within the same partition (and thus are stored on the same storage node), there is no need for separate prepare and commit phases. The storage node can perform all the necessary precondition checks and immediately execute the write operations.</p>
</li>
<li><p><strong>Reduced communication overhead</strong>: This approach significantly reduces the communication overhead between the transaction coordinator and storage nodes, especially in highly concurrent environments, improving system performance.</p>
</li>
</ul>
</li>
</ol>
<h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h1><p><strong>Why does DynmoDB not use the two-phase locking protocol?</strong> </p>
<p>While two-phase locking is used traditionally to prevent concurrent transactions from reading and writing the same data items, it has drawbacks. Locking <strong>restricts concurrency</strong> and can lead to <strong>deadlocks</strong>. Moreover, it requires <strong>a recovery mechanism</strong> to release locks when an application fails after acquiring locks as part of a transaction but before that transaction commits. To simplify the design and take advantage of low-contention workloads, DynamoDB uses an optimistic concurrency control scheme that avoids locking altogether.</p>
<p><strong>With DynamoDB, what is the role of a transaction coordinator?</strong></p>
<ul>
<li>The <strong>Transaction Coordinator</strong> plays a central role in handling transactions that span multiple items or storage nodes. The TC is responsible for</li>
<li><ul>
<li>breaking down the transaction into individual operations and coordinating these operations across the necessary storage nodes.</li>
<li>ensuring that the operations follow two-phase commit and all parts of the transaction are either completed successfully or rolled back.</li>
<li>assigning timestamps to ensure the correct ordering of operations and managing any potential conflicts between concurrent transactions.</li>
</ul>
</li>
</ul>
<p><strong>Is DynamoDB a relational database management system?</strong></p>
<p>No, DynamoDB is not a relational database management system (RDBMS). It is a NoSQL database, specifically a key-value and document store. Here’s how it differs from an RDBMS:</p>
<ol>
<li><strong>Data Model</strong>: DynamoDB does not use tables with fixed schemas like relational databases. Instead, it stores data as key-value pairs or documents (JSON-like structure). Each item can have different attributes, and there’s no need for predefined schemas.</li>
<li><strong>Relationships</strong>: Relational databases focus on managing relationships between data (using joins, foreign keys, etc.), while DynamoDB is optimized for storing large amounts of data without complex relationships between the data items.</li>
<li><strong>Querying</strong>: RDBMSs typically use <strong>SQL</strong> for querying data, which allows for complex joins and aggregations. DynamoDB uses its own API for querying and does not support SQL natively. While it allows querying by primary key and secondary indexes, it doesn’t support joins.</li>
<li><strong>Consistency and Transactions</strong>: DynamoDB supports <strong>eventual consistency</strong> or <strong>strong consistency</strong> for reads, while traditional relational databases typically ensure strong consistency through ACID transactions. DynamoDB has introduced <strong>transactions</strong>, but they work differently compared to those in relational databases.</li>
<li><strong>Scalability</strong>: DynamoDB is designed for horizontal scalability across distributed systems, allowing it to handle very large amounts of traffic and data by automatically partitioning data. In contrast, RDBMSs are typically vertically scaled and are not as naturally distributed.</li>
</ol>
<p><strong>How is DynamoDB’s transaction coordinator different than Gamma’s scheduler?</strong> </p>
<ul>
<li>DynamoDB’s transaction coordinator uses Optimistic Concurrency Control (OCC) to manage distributed transactions, ensuring atomicity without 2PC, focusing on scalability and performance in a globally distributed system.</li>
<li>Gamma’s scheduler, on the other hand, uses the traditional Two-Phase Locking (2PL) protocol to guarantee strong consistency in a distributed environment, prioritizing strict coordination across nodes.</li>
</ul>
<p><strong>Name one difference between FoundationDB and DynamoDB?</strong></p>
<p>FoundationDB: FoundationDB is a multi-model database that offers a core key-value store as its foundation, but it allows you to build other data models (such as documents, graphs, or relational) on top of this key-value layer. It’s highly flexible and provides transactional support for different types of data models via layers.</p>
<p>DynamoDB: DynamoDB is a NoSQL key-value and document store with a fixed data model designed specifically for highly scalable, distributed environments. It does not offer the flexibility of building different models on top of its architecture and is focused on high-performance operations with automatic scaling.</p>
<p><strong>What partitioning strategy does FoundationDB use to distribute key-value pairs across its StorageServers?</strong></p>
<p>FoundationDB uses a range-based partitioning strategy to distribute key-value pairs across its StorageServers.</p>
<p>Here’s how it works:</p>
<ol>
<li><strong>Key Ranges</strong>: FoundationDB partitions the key-value pairs by dividing the key space into <strong>contiguous ranges</strong>. Each range of keys is assigned to a specific <strong>StorageServer</strong>.</li>
<li><strong>Dynamic Splitting</strong>: The key ranges are <strong>dynamically split</strong> and adjusted based on data distribution and load. If a particular range grows too large or becomes a hotspot due to frequent access, FoundationDB will automatically split that range into smaller sub-ranges and distribute them across multiple <strong>StorageServers</strong> to balance the load.</li>
<li><strong>Data Movement</strong>: When a key range is split or needs to be rebalanced, the corresponding data is migrated from one <strong>StorageServer</strong> to another without manual intervention, ensuring even distribution of data and load across the system.</li>
</ol>
<p><strong>Why do systems such as Nova-LSM separate storage of data from its processing?</strong> </p>
<ul>
<li><strong>Independent Scaling</strong>: Storage and processing resources can scale independently to meet varying load demands.</li>
<li><strong>Resource Optimization</strong>: Storage nodes focus on data persistence and I&#x2F;O performance, while processing nodes handle computation, improving overall resource efficiency.</li>
<li><strong>Fault Tolerance</strong>: Data remains safe in storage even if processing nodes fail, ensuring high availability.</li>
</ul>
<p>Reference: </p>
<ul>
<li><a href="https://www.usenix.org/system/files/atc23-idziorek.pdf">https://www.usenix.org/system/files/atc23-idziorek.pdf</a></li>
<li><a href="https://www.usenix.org/system/files/atc22-elhemali.pdf">https://www.usenix.org/system/files/atc22-elhemali.pdf</a></li>
</ul>
]]></content>
      <categories>
        <category>数据库系统</category>
        <category>分布式系统</category>
      </categories>
  </entry>
  <entry>
    <title>HRPS</title>
    <url>/undefined/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/2024/09/12/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/HRPS/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>The HRPS declusters a relation into fragment based on the following criteria:</p>
<ul>
<li>Each fragment contains approximately FC tuples.</li>
<li>Each fragment contains a unique range of values of the partitioning attribute.</li>
</ul>
<p>The variable FC is determined based on the processing capability of the system and the resource requirements of the queries that access the relation (rather than the number of processors in the configuration).</p>
<p>A major underlying assumption of this partitioning strategy is that the selection operators which access the database retrieve and process the selected tuples using either a range predicate or an equality predicate.</p>
<p>For each query Qi, the workload defines the CPU processing time (CPUi), the Disk Processing Time (Diski), and the Network Processing time (Neti) of that query. Observe that these times are determined based on the resource requirements of each individual query and the processing capability of the system. Each query retrieves and processes (TuplesPerQi) tuples from the database. Furthermore, we assume that the workload defines the frequency of occurrence of each query (FreqQi).</p>
<p>Rather than describing the HRPS with respect to each query in the workload, we deline an average query (Qavg) that is representative of all the queries in the workload. The CPU, disk and network processing quanta for this query are:</p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/CPU_Disk_Net_TPQ.png" alt="截屏2025-05-30 18.28.03"></p>
<p>Assume that a single processor cannot overlap the use of two resources for an individual query. Thus, the execution time of Qavg on a single processor in a single user environment is:</p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/exe_time.png" alt="截屏2025-05-30 18.28.21"></p>
<p>As more processors are used for query execution, the response time decreases. However, this also incurs additional overhead, represented by the variable CP, which refers to the cost of coordinating the query execution across multiple processors (e.g., messaging overhead). The response time of the query on M processors can be described by the following formula:</p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/RT_M.png" alt="RT_M"></p>
<p>In a single-user environment, both HRPS and range partitioning perform similarly because they both efficiently execute the query on the required processor. However, in a multi-user environment, the range partitioning strategy is likely to perform better because it can distribute the workload across multiple processors, improving system throughput. In contrast, HRPS might not utilize all available processors as effectively, potentially leading to lower throughput.</p>
<p>Instead of M representing the number of processors over which a relation should be declustered, M is used instead to represent the number of processors that should participate in the execution of Qavg. Since Qavg processes TuplesPerQavg tuples, each fragment of the relation should contain FC &#x3D; TuplesPerQavg &#x2F; M tuples.</p>
<p>The process of fragmenting and distributing data in HRPS:</p>
<ol>
<li><strong>Sorting the relation</strong>: The relation is first sorted based on the partitioning attribute to ensure each fragment contains a distinct range of values.</li>
<li><strong>Fragmentation</strong>: The relation is then split into fragments, each containing approximately <strong>FC</strong> tuples.</li>
<li><strong>Round-robin distribution</strong>: These fragments are distributed to processors in a <strong>round-robin fashion</strong>, ensuring that adjacent fragments are assigned to different processors (unless the number of processors <strong>N</strong> is less than the required processors <strong>M</strong>).</li>
<li><strong>Storing fragments</strong>: All the fragments for a relation on a given processor are stored in the same physical file.</li>
<li><strong>Range table</strong>: The mapping of fragments to processors is maintained in a <strong>one-dimensional directory</strong> called the range table.</li>
</ol>
<p>This method ensures that at least M processors and at most M + 1 processors participate in the execution of a query.</p>
<p><strong>M &#x3D; N</strong>：系统和查询需求匹配，HRPS 调度所有处理器，达到最大并行度和最优性能。</p>
<p><strong>M &lt; N</strong>：HRPS 只调度一部分处理器执行查询，减少通信开销，但部分处理器资源可能闲置。</p>
<p><strong>M &gt; N</strong>：HRPS 将多个片段分配给处理器，尽量利用所有处理器，但每个处理器负担加重，查询执行速度可能受到影响。</p>
<p>HRPS in this paper supports only homogeneous nodes.</p>
<h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h1><p><strong>How does HRPS decide the ideal degree of parallelism for a query?</strong></p>
<p>HRPS (Hybrid-Range Partitioning Strategy) decides the ideal degree of parallelism by analyzing the resource requirements of the query, such as CPU, disk I&#x2F;O, and communication costs. It calculates the optimal number of processors (denoted as M) based on these factors. The strategy strikes a balance between minimizing query response time and avoiding excessive overhead from using too many processors.</p>
<p><strong>Why is it not appropriate to direct a query that fetches one record using an index structure to all the nodes of a system based on the shared-nothing architecture?</strong> </p>
<p>Fetching one record should only involve the node that contains the relevant data, as querying all nodes wastes resources and increases response time.</p>
<p><strong>How to extend HRPS to support heterogeneous nodes?</strong></p>
<ol>
<li>More powerful nodes would receive more fragments, while weaker nodes would handle fewer fragments.</li>
<li>The system could monitor node performance and dynamically adjust the degree of parallelism and fragment allocation based on current load and node availability.</li>
<li>Heavier tasks may be directed to more powerful nodes, while smaller or simpler queries could be executed on less powerful nodes.</li>
</ol>
<p>Reference: <a href="https://www.vldb.org/conf/1990/P481.PDF">https://www.vldb.org/conf/1990/P481.PDF</a></p>
]]></content>
      <categories>
        <category>数据库系统</category>
      </categories>
  </entry>
  <entry>
    <title>IQ</title>
    <url>/undefined/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/2024/11/07/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/IQ/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h1 id="What-is-the-IQ-Framework"><a href="#What-is-the-IQ-Framework" class="headerlink" title="What is the IQ Framework?"></a>What is the IQ Framework?</h1><p>The IQ framework is a solution designed for Cache-Augmented SQL (CASQL) systems, which combine relational databases (RDBMS) and key-value stores (KVS) to boost performance by caching database query results. However, CASQL systems often face challenges related to stale data and race conditions. The IQ framework ensures strong consistency while maintaining high performance.</p>
<h1 id="Challenges-in-CASQL-Systems"><a href="#Challenges-in-CASQL-Systems" class="headerlink" title="Challenges in CASQL Systems"></a>Challenges in CASQL Systems</h1><ol>
<li><p><strong>Stale Data in Cache</strong>:</p>
<ul>
<li><p>Cached data in the KVS can become outdated if updates to the RDBMS are not properly synchronized.</p>
</li>
<li><p>For example, if a record in the database is modified, but the corresponding cache entry isn’t updated, subsequent reads might return incorrect values.</p>
</li>
</ul>
</li>
<li><p><strong>Concurrency Issues</strong>:</p>
<ul>
<li><p>Multiple sessions accessing and modifying the same key in KVS concurrently can lead to inconsistent results.</p>
</li>
<li><p>Example:</p>
<ul>
<li>One session updates a value while another session modifies it based on outdated data.</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>RDBMS and Cache Coordination</strong>:</p>
<ul>
<li>While RDBMS ensures transactional consistency, KVS often lacks this capability, making it difficult to synchronize their states.</li>
</ul>
</li>
</ol>
<h1 id="Key-Features-of-the-IQ-Framework"><a href="#Key-Features-of-the-IQ-Framework" class="headerlink" title="Key Features of the IQ Framework"></a>Key Features of the IQ Framework</h1><ol>
<li><strong>Lease Mechanism: Inhibit (I) and Quarantine (Q)</strong>:<ol>
<li><strong>I Lease</strong> (for reads):<ol>
<li>Ensures that only one session can query the RDBMS for a cache miss and update the KVS.</li>
<li>Other sessions attempting to read the same key must “back off” and wait.</li>
</ol>
</li>
<li><strong>Q Lease</strong> (for writes):<ol>
<li>Required for modifying, deleting, or incrementally updating keys in the KVS.</li>
<li>If an I lease exists, the Q lease invalidates it to ensure the write operation’s integrity.</li>
<li>The KVS ignores I’s write operation because this I lease is no longer valid.</li>
</ol>
</li>
</ol>
</li>
<li><strong>Lease Expiry</strong>:<ol>
<li>A lease for a key has a fixed life time and is granted to one KVS connection (thread) at a time.</li>
<li>Expired leases are automatically released, ensuring system availability.</li>
<li>The finite life time enables the KVS to release the lease and continue processing operations in the presence of node failures hosting the application.</li>
</ol>
</li>
<li><strong>Session-based Model</strong>:<ol>
<li>The framework operates through sessions, similar to the <strong>two-phase locking protocol</strong>.</li>
<li>Leases can be acquired either before or during an RDBMS transaction, providing flexibility.</li>
</ol>
</li>
</ol>
<h2 id="Implementing-ACID-Properties"><a href="#Implementing-ACID-Properties" class="headerlink" title="Implementing ACID Properties"></a>Implementing ACID Properties</h2><p>原子性 (Atomicity)： IQ 框架确保事务的操作同时在数据库 (RDBMS) 和缓存 (KVS) 中执行。也就是说，操作不会只在数据库中完成而没有更新缓存。这种设计假设 KVS 中的数据是 RDBMS 数据的一部分，因此如果遇到问题，可以直接删除 KVS 中的数据来保持一致。</p>
<p>一致性 (Consistency)： IQ 框架保证事务在数据库和缓存中的数据状态从一个有效状态变为另一个有效状态。如果数据库的事务回滚 (abort)，那么缓存中的操作也不会被应用，确保不会留下无效的缓存数据。</p>
<p>隔离性 (Isolation)： 即使有多个会话 (session) 同时执行，IQ 框架也让每个会话看起来像是独立执行的，避免了并发问题。例如，即使两个用户同时读写相同的数据，他们看到的结果也是正确且一致的。</p>
<p>持久性 (Durability)： 持久性是由数据库 (RDBMS) 提供的，而缓存 (KVS) 则作为数据库的一部分镜像。KVS 存储的数据是在内存中的副本，但一旦数据库中的事务提交，数据就会被持久保存。</p>
<blockquote>
<p>CAS 操作只能保证单一操作的原子性，但无法在多个并发会话中保证强一致性。 由于数据库和缓存系统中的操作顺序可能不一致，会导致数据不同步。</p>
<p>在并发场景下：CAS 无法感知其他会话在其读取后对数据的更改。 多个会话同时执行 CAS 操作时，可能导致更新丢失或顺序混乱，如本例中 S2 的更新被 S1 覆盖。</p>
<p>Q 租约用于写操作，确保某一时刻只有一个会话能够修改目标键值。如果某个键值已有 Q 租约，其他会话（如 S1）会被要求退避（back off）或中止操作。</p>
</blockquote>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/RDBMS_KVS_OPER.png" alt="img"></p>
<h1 id="Invalidate"><a href="#Invalidate" class="headerlink" title="Invalidate"></a>Invalidate</h1><h2 id="What-is-Snapshot-Isolation"><a href="#What-is-Snapshot-Isolation" class="headerlink" title="What is Snapshot Isolation?"></a>What is Snapshot Isolation?</h2><p>Snapshot isolation is a multi-version concurrency control mechanism commonly used in RDBMS to allow concurrent transactions to execute efficiently. It guarantees:</p>
<ol>
<li><strong>Consistent Snapshot</strong>: All reads in a transaction observe the same consistent state of the database, as it existed at the transaction’s start.</li>
<li><strong>Conflict Detection</strong>: A transaction can only commit if its updates do not conflict with updates made by other transactions since its snapshot was taken.</li>
</ol>
<h3 id="The-Problem"><a href="#The-Problem" class="headerlink" title="The Problem"></a>The Problem</h3><p>Snapshot isolation can cause a race condition between a write session (S1) and a read session (S2) when KVS is involved. The issue unfolds as follows:</p>
<ol>
<li><p><strong>Write Session (S1)</strong>:</p>
<ul>
<li><p>S1 modifies the RDBMS and triggers a delete operation in the KVS to invalidate outdated key-value pairs.</p>
</li>
<li><p>S1 commits the transaction after completing its changes in the RDBMS.</p>
</li>
</ul>
</li>
<li><p><strong>Read Session (S2)</strong>:</p>
<ul>
<li><p>S2 starts after S1’s delete operation in the KVS. It observes a <strong>KVS miss</strong> for a key-value pair because S1 has invalidated it.</p>
</li>
<li><p>S2 queries the RDBMS to recompute the key-value pair. However, because snapshot isolation allows S2 to read an <strong>older snapshot of the database</strong>, it retrieves outdated (stale) data.</p>
</li>
<li><p>S2 inserts this <strong>stale data</strong> back into the KVS before S1 commits its changes to the RDBMS.</p>
</li>
</ul>
</li>
<li><p><strong>Inconsistency</strong>:</p>
<ul>
<li>After both sessions complete, the KVS contains a stale key-value pair inconsistent with the RDBMS, leading to incorrect results for future reads.</li>
</ul>
</li>
</ol>
<h3 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h3><p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/invalidate_tbl.png" alt="img"></p>
<p>I Lease (Inhibit Lease):</p>
<ul>
<li>Used by <strong>read sessions</strong> (e.g., S2).</li>
<li>When a read session observes a <strong>KVS miss</strong>, it requests an I lease for the key (<code>k_j</code>) from the KVS server.</li>
<li>The I lease allows the read session to query the RDBMS, compute a value, and insert the computed key-value pair into the KVS.</li>
<li>If a Q lease is already in place, the I lease is denied, and the read session is told to <strong>back off</strong> and retry later.</li>
</ul>
<p>Q Lease (Quarantine Lease):</p>
<ul>
<li>Used by <strong>write sessions</strong> (e.g., S1).</li>
<li>When a write session plans to invalidate a key in the KVS, it requests a Q lease for the key (<code>k_j</code>).</li>
<li>The Q lease prevents other sessions (including those holding I leases) from modifying or inserting the key in the KVS.</li>
<li>Multiple Q leases can be granted for the same key since deleting a key is idempotent (doesn’t create conflicts).</li>
</ul>
<h1 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h1><h2 id="The-Problem-1"><a href="#The-Problem-1" class="headerlink" title="The Problem"></a>The Problem</h2><ul>
<li>In the original scenario, <strong>write sessions (e.g., S1)</strong> immediately delete key-value pairs in the KVS as soon as they acquire a Q lease (e.g., Step 1.3 in Figure 3).</li>
<li>This can cause <strong>read sessions (e.g., S2)</strong> to encounter KVS misses, triggering redundant operations like querying the RDBMS, recalculating values, and reinserting them into the KVS.</li>
</ul>
<h2 id="The-Proposed-Optimization"><a href="#The-Proposed-Optimization" class="headerlink" title="The Proposed Optimization"></a>The Proposed Optimization</h2><p><strong>Deferring Key Deletion Until Write Commit</strong></p>
<ol>
<li><p><strong>Key Changes</strong>:</p>
<ul>
<li><p>Instead of deleting the key immediately in Step 1.3, the write session (S1) holds the Q lease and <strong>defers the deletion</strong> until the write session commits (Step 1.5).</p>
</li>
<li><p>While S1 is mid-flight, the invalidated key-value pair remains in the KVS for other read sessions (S2) to observe.</p>
</li>
</ul>
</li>
<li><p><strong>Handling KVS Hits</strong>:</p>
<ul>
<li><p>Read sessions like S2 that encounter a <strong>KVS hit</strong> consume the “stale” key-value pair, treating it as valid.</p>
</li>
<li><p>This is acceptable because S2’s actions can be <strong>serialized to occur before</strong> S1, which is still in progress and has not yet committed its RDBMS changes.</p>
</li>
</ul>
</li>
<li><p><strong>Handling Write Aborts</strong>:</p>
<ul>
<li><p>If a write session (S1) encounters an exception and aborts, the Q lease is released without deleting the key.</p>
</li>
<li><p>The current key-value pair in the KVS remains valid and accessible to other sessions.</p>
</li>
</ul>
</li>
</ol>
<h2 id="Implementation-Details"><a href="#Implementation-Details" class="headerlink" title="Implementation Details"></a>Implementation Details</h2><ol>
<li><p><strong>Versioning Concept</strong>:</p>
<ul>
<li><p>The optimization can be conceptualized as maintaining a <strong>temporary version</strong> of the key-value pair for use by all sessions except the one currently invalidating it (S1).</p>
</li>
<li><p>Once S1 commits, the temporary version is removed.</p>
</li>
</ul>
</li>
<li><p><strong>Abort Command</strong>:</p>
<ul>
<li><p>If a write session (S1) aborts due to constraints or exceptions, an <strong>abort command</strong> releases all Q leases held by S1 without deleting the key-value pair.</p>
</li>
<li><p>Without this command, Q leases would expire naturally after a timeout, during which no other session could modify or access the key.</p>
</li>
</ul>
</li>
</ol>
<p><strong>Re-Arrangement Window</strong>:</p>
<ul>
<li>With this optimization, S2 and S1 can be <strong>re-arranged</strong> in a serializable schedule where S2 logically occurs before S1.</li>
<li>Without the optimization, the re-arrangement window shrinks to zero because S2 would have already queried the RDBMS for stale data, violating consistency.</li>
</ul>
<h1 id="Refresh-and-Incremental-Update"><a href="#Refresh-and-Incremental-Update" class="headerlink" title="Refresh and Incremental Update"></a>Refresh and Incremental Update</h1><h2 id="Key-Issues-with-Compare-and-Swap-CAS"><a href="#Key-Issues-with-Compare-and-Swap-CAS" class="headerlink" title="Key Issues with Compare-and-Swap (CAS)"></a>Key Issues with Compare-and-Swap (CAS)</h2><ul>
<li><p><strong>CAS Limitation</strong>:</p>
<ul>
<li>CAS alone cannot ensure strong consistency. It provides atomic updates to a single key-value pair but does not coordinate these updates with RDBMS transactions.</li>
</ul>
</li>
<li><p><strong>Example (Figure 2)</strong>:</p>
<ul>
<li><p>KVS writes can occur either:</p>
<ol>
<li><p><strong>Prior to</strong> the RDBMS transaction, or</p>
</li>
<li><p><strong>As part of</strong> the RDBMS transaction.</p>
</li>
</ol>
</li>
<li><p><strong>Problem</strong>: If the RDBMS transaction aborts, the KVS will retain the modified key-value pair, potentially exposing <strong>dirty reads</strong> to other sessions.</p>
</li>
</ul>
</li>
<li><p><strong>Figure 6 (Dirty Read Problem)</strong>:</p>
<ul>
<li>Write session S1 modifies a key-value pair in KVS.</li>
<li>S1’s transaction later aborts, but the intermediate KVS value is consumed by a read session S2 before the rollback, leading to inconsistencies.</li>
</ul>
</li>
<li><p><strong>Developer Responsibility</strong>:</p>
<ul>
<li>Without additional mechanisms, developers must implement complex logic to restore KVS key-value pairs to their original values when RDBMS transactions abort.</li>
</ul>
</li>
</ul>
<h2 id="Race-Conditions-with-Incremental-Updates-δ-Operations"><a href="#Race-Conditions-with-Incremental-Updates-δ-Operations" class="headerlink" title="Race Conditions with Incremental Updates (δ Operations)"></a>Race Conditions with Incremental Updates (δ Operations)</h2><ul>
<li><p><strong>Figure 7 (Snapshot Isolation with δ Operations)</strong>:</p>
</li>
<li><ul>
<li>Write session S1 updates the RDBMS and KVS using an incremental update (e.g., appending to a value).</li>
<li>Concurrently, read session S2 queries the RDBMS and overwrites the key-value pair in the KVS.</li>
<li><strong>Result</strong>: The KVS reflects inconsistent state, as S2’s overwrite may invalidate S1’s incremental change.</li>
</ul>
</li>
<li><p><strong>Figure 8 (Reordering KVS Operations)</strong>:</p>
</li>
<li><ul>
<li>Delaying KVS updates until after the RDBMS transaction doesn’t solve the problem.</li>
</ul>
</li>
<li><p><strong>Example in Figure 8</strong>:</p>
</li>
<li><ul>
<li>S1 appends a change to a value based on its RDBMS view.</li>
<li>S2 modifies the RDBMS during S1’s execution, which S1 unknowingly incorporates into its KVS update.</li>
<li><strong>Problem</strong>: S2’s modifications are reflected twice in the KVS, introducing inconsistencies.</li>
</ul>
</li>
</ul>
<h2 id="Solution-1"><a href="#Solution-1" class="headerlink" title="Solution"></a>Solution</h2><p><strong>Key Concepts in the Solution</strong></p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/refresh_tbl.png" alt="img"></p>
<ol>
<li><p><strong>Q Leases for Write Sessions</strong>:</p>
<ul>
<li><p>A <strong>Q lease</strong> must be obtained for each key-value pair that a session intends to update.</p>
</li>
<li><p>This prevents race conditions by locking the key-value pair until the session completes its operations.</p>
</li>
</ul>
</li>
<li><p><strong>Steps for Write Sessions</strong>:</p>
<ul>
<li><p><strong>Step 1</strong>: Obtain Q leases for the keys to be updated before committing the RDBMS transaction. This can happen:</p>
<ul>
<li><p>Before starting the RDBMS transaction.</p>
</li>
<li><p>As part of the RDBMS transaction.</p>
</li>
</ul>
</li>
<li><p><strong>Step 2</strong>: Write the updated key-value pairs to the KVS after committing the RDBMS transaction.</p>
</li>
<li><p><strong>Step 3</strong>: Release the Q leases once the KVS is updated.</p>
</li>
<li><p><strong>Automatic Cleanup</strong>: If a Q lease expires, the KVS deletes the associated key-value pair to avoid stale data.</p>
</li>
</ul>
</li>
<li><p><strong>Command Design for Write Operations</strong>:</p>
<ul>
<li><p><strong>QaRead (Quarantine-and-Read)</strong>:</p>
<ul>
<li><p>Acquires a Q lease on the referenced key and reads its value from the KVS.</p>
</li>
<li><p>If a Q lease for the same key is already held by another session, the requesting session receives an <strong>abort message</strong>, must roll back its RDBMS transaction, release all leases, back off, and retry later.</p>
</li>
<li><p>If no value exists in the KVS (a <strong>KVS miss</strong>), the application can:</p>
<ul>
<li>Skip updating the key, or</li>
<li>Query the RDBMS, compute a new value, and insert it using <strong>SaR</strong> (below).</li>
</ul>
</li>
<li><p>If a <strong>QaRead lease</strong> encounters an <strong>I lease</strong> held by a read session, it invalidates the I lease to prevent race conditions.</p>
</li>
</ul>
</li>
<li><p><strong>SaR (Swap-and-Release)</strong>:</p>
<ul>
<li>Updates the value of a key in the KVS with the new value and releases the Q lease.</li>
<li>If the new value is <code>null</code>, the Q lease is simply released without updating the KVS.</li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 id="Handling-Race-Conditions"><a href="#Handling-Race-Conditions" class="headerlink" title="Handling Race Conditions"></a>Handling Race Conditions</h2><ol>
<li><p><strong>Q Leases for Concurrent Write Sessions</strong>:</p>
<ul>
<li><p>If two write sessions request Q leases for the same key, the KVS resolves the conflict by:</p>
<ul>
<li>Aborting one session.</li>
<li>Ensuring the aborted session retries later, serializing its updates after the session holding the Q lease.</li>
</ul>
</li>
<li><p>This guarantees a valid serial schedule in the RDBMS and KVS.</p>
</li>
</ul>
</li>
<li><p><strong>Read Sessions and I Leases</strong>:</p>
<ul>
<li><p>Read sessions use <strong>I leases</strong> to avoid race conditions when querying the KVS.</p>
</li>
<li><p>If a write session issues a <strong>QaRead</strong> that encounters an existing <strong>I lease</strong>, the <strong>I lease</strong> is invalidated to ensure the KVS reflects the latest updates from the RDBMS.</p>
</li>
</ul>
</li>
</ol>
<h2 id="Integration-with-Two-Phase-Locking"><a href="#Integration-with-Two-Phase-Locking" class="headerlink" title="Integration with Two-Phase Locking"></a>Integration with Two-Phase Locking</h2><ul>
<li><p>The Q lease mechanism resembles <strong>two-phase locking</strong>:</p>
<ol>
<li><p><strong>Growing Phase</strong>: The session acquires all necessary Q leases using <strong>QaRead</strong> before committing its RDBMS transaction.</p>
</li>
<li><p><strong>Shrinking Phase</strong>: The session releases all Q leases using <strong>SaR</strong> after committing its RDBMS transaction.</p>
</li>
</ol>
</li>
<li><p>Flexibility:</p>
<ul>
<li>A session can issue <strong>QaRead</strong> commands either before starting the RDBMS transaction or as part of the transaction.</li>
</ul>
</li>
</ul>
<h2 id="Key-Concepts-of-Incremental-Updates"><a href="#Key-Concepts-of-Incremental-Updates" class="headerlink" title="Key Concepts of Incremental Updates"></a>Key Concepts of Incremental Updates</h2><ol>
<li><p><strong>Incremental Update Command: IQ-δ</strong>:</p>
<ul>
<li><p><strong>Purpose</strong>: Allows a write session to perform an incremental update, such as appending data to an existing key-value pair.</p>
</li>
<li><p><strong>Syntax</strong>: <code>IQ-δ(ki, δi)</code></p>
<ul>
<li><code>ki</code>: The key to be updated.</li>
<li><code>δi</code>: The incremental change to apply (e.g., the value to append).</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Similarities to QaRead</strong>:</p>
<ul>
<li><p><strong>Q Lease Requirement</strong>: Before issuing the <code>IQ-δ</code> command, the session must obtain a <strong>Q lease</strong> for the key <code>ki</code> to ensure exclusive access.</p>
</li>
<li><p><strong>Abort on Conflict</strong>:</p>
<ul>
<li><p>If another session already holds a Q lease on the same key (<code>ki</code>), the <strong>KVS returns an abort message</strong>.</p>
</li>
<li><p>The write session must:</p>
<ol>
<li><p>Release all its leases.</p>
</li>
<li><p>Abort its ongoing RDBMS transaction (if any).</p>
</li>
<li><p>Retry the operation later.</p>
</li>
</ol>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<h1 id="优化关键点总结"><a href="#优化关键点总结" class="headerlink" title="优化关键点总结"></a>优化关键点总结</h1><ol>
<li><p><strong>保留旧版本（Older Version）</strong>：</p>
<ul>
<li><p>当写会话（S1）更新某键值对 (<code>ki-vi</code>) 时，KVS 暂时保留该键值对的旧版本 (<code>ki-vi_old</code>)，直到 S1 提交。</p>
</li>
<li><p>这避免了读会话在写会话更新期间遇到 <strong>KVS miss</strong>。</p>
</li>
</ul>
</li>
<li><p>写会话的更新视图：</p>
<ul>
<li><p>写会话（S1）在更新期间必须能够看到自己的修改结果（<code>ki-vi_new</code>）。</p>
</li>
<li><p>KVS 确保为 S1 提供其最新的更新视图。</p>
</li>
</ul>
</li>
</ol>
<h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h1><p><strong>Why is it acceptable for invalidate to delete cache entries?</strong></p>
<p>Consistency Assurance: The cache entry being invalidated represents stale data that is no longer consistent with the current state of the RDBMS. Deleting it prevents read sessions from accessing outdated information.</p>
<p><strong>How is a lease different than a lock?</strong> </p>
<ul>
<li><strong>Lease</strong>: Has a fixed lifetime and expires automatically after a certain duration. This makes leases useful in distributed systems where failures or delays could otherwise cause indefinite blocking.</li>
<li><strong>Lock</strong>: Typically remains active until explicitly released, which can lead to deadlocks or indefinite resource contention if not managed properly.</li>
</ul>
<p><strong>True or False: IQ leases require changes to the RDBMS software.</strong></p>
<p>False:</p>
<p>IQ leases do not require changes to the RDBMS software.</p>
<p>Instead, they extend the functionality of the Key-Value Store (KVS) by introducing new lease-based commands (e.g., <code>QaRead</code> and <code>SaR</code>) to coordinate operations between the KVS and the RDBMS. This design leverages existing RDBMS features without altering its underlying implementation.</p>
<p><strong>What factors does CAMP consider when selecting a victim?</strong></p>
<p>H(p) &#x3D; L + size(p) &#x2F; cost(p)</p>
<p><strong>What is the definition of cost? Provide an example.</strong></p>
<ul>
<li><strong>Computation Time</strong>: The time required to regenerate or recompute the data if it is evicted from memory.</li>
<li><strong>Access Latency</strong>: The time it would take to fetch the data from disk or another slower storage tier.</li>
<li><strong>Importance</strong>: The priority or weight assigned to the data based on how frequently or critically it is used.</li>
</ul>
<p><strong>How does CAMP insert a key-value pair in memory?</strong></p>
<p>When a new key-value pair p needs to be inserted into memory, CAMP performs the following steps:</p>
<p><strong>1. Check Cache Capacity</strong></p>
<ul>
<li>If there is <strong>enough memory</strong> to store the new key-value pair:</li>
<li><ul>
<li>The pair is inserted directly into the appropriate <strong>priority group</strong> based on its cost-to-size ratio.</li>
<li>L is not updated.</li>
</ul>
</li>
<li>If the cache is <strong>full</strong>:</li>
<li><ul>
<li>CAMP selects one or more key-value pairs to <strong>evict</strong> based on their H(p) values.</li>
<li>It removes the pair(s) with the <strong>lowest H(p)</strong> values until there is sufficient space for the new pair.</li>
</ul>
</li>
</ul>
<p><strong>2. Insert the New Pair</strong></p>
<ul>
<li>The new key-value pair p is added to the cache, and its H(p) value is computed and recorded.</li>
<li>The pair is placed in the appropriate priority queue based on its cost-to-size ratio.</li>
</ul>
<p><strong>With BG, what is the definition of Service Level Agreement, SLA?</strong></p>
<p>SLA, e.g., 95% of requests to observe a response time equal to or faster than 100 msec with at most 0.1% of requests observing unpredictable data for 10 minutes.</p>
<p><strong>Name one reason why a system may produce unpredictable data?</strong></p>
<p>Eventual consistency. Or multiple threads are updating the same data item.</p>
<p>Reference: <a href="https://dl.acm.org/doi/abs/10.1145/2663165.2663318">https://dl.acm.org/doi/abs/10.1145/2663165.2663318</a></p>
]]></content>
      <categories>
        <category>数据库系统</category>
      </categories>
  </entry>
  <entry>
    <title>MapReduce</title>
    <url>/undefined/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2024/11/21/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/MapReduce/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h1 id="编程模型-Programming-Model"><a href="#编程模型-Programming-Model" class="headerlink" title="编程模型 (Programming Model)"></a>编程模型 (Programming Model)</h1><p><strong>输入与输出 (Input and Output):</strong></p>
<ul>
<li>接收一组<strong>输入键&#x2F;值对 (input key&#x2F;value pairs)</strong>。</li>
<li>生成一组<strong>输出键&#x2F;值对 (output key&#x2F;value pairs)</strong>。</li>
</ul>
<p><strong>用户自定义函数 (User-Defined Functions):</strong></p>
<ul>
<li><strong>映射函数 (Map Function)</strong>:<ul>
<li>由用户编写。</li>
<li>处理每个输入键&#x2F;值对。</li>
<li>生成一组<strong>中间键&#x2F;值对 (intermediate key&#x2F;value pairs)</strong>。</li>
</ul>
</li>
<li><strong>归约函数 (Reduce Function)</strong>:<ul>
<li>同样由用户编写。</li>
<li>接收一个中间键 <code>I</code> 及其关联的<strong>值集合 (set of values)</strong>。</li>
<li>合并这些值以产生一个<strong>更小集合 (smaller set)</strong> 的输出值，通常为零个或一个值。</li>
</ul>
</li>
</ul>
<p><strong>中间数据处理 (Intermediate Data Handling):</strong></p>
<ul>
<li><strong>MapReduce 库 (MapReduce library)</strong> 将中间值按其键 (<code>I</code>) 分组，并将它们发送给归约函数。</li>
<li>中间值通过<strong>迭代器 (iterator)</strong> 提供给归约函数，从而能够高效处理因数据量过大而无法全部放入内存的数据集。</li>
</ul>
<p><strong>容错性与可扩展性 (Fault Tolerance and Scalability):</strong></p>
<ul>
<li>通过将任务分解成更小的独立计算单元，MapReduce 确保了即使在大型分布式环境中也能实现可扩展性和容错性。</li>
</ul>
<h1 id="实现-Implementation"><a href="#实现-Implementation" class="headerlink" title="实现 (Implementation)"></a>实现 (Implementation)</h1><p><a href="https://../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F//mapred_exe_overview.png"><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/mapred_exe_overview.png" alt="img"></a></p>
<p><strong>数据分割与任务分配 (Data Splitting and Task Assignment):</strong></p>
<ul>
<li><strong>输入数据划分</strong>: MapReduce 库自动将输入文件分割成 M 个片段（通常每个片段大小为 16MB 到 64MB，可由用户控制）。</li>
<li><strong>启动程序实例</strong>: 在集群中启动多个程序副本。</li>
<li><strong>角色分配</strong>: 其中一个程序实例被指定为<strong>主节点 (master)</strong>，其余的作为<strong>工作节点 (workers)</strong>。</li>
</ul>
<p><strong>任务调度 (Task Scheduling):</strong></p>
<ul>
<li><strong>主节点的职责</strong>: 主节点负责管理 M 个 map 任务和 R 个 reduce 任务。</li>
<li><strong>任务分配</strong>: 主节点将空闲的工作节点分配给 map 任务或 reduce 任务。</li>
</ul>
<p><strong>Map 阶段 (Map Phase):</strong></p>
<ul>
<li><strong>读取数据</strong>: 被分配 map 任务的工作节点读取对应的输入片段。</li>
<li><strong>处理数据</strong>: 解析出键&#x2F;值对，并将其传递给用户定义的 Map 函数。</li>
<li><strong>生成中间结果</strong>: <strong>Map 函数产生的中间键&#x2F;值对会存储在本地磁盘中。</strong></li>
</ul>
<p><strong>中间数据处理 (Intermediate Data Processing):</strong></p>
<ul>
<li><strong>写入本地磁盘</strong>: **缓存的中间结果会定期写入本地磁盘，<strong>并根据分区函数划分为 R 个区域 (partitioned into R regions)。</strong></li>
<li><strong>通知主节点</strong>: 工作节点将这些中间数据的位置告知主节点，主节点负责将这些信息传递给 reduce 工作节点。</li>
</ul>
<p><strong>Reduce 阶段准备 (Reduce Phase Preparation):</strong></p>
<ul>
<li><strong>读取中间数据</strong>: reduce 工作节点收到主节点的通知后，通过<strong>远程过程调用 (RPC - Remote Procedure Call)</strong> 从 map 工作节点的本地磁盘读取中间数据。</li>
<li><strong>排序数据</strong>: reduce 工作节点将所有中间数据按键排序，以确保相同的键聚集在一起。如果数据量过大，无法全部加载到内存，会采用<strong>外部排序 (external sort)</strong>。</li>
</ul>
<p><strong>Reduce 阶段 (Reduce Phase):</strong></p>
<ul>
<li><strong>执行 Reduce 函数</strong>: reduce 工作节点遍历排序后的中间数据，对于每个唯一的中间键，将键和对应的值列表传递给用户定义的 Reduce 函数。</li>
<li><strong>生成最终输出</strong>: Reduce 函数的输出被追加到该 reduce 分区的最终输出文件中。</li>
</ul>
<p><strong>任务完成与结果返回 (Task Completion and Result Retrieval):</strong></p>
<ul>
<li><strong>任务监控</strong>: 当所有的 map 和 reduce 任务都完成后，主节点会唤醒用户程序。</li>
<li><strong>返回结果</strong>: 此时，用户程序中的 MapReduce 调用返回，用户可以获取 R 个输出文件（每个 reduce 任务对应一个输出文件）。</li>
</ul>
<p><strong>额外说明 (Additional Notes):</strong></p>
<ul>
<li><strong>数据处理链</strong>: 通常用户不需要将这 R 个输出文件合并成一个文件，因为这些文件可以直接作为下一个 MapReduce 调用的输入，或者被能够处理多文件输入的分布式应用程序使用。</li>
<li><strong>流程图参考</strong>: 上图👆用于展示 MapReduce 操作的整体流程（对应上述 7 个步骤）。</li>
</ul>
<h2 id="主节点数据结构-Master-Data-Structure"><a href="#主节点数据结构-Master-Data-Structure" class="headerlink" title="主节点数据结构 (Master Data Structure)"></a>主节点数据结构 (Master Data Structure)</h2><p><strong>任务状态跟踪 (Task State Tracking):</strong></p>
<ul>
<li>对于每个 <strong>map</strong> 和 <strong>reduce 任务</strong>，主节点存储：<ul>
<li><strong>状态</strong>:<ul>
<li><code>idle</code> (空闲): 任务尚未分配。</li>
<li><code>in-progress</code> (执行中): 任务正在被执行。</li>
<li><code>completed</code> (已完成): 任务执行完毕。</li>
</ul>
</li>
<li><strong>工作节点标识 (Worker Identity)</strong>: 处理该任务的工作机器（针对非空闲任务）。</li>
</ul>
</li>
</ul>
<p><strong>中间数据管理 (Intermediate Data Management):</strong></p>
<ul>
<li>主节点充当将中间数据从 map 任务传递到 reduce 任务的<strong>管道 (conduit)</strong>。</li>
<li>对于每个已完成的 map 任务：<ul>
<li>它记录所生成的 <code>R</code> 个中间文件区域的<strong>位置</strong> 和<strong>大小</strong>。</li>
<li>这些数据对于 reduce 任务从相应的 map 工作节点获取中间结果至关重要。</li>
</ul>
</li>
</ul>
<p><strong>动态更新 (Dynamic Updates):</strong></p>
<ul>
<li>随着 map 任务完成，主节点持续更新其记录的中间文件位置和大小。</li>
<li>这些更新会增量式地推送给当前正在执行中的 reduce 工作节点。</li>
</ul>
<h2 id="容错机制-Fault-Tolerance"><a href="#容错机制-Fault-Tolerance" class="headerlink" title="容错机制 (Fault Tolerance)"></a>容错机制 (Fault Tolerance)</h2><p><strong>工作节点故障 (Worker Failure)</strong></p>
<ul>
<li><strong>故障检测 (Failure Detection)</strong>:<ul>
<li><strong>主节点</strong>定期向<strong>每个工作节点</strong>发送 <strong>ping</strong>。</li>
<li>如果工作节点在特定时间窗口内未响应，主节点将其标记为<strong>故障</strong>。</li>
</ul>
</li>
<li><strong>任务重新调度 (Task Rescheduling)</strong>:<ul>
<li><strong>Map 任务 (Map Tasks)</strong>:<ul>
<li><strong>已完成的 Map 任务 (Completed Map Tasks)</strong>:<ul>
<li>如果故障工作节点已完成 map 任务，其输出将变得不可访问（存储在故障机器的本地磁盘上）。</li>
<li>这些任务被重置为<strong>空闲状态 (idle state)</strong> 并在其他工作节点上重新执行。</li>
</ul>
</li>
<li><strong>执行中的 Map 任务 (In-Progress Map Tasks)</strong>:<ul>
<li>类似地，执行中的任务被标记为空闲并重新分配给可用的工作节点。</li>
</ul>
</li>
</ul>
</li>
<li><strong>Reduce 任务 (Reduce Tasks)</strong>:<ul>
<li><strong>已完成的 Reduce 任务 (Completed Reduce Tasks)</strong>:<ul>
<li>这些任务<strong>不需要</strong>重新执行，因为它们的输出存储在<strong>全局文件系统 (global file system)</strong> 中，即使发生故障也仍然可访问。</li>
</ul>
</li>
<li><strong>执行中的 Reduce 任务 (In-Progress Reduce Tasks)</strong>:<ul>
<li>如果某些 reduce 工作节点尚未读取中间数据，它们会从新的（重新执行的 map 任务的）结果中读取数据。</li>
</ul>
</li>
</ul>
</li>
<li><strong>数据协调 (Data Coordination)</strong>:<ul>
<li>当 map 任务在新的工作节点上重新执行时：<ul>
<li><strong>通知 (Notification)</strong>: 所有 reduce 工作节点会被告知该重新执行。</li>
<li><strong>数据重定向 (Data Redirection)</strong>: 尚未从故障工作节点获取中间数据的 reduce 工作节点将改为从新的工作节点获取数据。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>主节点故障 (Master Failure)</strong></p>
<ul>
<li>可以很方便地让主节点定期将上述主节点数据结构写入<strong>检查点 (checkpoints)</strong>。如果主节点任务终止，可以从最后一个检查点状态启动一个新的副本。</li>
<li>然而，考虑到只有一个主节点，其故障的可能性很低；<strong>因此我们当前的实现在主节点故障时会中止 MapReduce 计算。</strong> 客户端可以检测到此情况，并在需要时重试 MapReduce 操作。</li>
</ul>
<h2 id="数据本地化-Locality"><a href="#数据本地化-Locality" class="headerlink" title="数据本地化 (Locality)"></a>数据本地化 (Locality)</h2><ul>
<li><strong>存储设计</strong>: 数据存储在 <strong>Google 文件系统 (GFS - Google File System)</strong> 中。GFS 将每个文件分割为 64 MB 的块 (blocks)，并在不同的机器上保存多个副本（通常是 3 个）。</li>
<li><strong>任务调度优先级</strong>:<ul>
<li><strong>优先本地化调度</strong>: 主节点优先将 map 任务分配给<strong>包含对应数据块副本的同一台机器</strong>上的工作节点。</li>
<li><strong>次优调度</strong>: 如果本地调度不可行（例如，拥有数据块副本的工作节点繁忙），主节点将任务分配给靠近副本的机器，例如同一机架 (rack) 或数据中心 (data center) 内的机器。</li>
</ul>
</li>
<li><strong>实际效果</strong>: 在运行大型 MapReduce 操作时，大部分输入数据会从本地磁盘读取。因为数据本地化，减少了跨网络传输的数据量，从而节省网络带宽。</li>
</ul>
<h2 id="任务粒度-Task-Granularity"><a href="#任务粒度-Task-Granularity" class="headerlink" title="任务粒度 (Task Granularity)"></a>任务粒度 (Task Granularity)</h2><ol>
<li><strong>Map 和 Reduce 阶段的划分</strong><ul>
<li><strong>任务数量 (M 和 R)</strong>: Map 阶段被划分为 M 个任务。Reduce 阶段被划分为 R 个任务。</li>
<li><strong>划分原则</strong>: 理想情况下，M 和 R 的数量应该<strong>远大于</strong>工作节点的数量（即机器的数量）。</li>
</ul>
</li>
<li><strong>多任务划分的好处</strong><ul>
<li><strong>动态负载均衡</strong>: 每个工作节点可执行多个任务，这样可以动态调整任务分配，避免某些节点过载或闲置。</li>
<li><strong>故障恢复加速</strong>: 如果某个工作节点失败，其已完成的多个任务可以分散到其他节点重新执行，恢复速度更快。</li>
</ul>
</li>
<li><strong>任务划分的实际限制</strong><ul>
<li><strong>调度开销</strong>: 主节点需要进行 O(M + R) 次调度决策，且需要存储 O(M × R) 的状态信息。虽然每对 map&#x2F;reduce 任务对仅占用约 1 字节内存，但过多任务会增加内存需求和调度复杂性。</li>
<li><strong>输出文件限制</strong>: R 的大小往往受到用户需求限制，因为每个 reduce 任务会生成一个独立的输出文件。输出文件过多会导致文件管理复杂。</li>
</ul>
</li>
<li><strong>实际任务大小选择</strong><ul>
<li><strong>Map 阶段</strong>: 每个 map 任务通常处理 <strong>16 MB 到 64 MB</strong> 的输入数据。这样的任务大小可以充分利用<strong>数据本地化优化</strong>（即尽量从本地磁盘读取数据）。</li>
<li><strong>Reduce 阶段</strong>: R 通常是工作节点数量的几倍，以充分利用并行能力。在一个典型的大规模 MapReduce 计算中：<ul>
<li>M &#x3D; 200,000（Map 阶段任务数）。</li>
<li>R &#x3D; 5,000（Reduce 阶段任务数）。</li>
<li>工作节点 &#x3D; 2,000（机器数量）。</li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 id="备份任务-Backup-Tasks"><a href="#备份任务-Backup-Tasks" class="headerlink" title="备份任务 (Backup Tasks)"></a>备份任务 (Backup Tasks)</h2><ol>
<li><strong>什么是拖后腿的任务（Straggler Tasks）？</strong><ul>
<li><strong>定义</strong>: 拖后腿任务指的是 MapReduce 作业中运行速度<strong>远慢于</strong>其他任务的任务（map 或 reduce），从而<strong>延迟整个作业的完成</strong>。</li>
</ul>
</li>
<li><strong>解决方法</strong>:<ul>
<li><strong>备份任务机制</strong>: 当 MapReduce 计算接近完成时，主节点会为<strong>未完成的任务</strong>安排<strong>备份执行 (Backup Executions)</strong>。同一任务的多个副本在不同的工作节点上<strong>同时运行</strong>。只要其中一个副本完成，任务即被标记为完成。</li>
<li><strong>资源开销</strong>: 调整后的机制只增加少量（通常是几个百分点）的计算资源使用。通过备份执行，能够<strong>显著缩短</strong>总执行时间。</li>
</ul>
</li>
</ol>
<h1 id="优化与增强-Refinement"><a href="#优化与增强-Refinement" class="headerlink" title="优化与增强 (Refinement)"></a>优化与增强 (Refinement)</h1><p><strong>分区函数 (Partitioning Function)</strong></p>
<ol>
<li><strong>Reduce 任务与分区</strong><ul>
<li>用户通过设置 <strong>R</strong> 来指定需要的 reduce 任务数或输出文件数。</li>
<li>数据在这些 reduce 任务之间分区，分区方式取决于<strong>分区函数</strong>。</li>
</ul>
</li>
<li><strong>默认分区方式</strong><ul>
<li>默认使用<strong>哈希函数</strong>。</li>
<li><strong>分区规则</strong>: <code>hash(key) mod R</code>。</li>
<li><strong>优势</strong>: 通常能实现较为<strong>均衡的分区</strong>（即数据均匀分布到不同 reduce 任务中）。</li>
</ul>
</li>
<li><strong>自定义分区方式</strong><ul>
<li>有时默认的哈希分区不满足实际需求，需要根据特定逻辑对数据进行分区。例如：数据的键是 URL，用户希望所有来自<strong>同一主机 (host)</strong> 的条目存储在同一个输出文件中。</li>
<li><strong>解决方案</strong>: 用户可以定义自己的分区函数，例如：<code>hash(Hostname(urlkey)) mod R</code>：根据 URL 的<strong>主机名 (hostname)</strong> 分区。这样，来自同一主机的所有条目会被分配到<strong>相同的 reduce 任务</strong>中。</li>
</ul>
</li>
</ol>
<p><strong>排序保证 (Ordering Guarantees)</strong></p>
<ol>
<li><strong>排序保证</strong><ul>
<li>在 MapReduce 的<strong>每个分区内</strong>，中间的键&#x2F;值对（key&#x2F;value pairs）会按照<strong>键的递增顺序</strong> 进行处理。</li>
<li><strong>目标</strong>: 确保每个分区的输出文件是<strong>有序的</strong>。</li>
</ul>
</li>
<li><strong>排序的作用</strong><ul>
<li><strong>生成有序输出文件</strong>: 每个 reduce 任务生成的输出文件是按键排序的，直接支持有序数据的存储。</li>
<li><strong>支持高效随机访问</strong>: 有序数据便于通过键值实现高效的随机访问。</li>
<li><strong>用户便利</strong>: 用户使用这些输出文件时，通常不需要额外排序。</li>
</ul>
</li>
</ol>
<p><strong>合并函数 (Combiner Function)</strong></p>
<ol>
<li><strong>问题背景</strong><ul>
<li>在某些情况下，中间键<strong>重复率较高</strong>，每个 map 任务可能会生成大量重复的中间键记录。<strong>示例</strong>: 在单词计数任务中（例如 <code>&lt;the, 1&gt;</code>），常见单词（如 “the”）会频繁出现。</li>
<li><strong>结果</strong>: 这些重复记录需要通过网络传输到同一个 reduce 任务，增加了网络负载。</li>
</ul>
</li>
<li><strong>Combiner 函数的解决方案</strong><ul>
<li><strong>定义</strong>: Combiner 是一个<strong>可选的、局部的聚合函数</strong>，<strong>用于在 map 任务所在机器上对中间数据进行部分合并。</strong></li>
<li><strong>工作原理</strong>:<ul>
<li><strong>执行位置</strong>: Combiner 在 map 任务的机器上运行。</li>
<li><strong>功能</strong>: 对<strong>重复键</strong>的中间结果进行<strong>局部汇总</strong>，减少需要传输的数据量。</li>
<li><strong>例如</strong>: 将 <code>&lt;the, 1&gt;</code>、<code>&lt;the, 1&gt;</code>、<code>&lt;the, 1&gt;</code> 合并为 <code>&lt;the, 3&gt;</code>。</li>
</ul>
</li>
</ul>
</li>
<li><strong>Combiner 和 Reduce 的区别</strong><ul>
<li><strong>相同点</strong>: 通常，Combiner 的代码与 Reduce 函数的代码<strong>相同</strong>。都用于对数据进行<strong>聚合处理</strong>。</li>
<li><strong>不同点</strong>:<ul>
<li><strong>Combiner</strong>: 输出的是<strong>中间结果</strong>，数据会<strong>继续传递</strong>给 Reduce 任务。</li>
<li><strong>Reduce</strong>: 输出的是<strong>最终结果</strong>，数据写入最终的输出文件。</li>
</ul>
</li>
</ul>
</li>
<li><strong>优化效果</strong><ul>
<li><strong>减少网络传输量</strong>: 通过提前合并数据，Combiner 显著减少了从 map 任务到 reduce 任务的数据量。例如，不传输 1000 条 <code>&lt;the, 1&gt;</code>，而是只传输 1 条 <code>&lt;the, 1000&gt;</code>。</li>
<li><strong>提升性能</strong>: 对于重复率高的任务，Combiner 能显著加快 MapReduce 操作的速度。</li>
</ul>
</li>
</ol>
<p><strong>输入与输出类型 (Input and Output Types)</strong></p>
<ol>
<li><strong>输入数据格式的支持</strong><ul>
<li><strong>预定义格式</strong>:<ul>
<li><strong>文本模式</strong>: 每行数据被视为一个键&#x2F;值对。<ul>
<li>键：文件中该行的<strong>偏移量</strong>。</li>
<li>值：该行的<strong>内容</strong>。</li>
</ul>
</li>
<li><strong>排序键&#x2F;值对模式 (sorted key&#x2F;value mode)</strong>: 存储的键&#x2F;值对按键排序，便于按范围处理。</li>
</ul>
</li>
<li><strong>自动分割范围</strong>: 每种输入格式都有<strong>分割机制</strong>，可将输入数据划分为适合 map 任务处理的范围。例如，文本模式会确保分割发生在<strong>行边界</strong>，而不是行中间，保证数据的完整性。</li>
<li><strong>用户自定义格式</strong>: 用户可以通过实现简单的<strong>读取接口 (reader interface)</strong>，支持新的输入类型。<ul>
<li><strong>非文件输入</strong>: 数据可以来自其他来源，如数据库或内存中的数据结构，而不一定是文件。</li>
</ul>
</li>
</ul>
</li>
<li><strong>输出数据格式的支持</strong><ul>
<li>类似输入格式，MapReduce 也支持多种输出格式：<ul>
<li><strong>预定义格式</strong>: 提供了一些常用的输出格式。</li>
<li><strong>自定义格式</strong>: 用户可以通过实现新的接口定义输出数据格式。</li>
</ul>
</li>
</ul>
</li>
</ol>
<p><strong>跳过错误记录 (Skipping Bad Records)</strong></p>
<ol>
<li><strong>问题背景</strong><ul>
<li><strong>用户代码缺陷</strong>: Map 或 Reduce 函数中可能存在错误（如某些记录引发崩溃）。</li>
<li><strong>确定性崩溃</strong>: 对特定记录，每次处理都会发生崩溃。</li>
<li><strong>问题影响</strong>: 这类错误可能<strong>阻止整个 MapReduce 操作完成</strong>。</li>
<li><strong>无法修复的情况</strong>: 错误可能在<strong>第三方库</strong>中，用户无法访问源代码。</li>
</ul>
</li>
<li><strong>MapReduce 提供的解决方案</strong><ul>
<li><strong>跳过问题记录</strong>: MapReduce 允许系统检测引发崩溃的记录，并跳过这些记录以继续操作。</li>
<li><strong>实现机制</strong>:<ul>
<li><strong>信号处理</strong>: 每个工作节点安装<strong>信号处理器</strong>，捕获<strong>段错误 (segmentation violations)</strong> 和<strong>总线错误 (bus errors)</strong>。</li>
<li><strong>记录错误序号</strong>: 在调用用户的 Map 或 Reduce 函数之前，系统将参数的<strong>序列号 (sequence number)</strong> 存储在全局变量中。</li>
<li><strong>发送错误报告</strong>: 如果用户代码触发错误，信号处理器会发送一个 <strong>“最后的喘息” (last gasp)</strong> UDP 数据包，包含引发错误的记录序号，通知主节点。</li>
<li><strong>主节点决策</strong>: 如果一条记录多次导致失败，主节点指示在下次重试该任务时<strong>跳过 (skip)</strong> 这条记录。</li>
</ul>
</li>
</ul>
</li>
</ol>
<p><strong>本地执行 (Local Execution)</strong></p>
<ol>
<li><strong>分布式调试的挑战</strong><ul>
<li><strong>复杂性</strong>: Map 和 Reduce 函数的实际计算是在分布式系统上完成，涉及数千台机器。主节点动态分配任务，调试难以直接定位问题。</li>
<li><strong>常见问题</strong>: 分布式环境下的日志、任务状态和数据流使得问题排查更加困难。</li>
</ul>
</li>
<li><strong>本地执行模式的设计</strong><ul>
<li><strong>功能</strong>: MapReduce 提供了一种<strong>本地执行的替代实现</strong>，在<strong>单台机器</strong>上<strong>顺序执行</strong>整个 MapReduce 操作。</li>
<li><strong>特点</strong>: 所有任务按顺序运行，无需分布式调度。用户可以<strong>限制计算范围</strong>，仅调试特定的 map 任务。</li>
</ul>
</li>
</ol>
<p><strong>计数器 (Counter)</strong></p>
<ul>
<li>计数器用于跟踪 MapReduce 操作期间特定事件的发生次数，例如：<ul>
<li>用户定义的<strong>自定义事件</strong>（例如，单词计数、检测特定模式）。</li>
<li><strong>系统定义的指标</strong>，如处理的输入&#x2F;输出键值对数量。</li>
</ul>
</li>
</ul>
<p><strong>计数器工作原理 (How Counters Work)</strong></p>
<ul>
<li><strong>传播到主节点 (Propagation to the Master)</strong>: 来自各个工作节点的计数器值通过 <strong>ping 响应</strong> 发送到<strong>主节点</strong>。</li>
<li><strong>聚合 (Aggregation)</strong>:<ul>
<li>主节点聚合所有已完成任务的计数器值。</li>
<li>它通过忽略重复的任务执行（例如，由于重新执行或备份任务）来确保<strong>没有重复计数</strong>。</li>
</ul>
</li>
</ul>
<p><strong>监控与报告 (Monitoring and Reporting)</strong></p>
<ul>
<li><strong>实时监控 (Real-Time Monitoring)</strong>: 当前的计数器值显示在<strong>主节点状态页面</strong> 上，允许用户观察计算的进度。</li>
<li><strong>最终报告 (Final Reporting)</strong>: 当 MapReduce 作业完成时，聚合后的计数器值返回给用户程序。</li>
</ul>
<h1 id="问题-Questions"><a href="#问题-Questions" class="headerlink" title="问题 (Questions)"></a>问题 (Questions)</h1><p><strong>假设 M&#x3D;10 且 R&#x3D;20，映射器 (mappers) 产生的文件总数是多少？</strong></p>
<blockquote>
<p>总文件数 &#x3D; M × R &#x3D; 10 × 20 &#x3D; 200</p>
</blockquote>
<p><strong>为什么 MapReduce 将 Reduce 的输出存储在 Google 文件系统 (GFS) 中？</strong></p>
<blockquote>
<ul>
<li><strong>高可用性 (High Availability)</strong>: GFS 通过在多个机器上<strong>复制数据 (replicating data)</strong> 提供容错能力。这确保了即使一台机器故障，输出也不会丢失。</li>
<li><strong>可扩展性 (Scalability)</strong>: GFS 专为处理大规模数据存储而设计，适用于 MapReduce 作业产生的大量输出。</li>
</ul>
</blockquote>
<p><strong>拖后腿任务 (straggler) 的目的是什么？</strong></p>
<blockquote>
<ul>
<li><strong>“拖后腿任务 (Straggler)” 指的是运行缓慢的任务</strong>，通常是 map 或 reduce 任务，它们会<strong>显著延迟</strong> MapReduce 作业的完成。</li>
<li><strong>解决方法</strong>:<ul>
<li><strong>备份执行 (Backup Execution)</strong>: 主节点在其它可用工作节点上为拖后腿任务安排备份执行。</li>
</ul>
</li>
</ul>
</blockquote>
<p><strong>判断对错：可以在没有模式 (schema) 的情况下，对 CSV 数据文件使用 SQL++。</strong></p>
<blockquote>
<p><strong>正确 (True)</strong>: SQL++ 可以操作半结构化数据，包括 CSV 文件，而<strong>不需要</strong>预定义的模式。</p>
</blockquote>
<p><strong>在 SQL++ 中，pivot 和 unpivot 有什么区别？</strong></p>
<blockquote>
<p><strong>Pivot (透视)</strong>:</p>
<ul>
<li><strong>目的</strong>: 将<strong>行 (rows)</strong> 转换为<strong>属性 (attributes) &#x2F; 列 (columns)</strong>。</li>
<li><strong>示例</strong>:<ul>
<li>输入: <code>[ &#123; &quot;symbol&quot;: &quot;amzn&quot;, &quot;price&quot;: 1900 &#125;, &#123; &quot;symbol&quot;: &quot;goog&quot;, &quot;price&quot;: 1120 &#125;, &#123; &quot;symbol&quot;: &quot;fb&quot;, &quot;price&quot;: 180 &#125; ]</code></li>
<li>查询: <code>PIVOT sp.price AT sp.symbol FROM today_stock_prices sp;</code></li>
<li>输出: <code>&#123; &quot;amzn&quot;: 1900, &quot;goog&quot;: 1120, &quot;fb&quot;: 180 &#125;</code></li>
</ul>
</li>
</ul>
<p><strong>Unpivot (逆透视)</strong>:</p>
<ul>
<li><strong>目的</strong>: 将<strong>属性 (attributes) &#x2F; 列 (columns)</strong> 转换为<strong>行 (rows)</strong>。</li>
<li><strong>示例</strong>:<ul>
<li>输入: <code>&#123; &quot;date&quot;: &quot;4/1/2019&quot;, &quot;amzn&quot;: 1900, &quot;goog&quot;: 1120, &quot;fb&quot;: 180 &#125;</code></li>
<li>查询: <code>UNPIVOT c AS price AT sym FROM closing_prices c WHERE sym != &#39;date&#39;;</code></li>
<li>输出: <code>[ &#123; &quot;date&quot;: &quot;4/1/2019&quot;, &quot;symbol&quot;: &quot;amzn&quot;, &quot;price&quot;: 1900 &#125;, &#123; &quot;date&quot;: &quot;4/1/2019&quot;, &quot;symbol&quot;: &quot;goog&quot;, &quot;price&quot;: 1120 &#125;, &#123; &quot;date&quot;: &quot;4/1/2019&quot;, &quot;symbol&quot;: &quot;fb&quot;, &quot;price&quot;: 180 &#125; ]</code></li>
</ul>
</li>
</ul>
</blockquote>
<p><strong>使用 BG ，可以通过其 SoAR (Satisfaction of Agreement Ratio) 来总结数据存储的性能。计算数据存储 SoAR 的 BG 输入是什么？</strong></p>
<blockquote>
<p><strong>1. SLA 规范 (SLA Specifications)</strong></p>
<p>服务等级协议 (SLA) 定义了计算 SoAR 的条件。SLA 包括：</p>
<ul>
<li><strong>α</strong>: 必须观察到响应时间小于或等于 β 的请求百分比（例如，95%）。</li>
<li><strong>β</strong>: 最大可接受响应时间（例如，100 毫秒）。</li>
<li><strong>τ</strong>: 观察到不可预测（过时或不一致）数据的请求的最大允许百分比（例如，0.01%）。</li>
<li><strong>Δ</strong>: SLA 必须被满足的持续时间（例如，10 分钟）。</li>
</ul>
<p><strong>2. 数据库配置 (Database Configuration)</strong></p>
<p>关于被测数据存储的详细信息：</p>
<ul>
<li><strong>逻辑模式 (Logical Schema)</strong>: 数据存储使用的数据模型（例如，关系模式、NoSQL 的类 JSON 模式）。</li>
<li><strong>物理设置 (Physical Setup)</strong>: 硬件配置，包括：<ul>
<li>节点数量。</li>
<li>存储和内存资源。</li>
<li>网络能力。</li>
</ul>
</li>
<li><strong>数据量大小 (Population Size)</strong>:<ul>
<li><strong>M</strong>: 数据库中的成员数量。</li>
<li><strong>ϕ</strong>: 每个成员的关注者&#x2F;朋友数量。</li>
<li><strong>ρ</strong>: 每个成员的资源数量。</li>
</ul>
</li>
</ul>
<p><strong>3. 工作负载参数 (Workload Parameters)</strong></p>
<p>工作负载指定了 BG 将模拟的操作的性质和强度：</p>
<ul>
<li><strong>操作混合比例 (Mix of Actions)</strong>:<ul>
<li>社交网络操作的类型（例如，查看个人资料、列出朋友、查看好友请求）。</li>
<li>每种操作类型的百分比（读密集型、写密集型或混合工作负载）。</li>
</ul>
</li>
<li><strong>思考时间 (ϵ - Think Time)</strong>: 单个线程执行连续操作之间的延迟。</li>
<li><strong>到达间隔时间 (ψ - Inter-Arrival Time)</strong>: 新用户会话之间的延迟。</li>
</ul>
<p><strong>4. 环境参数 (Environmental Parameters)</strong></p>
<p>关于 BG 如何生成和管理工作负载的详细信息：</p>
<ul>
<li><strong>BGClients 数量 (N)</strong>: 负责生成请求的实例数。</li>
<li><strong>线程数量 (T)</strong>: 并发级别（每个 BGClient 的线程数）。</li>
<li><strong>D-Zipfian 分布参数 (θ)</strong>: 定义访问模式（例如，热门数据与冷门数据的访问频率）。</li>
</ul>
</blockquote>
<p><strong>考虑键值对优先级 (priority) 的以下二进制表示：00101001。其精度为 4 的 CAMP 舍入 (CAMP rounding) 结果是什么？</strong></p>
<blockquote>
<p>00101000<br><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/bg_bm_rounding.png" alt="img"></p>
</blockquote>
<p><strong>什么是惊群效应 (thundering herd)？IQ 框架如何防止它导致持久化数据存储成为瓶颈？</strong></p>
<blockquote>
<p><strong>惊群效应问题 (Thundering Herd Problem)</strong>:</p>
<ul>
<li>当一个键值对在键值存储 (KVS) 中<strong>未找到</strong>（发生 <strong>KVS 未命中 (KVS miss)</strong>）时，多个读取会话可能会<strong>同时</strong>查询关系数据库管理系统 (RDBMS) 以获取该值。</li>
<li>这可能在<strong>高并发</strong>情况下使 RDBMS <strong>过载</strong>并导致性能下降。</li>
</ul>
<p><strong>IQ 框架的解决方案</strong>:</p>
<ul>
<li>当<strong>第一个</strong>读取会话遇到 KVS 未命中时，它会为该键请求一个 <strong>I 租约 (I lease)</strong>。</li>
<li>一旦 I 租约被授予，KVS 会<strong>阻止</strong>其他读取会话为同一个键查询 RDBMS。</li>
<li>所有其他读取会话必须 <strong>“回退 (back off)”</strong> 并等待持有 I 租约的会话将值更新到 KVS 中。</li>
</ul>
<blockquote>
<p>(补充解释) 惊群效应发生在特定键经历<strong>大量读写活动</strong>时。</p>
<ul>
<li>写入操作<strong>重复地使缓存失效 (invalidate the cache)</strong>。</li>
<li>所有读取操作都<strong>被迫查询数据库</strong>。</li>
</ul>
<p><strong>I 租约解决了这个问题</strong>：</p>
<ul>
<li>对特定键的<strong>第一次读取</strong>被授予 I 租约。</li>
<li>所有其他读取观察到未命中并<strong>回退</strong>。</li>
<li>持有 I 租约的读取查询 RDBMS，计算缺失的值，并将该值<strong>填充 (populate)</strong> 到缓存中。</li>
<li>所有其他读取随后会<strong>观察到缓存命中 (cache hit)</strong>。</li>
</ul>
</blockquote>
</blockquote>
<p><strong>参考</strong>: <a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/mapreduce-osdi04.pdf">https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/mapreduce-osdi04.pdf</a></p>
]]></content>
      <categories>
        <category>数据库系统</category>
        <category>分布式系统</category>
      </categories>
  </entry>
  <entry>
    <title>Nova-LSM</title>
    <url>/undefined/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2024/09/19/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/Nova-LSM/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h1 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h1><p>LSM-Tree（Log-Structured Merge Tree）的核心思想是将大量的随机写入转换为更高效的顺序写入。简单来说，它通过以下方式来实现：</p>
<ol>
<li><strong>写入内存</strong>：当有新的数据写入时，LSM-Tree首先将这些数据存储在内存中的缓冲区（称为MemTable）。这是一个有序的结构，数据按键排序。</li>
<li><strong>批量写入磁盘</strong>：当内存中的数据积累到一定程度时，整个MemTable会被一次性地写入磁盘，这个过程是<strong>顺序写入</strong>，非常高效。写入磁盘后，这个数据成为一个不可修改的文件，称为SSTable（Sorted String Table）。</li>
<li><strong>合并和压缩</strong>：随着时间的推移，磁盘上会产生多个SSTable。为了优化读取性能，系统会周期性地将这些SSTable进行合并和压缩，使得数据保持有序并减少冗余。</li>
</ol>
<p>这样，LSM-Tree通过将频繁的随机写操作缓存在内存中，最后批量顺序写入磁盘，大大提高了写入性能。这种方式适合写入密集型的工作负载，同时还能保证数据查询的效率。</p>
<p><strong>LSM-Tree的基础结构</strong>，特别是数据如何从内存（memtable）移动到磁盘，并经过多级的归并排序（compaction）过程来进行存储。</p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/nova_lsm_basic_structure.png" alt="img"></p>
<ol>
<li><p>MemTable（内存表）</p>
<ul>
<li><p>数据的写入首先进入到内存中的memtable，通常是一个有序的数据结构（比如跳表或B+树），这使得数据在内存中是有序的，便于快速写入和查询。</p>
</li>
<li><p>当memtable满了或者系统需要将数据持久化时，memtable中的数据会被flush（刷新）到磁盘，形成第一层的SSTable。</p>
</li>
</ul>
</li>
<li><p>Level-0（磁盘上的第一层）</p>
<ul>
<li><p>数据从内存写入磁盘后，存储在Level-0层的SSTable中。此时，SSTable的数据顺序与memtable一致，但可能存在多个SSTable，且它们之间的键值范围可能重叠。</p>
</li>
<li><p>Level-0的SSTable是逐渐积累的，并不会自动排序或整理，直到执行compaction（归并操作）。</p>
</li>
</ul>
</li>
<li><p>Compaction（归并操作）</p>
<ul>
<li><p>当Level-0层的数据达到一定量时，系统会执行归并操作，将Level-0层的多个SSTable合并，并将合并后的有序数据移到Level-1层。</p>
</li>
<li><p>Level-1开始，所有的SSTable都是有序且互不重叠的。也就是说，每个SSTable都有自己独立的键值范围，不会与其他SSTable的键值范围重叠，这使得查询时能够快速定位到目标SSTable。</p>
</li>
</ul>
</li>
<li><p>逐级沉降</p>
<ul>
<li><p>数据会随着系统运行，从Level-0层逐步沉降到更深的层级（如Level-1、Level-2等）。在每一层，数据都通过归并操作变得更加有序且结构紧凑。</p>
</li>
<li><p>每次合并后，数据被重新整理，分配到新的不重叠的SSTable中，从而保持物理上的键值有序性。</p>
</li>
</ul>
</li>
</ol>
<p><strong>LSM-Tree查询</strong></p>
<p>基于LSM-Tree的查询可分为点查与范围查询两大类，对应的执行方式如下：</p>
<ul>
<li>点查（point lookup）：从上往下进行查询，先查memtable，再到L0层、L1层。因为上层的数据永远比下层版本新，所以在第一次发生匹配后就会停止查询。</li>
<li>范围查询（range lookup）：每一层都会找到一个匹配数据项的范围，再将该范围进行<strong>多路归并</strong>，归并过程中同一key只会保留最新版本。</li>
</ul>
<p><strong>LSM-Tree性能的衡量</strong>主要考虑三个因素：空间放大、读放大和写放大。</p>
<p>一是空间放大（space amplification）。LSM-Tree的所有写操作都是顺序追加写，对数据的更新并不会立即反映到数据既有的值里，而是通过分配新的空间来存储新的值，即out-place update。因此冗余的数据或数据的多版本，仍会在LSM-Tree系统里存在一定时间。这种实际的占用空间大于数据本身的现象我们称之为空间放大。因为空间有限，为了减少空间放大，LSM-Tree会从L1往L2、L3、L4不断做compaction，以此来清理过期的数据以及不同数据的旧版本，从而将空间释放出来。</p>
<p>二是读放大（read amplification）。假设数据本身的大小为1k，由于存储结构的设计，它所读到的值会触发多次IO操作，一次IO意味着一条读请求，这时它所读取到的则是在后端所需要做大的磁盘读的实际量，已经远大于目标数据本身的大小，从而影响到了读性能。这种现象我们称之为读放大。为了减轻读放大，LSM-Tree采用布隆过滤器来避免读取不包括查询键值的SST文件。</p>
<p>三是写放大（write amplification）。在每层进行compaction时，我们会对多个SST文件进行反复读取再进行归并排序，在删掉数据的旧版本后，再写入新的SST文件。从效果上看，每条key在存储系统里可能会被多次写入，相当于一条key在每层都会写入一次，由此带来的IO性能损失即写放大。</p>
<p>LSM-Tree最初的理念是用空间放大和读放大来换取写放大的降低，从而实现较好的写性能，但也需要做好三者的平衡。以下是两种假设的极端情况。</p>
<p>第一种极端情况是：如果完全不做compaction，LSM-Tree基本等同于log文件，当memtable不断刷下来时，由于不做compaction，只做L0层的文件，这时如果要读一条key，读性能会非常差。因为如果在memtable里找不到该条key，就要去扫描所有的SST文件，但与此同时写放大现象也将不存在。</p>
<p>第二种极端情况是：如果compaction操作做到极致，实现所有数据全局有序，此时读性能最优。因为只需要读一个文件且该文件处于有序状态，在读取时可以很快找到对应的key。但要达到这种效果，需要做非常多的compaction操作，要不断地把需要删的SST文件读取合并再来写入，这会导致非常严重的写放大。</p>
<h1 id="Nova-LSM架构设计"><a href="#Nova-LSM架构设计" class="headerlink" title="Nova-LSM架构设计"></a>Nova-LSM架构设计</h1><p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/nova_lsm_arch.png" alt="img"></p>
<p>第一部分是写日志的组件，将WAL写成功后再往LSM-Tree的memtable中查询新的数据。</p>
<p>第二部分是本身处理LSM-Tree写入的线程，其缩写为LTC(LSM-Tree Component)，代表着将该线程单独组件化。</p>
<p>第三部分则是底层的存储，负责把接收到的上层LTC组件下发下来，并提供标准的文件接口。</p>
<p><strong>Nova-LSM所解决的核心问题</strong></p>
<p>第一个核心问题是：基于LSM-Tree结构的存储系统，例如LevelDB、RocksDB等，都会不可避免地遇到缓写或者停写的问题。比如内存里的memtable，在配置时最多可以写8个，因为写入多，需要全部flush到磁盘上。与此同时，当前L0层的SST文件非常多，L0层即将开始做compaction。但compaction会涉及到磁盘IO，在还没做完时，就会阻塞内存中的memtable对L0层SST进行flush的过程。当flush无法进行时，就会发生缓写，随着阈值的推进，在实在写不进时甚至会停写，这种现象体现在客户端就是请求掉零。</p>
<p>为了解决LSM-Tree结构存储系统中的缓写、停写问题，该文章提出了两个解决办法：</p>
<ul>
<li>第一种方法是设计了<strong>存算分离</strong>的架构体系，具体如上图所示。该架构的重要作用之一，是把处理写入和处理磁盘IO的两大主力模块拆分，计算存储分离，<strong>哪个部分慢就为哪个部分增加节点</strong>以此来提高该部分的能力，这是比较亮眼的突破。</li>
<li>第二种方法是引入了<strong>动态分区</strong>，即Drange机制。该机制的目的是为了让业务的写入压力，在LTC即计算层的memtable上进行区间划分，每个range都有自己的memtable，通过区间划分，从而<strong>实现多个range之间进行并行compaction</strong>。以L0层为例，我们可以把L0层变成没有互相重叠的状态，这时我们就可以对L0层进行并行的compaction，可以加快L0层的文件的消化，从而减轻对memtable flush到磁盘上的过程的影响。</li>
</ul>
<p>第二个核心问题是：在这种方式下需要划分很多不同的Drange，每个range都会增加一定的memtable数量，memtable数量的增加会影响scan和get的性能。假设有一个主请求，在原来所有数据都写在一个memtable里的情况下，在读取时，索引只需要面向这个memtable，再根据跳表进行get，如果get到则可以马上返回。现在划分成不同的Drange，memtable数量增加，因此需要查找的memtable以及L0层的SST也会变多。解决办法是：实现了一个索引，可以查询到一个key在memtable或L0 SST中的最新值（若存在）。</p>
<h1 id="Nova-LSM-中的重要设计"><a href="#Nova-LSM-中的重要设计" class="headerlink" title="Nova-LSM 中的重要设计"></a>Nova-LSM 中的重要设计</h1><h2 id="LTC和StoCs之间的写数据流程"><a href="#LTC和StoCs之间的写数据流程" class="headerlink" title="LTC和StoCs之间的写数据流程"></a>LTC和StoCs之间的写数据流程</h2><p>第一个比较重要的设计是LTC和StoCs之间的写数据流程。该流程展示的是：当在客户端发起写请求时，计算节点和存储节点是以怎样的方式将数据写进去的过程。</p>
<p>首先是计算节点的客户端发起一个新的写请求操作。存储节点在接收到该请求后，基于RDMA交互，它会在buffer区域分配一个内存区域，并且为这块内存和偏移量（当前哪块内存可以写）分配一个id，告知客户端。客户端接到响应后就会开始写数据，完成后会通知存储节点。存储节点接收到信号后，将数据持久化并且再告知客户端。</p>
<p>上述流程是写一个数据文件即SSTable。写完后，我们要以同样的流程将元数据文件更新。因为底层是分布式架构，需要知道哪些文件写在哪里以及每个SST的范围、版本号。</p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/nova_lsm_key_design.png" alt="img"></p>
<h2 id="动态区间划分"><a href="#动态区间划分" class="headerlink" title="动态区间划分"></a>动态区间划分</h2><p>第二个比较重要的设计是动态区间划分。假设业务的请求范围为0-1万，当前有10个计算节点，将这10个计算节点的区间划分为10等份，比如第一个key的空间范围为0-1000。在负责0-1000的计算节点里，它会再进行划分，这一层划分业务无感知。这就叫动态区间划分，简称Drange。其作用主要有以下几点：</p>
<p>首先，每个range都是一棵LSM-Tree，按照数据区间，不同的Drange都有自己的memtables。比如0-1000区间又可以划分为10个Drange，10个Drange之间的memtable相互独立。这样做的好处是这些Drange之间的key互不重叠，例如0-100、100-200、200-300。</p>
<p>其次，在Dranges下还有一层Tranges。如果发现Drange里的部分range比如890-895存在热点现象，而旁边的range并非热点，则可以用Tranges进行细粒度的复杂重均衡，实现动态均衡负载。</p>
<p>最后，在此基础上，因为Drange的key范围互不相交，当memtable变成immutable，不可再写后，它们需要独立地flush到磁盘上。这时，在L0层的SSTable来自不同的Drange，它们之间的key完全不相交，我们就可以进行并行的compaction。</p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/nova_lsm_key_design_2.png" alt="img"></p>
<p>文章还将没有Drange划分和有Drange划分两种情况进行了对比：</p>
<ul>
<li>在没有Drange划分的情况下，L0的compaction无法很好并行。在这种情况下，如果遇到最坏的情况，L0层的某一个SST有可能覆盖了整个key空间，假设key范围为0-600，L0层的SST文件的范围是0-1000，当发生compaction时，它必须要跟其他4个SST做归并，这时不但要把L0层的其他SST全部读取比较一遍，还要把L1层所有的SST都读一遍再做归并排序。这时写放大会较为严重，意味着L0层到L1层的compaction会变慢，flush也会变慢，甚至flush不了时，前端就会出现缓写、停写现象。</li>
<li>有Drange划分后，相当于compaction可以分开区间，如下方的示意图所示。在0-100区间，L0到L1可以独立去compaction，100-200区间也可以独立去compaction，可以较好地实现并行compaction。而在原生的RocksDB里，只有从L1开始compaction，才能进行并行compaction操作。</li>
</ul>
<h2 id="索引查找以及Scan操作"><a href="#索引查找以及Scan操作" class="headerlink" title="索引查找以及Scan操作"></a>索引查找以及Scan操作</h2><p>因为划分了很多不同的动态区间，memtable的数量也会增加，意味着查询操作的耗时也会增加。所以要如何在原来的基础上维护好读性能？这篇文章提出了以下解决思路：</p>
<p>每个LTC维护了一个lookup index。如果这些数据存在于memtable和L0层的SST上，通过lookup index我们就可以快速查找到想要的数据。当某一个L0层SST被compaction到L1层时，索引上就会移除掉对应的key。</p>
<p>LTC同时还维护了一个范围索引即range index。因为知道每个Drange的范围，所以当一个scan请求所涉及到的key都可以在memtable和L0层SST中找到时，该范围索引就能快速响应scan操作。</p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/nova_lsm_key_design_3.png" alt="img"></p>
<h2 id="SSTable的分布"><a href="#SSTable的分布" class="headerlink" title="SSTable的分布"></a>SSTable的分布</h2><p>最后一个比较重要的设计涉及到存储层。当某个SST文件要写到存储节点时，分布式系统首先要保证负载均衡，要保证数据避免单点故障不可恢复的场景。</p>
<p>该文章提出根据一定策略，将数据文件即SST打散写入到多个存储节点里。考虑到存储成本，每个SSTable采用纠删码（Erasure Coding）的方式进行编码然后分布式存放。默认情况下对每个 SSTable 采用 “3+1”的 EC 配置，将一个SSTable切分为3个数据块，根据一定算法，在这3个数据块里去计算出一个校验块，变成了“3+1”的形式。这种方式比传统的多副本可以<strong>节省更多空间</strong>。假设一个SSTable是3M，这种“3+1”的方式最终所占空间为4M，并且<strong>能容忍一个节点的丢失</strong>，与占用6M空间的双副本方案拥有同样的故障容忍等级。而元数据文件因为体积比较小，所以直接采用多副本存储的方式，比如1个元数据文件可以写3个副本。</p>
<h1 id="Challenges-and-Solutions"><a href="#Challenges-and-Solutions" class="headerlink" title="Challenges and Solutions"></a>Challenges and Solutions</h1><ol>
<li><p>Write Stalls, the solutions are:</p>
<ol>
<li><p>Vertical scaling: use large memory.</p>
</li>
<li><p>Horizontal scaling: use the bandwidth of many StoCs.</p>
</li>
</ol>
</li>
<li><p>Scans are slowed down, the solutions are:</p>
<ol>
<li><p>Construct Dranges at runtime based on workload. Drange faciliates parallel compaction.</p>
</li>
<li><p>Construct range index dynamically.</p>
</li>
</ol>
</li>
<li><p>Gets are slowed down, the solution is: Use lookup index.</p>
</li>
<li><p>Temporary Bottlenecks, the solution is:</p>
<ol>
<li><p>Scatter blocks of a SSTable across multiple StoCs.</p>
</li>
<li><p>Power-of-d: power-of-d is applied in Nova-LSM to help with load balancing during SSTable placement. When writing data to storage components (StoCs), Nova-LSM doesn’t randomly select just one StoC. Instead, it chooses d StoCs at random and writes to the one with the shortest queue. This method helps avoid bottlenecks and improves throughput, ensuring that data is distributed evenly across storage nodes without overwhelming any individual node.</p>
</li>
</ol>
</li>
<li><p>Logging, the solution is: Replicating Log records in the memory of StoCs to provide high availability.</p>
</li>
<li><p>Skewed Access Pattern, the solution is: Dranges enable LTC to write 65% less data to StoCs with skewed data access.</p>
</li>
</ol>
<h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h1><p><strong>Why do modern database systems disaggregate compute from storage?</strong></p>
<p>Modern database systems disaggregate compute from storage to improve scalability, resource utilization, and fault isolation. By separating compute (processing) and storage, the system can independently scale each based on demand. Compute nodes handle processing, while storage nodes handle data access, optimizing resources and ensuring that failures in one component don’t impact the other. This separation also benefits cloud environments, where elastic scaling of resources is crucial.</p>
<p><strong>How does Nova-LSM provide superior performance than monolithic data stores?</strong> </p>
<p>Nova-LSM improves performance by using a component-based architecture that disaggregates processing (LTC) and storage (StoC). It allows components to scale independently and uses RDMA for fast communication. Nova-LSM also introduces dynamic range partitioning (Dranges), allowing parallel compaction and reducing write stalls, which significantly enhances throughput. This architecture minimizes bottlenecks seen in monolithic stores like LevelDB and RocksDB, especially under skewed workloads.</p>
<p><strong>Why does the standard cost-based optimizer produce sub-optimal query plans? How does Kepler improve both the query planning time and query execution time?</strong></p>
<p>The standard cost-based optimizer can produce sub-optimal plans because it relies on simplified and static cost models that don’t always capture real execution costs, especially in dynamic environments. It also may lack up-to-date statistics, leading to inaccurate decisions. Kepler, on the other hand, uses machine learning to learn from past executions and adapts to current data distributions, improving query plan selection. By pruning the search space efficiently and using real-time data, it reduces both planning time and execution time while optimizing performance.</p>
<p>References: </p>
<ul>
<li><p><a href="https://cloud.tencent.com/developer/article/2002523?areaSource=102001.3&traceId=XIO8WvF-vqiMAsiAKu2Lv">https://cloud.tencent.com/developer/article/2002523?areaSource=102001.3&amp;traceId=XIO8WvF-vqiMAsiAKu2Lv</a></p>
</li>
<li><p><a href="https://dl.acm.org/doi/pdf/10.1145/3448016.3457297">https://dl.acm.org/doi/pdf/10.1145/3448016.3457297</a></p>
</li>
</ul>
]]></content>
      <categories>
        <category>数据库系统</category>
        <category>分布式系统</category>
      </categories>
  </entry>
  <entry>
    <title>OCC 和 MVCC</title>
    <url>/undefined/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/2024/10/10/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/OCC%20%E5%92%8C%20MVCC/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h1 id="Time-Stamp-Based-Protocols"><a href="#Time-Stamp-Based-Protocols" class="headerlink" title="Time-Stamp Based Protocols"></a>Time-Stamp Based Protocols</h1><p>Suppose transaction Ti issues read(Q):</p>
<ul>
<li>If TS(Ti) &lt; W-TimeStamp(Q), then Ti needs to read the value of Q which was already overwritten. Hence the read request is rejected and Ti is rolled back.</li>
<li>If TS(Ti) &gt;&#x3D; W-TimeStamp(Q), then the read operation is executed and the R-timeStamp(Q) is set to the maximum of R-TimeStamp(Q) and TS(Ti).</li>
</ul>
<p>Suppose transaction Ti issues write(Q):</p>
<ul>
<li>If TS(Ti) &lt; R-TimeStamp(Q), then this implies that some transaction has already consumed the value of Q and Ti should have produced a value before that transaction read it. Thus, the write request is rejected and Ti is rolled back.</li>
<li>If TS(Ti) &lt; W-TimeStamp(Q), then Ti is trying to write an obsolete value of Q. Hence reject Ti’s request and roll it back. &#x2F; Ignore this write operation. (Tomas’s Write Rule)</li>
<li>Otherwise, execute the write(Q) operation and update W-TimeStamp(Q) to TS(Ti).</li>
</ul>
<h1 id="OCC"><a href="#OCC" class="headerlink" title="OCC"></a>OCC</h1><p>Each transaction Ti has three phases:</p>
<ul>
<li>Read phase: reads the value of data items and copies its contents to variables local to Ti. All writes are performed on the temporary local variables.</li>
<li>Validation phase: Ti determines whether the local variables whose values have been overwritten can be copied to the database. If not, then abort. Otherwise, proceed to Write phase.</li>
<li><ul>
<li>When validating transaction Tj, for all transactions Ti with TS(Ti) &lt; TS(Tj), one of the following must hold:</li>
<li><ul>
<li>Finish(Ti) &lt; Start(Tj), OR</li>
<li>Set of data items written by Ti does not intersect with the set of data items read by Tj, and Ti completes its write phase before Tj starts its validation phase.</li>
</ul>
</li>
</ul>
</li>
<li>Write phase: The values stored in local variables overwrite the value of the data items in the database.</li>
</ul>
<p>A transaction has three time stamps:</p>
<ul>
<li>Start(Ti): When Ti started its execution.</li>
<li>Validation(Ti): When Ti finished its read phase and started its validation.</li>
<li>Finish(Ti): Done with the write phase.</li>
</ul>
<h1 id="MVCC"><a href="#MVCC" class="headerlink" title="MVCC"></a>MVCC</h1><p>Assume that transaction Ti issues either a read(Q) or a write(Q) operation.</p>
<p>Let Qk denote the version of Q whose write timestamp is the largest write timestamp less than TS(Ti), i.e., W-TimeStamp(Qk) &lt; TS(Ti).</p>
<ul>
<li>If Ti issues a Read(Q), then return the value of Qk.</li>
<li>If Ti issues a write(Q), and TS(Ti) &lt; R-TimeStamp(Qk), then Ti is rolled back.</li>
<li>Otherwise, a new version of Qk is created.</li>
</ul>
]]></content>
      <categories>
        <category>数据库系统</category>
      </categories>
  </entry>
  <entry>
    <title>SDM</title>
    <url>/undefined/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/2024/08/29/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/SDM/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h1 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h1><p>Data Models: Conceptual -&gt; Logical -&gt; Physical.</p>
<p>SDM is a conceptual data modeling tool, at the intersection of conceptual and logical. It facilitates <strong>an understaning of the meaning of the data</strong>.</p>
<ul>
<li>Identify and classify principal intensional (semantic) structures of an application.</li>
</ul>
<p>A set of constructs that express the essential meaning and structure of different problem domains.</p>
<h1 id="Basic-Structure"><a href="#Basic-Structure" class="headerlink" title="Basic Structure"></a>Basic Structure</h1><ul>
<li>Classes: a collection of entities. Each class has:</li>
<li><ul>
<li>A name.</li>
<li>A collection of members: Its entities. 3 member types:</li>
<li><ul>
<li>Objects:</li>
<li><ul>
<li>Concrete.</li>
<li>Abstraction: a generalization of another entity.</li>
<li>Aggregate: a collection of another type of entity.</li>
</ul>
</li>
<li>Events: Action or activities in the application. Point and duration events.</li>
<li>Names are deginators for objects or events.</li>
</ul>
</li>
<li>Attributes.</li>
<li>A description: nature, purpose, and uses of the class.</li>
<li>Identified as either base or nonbase.</li>
</ul>
</li>
<li>Schema: a collection of classes.</li>
</ul>
<p>Class Attributes:</p>
<ol>
<li><strong>Member attributes</strong> link the member to one or more related entities in the same or another class.</li>
<li><strong>Class determined attribute</strong> is associated with the whole class and has the same value for all members of that class.</li>
<li><strong>Class attribute</strong> describes a property of a class taken as a whole.</li>
</ol>
<p>An attribute value is either a primitive (user defined) or derived (a value calculated from other information in the database).</p>
<h1 id="Base-class"><a href="#Base-class" class="headerlink" title="Base class"></a>Base class</h1><p>It is independent of other classes. In SDM, it may be a concrete object class, a point event class, a duration event, a name class.</p>
<p>It is specified as either containing duplicates or not containing duplicates. The latter models a multiset&#x2F;bag of entities.</p>
<p>It has an associated list of groups of member attributes. One or more may serve as the unique identifier of a member.</p>
<h1 id="Nonbase-class"><a href="#Nonbase-class" class="headerlink" title="Nonbase class"></a>Nonbase class</h1><p>Subclass of a parent class. Members of the subclass inherit all attributes of the parent class. Subclass may add new member attributes. 2 types:</p>
<ol>
<li>Restrict: a predicate identifies which members of the parent belong to a subclass.</li>
<li>Subset: A human user decides entities in the subclass as long as the subclass is a subset of its parent.</li>
</ol>
<p>Attribute value: either an entity or a class of entities. It can be UNKNOWN.</p>
<p>Semantic types:</p>
<ol>
<li>A componenet models a physical part of an object.</li>
<li>A participant of the event entity models an entity that plays a role in an event.</li>
<li>A property of an attribute is an attribute that provides further information on the relationship between the entity and the value of one of its attributes.</li>
</ol>
<h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h1><p><strong>Why is it important for a relational schema to satisfy the 5 normal forms?</strong></p>
<p>To ensure the data integrity and consistency, and minimize the loss and redundancy of information.</p>
<p>1NF: all occurences of a record type must contain the same number of fields.</p>
<p>2 and 3NF: a non-key attribute is a fact about only the whole key.</p>
<p>4NF: a record should not contain two or more independent multi-valued fact about an entity.</p>
<p>5NF: decompose a table into smaller ones to eliminate multi-valued dependencies, while ensuring that the original data can be losslessly reconstructed through join operation.</p>
<p><strong>With SDM, what is the unique identifier of a class containing duplicates?</strong></p>
<p>There is no unique identifier of a class containing duplicates since some of the members of this class are indistinguishable.</p>
<p><strong>Is SDM a competitor to the relational data model?</strong> </p>
<p>Yes. But SDM is not intended to be a direct competitor to the relational data model. The goal of SDM is to provide a more semantic way to model complex application environments, expressing the structure and meaning of data more effectively than tradtional relational models. It is designed to enhance the relational data model.</p>
<p><strong>A database represents a snapshot of the state of an application and the changes to the database over time. What is the change in a 3D display that illuminates animations using FLSs? Does an FLS display represent a database using drones?</strong> </p>
<p>A 3D FLS display illuminates animations by computing the flight paths of the FLS drones based on the dynamic attributes of objects, such as geometry, color, and movement over time. Changes in the display represent transitions in the object’s states or visual properties.</p>
<p>Yes, the FLS display act as a dynamic visualization tool that represents a database where each drone corresponds to data points or entities, displaying multimedia content in a 3D space.</p>
<p><strong>Section 1 of the SDM paper states: “SDM is not dependent on the successful implementation of a new database management system that directly supports the SDM. The latter approach would be impractical for a variety of reasons.” Why is it impractical to implement a new database management system that supports the SDM? Do you know of a system?</strong></p>
<p>SDM emphasizes the <strong>meaning</strong> and <strong>relationship</strong> of data, requiring sophisticated handling of semantics, which adds complexity. Integrating SDM into existing systems will cause incompatibility with current DBMS architectures.</p>
<p>While there is not a widely adopted DBMS that fully supports SDM, some graph databases or knowledge graph systems such as <strong>Neo4j</strong>, <strong>RDF stores</strong> partially align with SDM principles.</p>
<p>Reference: <a href="https://dl.acm.org/doi/pdf/10.1145/509252.509264">https://dl.acm.org/doi/pdf/10.1145/509252.509264</a></p>
]]></content>
      <categories>
        <category>数据库系统</category>
      </categories>
  </entry>
  <entry>
    <title>SQL++</title>
    <url>/undefined/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/2024/11/14/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/SQL++/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h1 id="Data-Model"><a href="#Data-Model" class="headerlink" title="Data Model"></a>Data Model</h1><p><strong>SQL++ has a more flexible data model:</strong></p>
<ul>
<li>It relaxes traditional SQL’s strict rules to handle modern, semi-structured data like JSON or CBOR.</li>
<li>SQL++ databases can store self-describing data, meaning you don’t need a predefined schema (data structure).</li>
</ul>
<p><strong>Supports diverse data types:</strong></p>
<ul>
<li>Data can be single values (scalars), tuples (a set of key-value pairs), collections (like arrays or multisets), or combinations of these.</li>
<li>Unlike traditional SQL, tuples in SQL++ are <strong>unordered</strong>, which means the order of attributes doesn’t matter.</li>
</ul>
<p><strong>Allows duplicate attribute names but discourages them:</strong></p>
<ul>
<li>This is to accommodate non-strict formats like JSON.</li>
<li>However, duplicate names can lead to unpredictable query results, so they’re not recommended.</li>
</ul>
<p><strong>Two kinds of missing values:</strong> <strong><code>NULL</code> and <code>MISSING</code></strong>:</p>
<ul>
<li><strong><code>NULL</code></strong>: Means an attribute exists but has no value.</li>
<li><strong><code>MISSING</code></strong>: Means the attribute doesn’t exist at all.</li>
<li>This distinction is useful for clearer query results and error handling.</li>
</ul>
<p><strong>Importance of</strong> <strong><code>MISSING</code></strong>:</p>
<ul>
<li>SQL++ doesn’t stop processing if some data is missing; instead, it marks those cases as <code>MISSING</code> and continues.</li>
<li>This makes queries more robust and tolerant of data inconsistencies.</li>
</ul>
<h1 id="Accessing-Nested-Data"><a href="#Accessing-Nested-Data" class="headerlink" title="Accessing Nested Data"></a>Accessing Nested Data</h1><p><strong>SQL-92 vs. Modern Data:</strong></p>
<ul>
<li>SQL-92 only supports tables with rows (tuples) containing simple values (scalars).</li>
<li>Modern data formats often include <strong>nested structures</strong>, where attributes can hold complex data types like arrays, tables, or even arrays of arrays.</li>
</ul>
<p><strong>Nested Data Example:</strong></p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/SQLPP_code1.png" alt="img"></p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/SQLPP_code2.png" alt="img"></p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/SQLPP_code3.png" alt="img"></p>
<ul>
<li>In the example, the <code>projects</code> attribute of an employee is an <strong>array of tuples</strong>, representing multiple projects each employee is involved in.</li>
</ul>
<p><strong>Querying Nested Data in SQL++:</strong></p>
<ul>
<li>SQL++ can handle such nested data without adding new syntax to SQL.</li>
<li>For example, a query can find employees working on projects with “security” in their names and output both the employee’s name and the project’s name.</li>
</ul>
<p><strong>How It Works:</strong></p>
<ul>
<li>SQL++ uses <strong>left-correlation</strong>, allowing expressions in the <code>FROM</code> clause to refer to variables declared earlier in the same clause.</li>
<li>For instance, <code>e.projects</code> accesses the projects of an employee <code>e</code>.</li>
<li>This relaxes SQL’s restrictions and effectively enables a join between an employee and their projects.</li>
</ul>
<p><strong>Using Variables in Queries:</strong></p>
<ul>
<li>SQL++ requires <strong>explicit</strong> use of variables (e.g., <code>e.name</code> instead of just <code>name</code>) because schema is optional and cannot guarantee automatic disambiguation.</li>
<li>If a schema exists, SQL++ can still optimize by rewriting the query for clarity and execution.</li>
</ul>
<p><strong>Flexibility with Nested Collections:</strong></p>
<ul>
<li>Variables in SQL++ can represent any type of data—whether it’s a table, array, or scalar.</li>
<li>These variables can be used seamlessly in <code>FROM</code>, <code>WHERE</code>, and <code>SELECT</code> clauses.</li>
</ul>
<p><strong>Aliases Can Bind to Any Data Type:</strong></p>
<ul>
<li>In SQL++, variables (aliases) don’t have to refer only to tuples.</li>
<li>They can bind to <strong>arrays of scalars</strong>, <strong>arrays of arrays</strong>, or any combination of scalars, tuples, and arrays.</li>
</ul>
<p><strong>Flexibility in Querying Nested Data:</strong></p>
<ul>
<li>Users don’t need to learn new query syntax for different data structures.</li>
<li>The same <strong>unnesting feature</strong> is used regardless of whether the data is an array of tuples or an array of scalars.</li>
</ul>
<p>Example:</p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/SQLPP_code4.png" alt="img"></p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/SQLPP_code5.png" alt="img"></p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/SQLPP_code6.png" alt="img"></p>
<ul>
<li>If the <code>projects</code> attribute is an <strong>array of strings</strong> (instead of tuples), SQL++ queries can still process it.</li>
<li>The query would range over <code>e.projects</code> and bind <code>p</code> to each project name (a string).</li>
</ul>
<p><strong>Relaxed Semantics Compared to SQL:</strong></p>
<ul>
<li>In traditional SQL, the <code>FROM</code> clause binds variables strictly to tuples.</li>
<li>SQL++ generalizes this by treating the <code>FROM</code> clause as a function that can bind variables to <strong>any type of data</strong>—not just tuples.</li>
</ul>
<p><strong>Practical Outcome:</strong></p>
<ul>
<li>In the example, the <code>FROM</code> clause produced variable bindings like <code>&#123;e: employee_data, p: project_name&#125;</code>.</li>
<li>This allows the query to handle data structures that SQL would not support without extensions.</li>
</ul>
<h1 id="ABSENCE-OF-SCHEMA-AND-SEMI-STRUCTURED-DATA"><a href="#ABSENCE-OF-SCHEMA-AND-SEMI-STRUCTURED-DATA" class="headerlink" title="ABSENCE OF SCHEMA AND SEMI-STRUCTURED DATA"></a>ABSENCE OF SCHEMA AND SEMI-STRUCTURED DATA</h1><p>Schemaless Data:</p>
<ul>
<li>Many modern data formats (e.g., JSON) don’t require a predefined schema to describe their structure.</li>
<li>This allows for <strong>flexible and diverse data</strong>, but it also introduces <strong>heterogeneity</strong>.</li>
</ul>
<p>Types of Heterogeneity:</p>
<ul>
<li><strong>Attribute presence</strong>: Some tuples may have a specific attribute (e.g., <code>x</code>), while others may not.</li>
<li><strong>Attribute type</strong>: The same attribute can have different types across tuples. For example:<ul>
<li>In one tuple, <code>x</code> might be a string.</li>
<li>In another tuple, <code>x</code> might be an array.</li>
</ul>
</li>
<li><strong>Element types in collections</strong>: A collection (e.g., an array or a bag) can have elements of different types. For example:<ul>
<li>The first element could be a string, the second an integer, and the third an array.</li>
</ul>
</li>
<li><strong>Legacy or data evolution</strong>: These heterogeneities often result from evolving requirements or data conversions (e.g., converting XML to JSON).</li>
</ul>
<p>Heterogeneity Is Not Limited to Schemaless Data:</p>
<ul>
<li>Even structured databases can have heterogeneity. For example:<ul>
<li>Hive’s <strong>union type</strong> allows an attribute to hold multiple types, like a string or an array of strings.</li>
</ul>
</li>
</ul>
<p>How SQL++ Handles It:</p>
<ul>
<li>SQL++ is designed to work seamlessly with <strong>heterogeneous data</strong>, whether the data comes from a schemaless format or a schema-based system.</li>
<li>It offers features and mechanisms to process such data flexibly, without enforcing rigid structure requirements.</li>
</ul>
<h2 id="Missing-Attributes"><a href="#Missing-Attributes" class="headerlink" title="Missing Attributes"></a>Missing Attributes</h2><ol>
<li><p><strong>Representation of Missing Information</strong>:</p>
<ul>
<li><p>In SQL, a missing value is typically represented as <code>NULL</code> (e.g., Bob Smith’s title in the first example).</p>
</li>
<li><p>In SQL++, there’s an additional option: simply omitting the attribute altogether (as seen in the second example for Bob Smith).</p>
</li>
</ul>
</li>
<li><p><code>NULL</code> <strong>vs.</strong> <code>MISSING</code>:</p>
<ul>
<li><p><code>NULL</code>: Indicates the attribute exists but has no value.</p>
</li>
<li><p><code>MISSING</code>: Indicates the attribute is entirely absent.</p>
</li>
<li><p>SQL++ supports distinguishing between these two cases, unlike traditional SQL.</p>
</li>
</ul>
</li>
<li><p><strong>Why This Matters</strong>:</p>
<ul>
<li><p>Some data systems or formats (e.g., JSON) naturally omit <strong>missing</strong> attributes rather than assigning a <code>NULL</code> value.</p>
</li>
<li><p>SQL++ makes it easy to work with both approaches by allowing queries to handle <code>NULL</code> and <code>MISSING</code> values distinctly.</p>
</li>
</ul>
</li>
<li><p><strong>Query Behavior</strong>:</p>
<ul>
<li><p>Queries in SQL++ can propagate <code>NULL</code> and <code>MISSING</code> values as they are.</p>
</li>
<li><p>The system introduces the special value <code>MISSING</code> to represent absent attributes, allowing clear differentiation from <code>NULL</code>.</p>
</li>
</ul>
</li>
</ol>
<h2 id="MISSING-as-a-Value"><a href="#MISSING-as-a-Value" class="headerlink" title="MISSING as a Value"></a>MISSING as a Value</h2><p>What Happens When Data is Missing:</p>
<ul>
<li>If a query references an attribute that doesn’t exist in a tuple (e.g., <code>e.title</code> for Bob Smith), SQL++ assigns the value <code>MISSING</code>.</li>
<li>This avoids query failures and ensures processing can continue.</li>
</ul>
<p><strong>Three Cases Where</strong> <code>MISSING</code> <strong>is Produced</strong>:</p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/SQLPP_code7.png" alt="img"></p>
<ul>
<li><strong>Case 1</strong>: Accessing a missing attribute. For example, <code>&#123;id: 3, name: &#39;Bob Smith&#39;&#125;.title</code> results in <code>MISSING</code>.</li>
<li><strong>Case 2</strong>: Using invalid input types for functions or operators (e.g., <code>2 * &#39;some string&#39;</code>).</li>
<li><strong>Case 3</strong>: When <code>MISSING</code> is an input to a function or operator, it propagates as <code>MISSING</code> in the output.</li>
</ul>
<p>SQL Compatibility Mode:</p>
<ul>
<li>In SQL compatibility mode, <code>MISSING</code> behaves like <code>NULL</code> for compatibility. For instance, <code>COALESCE(MISSING, 2)</code> will return <code>2</code>, just as <code>COALESCE(NULL, 2)</code> does in SQL.</li>
</ul>
<p><strong>Propagation of</strong> <code>MISSING</code> <strong>in Queries</strong>:</p>
<ul>
<li>In queries, <code>MISSING</code> values flow naturally through transformations, enabling consistent handling of absent data.</li>
<li>For example, in a <code>CASE</code> statement, if <code>e.title</code> evaluates to <code>MISSING</code>, the result of the entire <code>CASE</code> expression will also be <code>MISSING</code>.</li>
</ul>
<p><strong>Results with</strong> <code>MISSING</code>:</p>
<ul>
<li>If a query result includes <code>MISSING</code>, SQL++ will omit the attribute from the result tuple.</li>
<li>In communication with external systems like JDBC&#x2F;ODBC, <code>MISSING</code> is transmitted as <code>NULL</code> to ensure compatibility.</li>
</ul>
<h1 id="RESULT-CONSTRUCTION-NESTING-AND-GROUPING"><a href="#RESULT-CONSTRUCTION-NESTING-AND-GROUPING" class="headerlink" title="RESULT CONSTRUCTION,NESTING, AND GROUPING"></a>RESULT CONSTRUCTION,NESTING, AND GROUPING</h1><h2 id="Creating-Collections-of-Any-Value"><a href="#Creating-Collections-of-Any-Value" class="headerlink" title="Creating Collections of Any Value"></a>Creating Collections of Any Value</h2><p><strong>Power of</strong> <code>SELECT VALUE</code>:</p>
<ul>
<li>The <code>SELECT VALUE</code> clause in SQL++ allows constructing collections of any type of data, not just tuples.</li>
<li>It enables creating outputs that match the structure of nested data without flattening it unnecessarily.</li>
</ul>
<p>Example Query:</p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/SQLPP_code8.png" alt="img"></p>
<ul>
<li>The query in Listing 10 demonstrates how to use <code>SELECT VALUE</code> to extract only the “security” projects of employees, resulting in a nested structure.</li>
<li>Each employee’s tuple includes their ID, name, title, and a collection of their security-related projects.</li>
</ul>
<p>Result:</p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/SQLPP_code9.png" alt="img"></p>
<ul>
<li>Listing 11 shows the result where each employee has a field <code>security_proj</code> containing a nested collection of projects that match the condition (e.g., projects with “Security” in the name).</li>
</ul>
<p>Key Difference from Standard SQL:</p>
<ul>
<li>SQL’s <code>SELECT</code> clause can be viewed as shorthand for <code>SELECT VALUE</code>, but with differences:<ul>
<li>SQL automatically coerces subquery results into scalar values, collections of scalars, or tuples based on context.</li>
<li>In contrast, <code>SELECT VALUE</code> in SQL++ consistently produces a collection and does not apply implicit coercion.</li>
</ul>
</li>
</ul>
<p>Flexibility:</p>
<ul>
<li>SQL++ avoids implicit “magic” by explicitly treating <code>SELECT</code> as shorthand for <code>SELECT VALUE</code>.</li>
<li>This approach aligns more closely with functional programming principles, making it easier to handle and compose nested data results.</li>
</ul>
<h2 id="GROUP-BY-and-GROUP-AS"><a href="#GROUP-BY-and-GROUP-AS" class="headerlink" title="GROUP BY and GROUP AS"></a>GROUP BY and GROUP AS</h2><p><strong>Introduction to</strong> <code>GROUP BY ... GROUP AS</code>:</p>
<ul>
<li>This feature extends SQL’s <code>GROUP BY</code> functionality, allowing groups (and their contents) to be directly accessible in the <code>SELECT</code> and <code>HAVING</code> clauses.</li>
<li>It is more efficient and intuitive for creating nested results compared to traditional SQL, especially when the output nesting doesn’t directly align with the input data structure.</li>
</ul>
<p>How It Works:</p>
<ul>
<li><strong>Generalization</strong>: Unlike SQL, which limits access to grouped data in <code>GROUP BY</code>, SQL++ allows accessing the full group details as part of the query.</li>
<li><strong>Pipeline Model</strong>: SQL++ processes queries in a step-by-step fashion, starting with <code>FROM</code>, followed by optional clauses like <code>WHERE</code>, <code>GROUP BY</code>, <code>HAVING</code>, and ending with <code>SELECT</code>.</li>
</ul>
<p>Example:</p>
<ul>
<li>In the query from <strong>Listing 12</strong>, employees are grouped by their project names (converted to lowercase), and a nested list of employees for each project is created.</li>
<li>The <code>GROUP BY LOWER(p) AS p GROUP AS g</code> clause groups data and stores each group in <code>g</code>.</li>
<li>The <code>SELECT</code> clause then extracts project names and employees.</li>
</ul>
<p>Result:</p>
<ul>
<li>The output (shown in <strong>Listing 13</strong>) contains nested objects:</li>
<li><ul>
<li>Each object has a <code>proj_name</code> (e.g., <code>&#39;OLTP Security&#39;</code>) and an <code>employees</code> field listing the names of employees associated with that project.</li>
</ul>
</li>
</ul>
<p><strong>Details of</strong> <code>GROUP BY ... GROUP AS</code>:</p>
<ul>
<li>The clause produces bindings like the ones in <strong>Listing 14</strong>, where each group (<code>g</code>) includes all the data for its corresponding key (<code>p</code>).</li>
<li>The result allows users to flexibly access and format the grouped data.</li>
</ul>
<p>SQL++ Flexibility:</p>
<ul>
<li>SQL++ allows placing the <code>SELECT</code> clause either at the start or the end of a query block, enhancing readability and flexibility.</li>
<li>This approach is more consistent with functional programming and reduces constraints found in traditional SQL.</li>
</ul>
<p>Advanced Features:</p>
<ul>
<li>SQL++ supports additional analytical tools like <code>CUBE</code>, <code>ROLLUP</code>, and <code>GROUPING SETS</code>, making it highly compatible with SQL but better suited for nested and semi-structured data.</li>
</ul>
<h2 id="Aggregate-Functions"><a href="#Aggregate-Functions" class="headerlink" title="Aggregate Functions"></a>Aggregate Functions</h2><p>Limitations of Traditional SQL Aggregate Functions:</p>
<ul>
<li>Aggregate functions like <code>AVG</code> and <code>MAX</code> in traditional SQL lack <strong>composability</strong>.</li>
<li>They work directly on table columns but don’t easily integrate with more complex expressions or subqueries.</li>
</ul>
<p>SQL++ Solution:</p>
<ul>
<li>SQL++ introduces <strong>composable aggregate functions</strong>, such as <code>COLL_AVG</code> (for calculating the average of a collection) and <code>COLL_MAX</code>.</li>
<li>These functions take a <strong>collection</strong> as input and return the aggregated value.</li>
</ul>
<p>Importance of Composability:</p>
<ul>
<li>In SQL++, data is conceptually <strong>materialized</strong> into a collection first, then passed to the composable aggregate function.</li>
<li>While this materialization is conceptual, SQL++ engines optimize the execution (e.g., using pipelined aggregation).</li>
</ul>
<p>Example 1: Calculating the Average Salary of Engineers:</p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/SQLPP_code10.png" alt="img"></p>
<ul>
<li><strong>SQL Query</strong> (Listing 15): Uses <code>AVG(e.salary)</code> directly.</li>
<li><strong>SQL++ Core Query</strong> (Listing 16): Converts <code>e.salary</code> into a collection and applies the <code>COLL_AVG</code> function.</li>
<li>SQL++ clearly defines the flow of data, making it more intuitive and flexible.</li>
</ul>
<p>Example 2: Calculating the Average Salary of Engineers by Department:</p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/SQLPP_code11.png" alt="img"></p>
<ul>
<li><strong>SQL Query</strong> (Listing 17): Uses <code>GROUP BY</code> and <code>AVG</code>.</li>
<li><strong>SQL++ Core Query</strong> (Listing 18):<ul>
<li>Uses <code>GROUP BY ... GROUP AS</code> to form groups.</li>
<li>Feeds each group into <code>COLL_AVG</code> to calculate the average salary.</li>
<li>Constructs the result using the <code>SELECT VALUE</code> clause, explicitly specifying the output format.</li>
</ul>
</li>
</ul>
<p>Flexibility of SQL++ Style:</p>
<ul>
<li>SQL++ allows the <code>SELECT</code> clause to be written at the end of a query block, consistent with functional programming styles.</li>
<li>This enhances readability and composability while maintaining compatibility with SQL.</li>
</ul>
<h1 id="Pivoting-and-Unpivoting"><a href="#Pivoting-and-Unpivoting" class="headerlink" title="Pivoting and Unpivoting"></a>Pivoting and Unpivoting</h1><h2 id="UNPIVOT-Transforming-Attributes-into-Rows"><a href="#UNPIVOT-Transforming-Attributes-into-Rows" class="headerlink" title="UNPIVOT: Transforming Attributes into Rows"></a>UNPIVOT: Transforming Attributes into Rows</h2><ol>
<li><p><strong>What is Unpivoting?</strong></p>
<ul>
<li><p>Unpivoting is the process of converting attribute names (used as keys) into data rows.</p>
</li>
<li><p>This is useful for cases where key-value pairs in the data need to be analyzed as individual rows.</p>
</li>
</ul>
</li>
<li><p><strong>Example (Listing 19-21)</strong>:</p>
</li>
</ol>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/SQLPP_code12.png" alt="img"></p>
<ul>
<li><p>Input: A <code>closing_prices</code> collection where stock symbols (<code>amzn</code>, <code>goog</code>, <code>fb</code>) are attributes with prices as values.</p>
</li>
<li><p>Query (Listing 20): The <code>UNPIVOT</code> clause transforms these attributes into rows with fields for <code>symbol</code> and <code>price</code>.</p>
</li>
<li><p>Output (Listing 21): A flattened structure where each row contains the date, stock symbol, and price.</p>
</li>
</ul>
<h2 id="Pivoting"><a href="#Pivoting" class="headerlink" title="Pivoting"></a>Pivoting</h2><ol>
<li><strong>Purpose of Pivoting</strong>:<ul>
<li>Pivoting transforms rows into attributes (columns).</li>
</ul>
</li>
<li><strong>Example from Listings 23-25</strong>:</li>
</ol>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/SQLPP_code13.png" alt="img"></p>
<ul>
<li><strong>Input (Listing 23)</strong>: Rows of <code>today_stock_prices</code> where each stock symbol and its price are separate rows.</li>
<li><strong>Query (Listing 24)</strong>: The <code>PIVOT</code> operation turns these rows into a single object, using <code>sp.symbol</code> as attribute names and <code>sp.price</code> as their values.</li>
<li><strong>Output (Listing 25)</strong>: A tuple where each stock symbol (<code>amzn</code>, <code>goog</code>, <code>fb</code>) is an attribute, and their corresponding prices are the values.</li>
</ul>
<p><strong>Combining Grouping and Pivoting</strong></p>
<ol>
<li><strong>Using Pivot with Grouping</strong>:</li>
<li><ul>
<li>Combining <code>GROUP BY</code> and <code>PIVOT</code> enables aggregation of grouped rows into a more structured output.</li>
<li>This is particularly useful when working with time-series data or hierarchical datasets.</li>
</ul>
</li>
<li><strong>Example Query (Listing 26)</strong>:</li>
</ol>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/SQLPP_code14.png" alt="img"></p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/SQLPP_code15.png" alt="img"></p>
<ul>
<li>Input: Data from <code>stock_prices</code> (Listing 27), which includes stock prices for multiple dates as individual rows.</li>
<li>Query:<ul>
<li>Groups the data by <code>date</code> using <code>GROUP BY sp.date</code>.</li>
<li>Pivots the grouped rows to produce a nested structure where each date contains all its stock prices as attributes.</li>
</ul>
</li>
<li>Output (Listing 28): For each date, an object with a <code>prices</code> field lists the stock symbols as attributes and their respective prices as values.</li>
</ul>
<h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h1><p><strong>SQL++ identifies aggregate functions as an SQL violation of functional composability. Give an example of an aggregate function and describe how it violates SQL’s functional composability.</strong></p>
<ul>
<li><p><strong>Aggregate Function</strong>:<code>COLL_AVG()</code></p>
</li>
<li><p><strong>Violation Explanation</strong>:</p>
<ul>
<li><p>In traditional SQL, aggregate functions like <code>AVG</code> processes the column and returns a single value.</p>
</li>
<li><p>In SQL++, this issue is resolved by providing <strong>composable versions</strong> of aggregate functions, such as <code>COLL_AVG</code>, which operate on collections, allowing intermediate results to flow naturally into the aggregation.</p>
</li>
</ul>
</li>
</ul>
<p><strong>With SQL++, what is the difference between NULL and Missing?</strong></p>
<p><code>NULL</code>: Indicates that an attribute exists but has no value.</p>
<p><code>MISSING</code>: Indicates that an attribute is completely absent in the data.</p>
<p><strong>True or false: One must define a schema for data prior to using SQL++.</strong> </p>
<p>False:</p>
<ul>
<li>SQL++ supports <strong>schema-optional</strong> and <strong>schema-less</strong> data formats, such as JSON.</li>
<li>While schemas can improve query optimization and validation, SQL++ can process data without requiring predefined schemas, making it highly flexible for semi-structured data use cases.</li>
</ul>
<p><strong>How does the I lease prevent a thundering herd?</strong></p>
<p>The I lease (Inhibit Lease) prevents a thundering herd problem by ensuring that only one read session at a time is allowed to query the RDBMS for a missing key-value pair in the Key-Value Store (KVS). Here’s how it works:</p>
<ol>
<li><p><strong>Thundering Herd Problem</strong>:</p>
<ul>
<li><p>When a key-value pair is not found in the KVS (a <strong>KVS miss</strong>), multiple read sessions might simultaneously query the RDBMS to fetch the value.</p>
</li>
<li><p>This can overload the RDBMS and degrade performance under high concurrency.</p>
</li>
</ul>
</li>
<li><p><strong>Role of the I Lease</strong>:</p>
<ul>
<li><p>When the first read session encounters a KVS miss, it requests an I lease for the key.</p>
</li>
<li><p>Once the I lease is granted, the KVS prevents other read sessions from querying the RDBMS for the same key.</p>
</li>
<li><p>All other read sessions must “back off” and wait for the value to be updated in the KVS by the session holding the I lease.</p>
</li>
</ul>
</li>
<li><p><strong>Result</strong>:</p>
<ul>
<li><p>The session with the I lease queries the RDBMS, retrieves the value, and populates the KVS.</p>
</li>
<li><p>Subsequent read sessions observe a <strong>KVS hit</strong> and do not need to access the RDBMS.</p>
</li>
<li><p>This mechanism avoids simultaneous RDBMS queries, effectively solving the thundering herd problem.</p>
</li>
</ul>
</li>
</ol>
<p><strong>What is the difference between invalidate and refresh&#x2F;refill for maintaining the cache consistent with the database management system?</strong></p>
<ul>
<li><strong>Invalidate</strong>: Deletes stale cache entries to prevent incorrect reads, but at the cost of forcing subsequent queries to access the RDBMS.</li>
<li><strong>Refresh&#x2F;Refill</strong>: Proactively updates the cache with new data, ensuring consistent reads while reducing future load on the RDBMS at the expense of immediate computation.</li>
</ul>
<p><strong>Describe how CAMP inserts a key-value pair in the cache.</strong></p>
<p><strong>Check Cache Capacity</strong></p>
<ul>
<li>If there is <strong>enough memory</strong> to store the new key-value pair:<ul>
<li>The pair is inserted directly into the appropriate <strong>priority group</strong> based on its cost-to-size ratio.</li>
<li>L is not updated.</li>
</ul>
</li>
<li>If the cache is <strong>full</strong>:<ul>
<li>CAMP selects one or more key-value pairs to <strong>evict</strong> based on their H(p) values.</li>
<li>It removes the pair(s) with the <strong>lowest H(p)</strong> values until there is sufficient space for the new pair.</li>
</ul>
</li>
</ul>
<p><strong>Insert the New Pair</strong></p>
<ul>
<li>The new key-value pair p is added to the cache, and its H(p) value is computed and recorded.</li>
<li>The pair is placed in the appropriate priority queue based on its cost-to-size ratio.</li>
</ul>
<p><strong>How does BG compute the SoAR of a database management system?</strong> </p>
<ol>
<li>Define the SLA.</li>
<li>Run a series of experiments with increasing numbers of threads (T) to find the peak throughput while ensuring SLA compliance.</li>
</ol>
<p>Reference: <a href="https://escholarship.org/content/qt2bj3m590/qt2bj3m590_noSplash_084218340bb4e928c05878f04d01f04d.pdf">https://escholarship.org/content/qt2bj3m590/qt2bj3m590_noSplash_084218340bb4e928c05878f04d01f04d.pdf</a></p>
]]></content>
      <categories>
        <category>数据库系统</category>
      </categories>
  </entry>
  <entry>
    <title>MySQL 架构</title>
    <url>/undefined/MySQL/2024/11/13/MySQL/MySQL%20%E6%9E%B6%E6%9E%84/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><p>MySQL 默认 InnoDB 存储引擎，擅长事务处理，具有崩溃恢复特性。</p>
<h2 id="内存结构"><a href="#内存结构" class="headerlink" title="内存结构"></a>内存结构</h2><p><img src="/../../images/MySQL/innodb-architecture-8-0.png" alt="InnoDB architecture diagram showing in-memory and on-disk structures. In-memory structures include the buffer pool, adaptive hash index, change buffer, and log buffer. On-disk structures include tablespaces, redo logs, and doublewrite buffer files."></p>
<h3 id="缓冲池"><a href="#缓冲池" class="headerlink" title="缓冲池"></a>缓冲池</h3><p>InnoDB 存储引擎是基于磁盘存储的，并将其中的记录按照页的方式进行管理。</p>
<p>缓冲池是一块内存区域，通过内存的速度来弥补磁盘速度较慢对数据库性能的影响。</p>
<p>如果要读取页面，首先从磁盘读到的页面放在缓冲池中，之后再读相同的页时，先判断该页是否在缓冲池中。若在缓冲池中则被命中，直接读取改页，否则就读取磁盘上的页。</p>
<p>对于修改操作，先修改缓冲池中的页，然后再以一定频率刷新到磁盘。</p>
<p>依据时间局部性原理与空间局部性原理，Buffer Pool 在存储当前活动数据页的时候，也会以预读的方式缓存目标数据页临近的其他数据页。对于 Buffer Pool 中数据的查询，InnoDB 直接读取返回；对于 Buffer Pool 中数据的修改，InnoDB 直接在 Buffer Pool 中修改，并在此之前将修改写入 Redo Log 中。<strong>当数据页被 LRU 算法淘汰时写入磁盘</strong>。若持久化前系统崩溃，则在重启后使用 Redo Log 进行恢复。</p>
<p>注意：页从缓冲池刷新回磁盘的操作并不是在每次页发生更新时触发，而是基于 Checkpoint 定时刷新回磁盘。</p>
<p>缓冲池以页为存储单位，采用双向链表数据结构管理缓存页，页的大小默认为 16KB，使用分区 LRU 算法淘汰数据页。</p>
<p><img src="/../../images/MySQL/mysql_arch_buffer_pool.drawio.png" alt="img"></p>
<p>按照数据类型：索引页、数据页、Undo 页、更改缓冲页、自适应哈希索引页、锁信息页、数据字典页等。</p>
<p>按照页面的修改状态：</p>
<ul>
<li>Free page：空闲页面，未被使用过。</li>
<li>Clean page：被使用（读取）过的页面，但是数据未被修改过。</li>
<li>Dirty page：脏页面，被使用并且数据被修改过，导致页中数据与磁盘产生了不一致。</li>
</ul>
<p>而且 InnoDB 允许存在多个缓冲池实例。每个页根据哈希值被分配到不同的缓冲池实例中，这样可以减少数据库内部的资源竞争，增加数据库的并发能力。</p>
<p><strong>LRU List，Free List 和 Flush List</strong></p>
<p>LRU 列表中加入了 midpoint 位置，位于 LRU 列表长度的 5&#x2F;8 处，新加载的页会被直接放入这个位置。 midpoint 之后的列表被称为 old 列表，之前的列表就是 young 列表。young 列表中的页都是最为活跃的热点数据。</p>
<blockquote>
<p>[!NOTE]</p>
<p>为什么不直接将读取的页放入 LRU 列表的头部呢？</p>
<p>因为一些操作，如索引或整张表的扫描操作，会使很多包含热点数据的缓冲页被淘汰掉。因此下次需要读取这些热点数据时，InnoDB 还需要再次访问磁盘。也就是说，将插入点设置在 LRU 列表中间的某个位置可以防止处于 young 区域的热点页面被某些大数据量的操作给淘汰掉。</p>
</blockquote>
<p>缓冲池还设置了在页被加入到 midpoint 位置之后要等待多久才会被加入到 LRU 列表的热区 young 中，防止短期时间内被高频访问的节点进入 young 区域。</p>
<p>LRU 列表用来管理已经加载的页面，但是当数据库刚启动时，LRU 列表是空的，这时候缓存页都被存放在 Free 列表中。当有新的数据加载到缓冲池中时，首先从 Free 列表中查找是否有可用的空闲页，若有则将该页从 Free 列表中删除并放入 LRU 列表中；否则，根据 LRU 算法，淘汰 LRU 列表末尾的页，并将对应的内存空间分配给新的页。</p>
<p>当 Free List 页数低于 <code>innodb_lru_scan_depth</code>（默认为1024）时，后台清理线程会扫描 LRU List，从 old 链表底部开始淘汰干净页。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Buffer pool size        8191</span><br><span class="line">Free buffers            6513</span><br><span class="line">Database pages          1654</span><br><span class="line">Old database pages      604</span><br><span class="line">Modified db pages       0</span><br></pre></td></tr></table></figure>

<blockquote>
<p>[!NOTE]</p>
<p>为什么 Free buffers + Database pages 不等于 Buffer pool size？</p>
<p>Free buffers 和 Database pages 分别表示空闲列表和 LRU 列表中的页面数。</p>
<p>但是缓冲池中的页还可能会被分配给自适应哈希索引元数据页，Lock 信息页，压缩页等，这些页不需要基于普通的 LRU 列表进行维护。</p>
</blockquote>
<p>缓冲是通过 <code>unzip_LRU</code> 来管理压缩页，因为压缩页的大小可能是 1KB、2KB、4KB、8KB 这些小于 16KB的页面。</p>
<p><code>unzip_LRU</code> 是怎样从缓冲池中分配内存的呢？</p>
<p>⾸先，在 <code>unzip_LRU</code> 列表中对不同压缩页⼤⼩的页进⾏分别管理。其次，通过伙伴算法进⾏内存的分配。例如对需要从缓冲池中申请页为 4KB 的⼤⼩，其过程如下：</p>
<ol>
<li>检查 4KB 的 <code>unzip_LRU</code> 列表是否有可用的空闲页；</li>
<li>若有，则直接使用；</li>
<li>否则，检查 8KB 的 <code>unzip_LRU</code> 列表；</li>
<li>若能得到空闲页，将页分成 2 个 4KB 页，存放到 4KB 的 unzip_LRU 列表；</li>
<li>若不能，从 LRU 列表中申请一个 16KB 的页，将页分为 1 个 8KB 的页和 2 个 4KB 的页，分别存放到对应的 <code>unzip_LRU</code> 列表中。</li>
</ol>
<p>在 LRU 列表中的页被修改之后，该页变成脏页，即该缓冲池页和磁盘页中的数据产生了不一致。之后数据库回通过 checkpoint 机制将脏页刷新到磁盘，Flush 列表就是脏页列表。脏页既存在于 LRU 列表中，也存在于 Flush 列表中。LRU 列表用来管理缓冲页的可用性，Flush 列表用来管理缓冲页的刷新，二者互不影响。</p>
<blockquote>
<p>[!NOTE]</p>
<p>InnoDB 中，页面清理线程会周期性地从 LRU List 和 Flush List 中刷写脏页；当进行日志文件轮转或日志文件即将填满时，检查点机制也会触发对 Flush List 中脏页的批量刷新以推进 Redo 日志的检查点位置。</p>
<p>这里的日志文件轮换指的是当重做日志写入到当前日志文件达到一定容量或达到指定条件时，MySQL 会停止往这个文件继续写，而是切换到下一个预先配置好的日志文件上继续写入。</p>
<p>检查点刷新与页面清理线程共享 Flush List，区别在于检查点会关注推进 redo log 写入位置，而页面清理线程更关注缓冲池空间管理。</p>
</blockquote>
<p><strong>更改缓冲</strong></p>
<p>该缓冲也是缓冲池中的一部分，但是只针对非唯一二级索引的插入、删除标记和物理删除操作，不支持聚簇主键索引、唯一索引（除删除标记）及其他特殊索引类型（如全文、空间索引）<strong>。</strong></p>
<p>在执行 DML 语句时，如果该语句要查找的<strong>索引页</strong>未在缓冲池中，系统不会直接操作磁盘，而是将数据变更存放在更改缓冲区中；当未来数据被读取时将数据合并恢复到缓冲池中，再将合并后的数据刷新到磁盘中。</p>
<p>Change Buffer 大小默认占 Buffer Pool 的 25%，在引擎启动时便初始化完成，其物理结构为一棵名为 ibuf 的 B-Tree。Change Buffer 的生效条件为：</p>
<ul>
<li><strong><code>innodb_change_buffering</code></strong> <strong>已启用</strong>：若将该变量设置为 none，则关闭所有缓冲；否则可选择性缓冲 inserts、deletes、purges 等操作。</li>
<li><strong>目标二级索引页不在缓冲池中</strong>：只有在索引页不在 Buffer Pool 时，才将修改缓存到 ibuf；若页已在内存，则直接修改页本身。</li>
<li><strong>表或索引页未被强制合并</strong>：在发生强制合并（如慢速关闭 <code>--innodb-fast-shutdown=0</code>）前，缓冲仍被保留；合并后 ibuf 会将缓存应用到 B-Tree 页。</li>
</ul>
<p>该缓冲合并变更到数据的时机为：</p>
<ul>
<li><strong>页被读入缓冲池时（On-demand Merge）</strong>：当后续查询需要读取某个被缓冲修改的二级索引页时，InnoDB 会在返回数据前先将 ibuf 中对应的缓存记录合并到页内。</li>
<li><strong>主线程空闲时（Background Merge）</strong>：InnoDB 的主线程（Master Thread）在系统空闲或后台作业期间，会批量合并 ibuf，以减少 IO 峰值对 OLTP 性能的影响。</li>
<li><strong>慢速关闭时（Slow Shutdown）</strong>：若以 <code>innodb_fast_shutdown=0</code> 重启或关闭，系统会进行全量合并，确保提交前所有缓冲都应用到磁盘页中。</li>
<li><strong>ibuf B-Tree 分裂时</strong>：当 ibuf 树或其位图页分裂，或下一次合并会导致超出 <code>innodb_change_buffer_max_size</code> 限制时，InnoDB 会触发部分合并以释放空间。</li>
</ul>
<p><img src="/../../images/MySQL/innodb-change-buffer.png" alt="Content is described in the surrounding text."></p>
<p>数据页：发生 DML 时立即更新。</p>
<p>非唯一的二级索引页：发生 DML 时，变更会先存储在 Change Buffer 中，延迟合并。</p>
<p>唯一的二级索引页：由于需要立即检查唯一性，变更不会存储在 Change Buffer 中。</p>
<p><strong>自适应哈希索引</strong></p>
<p>InnoDB 监控对索引页的访问频度，当检测某些页频繁被访问且 B-Tree 查找性能不足时，会动态建立哈希索引，以加速查询；与 Change Buffer 机制互不干扰。</p>
<h3 id="Redo-日志缓冲"><a href="#Redo-日志缓冲" class="headerlink" title="Redo 日志缓冲"></a>Redo 日志缓冲</h3><p>Redo log 重做日志用于记录事务对磁盘数据页的修改，用于崩溃恢复，可实现持久性。</p>
<p>InnoDB 的<strong>日志缓冲区</strong>（log buffer）只用于缓存 <strong>redo log</strong> 的生成数据，默认大小为 16 MB，用来在事务提交前暂时保留日志，减少对磁盘的频繁写入。</p>
<p>InnoDB 除了包含缓冲池之外，还有 Redo 日志缓冲。InnoDB 首先将 Redo 日志信息放入该缓冲区，之后按一定频率将其刷新到磁盘的 Redo 日志文件中，这个频率一般情况下是一秒一次。</p>
<p>也就是说，Redo log 由两部分构成：</p>
<ol>
<li>重做日志缓冲（内存中）：用于暂时存储事务修改的日志。当日志量达到一定程度或事务提交时，InnoDB 会将这些日志刷新到磁盘上的 Redo Log 文件。</li>
<li>重做日志文件（磁盘中）：用于持久化保存事务修改的日志。</li>
</ol>
<p>写入和刷新策略：</p>
<table>
<thead>
<tr>
<th><strong>值</strong></th>
<th><strong>写入（write）</strong></th>
<th><strong>刷新（flush）</strong></th>
<th><strong>特点</strong></th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>每秒将日志缓冲区内容写入 redo 日志文件</td>
<td>每秒将 redo 日志文件刷新到磁盘（fsync）；<strong>事务提交时不执行</strong></td>
<td>性能最佳；在 mysqld 崩溃会丢失最多 1s 日志。</td>
</tr>
<tr>
<td>1</td>
<td>每次事务提交时写入 redo 日志文件</td>
<td>每次事务提交时刷新 redo 日志文件到磁盘</td>
<td>最安全，符合严格 ACID；写入开销最大。</td>
</tr>
<tr>
<td>2</td>
<td>每次事务提交时写入 redo 日志文件</td>
<td>每秒将 redo 日志文件刷新到磁盘；<strong>提交时不 fsync</strong></td>
<td>性能优于 1、安全性优于 0；可丢失最多 1s 日志。</td>
</tr>
</tbody></table>
<p>补充：</p>
<ul>
<li>write 指将缓冲区内容写入到操作系统文件缓存中；</li>
<li>flush 指调用 <code>fsync()</code> 等系统调用，将操作系统缓存的内容真正写到磁盘；</li>
<li>若想同时保证二进制日志（binlog）和 redo 日志的同步，可结合 <code>sync_binlog=1</code> 使用，以避免 binlog 丢失。</li>
</ul>
<p>下列三种情况会导致 Redo 日志缓冲中的内存刷新到磁盘的 Redo 日志文件中：</p>
<ol>
<li>Master Thread 每秒将 Redo 日志缓冲刷新到 Redo 日志文件中；</li>
<li>每个事务提交时会将 Redo 日志缓冲刷新到 Redo 日志文件中；</li>
<li>当 Redo 日志缓冲的剩余空间小于 1&#x2F;2 时，Redo 日志缓冲刷新到 Redo 日志文件中。</li>
</ol>
<p>注意：<strong>Undo Log</strong> 记录事务的回滚信息和 MVCC 版本，不经日志缓冲区，而是直接写入 undo 表空间中的数据页。</p>
<p><img src="/../../images/MySQL/mysql_arch_redo.drawio.png" alt="img"></p>
<p>当 MySQL 意外宕机后，InnoDB 会在启动时自动执行崩溃恢复，其中包括读取并应用 redo log 的操作，以将那些已经提交但尚未刷写到磁盘的数据页修改重做到磁盘上，从而保证数据的持久性与一致性。整个恢复分为分析、重做（Redo）和回滚（Undo）三个阶段：在重做阶段，InnoDB 会对比日志记录与磁盘页上的 LSN，将丢失的已提交修改应用回去；在回滚阶段，则撤销所有未提交的事务，以确保数据库最终处于一致状态。</p>
<h3 id="额外的内存池"><a href="#额外的内存池" class="headerlink" title="额外的内存池"></a>额外的内存池</h3><p>InnoDB 中对内存的管理通过内存堆来实现额。在对一些数据结构本身的内存进行分配时，需要从额外的内存池中进行申请，当该区域的内存不足时，会从缓冲池中进行申请。</p>
<h2 id="磁盘结构"><a href="#磁盘结构" class="headerlink" title="磁盘结构"></a>磁盘结构</h2><p><img src="/../../images/MySQL/mysql_arch_disk_struct.drawio.png" alt="img"></p>
<p>System tablespace（系统表空间）是默认的共享存储区域，通常由数据目录下名为 ibdata1 的文件（或多个通过 <code>innodb_data_file_path</code> 定义的文件）组成，用于保存 InnoDB 的数据字典、undo 日志和更改缓冲区；如果没有启用独立表空间或通用表空间，部分表和索引的数据也会存储在此处。该表空间在自动扩展（autoextend）模式下可按需增长，但在表被截断或删除后不会自动回收操作系统层面的空间。</p>
<p>**数据字典：**数据字典是由各种表对象的元数据信息（表结构，索引，列信息等）组成的内部表。</p>
<p>**修改缓冲：**内存中 Change Buffer 对应的持久化区域，同样为了数据完整性而设置。</p>
<p>InnoDB 的独立表空间（file-per-table）为每个数据库在数据目录下创建单独的子文件夹，每个表对应一个 .ibd 文件来存放该表的所有行数据、索引结构和变更缓冲（原插入缓冲）页；与此同时，每张表的结构定义仍保存在同名的 <code>.frm</code> 文件（MySQL 8.0 之后改为数据字典存储）。尽管表的数据和索引被分离到各自的 <code>.ibd</code> 文件中，诸如回滚日志、系统事务信息、双写缓冲等元数据仍持续写入共享的系统表空间（ibdata1），因此启用独立表空间后，系统表空间也不会停止增长。每个新创建的独立表空间文件初始大小约为 96 KB，并会根据表的需要自动扩展。</p>
<p>**通用表空间（General Tablespace）是指可以用于存储多个表的表空间，它位于用户自定义的位置，可以存储来自不同数据库的表和索引。**通用表空间是一个由 CREATE TABLESPACE 命令创建的共享表空间，创建时必须指定该表空间名称和 ibd 文件位置，ibd 文件可以放置于任何 MySQL 实例有权限的地方。<strong>通用表空间存在的目的是为了在系统表空间与独立表空间之间作出平衡</strong>。系统表空间与独立表空间中的表可以向通用表空间移动，反之亦可，但系统表空间中的表无法直接与独立表空间中的表相互转化。每个共享表空间初始大小为 64KB。</p>
<p>通用表空间允许多个表共享一个表空间文件，这与传统的每个表单独使用自己的表空间（独立表空间）不同。通过这种方式，可以更灵活地管理数据文件，特别是在管理存储多个小表时。通用表空间提供了以下好处：</p>
<ul>
<li><strong>减少小表空间碎片</strong>：如果每个表都有独立的表空间，那么大量的小表会导致存储碎片。而使用通用表空间可以集中管理这些小表，减少碎片。</li>
<li><strong>灵活的存储分配</strong>：通用表空间可以跨多个文件存储表的数据，这使得人们能够更灵活地管理磁盘空间，避免单一表空间文件过大或过小的问题。</li>
</ul>
<p>创建共享表空间：<code>create tablespace space_name add datafile file_name engine=engine_name;</code></p>
<p>为某个表指定表空间：<code>create table table_name ... tablespace space_name;</code></p>
<p>**Undo tablespace 撤销表空间：**在 MySQL 8.0 及更高版本中，InnoDB 在实例首次初始化时会自动创建 两个 独立的 Undo 表空间（默认为 <code>undo_001.ibu</code> 和 <code>undo_002.ibu</code>），以保证在事务回滚和一致性读（MVCC）过程中有至少两个回滚段可供轮换；每个表空间的初始大小均为 16 MB，并可按需自动扩展（最小扩展步长 16 MB，最大至 256 MB），当表空间超过 <code>innodb_max_undo_log_size</code> 后会被标记并截断以回收旧日志空间；这些 Undo 表空间专用于存储撤销日志，从而将大量长事务的日志写入负载与系统表空间分离，提升 I&#x2F;O 并发性能并防止 ibdata1 无限增长。</p>
<p>系统表空间是默认的共享存储区域，早期版本中所有的撤销日志都存放其中；而从 MySQL 5.7 开始，可以通过配置独立 Undo 表空间，将撤销日志与系统表空间中的数据字典、change buffer 等内容分离，从而改进 I&#x2F;O 分布和空间管理。</p>
<p>InnoDB 的临时表空间分为<strong>会话临时表空间</strong>（Session Temporary Tablespaces）和<strong>全局临时表空间</strong>（Global Temporary Tablespace），两者分别用于存储用户显式创建的临时表、优化器内部创建的临时表，以及这些表的回滚段。当你在 SQL 中使用子查询且需要落盘临时表（例如数据量超出内存限制或 optimizer 决定使用 on-disk 临时表）时，这些临时表会被创建到会话临时表空间中，而其回滚信息则存储在全局临时表空间中。</p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>MySQL 体系结构</title>
    <url>/undefined/MySQL/2024/10/04/MySQL/MySQL%20%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><p>MySQL 的体系结构如下：</p>
<p><img src="/../../images/MySQL/mysql-architecture.png" alt="MySQL architecture diagram showing connectors, interfaces, pluggable storage engines, the file system with files and logs."></p>
<table border="1" cellspacing="0" cellpadding="4">
  <tr>
    <td colspan="6" align="center"><strong>客户端连接器</strong></td>
  </tr>
  <tr>
    <td rowspan="2"><strong>系统管理和控制工具</strong></td>
    <td colspan="4" align="center"><strong>连接池</strong></td>
    <td colspan="1" align="center"><strong>连接层</strong></td>
  </tr>
  <tr>
    <td><strong>SQL 接口</strong></td>
    <td><strong>解析器</strong></td>
    <td><strong>查询优化器</strong></td>
    <td><strong>缓存</strong></td>
    <td colspan="1" align="center"><strong>服务层</strong></td>
  </tr>
  <tr>
    <td colspan="5" align="center"><strong>可插拔式存储引擎</strong></td>
    <td colspan="5" align="center"><strong>引擎层</strong></td>
  </tr>
  <tr>
    <td><strong>系统文件</strong></td>
    <td colspan="4"><strong>文件和日志</strong></td>
    <td colspan="1" align="center"><strong>存储层</strong></td>
  </tr>
</table>

<ul>
<li>连接层：负责网络协议解析、用户认证及会话管理，为每个客户端分配线程或线程池。</li>
<li>服务层：包含 SQL 解析、优化与执行模块，并实现跨引擎功能，如存储过程、触发器和视图等。</li>
<li>引擎层：通过统一的 Handler API 与各存储引擎（如 InnoDB、MyISAM）通信，负责数据的存储、检索及索引管理。</li>
<li>存储层：基于操作系统文件系统执行物理 I&#x2F;O，管理表空间、日志文件并支持异步或直通 I&#x2F;O 优化。</li>
</ul>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>MySQL 管理</title>
    <url>/undefined/MySQL/2024/10/24/MySQL/MySQL%20%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><p><code>/usr/local/mysql/bin</code> 目录下提供了多个客户端工具，具体如下：</p>
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>mysql</td>
<td>客户端程序，用于连接 MySQL 服务器</td>
</tr>
<tr>
<td>mysqldump</td>
<td>一个非常实用的 MySQL 数据库备份工具，用于创建一个或多个 MySQL 数据库级别的 SQL 转储文件，包括数据库的表结构和数据。对数据库备份、迁移或恢复非常重要。</td>
</tr>
<tr>
<td>mysqladmin</td>
<td>mysql 后面加上 admin 就表明这是一个 MySQL 的管理工具，它可以用来执行一些管理操作，比如说创建数据库、删除数据库、查看 MySQL 服务器的状态等。</td>
</tr>
<tr>
<td>mysqlcheck</td>
<td>mysqlcheck 是 MySQL 提供的一个命令行工具，用于检查、修复、分析和优化数据库表，对数据库的维护和性能优化非常有用。</td>
</tr>
<tr>
<td>mysqlimport</td>
<td>用于从文本文件中导入数据到数据库表中，非常适合用于批量导入数据。</td>
</tr>
<tr>
<td>mysqlshow</td>
<td>用于显示 MySQL 数据库服务器中的数据库、表、列等信息。</td>
</tr>
<tr>
<td>mysqlbinlog</td>
<td>用于查看 MySQL 二进制日志文件的内容，可以用于恢复数据、查看数据变更等。</td>
</tr>
</tbody></table>
<p>MySQL 在每个实例中都预装了四个系统数据库，用于存储元数据、权限及运行时性能统计等信息。<code>information_schema</code> 以视图形式提供数据字典和权限信息的只读访问；mysql 模式包含用户账户、时区、复制配置等必要的系统表；<code>performance_schema</code> 聚焦于运行时性能监控，采用专用存储引擎记录服务器内部执行情况；而 sys 模式则封装了一系列基于 performance_schema 的视图和存储过程，帮助 DBA 和开发人员快速诊断与调优。</p>
<p>与系统数据库配套，MySQL Server 安装包中还包括多种命令行工具：</p>
<ul>
<li><code>mysql</code>：交互式 SQL Shell，支持命令行编辑及脚本化操作，用于执行任意 SQL 语句，并以可读的格式显示结果。</li>
<li><code>mysqladmin</code>：管理型客户端，可检查服务器状态、创建&#x2F;删除数据库、执行刷新及关闭操作等。</li>
<li><code>mysqlbinlog</code>：二进制日志处理工具，可查看或导出 binlog、relay log，常用于增量备份与故障恢复。</li>
<li><code>mysqlshow</code>：快速展示已有数据库、表及字段信息，相当于对 SHOW 系列语句的轻量封装。</li>
<li><code>mysqldump</code>：生成逻辑备份的主力工具，将库表结构和数据导出为 SQL 脚本或其他格式，用于迁移和恢复<a href="https://dev.mysql.com/doc/en/mysqldump.html?utm_source=chatgpt.com"> </a>。</li>
<li><code>mysqlimport</code>：将文本文件批量导入到表中，通常与 <code>mysqldump -T</code> 导出的数据配合使用。</li>
<li><code>mysqlcheck</code>：表维护工具，可检查、修复、优化和分析表，用于日常健康检查与性能优化。</li>
<li><code>source</code>（MySQL 客户端内置命令）：在 <code>mysql&gt;</code> 提示符下执行指定的 <code>.sql</code> 文件，常用于批量恢复脚本。</li>
</ul>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>SQL</title>
    <url>/undefined/MySQL/2024/09/13/MySQL/SQL/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>注释：</p>
<p>单行注释：<em>–</em> 或 #</p>
<p>多行注释：<em>&#x2F;**&#x2F;</em></p>
<p>SQL分类：</p>
<p>DDL：数据定义语言，<strong>定义</strong>数据库对象（数据库，表，字段）。</p>
<p>DML：数据操作语言，对数据进行<strong>增删改</strong>。</p>
<p>DQL：数据查询语言，<strong>查询</strong>数据表的记录。</p>
<p>DCL：数据<strong>控制</strong>语言，创建数据库用户，控制数据库访问权限。</p>
<h1 id="DDL"><a href="#DDL" class="headerlink" title="DDL"></a>DDL</h1><p>查询所有数据库：<code>SHOW DATABASES;</code></p>
<p>查询当前数据库：<code>SELECT DATABASE();</code></p>
<p>创建数据库：<code>CREATE DATABASE [IF NOT EXISTS] 数据库名 [DEFAULT CHARSET 字符集] [COLLATE 排序规则];</code></p>
<p>删除数据库：<code>DROP DATABASE [IF EXISTS] 数据库名;</code></p>
<p>切换数据库：<code>USE 数据库名;</code></p>
<p>查询当前数据库中的所有表：<code>SHOW TABLES;</code></p>
<p>查询表结构：<code>DESC 表名;</code></p>
<p>查询指定表的建表语句：<code>SHOW CREATE TABLE 表名;</code></p>
<p>创建表：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> 表名(</span><br><span class="line">  字段<span class="number">1</span> 字段<span class="number">1</span>类型 [COMMENT 字段注释],</span><br><span class="line">  字段<span class="number">2</span> 字段<span class="number">2</span>类型 [COMMENT 字段注释],</span><br><span class="line">  ...</span><br><span class="line">  字段n 字段n类型 [COMMENT 字段注释]</span><br><span class="line">) [表注释];</span><br></pre></td></tr></table></figure>

<p>修改表：</p>
<ul>
<li>添加字段：<code>ALTER TABLE 表名 ADD 字段名 类型（长度）[COMMENT 注释] [约束];</code></li>
<li>修改数据类型： <code>ALTER TABLE 表名 MODIFY 字段名 新数据类型（长度）;</code></li>
<li>修改字段名和字段类型：<code>ALTER TABLE 表名 CHANGE 旧字段名 新字段名 类型（长度） [COMMENT 注释] [约束];</code></li>
<li>删除字段：<code>ALTER TABLE 表名 DROP 字段名;</code></li>
<li>修改表名：<code>ALTER TABLE 表名 RENAME TO 新表名;</code></li>
<li>删除表：<code>DROP TABLE [IF EXISTS] 表名;</code></li>
<li>删除指定表，并重新创建该表：<code>TRUNCATE TABLE;</code></li>
</ul>
<p>示例：</p>
<p>现有一张用户信息表 user_info，其中包含多年来在平台注册过的用户信息。</p>
<p>请在用户信息表，字段 level 的后面增加一列最多可保存 15 个汉字的字段 school；并将表中 job 列名改为 profession，同时 varchar 字段长度变为 10；achievement 的默认值设置为 0。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER TABLE</span> user_info <span class="keyword">ADD</span> school <span class="type">varchar</span>(<span class="number">15</span>) AFTER `level`;</span><br><span class="line"><span class="keyword">ALTER TABLE</span> user_info CHANGE job profession <span class="type">varchar</span>(<span class="number">10</span>);</span><br><span class="line"><span class="keyword">ALTER TABLE</span> user_info CHANGE <span class="keyword">COLUMN</span> achievement achievement <span class="type">int</span> <span class="keyword">DEFAULT</span> <span class="number">0</span>;</span><br></pre></td></tr></table></figure>

<h1 id="DML"><a href="#DML" class="headerlink" title="DML"></a>DML</h1><p>给指定字段添加数据：<code>INSERT INTO 表名 (字段1，字段2，...) VALUES (值1，值2);</code></p>
<p>给全部字段添加数据：<code>INSERT INTO 表名 VALUES (值1，值2);</code></p>
<p>批量添加数据：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT INTO</span> 表名 (字段<span class="number">1</span>，字段<span class="number">2</span>，...) <span class="keyword">VALUES</span> (值<span class="number">1</span>，值<span class="number">2</span>, ...), (值<span class="number">1</span>，值<span class="number">2</span>, ...), (值<span class="number">1</span>，值<span class="number">2</span>, ...);</span><br><span class="line"><span class="keyword">INSERT INTO</span> 表名 <span class="keyword">VALUES</span> (值<span class="number">1</span>，值<span class="number">2</span>，...), (值<span class="number">1</span>，值<span class="number">2</span>，...), (值<span class="number">1</span>，值<span class="number">2</span>，...);</span><br></pre></td></tr></table></figure>

<blockquote>
<p>[!NOTE]</p>
<p>将多次单行插入合并为一次批量插入（multi-row INSERT）能够显著提升性能，主要原因包括：</p>
<ul>
<li>减少网络往返次数，降低客户端与服务器的通信开销；</li>
<li>减少 SQL 解析与执行计划的开销，只需对一条语句进行解析与优化；</li>
<li>减少事务与日志写入开销，合并写入二进制日志（binlog）和 InnoDB 重做日志；</li>
<li>优化索引更新，批量更新索引比单次多次更新更高效；</li>
<li>降低锁竞争与事务开销，减少锁的申请与释放次数；</li>
<li>充分利用 InnoDB 的 Group Commit 机制，进一步减少磁盘刷新次数。</li>
</ul>
</blockquote>
<p>示例：</p>
<p>现有一张试卷作答记录表exam_record，结构如下表，其中包含多年来的用户作答试卷记录，由于数据越来越多，维护难度越来越大，需要对数据表内容做精简，历史数据做备份。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT INTO</span> exam_record_before_2021(uid, exam_id, start_time, submit_time, score)</span><br><span class="line"><span class="keyword">SELECT</span> uid, exam_id, start_time, submit_time, score</span><br><span class="line"><span class="keyword">FROM</span> exam_record</span><br><span class="line"><span class="keyword">WHERE</span> <span class="keyword">YEAR</span>(submit_time) <span class="operator">&lt;</span> <span class="string">&#x27;2021&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>现在有一套ID为9003的高难度SQL试卷，时长为一个半小时，请你将 2021-01-01 00:00:00 作为发布时间插入到试题信息表examination_info（其表结构如下图），不管该ID试卷是否存在，都要插入成功，请尝试插入它。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">REPLACE <span class="keyword">INTO</span> examination_info</span><br><span class="line"><span class="keyword">VALUES</span>(<span class="keyword">NULL</span>,<span class="number">9003</span>,<span class="string">&#x27;SQL&#x27;</span>,<span class="string">&#x27;hard&#x27;</span>,<span class="number">90</span>,<span class="string">&#x27;2021-01-01 00:00:00&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> examination_info</span><br><span class="line"><span class="keyword">WHERE</span> exam_id<span class="operator">=</span><span class="number">9003</span>;</span><br><span class="line"><span class="keyword">INSERT INTO</span> examination_info</span><br><span class="line"><span class="keyword">VALUES</span>(<span class="keyword">NULL</span>,<span class="number">9003</span>, <span class="string">&#x27;SQL&#x27;</span>,<span class="string">&#x27;hard&#x27;</span>, <span class="number">90</span>, <span class="string">&#x27;2021-01-01 00:00:00&#x27;</span>);</span><br></pre></td></tr></table></figure>

<p>修改数据：<code>UPDATE 表名 SET 字段1=值1， 字段2=值2，... [WHERE 条件];</code></p>
<p>删除数据：<code>DELETE FROM 表名 [WHERE 条件];</code></p>
<blockquote>
<p>[!NOTE]</p>
<p><strong>DELETE 与 TRUNCATE 的区别</strong></p>
<p>操作类型</p>
<ul>
<li>DELETE：属于 DML（数据操作语言），需要逐行删除数据，并记录每一行的删除操作。删除后需要手动提交事务。</li>
<li>TRUNCATE：属于 DDL（数据定义语言），直接释放表的所有数据页，然后重新初始化表，速度更快。</li>
</ul>
<p>日志记录</p>
<ul>
<li>DELETE：会记录每一行的删除操作到 binlog，用于事务回滚和主从同步。</li>
<li>TRUNCATE：只记录表的重建操作，不记录逐行删除，日志量较小。</li>
</ul>
<p>重置 AUTO_INCREMENT</p>
<ul>
<li>DELETE：不会重置自增值，下一次插入时继续从当前最大值递增。</li>
<li>TRUNCATE：会重置自增值为初始值。</li>
</ul>
<p>外键约束</p>
<ul>
<li>DELETE：可以针对有外键约束的表逐行删除，受外键规则影响。</li>
<li>TRUNCATE：不能直接操作有外键约束的表，否则会报错。</li>
</ul>
<p>当一个表中有大量的 DELETE 操作时，你会采取哪些措施来优化性能或管理存储空间？</p>
<ol>
<li>如果需要清空整张表，用 TRUNCATE 或 DROP。</li>
<li>如果 DELETE 操作是高频行为，考虑使用 分区表 或 分表。</li>
<li>如果需要保留数据历史，使用 软删除。</li>
<li>定期使用 OPTIMIZE TABLE 或分批 DELETE 来回收空间。</li>
</ol>
</blockquote>
<p>示例：</p>
<p>请删除exam_record表中未完成作答或作答时间小于5分钟整的记录中，开始作答时间最早的3条记录。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">delete</span> <span class="keyword">from</span> exam_record <span class="keyword">where</span> date_add(start_time, <span class="type">interval</span> <span class="number">5</span> <span class="keyword">minute</span>) <span class="operator">&gt;</span> submit_time <span class="keyword">or</span> submit_time <span class="keyword">is</span> <span class="keyword">null</span> limit <span class="number">3</span>;</span><br></pre></td></tr></table></figure>

<p>请删除exam_record表中所有记录，并重置自增主键。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">truncate</span> <span class="keyword">table</span> exam_record;</span><br></pre></td></tr></table></figure>

<h2 id="更新语句的执行过程"><a href="#更新语句的执行过程" class="headerlink" title="更新语句的执行过程"></a>更新语句的执行过程</h2><p><img src="/../../images/MySQL/mysql_update.drawio.png" alt="img"></p>
<p>在执行 UPDATE 时，InnoDB 会先按照 WHERE 条件对匹配的记录及其前后间隙加上 next-key 锁，以防幻读；然后从缓冲池中将数据页加载到内存，先在 Undo 日志中记录修改前的值（用于回滚和 MVCC），再将更新操作以物理日志的形式写入 Redo 日志并将数据页标记为“脏页”。之后 MySQL 采用两阶段提交：第一阶段将 Redo 日志持久化并标记为 prepare 状态，第二阶段将事务的所有变更以逻辑或行事件写入 Binlog 并执行 fsync，最后将 Redo 日志标记为已提交并释放锁，从而保证 Redo 与 Binlog 的原子一致性。</p>
<p>MySQL 在执行更新语句时，在服务层执行语句的解析和执行，在引擎层执行数据的提取和存储；在服务层对 binlog 进行写入，在引擎层对 redo log 进行写入。</p>
<h2 id="事务的两阶段提交"><a href="#事务的两阶段提交" class="headerlink" title="事务的两阶段提交"></a>事务的两阶段提交</h2><p>这是 MySQL 中保证数据一致性和持久性的关键机制。</p>
<p><img src="/../../images/MySQL/mysql_2pc.drawio.png" alt="mysql_2pc.drawio"></p>
<ol>
<li><strong>prepare 阶段</strong>：记录事务的变更到 redo log，并标记为 prepare 状态。</li>
<li><strong>binlog 写入</strong>：将对应的 SQL 语句写入 binlog。</li>
<li><strong>commit 阶段</strong>：将 redo log 中对应的日志条目标记为 commit 状态，并完成整个提交过程。</li>
</ol>
<p><strong>事务不一致的处理</strong></p>
<p>**情况一：**系统在 redo log 标记为 prepare 之后崩溃。这种情况下，事务已经记录到 redo log 中，但可能还未写入 binlog。恢复时，InnoDB 会检查 redo log 中的 prepare 状态。如果找到这样的记录，会继续检查 binlog。</p>
<ol>
<li>如果 binlog 中没有找到对应的记录，说明事务未提交，InnoDB 会回滚事务，确保数据一致性。</li>
<li>如果 binlog 中找到了对应的记录，说明事务已提交，InnoDB 会完成提交过程，确保数据一致性。</li>
</ol>
<p>**情况二：**系统在 binlog 写入后但在 redo log commit 前崩溃。在这种情况下，事务已经写入了 binlog，但未完成在 redo log 中的 commit 标记。恢复时，InnoDB 会首先检查 redo log，如果发现 prepare 状态的记录且 binlog 中有对应的记录，InnoDB 会将事务标记为 commit 状态并完成提交，这确保了事务的一致性和持久性。</p>
<h1 id="DQL"><a href="#DQL" class="headerlink" title="DQL"></a>DQL</h1><p>查询多个字段：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> 字段<span class="number">1</span>，字段<span class="number">2</span>，字段<span class="number">3.</span>.. <span class="keyword">FROM</span> 表名;</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> 表名;</span><br></pre></td></tr></table></figure>

<p>设置别名：<code>SELECT 字段1 [AS 别名1]，字段2[AS 别名2] ... FROM 表名;</code></p>
<p>去除重复记录：<code>SELECT DISTINCT 字段列表 FROM 表名;</code></p>
<p>聚合函数：<code>SELECT 聚合函数(字段) FROM 表名;</code></p>
<p>以上 SQL 语句将一列数据作为一个整体，进行纵向计算。NULL 不参与所有聚合函数运算。</p>
<p>分组查询：<code>SELECT 字段列表 FROM 表名 [WHERE 条件] GROUP BY 分组字段名 [HAVING 分组后过滤条件];</code></p>
<blockquote>
<p>[!NOTE]</p>
<p><strong>WHERE 和 HAVING 区别</strong></p>
<ul>
<li>执行时机不同：WHERE 是分组之前进行过滤；HAVING 是分组之后进行过滤。</li>
<li>判断条件不同：WHERE 不能对聚合函数进行判断，HAVING 可以。</li>
<li>执行顺序：WHERE &gt; 聚合函数 &gt; HAVING</li>
</ul>
</blockquote>
<p>排序查询：<code>SELECT 字段列表 FROM 表名 ORDER BY 字段1 排序方式1, 字段2 排序方式2;</code></p>
<p>排序方式：ASC 升序（默认），DESC 降序。</p>
<p>如果是多字段排序，当第一个字段值相同时，才会根据第二个字段进行排序。</p>
<p>分页查询：<code>SELECT 字段列表 FROM 表名 LIMIT 起始索引，查询记录数;</code></p>
<p>起始索引从0开始，起始索引 &#x3D;（查询页码 - 1）* 每页显示记录数;</p>
<h2 id="SELECT-查询执行顺序"><a href="#SELECT-查询执行顺序" class="headerlink" title="SELECT 查询执行顺序"></a>SELECT 查询执行顺序</h2><p><img src="/../../images/MySQL/mysql_select_exe_priority.drawio.png" alt="mysql_select_exe_priority.drawio"></p>
<ol>
<li><strong>FROM</strong>：对 FROM 子句中的左表<left_table>和右表<right_table>执行<strong>笛卡儿积</strong>（Cartesianproduct），产生虚拟表 VT1。</li>
<li><strong>ON</strong>：对虚拟表 VT1 应用 ON 筛选，只有那些符合<join_condition>的行才被插入虚拟表 VT2 中。</li>
<li><strong>JOIN</strong>：如果指定了 OUTER JOIN（如 LEFT OUTER JOIN、RIGHT OUTER JOIN），那么保留表中未匹配的行作为外部行添加到虚拟表 VT2 中，产生虚拟表 VT3。<strong>如果 FROM 子句包含两个以上表，则对上一个连接生成的结果表 VT3 和下一个表重复执行步骤 1）～步骤 3），直到处理完所有的表为止。</strong></li>
<li><strong>WHERE</strong>：对虚拟表 VT3 应用 WHERE 过滤条件，只有符合<where_condition>的记录才被插入虚拟表 VT4 中。</li>
<li><strong>GROUP BY</strong>：根据 GROUP BY 子句中的列，对 VT4 中的记录进行分组操作，产生 VT5</li>
<li><strong>CUBE | ROLLUP</strong>：对表 VT5 进行 CUBE 或 ROLLUP 操作，产生表 VT6。<ol>
<li><strong>CUBE</strong>：生成所有可能组合的汇总，包括每个维度的组合。适用于多维数据分析。</li>
<li><strong>ROLLUP</strong>：生成层级汇总，从详细级别到总体总和。适用于生成部分汇总数据。</li>
</ol>
</li>
<li><strong>HAVING</strong>：对虚拟表 VT6 应用 HAVING 过滤器，只有符合<having_condition>的记录才被插入虚拟表 VT7 中。</li>
<li><strong>SELECT</strong>：第二次执行 SELECT 操作，选择指定的列，插入到虚拟表 VT8 中。</li>
<li><strong>DISTINCT</strong>：去除重复数据，产生虚拟表 VT9。</li>
<li><strong>ORDER BY</strong>：将虚拟表 VT9 中的记录按照<order_by_list>进行排序操作，产生虚拟表 VT10。</li>
<li><strong>LIMIT</strong>：取出指定行的记录，产生虚拟表 VT11，并返回给查询用户。</li>
</ol>
<h2 id="DQL-语句的执行过程"><a href="#DQL-语句的执行过程" class="headerlink" title="DQL 语句的执行过程"></a>DQL 语句的执行过程</h2><p><img src="/../../images/MySQL/mysql_dql_exe.drawio.png" alt="img"></p>
<ol>
<li>客户端通过 TCP 连接发送 DQL 到 MySQL 服务器。</li>
<li>连接器开始处理该请求，包括建立连接、权限验证等。</li>
<li>解析器进行词法分词和语法分析，生成抽象语法树 AST 或解析树，同时检查 SQL 语法合法性和基本语法错误。在生成 AST 后，解析器将数据库名、表名和列名等标识符与内部数据字典中的对象进行映射，并对引用的对象执行权限检查，只有在用户拥有相应权限时，才允许继续执行。</li>
<li>优化器基于成本模型，对解析树进行查询重写（如谓词下推、视图展开）和逻辑优化，然后评估多种访问路径：全表扫描 vs 索引扫描、Nested Loop Join vs Hash Join 等，计算各方案的成本并选择最优执行计划，该计划以具体的物理操作算子（索引扫描、排序、聚合）为粒度进行组合。</li>
<li>执行器根据优化器生成的执行计划，调用相应的存储引擎接口，逐步执行算子操作（TableScan、IndexScan、Join、Sort），并在内存中构建最终的结果集。</li>
<li>对于 InnoDB 引擎，普通 SELECT 语句采用多版本并发控制（MVCC），从缓冲池内查找 Undo 日志中保存的历史版本来重建查询时刻的数据快照，若未命中则从磁盘读取并加载到缓冲池，同时维护 LRU 链表。</li>
<li>执行器完成结果集的生成后，通过 Protocol 层将数据逐行或一次性打包返回给客户端。</li>
</ol>
<h1 id="DCL"><a href="#DCL" class="headerlink" title="DCL"></a>DCL</h1><p>查询用户：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">USE mysql;</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">user</span>;</span><br></pre></td></tr></table></figure>

<p>创建用户：<code>CREATE USER &#39;用户名&#39;@&#39;主机名&#39; IDENTIFIED BY &#39;密码&#39;;</code></p>
<p>修改用户密码：<code>ALTER USER &#39;用户名&#39;@&#39;主机名&#39; IDENTIFIED WITH mysql_native_password BY &#39;新密码&#39;;</code></p>
<p>删除用户：<code>DROP USER &#39;用户名&#39;@&#39;主机名&#39;;</code></p>
<p>查询权限：<code>SHOW GRANTS FOR &#39;用户名&#39;@&#39;主机名&#39;;</code></p>
<p>授予权限：<code>GRANT 授权列表 ON 数据库名.表名 TO &#39;用户名&#39;@&#39;主机名&#39;;</code></p>
<p>撤销权限：<code>REVOKE 权限列表 ON 数据库名.表名 FROM &#39;用户名&#39;@&#39;主机名&#39;;</code></p>
<blockquote>
<p>[!NOTE]</p>
<p>主机名可使用 % 通配。</p>
<p>多个权限之间使用逗号分隔。</p>
<p>数据库名和表名可使用 <code>*</code> 进行通配，代表所有。</p>
</blockquote>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>主从复制</title>
    <url>/undefined/MySQL/2024/11/19/MySQL/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><p>在基于 Binlog 的异步复制模式中，主库将所有 DDL 与 DML 操作写入二进制日志，并在本地完成事务提交后立即返回，无需等待从库确认，从而实现松散耦合的复制流程。随后，从库的 <strong>IO 线程</strong>会与主库保持长连接，不断读取新生成的 binlog 事件并将它们写入本地的 <strong>Relay Log</strong>。接着，从库的 <strong>SQL 线程</strong>会顺序读取 Relay Log 中的事件，并在从库上重做这些 DDL 与 DML，以达到数据同步的目的。</p>
<p><img src="/../../images/MySQL/mysql_replic_ms.drawio.png" alt="img"></p>
<p>MySQL 支持一主多从复制拓扑，且从库本身也可以配置为其他从库的源库，实现链式复制。这种异步复制模式允许在主库出现故障时，通过提升任一从库为新的主库来快速切换并恢复服务，极大增强了系统的高可用性。同时，通过将写操作集中到主库、将读操作分散到从库，也减轻了主库的负载，并可在从库上执行备份任务，避免对主库性能产生影响。由于主库无需等待从库完成写入，可获得更高的写入吞吐量，但也可能引入复制延迟问题，需要结合监控指标加以管理。为进一步降低从库的应用延迟，可使用并行复制功能，让 SQL 线程并发地执行多个复制通道中的事件。总体而言，基于 Binlog 的异步复制以其配置简单、可扩展性强和高可用性好等特点，成为 MySQL 最常用的主从复制方案。</p>
<p>在主从复制中，<strong>Relay Log</strong> 起到四大关键作用：</p>
<p>首先，它充当从库的缓冲区——IO 线程不断地将主库的二进制日志拉取并写入本地的 Relay Log，即使 SQL 线程处理变更较慢，也不会影响向主库的读取，从而有效降低延迟；</p>
<p>其次，Relay Log 支持异步处理——IO 线程与 SQL 线程分离，前者专注拉取日志，后者专注重放语句，两者互不阻塞，大幅提升同步的并发能力；</p>
<p>第三，它增强了数据可靠性——日志落盘后即便网络波动或从库重启，SQL 线程也能从已持久化的 Relay Log 继续执行，无需重新拉取；</p>
<p>最后，在链式复制场景中，从库的 Relay Log 同样可以对下游从库提供日志源，成为二进制日志传递链上的一环。这样，Relay Log 不仅保证了数据的连续、高效复制，还提升了系统的容错与可扩展性。</p>
<h2 id="同步延迟的原因"><a href="#同步延迟的原因" class="headerlink" title="同步延迟的原因"></a>同步延迟的原因</h2><p>主从同步延迟通常是因为从库的复制流程存在瓶颈：主库可以同时接收大量并发写请求，但从库只有一个 IO 线程负责拉取 binlog、一个 SQL 线程负责执行，如果某条 SQL 在从库上执行耗时较长或因锁等待而阻塞，就会造成 binlog 在从库端堆积，进而引起读写不一致。为缓解这一问题，一方面可以在写操作后立即把紧接着的读操作路由到主库，以确保及时读取最新数据；另一方面也可在读从库失败时自动再去主库重试二次读取，这种方式改动最小，但会增加主库的读负载；此外，还可以将关键业务（如注册、登录）的所有读写都定向主库处理，而对一致性要求较低的查询（如用户资料展示）继续采用读写分离，从而在保证关键路径数据正确性的同时，将大部分查询压力分散到从库。</p>
<h2 id="同步模式"><a href="#同步模式" class="headerlink" title="同步模式"></a>同步模式</h2><h3 id="异步复制"><a href="#异步复制" class="headerlink" title="异步复制"></a>异步复制</h3><p>异步复制（Asynchronous Replication）是 MySQL 最基础也是最常用的复制方式，其中主库在本地提交事务并写入二进制日志后即可立即返回客户端，从库的 IO 线程随后异步地拉取这些 binlog 并将其写入 Relay Log，最后由 SQL 线程在从库上执行重放，从而完成数据同步。由于主库无需等待从库确认即完成提交，异步复制能够获得最高的写入吞吐量，但会产生一定的复制延迟，若主库故障，尚未同步的事务可能丢失。</p>
<h3 id="半同步复制"><a href="#半同步复制" class="headerlink" title="半同步复制"></a>半同步复制</h3><p>半同步复制（Semisynchronous Replication）介于异步与全同步之间，当主库提交一个事务时，会阻塞等待至少一个从库的确认（即从库已将该事务事件接收并写入 Relay Log，但不必执行完毕）后才向客户端返回，从而保证提交成功的事务至少存在于主库和一个从库上。相比纯异步复制，半同步复制在保证可用性的同时，显著提升了数据安全性；但因需等待确认，写延迟会略高于异步模式，尤其在网络或从库性能较差时更为明显。</p>
<h3 id="全同步复制（组复制）"><a href="#全同步复制（组复制）" class="headerlink" title="全同步复制（组复制）"></a>全同步复制（组复制）</h3><p>全同步复制通常由 MySQL Group Replication 或 NDB Cluster 实现，要求主库在提交时，所有或一定多数的副本必须完成提交确认后才继续执行，从而实现真正的强同步。该模式在保证各节点数据实时一致性方面最强，但也带来最高的写延迟和最复杂的部署需求，通常用于对一致性和故障切换要求极高的场景。</p>
<p><strong>百万千万级大表如何添加字段？</strong></p>
<p>在面对上千万行的大表时，直接执行 <code>ALTER TABLE … ADD COLUMN</code> 往往会长时间锁表，影响线上业务；常见的无停机扩容方案包括：</p>
<p>一是在新库&#x2F;新表中先创建完整的表结构并添加字段，然后通过分批次或全量迁移程序将旧表数据复制过去，最后再原子化地用新表替换旧表（此法简洁但需要额外迁移逻辑）；</p>
<p>二是借助 Percona 的 pt-online-schema-change 或 GitHub 的 gh-ost 等在线变更工具，它们会在后台创建影子表、实时捕获并同步写入，通过触发器或 binlog 流将增量写入合并到新表，待数据迁移完成后再用重命名操作切换，无需停机且复制过程中表仍可读写；</p>
<p>三是针对极高并发的热表，可先在从库执行字段添加操作，待从库完成同步并切换读写角色后，再依次在其他节点上部署新字段，最大程度上降低主库负载和用户感知的停机风险。</p>
<p><strong>当 MySQL 表的数据量增长过快，导致查询性能下降时，你会采取哪些措施来优化表的设计或查询？</strong></p>
<p>当表数据量激增导致单表查询与写入性能下降时，可采取以下优化措施：</p>
<p>首先，通过水平分表将数据按用户 ID 或时间等分片键拆分到多张子表或多库中，以减少单表大小、降低锁竞争并分散 I&#x2F;O 压力；</p>
<p>其次，合理设计索引，包括对经常用于过滤的单个字段创建单列索引、对多字段组合查询创建复合索引，以及使用覆盖索引来避免回表，但切忌在索引字段上使用函数或表达式以免导致索引失效；</p>
<p>其三，可在应用层或独立缓存层（如 Redis）缓存热点数据或热点查询结果，显著减少数据库访问次数并缓解压力；</p>
<p>第四，定期将历史或冷数据归档到独立的存档表、数据仓库或专用归档系统中，保持主表的数据量在可控范围内，从而提升主表的查询效率；</p>
<p>最后，当单机 MySQL 无法再满足性能与扩展需求时，可考虑迁移到分布式数据库（如 TiDB、PolarDB），利用其水平可扩展架构和分布式事务能力，实现更大规模的数据存储与高并发访问。</p>
<h2 id="读写分离"><a href="#读写分离" class="headerlink" title="读写分离"></a>读写分离</h2><p>在主从复制架构中，可以将数据库服务器组织成一主一从或一主多从的集群模式：所有写操作（INSERT、UPDATE、DELETE 等）都集中发送到主库，以保证强一致性；主库会将数据变更实时同步到一个或多个从库，而从库则专注于处理只读查询，提供最终一致性的读服务。业务服务器根据操作类型，将写请求路由到主库，将读请求路由到从库，从而在不影响写入性能和一致性的前提下，大幅提升整体系统的读扩展能力和稳定性。</p>
<p>这样做有几个好处：</p>
<p>第一，写入流量只作用于主库，从库则专注于处理查询请求，可显著减轻单台数据库的压力；</p>
<p>第二，通过增加从库数量，可以水平扩展读能力，提升整体系统的并发查询性能；</p>
<p>第三，即使在从库进行备份或维护时，也能保证主库持续提供写入服务，增强了系统的可用性和抗故障能力。</p>
<p>需要注意的是，从库与主库之间存在微小的复制延迟，因此对于对实时性要求极高的查询，应优先访问主库或使用读写路由策略进行合理调度；同时，还要考虑事务隔离和一致性需求，确保读写分离不会引入数据不一致风险。通过合理配置负载均衡和故障切换机制，读写分离能够在保证数据安全与一致性的前提下，大幅提升数据库集群的性能和稳定性。</p>
<p><img src="/../../images/MySQL/mysql_replic_re_decoup.drawio.png" alt="img"></p>
<p>在程序层面，实现读写分离通常有两种方式：</p>
<p>一种是在业务代码中抽象出一个数据访问层（或“中间层”），由这一层统一管理主从库的连接和路由逻辑，业务逻辑只需调用该层提供的接口即可完成读写分离，如下图；</p>
<p><img src="/../../images/MySQL/mysql_replic_mid.drawio.png" alt="img"></p>
<p>另一种是通过独立部署的中间件系统来承担这项工作，它对外提供与数据库协议兼容的接口，自动将写请求路由到主库、读请求分发到从库，业务服务器无需关心具体的分库路由和连接管理。这样既能保持程序的清晰简洁，又能在中间件层面灵活扩展和运维读写分离的能力。具体结构如下图：</p>
<p><img src="/../../images/MySQL/mysql_replic_mycat.drawio.png" alt="img"></p>
<p>如果要是用 MyCat 作为中间件的话，可参考：<a href="https://bbs.huaweicloud.com/blogs/343277">https://bbs.huaweicloud.com/blogs/343277</a></p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>SQL 优化</title>
    <url>/undefined/MySQL/2024/10/08/MySQL/SQL%20%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><p>在阐述 SQL 的优化方案之前，我们需要先了解 SQL 的执行流程，如下：</p>
<ol>
<li><p>客户端发送 SQL 语句给 MySQL 服务器。</p>
</li>
<li><p>如果查询缓存打开则会优先查询缓存，如果缓存中有对应的结果，直接返回给客户端。不过，MySQL 8.0 版本已经移除了查询缓存。</p>
</li>
<li><p>分析器对 SQL 语句进行语法分析，判断是否有语法错误。</p>
</li>
<li><p>明确 SQL 语句的目的后，MySQL 通过优化器生成执行计划。优化器通过成本计算预估出执行效率最高的方式，基本的预估维度为：</p>
</li>
<li><p>IO 成本：</p>
<ol>
<li>数据量越大，IO 成本越高，所以要避免 <code>select *</code>；尽量分页查询。</li>
<li>尽量通过索引加快查询。</li>
</ol>
</li>
<li><p>CPU 成本：</p>
<ol>
<li>尽量避免复杂的查询条件，如有必要，考虑对子查询结果进行过滤。</li>
<li>尽量缩减计算成本，比如说为排序字段加上索引，提高排序效率；比如说使用 union all 替代 union，减少去重处理。</li>
</ol>
</li>
<li><p>执行器调用存储引擎的接口，执行 SQL 语句。</p>
</li>
</ol>
<h2 id="SQL-性能分析工具"><a href="#SQL-性能分析工具" class="headerlink" title="SQL 性能分析工具"></a>SQL 性能分析工具</h2><p>如果要查询某一类 SQL 语句的执行频率，比如查看当前数据库的增删改查操作的访问频次，我们可以使用如下命令：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SHOW</span> [<span class="keyword">GLOBAL</span> <span class="operator">|</span> SESSION] STATUS <span class="keyword">LIKE</span> <span class="string">&#x27;Com_%&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p><strong>慢查询日志</strong>记录了执行时间超过指定参数（<code>long_query_time</code>，单位：秒，默认 10 秒）的所有 SQL 语句。</p>
<p>慢查询日志默认不开启，所以我们需要在配置文件 <code>/etc/my.cnf</code> 中配置如下信息来启动慢查询日志：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">slow_query_log = 1</span><br><span class="line"></span><br><span class="line">long_query_time = 2 # 执行时间超过 2s 的操作被记录到慢查询日志当中</span><br></pre></td></tr></table></figure>

<p>profile 详情（默认关闭），该功能可以帮助了解 SQL 语句耗时的部分。比如：</p>
<ul>
<li>查看每一条 SQL 的耗时基本情况：<strong>SHOW</strong> <strong>PROFILES</strong>;</li>
<li>查看指定 query_id 的 SQL 语句各个阶段的耗时情况（或CPU 使用情况）：<code>show profile [cpu] for query query_id;</code></li>
<li>查看是否支持 profile 操作：<code>SELECT @@have_profiling;</code></li>
</ul>
<p>如果需要开启 profile 操作，我们可以设置：<code>SET profiling = 1;</code></p>
<p><code>EXPLAIN SELECT SQL语句;</code> 可以获取 MySQL 如何执行 SELECT 语句的信息，包括 SELECT 语句执行过程中表如何连接和连接的顺序，也就是该 SQL 语句的执行计划的细节。</p>
<p><img src="/../../images/MySQL/explain.png" alt="img"></p>
<p>上图展示了 explain 语句的结果中的各个字段，这些字段的含义如下表：</p>
<table>
<thead>
<tr>
<th>列名</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><strong>id</strong></td>
<td>表示查询中执行 <code>SELECT</code> 子句或操作表的顺序。<br>– <code>id</code> 相同：按顺序从上到下执行。<br>– <code>id</code> 不同：数值越大越优先执行。</td>
</tr>
<tr>
<td><strong>select_type</strong></td>
<td>表示 <code>SELECT</code> 的类型：<br>– <code>SIMPLE</code>: 简单查询，不使用 <code>JOIN</code> 或子查询。<br>– <code>PRIMARY</code>: 主查询，即最外层查询。<br>– <code>UNION</code>: <code>UNION</code> 中第二个或后面的查询。<br>– <code>SUBQUERY</code>: 在 <code>SELECT</code> &#x2F; <code>WHERE</code> 后包含子查询。<br>– <code>DERIVED</code>: 派生表的 <code>SELECT</code>（<code>FROM</code> 子句中的子查询）。</td>
</tr>
<tr>
<td><strong>table</strong></td>
<td>查询的表名。</td>
</tr>
<tr>
<td><strong>type</strong></td>
<td>表示连接类型，性能由好到差：<br>– <code>system</code>: 表只有一行，通常是系统表，速度最快。<br>– <code>const</code>, <code>eq_ref</code>, <code>ref</code>: 使用索引查找单个行，<code>const</code> 最优。<br>– <code>range</code>: 检索给定范围的行。<br>– <code>index</code>: 遍历索引树读取。<br>– <code>ALL</code>: 全表扫描，效率最低。</td>
</tr>
<tr>
<td><strong>possible_keys</strong></td>
<td>显示该表可能会使用的索引（一个或多个），但不一定真的被使用。</td>
</tr>
<tr>
<td><strong>key</strong></td>
<td>实际使用的索引；如果为 <code>NULL</code>，则未使用索引。</td>
</tr>
<tr>
<td><strong>key_len</strong></td>
<td>索引中使用的字节数，是索引字段的最大可能长度，并非实际长度；值越短越好。</td>
</tr>
<tr>
<td><strong>ref</strong></td>
<td>用于与索引列比较的值来源：<br>– <code>const</code>: 常量（如 <code>WHERE column = &#39;value&#39;</code>）。<br>– 列名称：通常在 <code>JOIN</code> 操作中，表示 <code>JOIN</code> 条件依赖的字段。<br>– <code>NULL</code>: 未使用索引或全表扫描。</td>
</tr>
<tr>
<td><strong>rows</strong></td>
<td>估算为得到结果集需扫描的行数，越少越好。</td>
</tr>
<tr>
<td><strong>filtered</strong></td>
<td>表示返回结果行数占扫描行数的百分比，越大越好。</td>
</tr>
<tr>
<td><strong>Extra</strong></td>
<td>其他信息：<br>– <code>using index condition</code> &#x2F; <code>NULL</code>: 查找使用了索引，但需回表查询数据。<br>– <code>using where, using index</code>: 查找使用了索引，且所需数据都在索引列中，无需回表。<br>– <code>using temporary</code>: 使用临时表存储中间结果。</td>
</tr>
</tbody></table>
<p>示例：</p>
<table>
<thead>
<tr>
<th>id</th>
<th>select_type</th>
<th>table</th>
<th>partitions</th>
<th>type</th>
<th>possible_keys</th>
<th>key</th>
<th>key_len</th>
<th>ref</th>
<th>rows</th>
<th>filtered</th>
<th>Extra</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>SIMPLE</td>
<td>user</td>
<td>NULL</td>
<td>range</td>
<td>PRIMARY</td>
<td>PRIMARY</td>
<td>4</td>
<td>NULL</td>
<td>6</td>
<td>100.00</td>
<td>Using where</td>
</tr>
</tbody></table>
<p>通过 explain 命令，我们能分析出一些慢 SQL 的常见原因：</p>
<p>首先是索引使用问题，我们可通过 possible_keys(预计使用的索引) 和 key(实际使用的索引) 两个字段查看 InnoDB 有没有使用索引，优化器是否选择了错误索引，以及有没有实现覆盖索引。</p>
<p>接着是 I&#x2F;O 开销问题，通过 rows(执行当前查询要遍历的行数) 和 filtered(有效行数&#x2F;扫描行数比值) 字段来查看，是否扫描的行数过多，是否返回无用列且无用列有明显 I&#x2F;O 性能开销(比如text、blob、json 等类型）。</p>
<p><code>optimizer_trace</code> 可用于跟踪执行语句的解析、优化、执行的全过程。</p>
<p>使用步骤：</p>
<ul>
<li>查看系统变量信息：<code>show variables like &#39;%optimizer_trace%&#39;;</code></li>
<li>打开 optimizer trace 开关：<code>set optimizer_trace=&quot;enabled=on&quot;;</code></li>
<li>执行 SQL 语句。</li>
<li>查看 INFORMATION_SCHEMA.OPTIMIZER_TRACE 表中跟踪结果：<code>select * from INFORMATION_SCHEMA.OPTIMIZER_TRACE;</code>，并分析执行树：<ul>
<li><code>join_preparation</code>：准备阶段；</li>
<li><code>join_optimization</code>：分析阶段；</li>
<li><code>join_execution</code>：执行阶段。</li>
</ul>
</li>
</ul>
<p>关闭该功能：<code>set optimizer_trace=&quot;enabled=off&quot;;</code></p>
<h2 id="定位慢-SQL"><a href="#定位慢-SQL" class="headerlink" title="定位慢 SQL"></a>定位慢 SQL</h2><p>定位和优化慢 SQL 是提升 MySQL 性能的关键环节。通常可通过以下四大步骤完成：</p>
<ol>
<li>慢查询日志：记录所有执行时间超过阈值的 SQL，并借助 mysqldumpslow 汇总分析；</li>
<li>服务监控：在应用层面通过字节码插桩、连接池或 ORM 拦截对慢 SQL 进行实时监控与告警；</li>
<li>SHOW PROCESSLIST：在数据库层面查看当前运行的会话及其执行时间，快速锁定长时间运行的语句；</li>
<li>EXPLAIN：对疑似慢 SQL 执行 EXPLAIN，洞察查询执行计划，从而发现索引缺失、全表扫描等根本原因。</li>
</ol>
<p><img src="/../../images/MySQL/sql_optimize.png" alt="img"></p>
<h2 id="索引优化"><a href="#索引优化" class="headerlink" title="索引优化"></a>索引优化</h2><p>覆盖索引指的是当查询所需字段全部存在于索引叶节点时，数据库可以仅依赖索引而无需回表读取，显著降低 I&#x2F;O 开销。因此我们需要避免不必要的列，只查询需要的列。</p>
<p>创建联合索引能使多个查询字段同时被索引覆盖，从而避免回表和索引合并操作，且应遵循最左前缀规则以确保索引被有效利用。</p>
<p>为了保持索引的可用性，应避免使用 <code>!=</code>、<code>&lt;&gt;</code> 等非等值算符以及在索引列上应用函数，因为这些写法会导致索引失效，全表扫描或全索引扫描，从而影响性能。</p>
<p>当对较长字符串字段建立前缀索引时，可节省存储空间，但由于前缀索引无法存储完整值，MySQL 无法利用其实现排序或分组操作，依然可能触发 filesort 或临时表。</p>
<p>此外，InnoDB 默认启用索引下推技术（ICP），能将部分过滤条件下放至存储引擎层，仅在满足索引列过滤的记录上执行回表，从而减少数据传输量与回表次数，进一步提升查询效率。</p>
<p>假设我要执行如下命令：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> users <span class="keyword">WHERE</span> age <span class="operator">&gt;</span> <span class="number">30</span> <span class="keyword">AND</span> city <span class="operator">=</span> <span class="string">&#x27;Los Angeles&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>在未启用索引下推时，InnoDB 存储引擎仅依据 age &gt; 30 的索引范围扫描收集所有符合该条件的行，并将它们一股脑儿地返回给 MySQL 服务器层，由服务器再对 <code>city = &#39;Los Angeles&#39;</code> 条件逐行筛选；而启用索引下推后，存储引擎会在索引扫描阶段同时评估 <code>age &gt; 30</code> 与 <code>city = &#39;Los Angeles&#39;</code> 两个条件，只有同时满足的行才会被送到服务器层，从而避免了无谓的行回表和服务器级过滤，显著减少了 I&#x2F;O 操作并提升了查询性能。实际执行时，若在 EXPLAIN 的 Extra 列中看到 Using index condition 即表示已启用这一优化。</p>
<h2 id="join-优化"><a href="#join-优化" class="headerlink" title="join 优化"></a>join 优化</h2><p>在实际生产环境中，为了避免子查询带来的性能瓶颈，我们通常将其改写为等价的 JOIN 操作，并让行数较少的小表首先驱动行数庞大的大表，从而缩小中间结果集，减少随机 I&#x2F;O；同时可以在业务表中适当增加冗余字段，将频繁关联的维度信息直接存储在事实表中，以降低 JOIN 次数；为控制单次查询的复杂度，通常不超过三张表联合查询，如若业务允许，还可将逻辑复杂的多表 JOIN 拆分为多个简单查询，再在应用层按需合并结果，以实现更稳定高效的查询性能。</p>
<h2 id="insert-优化"><a href="#insert-优化" class="headerlink" title="insert 优化"></a>insert 优化</h2><p>在大规模数据写入场景下，将多条记录合并到单条 INSERT 语句中（例如一次提交 500–1000 条）能显著减少网络往返与语句解析开销，性能远超逐行插入；同时，关闭 AUTOCOMMIT 并使用 <code>START TRANSACTION…COMMIT</code> 手动提交事务，可以将多次写操作合并在一次事务中，避免频繁的事务开启与提交，从而进一步提升吞吐量；对于尤其庞大的数据集，采用 <code>LOAD DATA LOCAL INFILE</code> 命令从客户端文件批量导入，可利用服务器端的高速流式加载机制，其速度通常比批量 INSERT 快一个数量级以上；最后，确保插入数据按照主键单调递增的顺序写入 InnoDB 表，可减少聚簇索引中的页分裂与随机 I&#x2F;O，获得优于乱序插入的最佳写入性能。</p>
<h2 id="主键优化"><a href="#主键优化" class="headerlink" title="主键优化"></a>主键优化</h2><p><strong>选择简短且固定长度的整型主键</strong>：主键长度越短，聚簇索引和二级索引的存储和缓存开销越小；建议使用 INT 或 BIGINT 类型，并尽量避免使用 UUID 等无序且长度较长的值。</p>
<p><strong>采用自增（<code>AUTO_INCREMENT</code>）主键</strong>：自增主键保证插入顺序与唯一性，能够最大化页的填充率并避免频繁的页分裂；只要满足业务需求，应优先使用自增主键而非自然主键（如身份证号）。</p>
<p><strong>避免修改主键值</strong>：主键一旦更新，InnoDB 必须删除旧记录并插入新记录，等同于一次删除加一次插入，极易导致页分裂和 B+ 树重组，严重影响写入性能和存储布局。</p>
<p><strong>显式定义主键</strong>：即使表中已有唯一索引，仍应显式声明主键列；若未定义主键，InnoDB 会隐式创建一个隐藏的聚簇索引，增加不确定性，且可能浪费空间和管理成本。</p>
<h2 id="order-by-优化"><a href="#order-by-优化" class="headerlink" title="order by 优化"></a>order by 优化</h2><p>在 MySQL 中，任何无法直接利用索引有序性完成的 ORDER BY 操作都会触发 <strong>filesort</strong>：存储引擎先全表（或范围）扫描读取所有匹配行，将它们放入排序缓冲区（<code>sort_buffer</code>）中完成内存（或磁盘）排序后再返回结果；而如果能建立一个正好覆盖排序字段并且包含查询所需列的索引（<strong>Using index</strong>），MySQL 则可通过顺序扫描该索引直接输出有序结果，无需额外排序，效率更高。例如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> age, phone </span><br><span class="line"><span class="keyword">FROM</span> table_name </span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> age <span class="keyword">ASC</span>, phone <span class="keyword">DESC</span>;</span><br></pre></td></tr></table></figure>

<p>若事先创建：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> INDEX idx_user_age_pho_ad </span><br><span class="line"><span class="keyword">ON</span> table_name(age <span class="keyword">ASC</span>, phone <span class="keyword">DESC</span>);</span><br></pre></td></tr></table></figure>

<p>则该查询可通过索引顺序扫描直接返回，避免 filesort 和回表查询；否则，MySQL 在执行时仍需先回表取出 phone 字段，再对 age、phone 结果集进行 filesort，才能满足排序要求。对于多列排序，除了要遵循<strong>最左前缀</strong>原则以保证索引可用，还需在建索引时指定正确的 ASC&#x2F;DESC 顺序；当无法避免 filesort 时，可通过增大 <code>sort_buffer_size</code>（默认为 256 KB）来提升大数据量场景下的排序性能。</p>
<h2 id="group-by-优化"><a href="#group-by-优化" class="headerlink" title="group by 优化"></a>group by 优化</h2><p>在 MySQL 中，如果将用于 GROUP BY 的列定义在符合<strong>最左前缀</strong>规则的复合 B+Tree 索引上，服务器就可以直接沿着索引的有序叶节点执行分组操作，而无需使用临时表或 filesort，从而显著提高聚合查询性能；例如对于 <code>GROUP BY(a, b)</code> 的场景，只要存在 <code>(a, b, …)</code> 这样的复合索引，MySQL 就能利用该索引在扫描叶节点时即完成对 (a,b) 键值的分组，而不是先拉取所有行再在服务器层排序和分组。</p>
<h2 id="limit-优化"><a href="#limit-优化" class="headerlink" title="limit 优化"></a>limit 优化</h2><p>在面对海量数据分页时，传统的 <code>LIMIT … OFFSET</code> 会因数据库必须扫描并丢弃前 OFFSET 行而导致深度分页速度骤降；为此，可采用延迟关联（Deferred Join）技术——先在子查询中仅基于主键索引完成分页，再与主表 JOIN 获取完整行，以大幅缩减扫描量并保持深度分页的稳定性能；另一种常见做法是书签或键集分页（Keyset Pagination），即在每页结果中记录最后一行的排序键，下次查询以 <code>WHERE key &gt; last_key LIMIT N</code> 的方式继续，既避免了昂贵的 OFFSET 跳过开销，又能直接利用索引顺序扫描；总之，通过延迟关联减少笛卡尔积运算并使用游标式或书签式分页策略，可在保持简洁 SQL 的同时显著提升大数据量分页查询的执行效率。</p>
<h2 id="count-优化"><a href="#count-优化" class="headerlink" title="count 优化"></a>count 优化</h2><p>在 MySQL 中，<code>COUNT(column)</code> 最慢，因为引擎要逐行取出指定列的值并判断是否为 NULL，只有非空值才累加；<code>COUNT(primary_key)</code> 略快一些，因为主键列本身有 NOT NULL 约束，无需判断空值即可累加；<code>COUNT(1)</code> 与 <code>COUNT(*)</code> 在现代 MySQL 中被优化为等价操作，它们都不实际读取任何列值，而是在服务层对每行隐式累加一个常量，性能十分接近，通常是最快的计数方式。</p>
<p>大多数权威测试与官方文档都表明，COUNT(1) 与 COUNT(*) 在 MySQL&#x2F;InnoDB 上几乎没有性能差异，且二者优于其他形式的 COUNT（例如 COUNT(column)）。</p>
<blockquote>
<p>[!NOTE]</p>
<p>如果我们需要在大数据量下统计唯一值，同时对处理速度要求很高，但是允许出现小幅度误差，这个时候我们可以使用 HyperLogLog 算法。</p>
<p>HyperLogLog 是一种概率算法，通过统计哈希值中最长前导零长度来估算数据基数，误差一般在 1–2% 范围内。</p>
<p>具体论文，可参考：<a href="https://algo.inria.fr/flajolet/Publications/FlFuGaMe07.pdf">https://algo.inria.fr/flajolet/Publications/FlFuGaMe07.pdf</a></p>
</blockquote>
<h2 id="update-优化"><a href="#update-优化" class="headerlink" title="update 优化"></a>update 优化</h2><p>InnoDB 的行锁实际上是对索引记录（index record）加锁，而非对物理存储行本身加锁：当执行带有 WHERE 条件的 <code>UPDATE</code>、<code>DELETE</code> 或 <code>SELECT … FOR UPDATE</code> 时，InnoDB 会在匹配条件的索引叶节点上设置记录锁和必要的间隙锁，从而实现行级并发控制；但如果查询条件无法利用任何合适的索引，InnoDB 就必须扫描整个表并在聚簇索引（或隐式主键索引）上对所有记录加锁，这时就会退化为表级锁，阻塞全表写操作；同样地，若使用的索引失效（例如对非索引列做范围扫描或函数运算），也会触发锁粒度升级为表锁，导致并发性能急剧下降。因此，为了保持细粒度的行锁并避免意外的表锁锁阻塞，务必为常用的查询条件列创建合适且选择性高的索引。</p>
<h2 id="union-优化"><a href="#union-优化" class="headerlink" title="union 优化"></a>union 优化</h2><p>在使用 UNION 语句时，为了让优化器更高效地执行查询，应将共同的过滤条件（如 WHERE）和分页限制（如 LIMIT）尽可能下推到各个子查询中，这样每个子查询只需处理满足自身子集条件的行，并在各自范围内完成截取与过滤，避免先将所有子查询结果合并后再做统一筛选，从而减少中间结果集的大小、降低 I&#x2F;O 与内存开销，并加快整体查询响应速度。</p>
<p><strong>MySQL 数据库 cpu 飙升的话，要怎么处理呢？</strong></p>
<p>在 MySQL 出现 CPU 飙升时，首先可借助操作系统工具（如 top 或 htop）确认是 mysqld 进程占用过高，接着在数据库层面执行 <code>SHOW PROCESSLIST</code> 或查询 <code>information_schema.processlist</code>，快速定位执行时间或状态异常的会话，并对最耗资源的 SQL 做 EXPLAIN 分析，检查是否缺失索引或数据量过大；发现可疑线程后，可使用 KILL 语句终止它们，同时观察 CPU 是否回落，然后针对性地优化（如新增索引、重写慢查询、调整内存参数等）并重新执行这些 SQL；此外，如果是大量会话瞬间涌入导致 CPU 突增，则需与应用方协同排查连接激增的原因，并可考虑设置最大连接数或在业务层做限流，以防过多并发请求压垮数据库服务器。</p>
<p><strong>有一个查询需求，MySQL 中有两个表，一个表 1000W 数据，另一个表只有几千数据，要做一个关联查询，如何优化？</strong></p>
<p>如果 orders 表是大表（比如 1000 万条记录），而 users 表是相对较小的表（比如几千条记录）。</p>
<ol>
<li><p>为关联字段建立索引，确保两个表中用于 JOIN 操作的字段都有索引。这是最基本的优化策略，避免数据库进行全表扫描，可以大幅度减少查找匹配行的时间。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> INDEX idx_user_id <span class="keyword">ON</span> users(user_id);</span><br><span class="line"><span class="keyword">CREATE</span> INDEX idx_user_id <span class="keyword">ON</span> orders(user_id);</span><br></pre></td></tr></table></figure>
</li>
<li><p>小表驱动大表，在执行 JOIN 操作时，先过滤小表中的数据，这样可以减少后续与大表进行 JOIN 时需要处理的数据量，从而提高查询效率。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> u.<span class="operator">*</span>, o.<span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> (</span><br><span class="line">  <span class="keyword">SELECT</span> user_id</span><br><span class="line">  <span class="keyword">FROM</span> users</span><br><span class="line">  <span class="keyword">WHERE</span> some_condition <span class="comment">-- 这里是对小表进行过滤的条件</span></span><br><span class="line">) <span class="keyword">AS</span> filtered_users</span><br><span class="line"><span class="keyword">JOIN</span> orders o <span class="keyword">ON</span> filtered_users.user_id <span class="operator">=</span> o.user_id</span><br><span class="line"><span class="keyword">WHERE</span> o.some_order_condition; <span class="comment">-- 如果需要，可以进一步过滤大表</span></span><br></pre></td></tr></table></figure></li>
</ol>
<p><strong>如何解决慢查询问题？</strong></p>
<p>首先，开启慢查询日志，用于记录执行时间超过阈值的查询，帮助定位慢查询的 SQL 语句。</p>
<p>开启方法如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SET</span> <span class="keyword">GLOBAL</span> slow_query_log <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">GLOBAL</span> long_query_time <span class="operator">=</span> <span class="number">1</span>; <span class="comment">-- 设置慢查询的阈值为1秒</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SHOW</span> VARIABLES <span class="keyword">LIKE</span> <span class="string">&#x27;slow_query_log%&#x27;</span>; <span class="comment">-- 确认是否启用</span></span><br></pre></td></tr></table></figure>

<p>之后检查慢查询日志文件，定位耗时较长的 SQL 语句，并使用 EXPLAIN 分析 SQL 的执行计划，判断是否使用了索引或是否存在全表扫描等问题。</p>
<p>比如说：<code>EXPLAIN SELECT * FROM table_name WHERE column_name = &#39;value&#39;;</code>，该命令中的关键字段解释如下：</p>
<ol>
<li>type：查询类型，优化目标是避免 ALL（全表扫描），优先选择 index、range。</li>
<li>key：实际使用的索引。</li>
<li>rows：扫描的行数，值越小越好。</li>
<li>extra：留意 Using temporary 或 Using filesort，这些会影响性能。</li>
</ol>
<p>如果缺少索引，那么我们需要为查询条件中的字段添加索引，特别是 WHERE、JOIN、GROUP BY、ORDER BY 中涉及的字段。<br>比如说：<code>CREATE INDEX idx_column ON table_name (column_name);</code></p>
<p>如果大量数据出现回表操作，那么需要改成覆盖索引，减少回表操作。<br>比如说：<code>CREATE INDEX idx_multi_column ON table_name (column1, column2);</code></p>
<p>同时，还要判断是否出现索引失效。对此，我们可以避免对索引列使用函数或表达式，避免隐式类型转换（如字符串与数字比较）。</p>
<p>然后，我们可以重构查询语句，比如说使用 LIMIT 分页来避免返回大量数据：<code>SELECT * FROM table_name WHERE condition LIMIT 100;</code>，或者可以明确查询字段：<code>SELECT column1, column2 FROM table_name WHERE condition;</code>，避免运行 <code>SELECT *;</code>，再者可以在 JOIN 字段上设置索引，并尽量减少复杂的嵌套查询。</p>
<p>最后，我们可以进行表结构优化。</p>
<p>比如说可以使用分区表，也就是如果查询条件中经常使用时间或地理区域，可以将表按这些字段分区，减少扫描范围：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> table_name (</span><br><span class="line">  id <span class="type">BIGINT</span> <span class="keyword">NOT NULL</span>,</span><br><span class="line">  created_at <span class="type">DATE</span> <span class="keyword">NOT NULL</span></span><br><span class="line">) <span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="keyword">RANGE</span> (<span class="keyword">YEAR</span>(created_at)) (</span><br><span class="line">  <span class="keyword">PARTITION</span> p2023 <span class="keyword">VALUES</span> LESS THAN (<span class="number">2024</span>),</span><br><span class="line">  <span class="keyword">PARTITION</span> p2024 <span class="keyword">VALUES</span> LESS THAN (<span class="number">2025</span>)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>或者如果单表数据量仍然过大，还可以按特定规则（如用户 ID）将表拆分为多个子表，降低单表数据量。</p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>介绍</title>
    <url>/undefined/MySQL/2024/09/11/MySQL/%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>数据库是数据存储的仓库，是文件的集合，是依照某种数据模型组织起来并存放于二级存储器中的数据集合。</p>
<p>数据库实例是程序，是位于用户和操作系统之间的一层数据管理软件，用户对数据库数据的任何操作都是在数据库实例下进行的。应用程序只有通过数据库实例才能和数据库打交道。</p>
<p>在 MySQL 中，实例和数据库的关系通常是一一对应的。但在集群下可能存在一个数据库被多个数据库实例使用的情况。</p>
<p>关系型数据库（结构数据模型，表）：建立在关系模型基础上，由多张相互连接的<strong>二维表</strong>组成的数据库。</p>
<p>数据库管理系统（DBMS）：操纵和管理数据库的应用程序。</p>
<p>SQL：操作关系型数据库的编程语言，也是一套标准。</p>
<p>客户端&#x3D;&gt;数据库管理系统&#x3D;&gt;数据库&#x3D;&gt;数据表。</p>
<h1 id="数据库三大范式"><a href="#数据库三大范式" class="headerlink" title="数据库三大范式"></a>数据库三大范式</h1><p>第一范式（1NF）：确保表的每一列都是<strong>不可分割</strong>的基本数据单元，比如说用户地址，应该拆分成省、市、区、详细信息等 4 个字段。</p>
<p>第二范式（2NF）：在 1NF 的基础上，要求数据库表中的<strong>每一列都和主键直接相关</strong>，而不能只与主键的某一部分相关（主要针对联合主键）。</p>
<p>第三范式（3NF）：在 2NF 的基础上，消除非主键列对主键的传递依赖，即<strong>非主键列只依赖于主键列</strong>，不依赖于其他非主键列。</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>MySQL 是一款开源的关系型数据库管理系统（RDBMS），最初由 MySQL AB 于 1995 年 5 月 23 日推出，现由 Oracle 维护和发布。MySQL 使用 SQL 来定义、操作和管理数据表，将数据组织为由行与列构成的表格，以实现数据之间的关联与查询。它原生支持完整的 ACID 事务特性和多版本并发控制（MVCC），在高并发环境下能够保持数据的一致性与隔离度；InnoDB 引擎通过回滚段存储旧版本数据，并结合两阶段锁定（Two-Phase Locking）和插入意向锁等机制，实现并发控制与死锁检测。MySQL 可跨 Windows、Linux、macOS、FreeBSD 等多个操作系统部署，凭借易用性、高性能与可靠性，长期被广泛应用于 Web 应用、电子商务平台和企业级系统。</p>
<p>MySQL 采用可插拔的存储引擎架构，允许用户根据不同业务需求选择最合适的引擎。默认的 InnoDB 引擎提供事务处理、行级锁、外键约束、崩溃恢复（通过 redo log）和双写缓冲等功能，以确保数据安全与快速恢复。在 InnoDB 之前，MyISAM 曾为默认引擎，其采用表级锁设计、不支持事务与外键，适用于读密集型场景但无法满足高并发写入需求。此外，MySQL 还支持 Memory 引擎（将数据保存在内存中，适合临时表或高速缓存）和 NDB Cluster 引擎（面向分布式高可用集群，支持自动分片和多主复制），以满足不同场景下对性能与可用性的多样化需求。</p>
<p>在服务器层面，MySQL 包括 SQL 解析器、查询优化器和执行器三大组件。解析器负责将客户端提交的 SQL 文本进行词法与语法分析，生成内部抽象语法树（AST）；优化器基于统计信息与索引代价估算，选择最优执行计划；执行器则通过存储引擎接口调用底层引擎完成实际的数据访问和操作，例如数据页读取、加锁、写入等。MySQL 采用磁盘导向的存储架构，InnoDB 使用页为单位将数据加载到缓冲池并通过分代 LRU 策略进行页面替换，以优化磁盘 I&#x2F;O 性能。在并发查询执行方面，MySQL 以元组级的迭代器模型处理查询，不支持内部并行化，但可借助索引和优化器策略减少 I&#x2F;O 次数，从而提升查询效率。</p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>事务</title>
    <url>/undefined/MySQL/2024/09/27/MySQL/%E4%BA%8B%E5%8A%A1/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><p>一组 SQL 操作的集合，不可分割的工作单位。也就是说，事务会把所有操作作为一个整体向系统进行提交或撤销，即这些操作要么同时成功，要么同时失败。</p>
<p>MYSQL 的事务默认是自动提交的，即当执行一条 DML 语句时，MYSQL 会立即隐式地提交事务。</p>
<p>查看&#x2F;设置事务提交方式：</p>
<ul>
<li>查看自动提交状态：<code>SELECT @@autocommit;</code> （1 为自动提交，0 为手动提交）</li>
<li>设置手动提交：<code>SET @@autocommit = 0;</code></li>
</ul>
<p>事务的回滚以转账为例：</p>
<table>
<thead>
<tr>
<th></th>
<th>开启事务</th>
</tr>
</thead>
<tbody><tr>
<td>查询发起人账户余额</td>
<td></td>
</tr>
<tr>
<td>发起人账户余额 -1000</td>
<td></td>
</tr>
<tr>
<td></td>
<td>如果抛异常，回滚事务</td>
</tr>
<tr>
<td>接收人账户余额 +1000</td>
<td></td>
</tr>
<tr>
<td></td>
<td>结束事务</td>
</tr>
</tbody></table>
<p>事务四大特性</p>
<ul>
<li>原子性（Atomicity）：事务是不可分割的最小操作单元，全部成功或全部失败。</li>
<li>一致性（Consistency）：事务中必须保持所有数据处于一致状态，即从一个合法状态转向另一合法状态。</li>
<li>隔离性（Isolation）：数据库系统提供的隔离机制，保证事务在不受外部并发操作影响的独立环境下运行，即并发执行的事务是彼此隔离的。</li>
<li>持久性（Durability）：事务一旦提交或回滚，对数据库中的数据的改变是永久的（通过数据库的恢复和日志机制来实现）。</li>
</ul>
<h2 id="事务分类"><a href="#事务分类" class="headerlink" title="事务分类"></a>事务分类</h2><p>从事务理论的角度来说，可以把事务分为以下几种类型：</p>
<ul>
<li>扁平事务 (Flat Transactions)</li>
<li>带有保存点的扁平事务 (Flat Transactions with Savepoints)</li>
<li>链事务 (Chained Transactions)</li>
<li>嵌套事务 (Nested Transactions)</li>
<li>分布式事务 (Distributed Transactions)</li>
</ul>
<p><strong>扁平事务</strong>是事务类型中最简单的一种，但在实际生产环境中，这可能是使用最为频繁的事务。在扁平事务中，所有操作都处于同一层次，其由 BEGIN 开始，由 COMMIT 或 ROLLBACK 结束，其间的操作是原子的，要么都执行，要么都回滚。因此扁平事务是应用程序成为原子操作的基本组成模块。下图显示了扁平事务的三种不同结果。</p>
<p><img src="/../../images/MySQL/mysql_redo_flat_res.drawio.png" alt="img"></p>
<p>扁平事务的主要限制是不能提交或者回滚事务的某一部分，或分几个步骤提交。</p>
<p>例如用户在旅行网站上进行自己的旅行度假计划。用户想从南昌到洛杉矶的圣莫妮卡，这两个城市之间没有直达的班机，需要用户预订并转乘航班，或者需要搭火车等待。用户预订旅行度假的事务为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">BEGIN </span><br><span class="line"></span><br><span class="line">S1：预订南昌到上海的高铁。</span><br><span class="line"></span><br><span class="line">S2：上海浦东国际机场坐飞机，预订去洛杉矶的航班。</span><br><span class="line"></span><br><span class="line">S3：在洛杉矶打 Uber 前往圣莫妮卡。</span><br><span class="line"></span><br><span class="line">COMMIT</span><br></pre></td></tr></table></figure>

<p>但是当用户执行到 S3 时，发现由于飞机到达洛杉矶的时间太晚，打不到 Uber 了。这时用户希望在 LAX 附近住一晚，第二天出发去圣莫妮卡。这时如果事务为扁平事务，则需要回滚之前 S1、S2、S3 的三个操作，这个代价就显得有点大。因为当再次进行该事务时，S1、S2 的执行计划是不变的。也就是说，如果支持有计划的回滚操作，那么就不需要终止整个事务。因此就出现了带有保存点的扁平事务。</p>
<p><strong>带有保存点的扁平事务</strong>除了支持扁平事务支持的操作外，允许在事务执行过程中回滚到同一事务中较早的一个状态。这是因为某些事务可能在执行过程中出现的错误并不会导致所有的操作都无效，放弃整个事务不合乎平衡，也开销太大。保存点（Savepoint）用来通知系统应该记住事务当前的状态，以便当之后发生错误时，事务能回到保存点当时的状态。</p>
<p>对于扁平的事务来说，其隐式地设置了一个保存点。然而在整个事务中，只有这一个保存点，因此，回滚只能回滚到事务开始时的状态。保存点用 SAVE WORK 函数来建立，通知系统记录当前的处理状态。当出现问题时，保存点能用作内部的重启动点，根据应用逻辑，决定是回到最近一个保存点还是其他更早的保存点。下图显示了在事务中使用保存点。</p>
<p><img src="/../../images/MySQL/mysql_redo_savepoint.drawio.png" alt="img"></p>
<p>上图中，灰色背景部分的操作表示由 ROLLBACK WORK 而导致部分回滚，实际上并没有执行的操作。当用 BEGIN WORK 开启一个事务时，隐式地包含了一个保存点；当事务通过 ROLLBACK WORK : 2 发出部分回滚命令时，事务回滚到保存点 2，接着依次执行，并再次执行到 ROLLBACK WORK : 7，直到最后的 COMMIT WORK 操作，这时表示事务结束，除灰色阴影部分的操作外，其余操作都已经执行，并且提交。</p>
<p>另一点需要注意的是，保存点在事务内部是递增的，这从上图中也能看出。有人可能会想，返回保存点 2 以后，下一个保存点可以为 3，因为之前的工作终止了。然而新的保存点编号为 5，这意味着 ROLLBACK 不影响保存点的计数，并且单调递增的编号能保持事务执行的整个历史过程，包括在执行过程中想法的改变。</p>
<p>此外，当事务通过 ROLLBACK WORK : 2 命令发出部分回滚命令时，要记住事务并没有完全被回滚，只是回滚到了保存点 2 而已。这代表当前事务还是活跃的，如果想要完全回滚事务，还需要再执行命令 ROLLBACK WORK。</p>
<p><strong>链事务</strong>可视为保存点模式的一种变种。带有保存点的扁平事务，当发生系统崩溃时，所有的保存点都将消失，因为其保存点是易失的 (volatile)，而非持久的 (persistent)。这意味着当进行恢复时，事务需要从头开始重新执行，而不能从最近的一个保存点继续执行。</p>
<p>链事务的思想是：在提交一个事务时，释放不需要的数据对象，将必要的处理上下文隐式地传给下一个要开始的事务。注意，提交事务操作和开始下一个事务操作将合并为一个原子操作。这意味着下一个事务将看到上一个事务的结果，就好像在一个事务中进行的一样。下图显示了链事务的工作方式：</p>
<p><img src="/../../images/MySQL/mysql_redo_chain_txn.drawio.png" alt="img"></p>
<p>上图中，第一个事务提交触发第二个事务的开始。</p>
<p>链事务与带有保存点的扁平事务不同的是，带有保存点的扁平事务能回滚到任意正确的保存点。而链事务中的回滚仅限于当前事务，即只能恢复到最近一个的保存点，也就是说，每个子事务刚开始时，系统会“隐式地”在那个点打一个恢复点，但你<strong>没有</strong>机会在同一个子事务里再自己开第二个、第三个保存点。</p>
<p>对于锁的处理，两者也不相同。带保存点的扁平事务开始后，一直占有它所申请的所有行锁、表锁（或者更高级别的锁），即便你中途用 ROLLBACK TO SAVEPOINT 回滚到某个保存点，也只是撤销了回滚点之后的逻辑修改，但<strong>不会</strong>释放任何锁。而链事务中，每当一个子事务执行 COMMIT，它所持有的锁就立即释放，数据库中其它会话或下一个子事务都可以并发访问那些之前被锁定的资源。</p>
<p><strong>嵌套事务</strong>将一个大事务组织成“事务树”——顶层事务（parent）控制若干子事务（child），子事务内又可有更深层的子事务，直到叶子节点。叶子节点的事务是真正向数据库发起操作的“扁平事务”，上层事务只负责逻辑控制与协调。</p>
<p><strong>提交与生效</strong></p>
<ul>
<li>子事务提交：仅把该子事务状态标记为“准备就绪”，真正对外生效要等到其所有祖先（尤其是顶层事务）都提交后才算完成。</li>
<li>父事务提交：向下统一提交整棵事务树，所有子事务的修改才真正持久化。</li>
</ul>
<p>回滚某一事务节点，会<strong>递归地</strong>回滚其所有子孙事务。因此，只有顶层事务具备全局回滚能力，子事务无法独立保留已提交的修改。</p>
<p>嵌套事务可以<strong>选择性地继承</strong>父事务的锁，也可以通过“反向继承”让父事务获得子事务锁。不同子事务可对同一资源持有不同级别的锁；上层事务在其自身提交前，锁不会被释放。</p>
<p>保存点可模拟嵌套回滚的灵活性（任意回到某个保存点），但无法在锁继承、并行执行等方面还原嵌套事务的精细控制。若需要子事务并行执行或精确的锁传递，就必须由系统原生支持嵌套事务。</p>
<p><strong>分布式事务</strong>通常是一个在分布式环境下运行的扁平事务，因此需要根据数据库所在位置访问网络中的不同节点。</p>
<p>假设一个用户在 ATM 机进行银行的转账操作，例如持卡人从招商银行的储蓄卡转账 10 000 元到工商银行的储蓄卡。在这种情况下，可以将 ATM 机视为节点 A，招商银行的后台数据库视为节点 B，工商银行的后台数据库视为节点 C，这个转账的操作可分解为以下步骤：</p>
<ol>
<li>节点 A 发出转账命令。</li>
<li>节点 B 执行储蓄卡中的余额值减去 10 000。</li>
<li>节点 C 执行储蓄卡中的余额值加上 10 000。</li>
<li>节点 A 通知用户操作完成或者通知用户操作失败。</li>
</ol>
<p>这里需要使用分布式事务，因为节点 A 不能通过调用一台数据库就完成任务，需要访问网络中多个节点的数据库，而在每个节点的数据库上执行的事务操作又都是扁平事务。分布式事务同样需要满足 ACID 特性，要么都发生，要么都失效。对于上述例子，如果步骤 2 或 3 中的任何一个操作失败，都必须回滚整个分布式事务，否则结果将非常不可控。</p>
<p>对于 InnoDB 存储引擎来说，支持扁平事务、带有保存点的事务、链事务和分布式事务。但<strong>原生并不支持</strong>嵌套事务，因此对于有并行事务需求的用户来说，MySQL 或 InnoDB 在这方面能力有限。不过，用户仍可通过带有保存点的事务来模拟串行的嵌套事务。</p>
<h2 id="并发场景下的事务问题"><a href="#并发场景下的事务问题" class="headerlink" title="并发场景下的事务问题"></a>并发场景下的事务问题</h2><p>脏读：一个事务读到另一个事务<strong>未提交</strong>的数据，这些数据可能在之后被回滚，从而导致读取到的数据无效。数据库系统在较低的隔离级别下允许其他事务读取尚未提交的数据，可以减少数据锁定的时间，从而提升系统的吞吐量和响应时间。</p>
<p>不可重复读：一个事务先后读取同一条事务，但<strong>两次读取的数据</strong>不同。具体来说，事务 A 在读取数据后，事务 B 更新了该数据并提交，事务 A 再次读取时，数据已经被改变，导致了前后读取的数据不一致。</p>
<p>幻读：一个事务按照条件查询数据时，没有对应的数据行，但之后又查询数据时，又发现这行数据已存在，可能是别的事务在这两次查询之间插入了新的数据。</p>
<h2 id="事务的隔离级别"><a href="#事务的隔离级别" class="headerlink" title="事务的隔离级别"></a>事务的隔离级别</h2><p>读未提交：这是最低的隔离级别，对普通一致性读不加锁，允许读取其他事务未提交的更改，因此可能出现脏读、不可重复读和幻读。InnoDB 在该级别下仍使用 MVCC 快照（Read View）进行一致性读，但允许直接读取缓冲区中的最新行版本，无需检查事务是否已提交。</p>
<p>读已提交：在该级别下，每条普通 SELECT 都会生成一个新的 Read View，只读取已提交的行版本，从而避免脏读，但仍可能出现不可重复读和幻读。一致性读不加行锁，只有在显式锁定读（<code>SELECT … FOR UPDATE/SHARE</code>）或 DML 操作时才会加锁。该级别只能工作在二进制日志为 ROW 的格式下。但即使不使用 READ COMMITTED 的事务隔离级别，也应该考虑将二进制日志的格式更换成 ROW，因为这个格式记录的是行的变更，而不是简单的 SQL 语句，所以可以避免一些不同步现象的产生，进一步保证数据的同步。</p>
<p>可重复读：这是 InnoDB 的默认隔离级别，事务在第一次读取时创建一个 Read View，后续所有普通读都使用相同快照，保证事务内多次读取相同记录的结果一致，从而避免脏读和不可重复读。同时，InnoDB 在该隔离级别下启用 Next-Key 锁（记录锁 + 间隙锁）阻止其他事务在范围内插入新行，以防止幻读。</p>
<p>串行化：这是最高隔离级别，所有普通 SELECT 都作为共享锁定读执行（LOCK IN SHARE MODE），对每条检索到的记录及其所在间隙加 Shared Next-Key 锁，彻底消除脏读、不可重复读和幻读。写操作继续使用 Exclusive Next-Key 锁，锁粒度保持行级；同时在表层加意向锁（IS&#x2F;IX）以协调多粒度锁，但并不加表级锁。</p>
<table>
<thead>
<tr>
<th>隔离级别</th>
<th>脏读</th>
<th>不可重复读</th>
<th>幻读</th>
</tr>
</thead>
<tbody><tr>
<td>Read uncommitted</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>Read committed</td>
<td>❌</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>Repeatable read（默认）</td>
<td>❌</td>
<td>❌</td>
<td>❌</td>
</tr>
<tr>
<td>Serializable</td>
<td>❌</td>
<td>❌</td>
<td>❌</td>
</tr>
</tbody></table>
<p>✅：会发生</p>
<p>❌：不会发生</p>
<p>查看事务隔离级别：<code>SELECT @@TRANSACTION_ISOLATION;</code></p>
<p>设置事务隔离级别：<code>SET [SESSION | GLOBAL] TRANSACTION_ISOLATION LEVEL [READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE];</code></p>
<p>隔离级别越高，数据越安全，但是性能越低。</p>
<h2 id="长事务"><a href="#长事务" class="headerlink" title="长事务"></a>长事务</h2><p>长事务就是执行时间较长的事务。</p>
<p>长事务的典型场景如下：</p>
<ul>
<li>开发错误：开启事务后忘记提交或回滚。</li>
<li>业务逻辑复杂：一些业务逻辑需要执行多个步骤或设计的数据量大，耗时较长，可能导致事务一直未提交。</li>
</ul>
<p>例如，对于银行系统的数据库，每过一个阶段可能需要更新对应账户的利息。如果对应账户的数量非常大，例如对有 1 亿用户的表 account，需要执行下列语句：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> account <span class="keyword">SET</span> account_total <span class="operator">=</span> account_total <span class="operator">+</span> (<span class="number">1</span> <span class="operator">+</span> interest_rate);</span><br></pre></td></tr></table></figure>

<p>这时这个事务可能需要非常长的时间来完成。可能需要 1 个小时，也可能需要 4、5 个小时，这取决于数据库的硬件配置。同时由于事务 ACID 的特性，这个操作被封装在一个事务中完成。这就产生了一个问题：在执行过程中，当数据库或操作系统、硬件等发生故障时，重新开始事务的代价变得不可接受。数据库需要回滚所有已经发生的变化，而这个过程可能比产生这些变化的时间还要长。</p>
<p>因此，对于长事务的问题，有时可以通过转化为小批量（mini batch）的事务来进行处理。事务发生错误时，只需要回滚一部分数据，然后接着上次已完成的小事务继续进行。例如，对于前面讨论的银行利息计算问题，我们可以将一个需要处理 1 亿用户的大事务，分解为每次处理 10 万用户的小事务。既可以在应用层通过循环和分页来完成，也可以写成存储过程。将大事务拆分成小事务后：</p>
<ul>
<li>每一次只更新一小批用户，某一批出错时只需回滚该批，前边已成功的批次不受影响；</li>
<li>事务时间大幅缩短，锁竞争和系统压力随之下降；</li>
<li>用户或监控系统能够更清晰地看到进度，例如已更新到第几批。</li>
</ul>
<p>长事务的危害</p>
<ul>
<li>长事务会长时间占用行锁或表锁，导致其他事务无法访问相关资源，可能引发大量阻塞甚至死锁；</li>
<li>事务未提交前，MySQL 需要保留 Undo 日志以支持事务的回滚操作，这会增加存储空间和内存压力，并且还会造成长时间回滚；</li>
<li>长时间未提交的事务可能会影响数据库备份、复制和其他管理操作；</li>
<li>并发情况下，数据库连接池中的可用连接会被耗尽。</li>
</ul>
<p>长事务的优化</p>
<ul>
<li>将查询等数据准备操作放到事务外；</li>
<li>事务中避免远程调用，如果有的话，要设置超时时间，防止事务等待时间太久；</li>
<li>事务中避免一次性处理太多数据，可拆分成多个事务分次处理；</li>
<li>更新等涉及加锁的操作尽量放在事务靠后的位置；</li>
<li>尽量使用异步处理；</li>
<li>极端情况下，可在应用侧（业务代码）保证数据一致性，放弃事务。</li>
</ul>
<h2 id="事务控制语句"><a href="#事务控制语句" class="headerlink" title="事务控制语句"></a>事务控制语句</h2><p>在 MySQL 命令行的默认设置下，事务都是自动提交（auto commit）的，即执行 SQL 语句后就会马上执行 <code>COMMIT</code> 操作。因此要显式地开启一个事务需使用命令 <code>BEGIN</code>、<code>START TRANSACTION</code>，或者执行命令 <code>SET AUTOCOMMIT=0</code>，禁用当前会话的自动提交。在具体介绍其含义之前，先来看看用户可以使用哪些事务控制语句。</p>
<ul>
<li><code>START TRANSACTION | BEGIN</code>：显式地开启一个事务。</li>
<li><code>COMMIT</code>：要想使用这个语句的最简形式，只需发出 <code>COMMIT</code>。也可以更详细一些，写为 <code>COMMIT WORK</code>，不过二者几乎是等价的。<code>COMMIT</code> 会提交事务，并使得已对数据库做的所有修改成为永久性的。</li>
<li><code>ROLLBACK</code>：要想使用这个语句的最简形式，只需发出 <code>ROLLBACK</code>。同样地，也可以写为 <code>ROLLBACK WORK</code>，但是二者几乎是等价的。回滚会结束用户的事务，并撤销正在进行的所有未提交的修改。</li>
<li><code>SAVEPOINT identifier</code>：SAVEPOINT 允许在事务中创建一个保存点，一个事务中可以有多个 SAVEPOINT。</li>
<li><code>RELEASE SAVEPOINT identifier</code>：删除一个事务的保存点，当没有一个保存点时执行这句话，会抛出一个异常。</li>
<li><code>ROLLBACK TO [SAVEPOINT] identifier</code>：这个语句与 SAVEPOINT 命令一起使用。可以把事务回滚到指定的保存点，而不回滚此保存点之前的任何工作。例如可以发出两条 UPDATE 语句，后面跟一个 SAVEPOINT，然后又是两条 DELETE 语句。如果执行 DELETE 语句期间出现了某种异常情况，并且捕获到这个异常，同时发出了 <code>ROLLBACK TO SAVEPOINT</code> 命令，事务就会回滚到指定的 SAVEPOINT，撤销 DELETE 完成的所有工作，而 UPDATE 语句完成的工作不受影响。</li>
<li><code>SET TRANSACTION</code>：这个语句用来设置事务的隔离级别。InnoDB 存储引擎提供的事务隔离级别有：READ UNCOMMITTED、READ COMMITTED、REPEATABLE READ、SERIALIZABLE。</li>
</ul>
<p><code>START TRANSACTION</code>、<code>BEGIN</code> 语句都可以在 MySQL 命令行下显式地开启一个事务。但是在存储过程中，MySQL 数据库的解析器会自动将 <code>BEGIN</code> 识别为 <code>BEGIN … END</code>，因此在存储过程中只能使用 <code>START TRANSACTION</code> 语句来开启一个事务。</p>
<p><code>COMMIT</code> 和 <code>COMMIT WORK</code> 语句基本一致，都是用来提交事务。不同之处在于 <code>COMMIT WORK</code> 用来控制事务结束后的行为是 <code>CHAIN</code> 还是 <code>RELEASE</code>。如果是 <code>CHAIN</code> 方式，那么事务就变成了链事务。</p>
<p>用户可以通过参数 <code>completion_type</code> 来进行控制，该参数默认为 0，表示没有任何操作。在这种设置下 <code>COMMIT</code> 和 <code>COMMIT WORK</code> 是完全等价的。当参数 <code>completion_type</code> 的值为 1 时，<code>COMMIT WORK</code> 等同于 <code>COMMIT AND CHAIN</code>，表示马上自动开启一个相同隔离级别的事务，如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">CREATE TABLE</span> t ( a <span class="type">INT</span>, <span class="keyword">PRIMARY KEY</span> (a) ) ENGINE<span class="operator">=</span>INNODB;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> @<span class="variable">@autocommit</span>\G;</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">@<span class="variable">@autocommit</span>: <span class="number">1</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SET</span> @<span class="variable">@completion_type</span><span class="operator">=</span><span class="number">1</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">BEGIN</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> t <span class="keyword">SELECT</span> <span class="number">1</span>;</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line">Records: <span class="number">1</span> Duplicates: <span class="number">0</span> Warnings: <span class="number">0</span></span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">COMMIT</span> WORK;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.01</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> t <span class="keyword">SELECT</span> <span class="number">2</span>;</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line">Records: <span class="number">1</span> Duplicates: <span class="number">0</span> Warnings: <span class="number">0</span></span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> t <span class="keyword">SELECT</span> <span class="number">2</span>;</span><br><span class="line">ERROR <span class="number">1062</span> (<span class="number">23000</span>): Duplicate entry <span class="string">&#x27;2&#x27;</span> <span class="keyword">for</span> key <span class="string">&#x27;PRIMARY&#x27;</span></span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">ROLLBACK</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line"># 注意回滚之后只有 <span class="number">1</span> 这一个记录，而没有 <span class="number">2</span> 这两个记录</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> t\G;</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">a: <span class="number">1</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<p>在这个示例中我们设置 <code>completion_type</code> 为 1，第一次通过 <code>COMMIT WORK</code> 来插入 1 这一个记录。之后插入记录 2 时我们并没有用 <code>BEGIN</code>（或者 <code>START TRANSACTION</code>）来显式地开启一个事务，后续再插入一条重复的记录 2 就会抛出异常。接着执行 <code>ROLLBACK</code> 操作，最后发现只有 1 这一个记录，2 并没有被插入。因为 <code>completion_type</code> 为 1 时，<code>COMMIT WORK</code> 会自动开启一个链事务，第二条 <code>INSERT INTO t SELECT 2</code> 语句是在同一个事务内的，因此回滚后 2 这条记录并没有被插入表 t 中。</p>
<p>参数 <code>completion_type</code> 为 2 时，<code>COMMIT WORK</code> 等同于 <code>COMMIT AND RELEASE</code>。在事务提交后会自动断开与服务器的连接，如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SET</span> @<span class="variable">@completion_type</span><span class="operator">=</span><span class="number">2</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">BEGIN</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> t <span class="keyword">SELECT</span> <span class="number">3</span>;</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line">Records: <span class="number">1</span> Duplicates: <span class="number">0</span> Warnings: <span class="number">0</span></span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">COMMIT</span> WORK;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.01</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> @<span class="variable">@version</span>\G;</span><br><span class="line">ERROR <span class="number">2006</span> (HY000): MySQL server has gone away</span><br><span class="line"><span class="keyword">No</span> connection. Trying <span class="keyword">to</span> reconnect...</span><br><span class="line">Connection id: <span class="number">54</span></span><br><span class="line"><span class="keyword">Current</span> database: test</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">@<span class="variable">@version</span>: <span class="number">5.1</span><span class="number">.45</span><span class="operator">-</span>log</span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<p>在这个例子中，设置了 <code>completion_type=2</code> 后，执行 <code>COMMIT WORK</code> 不仅提交了事务，而且释放（关闭）了当前连接。重新执行任何查询时，客户端都会发现与服务器的连接已断开，并尝试重新连接。</p>
<p><code>SAVEPOINT</code> 记录了一个保存点，可以通过 <code>ROLLBACK TO SAVEPOINT</code> 来回滚到某个保存点，但是如果回滚到一个不存在的保存点，会抛出异常：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">BEGIN</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">ROLLBACK</span> <span class="keyword">TO</span> <span class="keyword">SAVEPOINT</span> t1;</span><br><span class="line">ERROR <span class="number">1305</span> (<span class="number">42000</span>): <span class="keyword">SAVEPOINT</span> t1 does <span class="keyword">not</span> exist</span><br></pre></td></tr></table></figure>

<p>InnoDB 存储引擎中的事务都是原子的，这说明下述两种情况：构成事务的每条语句要么都提交（持久化），要么所有语句都回滚。这种保护还延伸到单个语句——一条语句要么完全成功，要么完全回滚（注意，这里说的是语句级回滚）。因此当一条语句失败并抛出异常时，并不会导致先前已经执行的语句自动回滚。所有已执行的操作都将保留，必须由用户自己决定是否对其进行提交或回滚。示例如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">CREATE TABLE</span> t (a <span class="type">INT</span>, <span class="keyword">PRIMARY KEY</span>(a)) ENGINE<span class="operator">=</span>INNODB;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">BEGIN</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> t <span class="keyword">SELECT</span> <span class="number">1</span>;</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line">Records: <span class="number">1</span> Duplicates: <span class="number">0</span> Warnings: <span class="number">0</span></span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> t <span class="keyword">SELECT</span> <span class="number">1</span>;</span><br><span class="line">ERROR <span class="number">1062</span> (<span class="number">23000</span>): Duplicate entry <span class="string">&#x27;1&#x27;</span> <span class="keyword">for</span> key <span class="string">&#x27;PRIMARY&#x27;</span></span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> t\G;</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">a: <span class="number">1</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<p>可以看到，当插入第二条记录 1 时，由于主键重复抛出了 1062 错误，但数据库并没有自动回滚事务；此时事务仍处于活动状态，必须由用户显式地执行 <code>COMMIT</code> 或 <code>ROLLBACK</code> 命令来结束事务。</p>
<p>另一个容易混淆的地方是 <code>ROLLBACK TO SAVEPOINT</code>——虽然它包含 “ROLLBACK”，但并不能真正结束整个事务。因此，即使执行了 <code>ROLLBACK TO SAVEPOINT</code>，之后仍需显式地运行 <code>COMMIT</code> 或 <code>ROLLBACK</code> 才能完成事务。具体示例如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">CREATE TABLE</span> t ( a <span class="type">INT</span>, <span class="keyword">PRIMARY KEY</span>(a) ) ENGINE<span class="operator">=</span>INNODB;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">BEGIN</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> t <span class="keyword">SELECT</span> <span class="number">1</span>;</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line">Records: <span class="number">1</span> Duplicates: <span class="number">0</span> Warnings: <span class="number">0</span></span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SAVEPOINT</span> t1;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> t <span class="keyword">SELECT</span> <span class="number">2</span>;</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line">Records: <span class="number">1</span> Duplicates: <span class="number">0</span> Warnings: <span class="number">0</span></span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SAVEPOINT</span> t2;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">RELEASE</span> <span class="keyword">SAVEPOINT</span> t1;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> t <span class="keyword">SELECT</span> <span class="number">2</span>;</span><br><span class="line">ERROR <span class="number">1062</span> (<span class="number">23000</span>): Duplicate entry <span class="string">&#x27;2&#x27;</span> <span class="keyword">for</span> key <span class="string">&#x27;PRIMARY&#x27;</span></span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">ROLLBACK</span> <span class="keyword">TO</span> <span class="keyword">SAVEPOINT</span> t2;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> t;</span><br><span class="line"><span class="operator">+</span><span class="comment">---+</span></span><br><span class="line"><span class="operator">|</span> a <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">1</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">ROLLBACK</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> t;</span><br><span class="line"><span class="keyword">Empty</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<p>可以看到，在上面的例子中，虽然在发生重复错误后用户通过 <code>ROLLBACK TO SAVEPOINT t2</code> 命令回滚到了保存点 t2，但是事务此时并没有结束。再运行命令 <code>ROLLBACK</code> 后，事务才会完整地回滚。这里再次提醒，<code>ROLLBACK TO SAVEPOINT</code> 命令并不真正地结束事务。</p>
<h2 id="隐式提交的-SQL-语句"><a href="#隐式提交的-SQL-语句" class="headerlink" title="隐式提交的 SQL 语句"></a>隐式提交的 SQL 语句</h2><p>以下这些 SQL 语句会产生一个隐式的提交操作，即执行完这些语句后，会有一个隐式的 COMMIT 操作。</p>
<ul>
<li><p>DDL 语句：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> DATABASE … UPGRADE DATA DIRECTORY NAME</span><br><span class="line"><span class="keyword">ALTER</span> EVENT</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">PROCEDURE</span></span><br><span class="line"><span class="keyword">ALTER TABLE</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">VIEW</span></span><br><span class="line"><span class="keyword">CREATE</span> DATABASE</span><br><span class="line"><span class="keyword">CREATE</span> EVENT</span><br><span class="line"><span class="keyword">CREATE</span> INDEX</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">PROCEDURE</span></span><br><span class="line"><span class="keyword">CREATE TABLE</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TRIGGER</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span></span><br><span class="line"><span class="keyword">DROP</span> DATABASE</span><br><span class="line"><span class="keyword">DROP</span> EVENT</span><br><span class="line"><span class="keyword">DROP</span> INDEX</span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">PROCEDURE</span></span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span></span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">TRIGGER</span></span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">VIEW</span></span><br><span class="line">RENAME <span class="keyword">TABLE</span></span><br><span class="line"><span class="keyword">TRUNCATE</span> <span class="keyword">TABLE</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>用来隐式地修改 MySQL 架构的操作：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">USER</span></span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">USER</span></span><br><span class="line"><span class="keyword">GRANT</span></span><br><span class="line">RENAME <span class="keyword">USER</span></span><br><span class="line"><span class="keyword">REVOKE</span></span><br><span class="line"><span class="keyword">SET</span> PASSWORD</span><br></pre></td></tr></table></figure>
</li>
<li><p>管理语句：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">ANALYZE <span class="keyword">TABLE</span></span><br><span class="line">CACHE INDEX</span><br><span class="line"><span class="keyword">CHECK</span> <span class="keyword">TABLE</span></span><br><span class="line">LOAD INDEX <span class="keyword">INTO</span> CACHE</span><br><span class="line">OPTIMIZE <span class="keyword">TABLE</span></span><br><span class="line">REPAIR <span class="keyword">TABLE</span></span><br></pre></td></tr></table></figure></li>
</ul>
<p>需要注意的是，<code>TRUNCATE TABLE</code> 语句是 DDL，因此虽然和对整张表执行 DELETE 的结果是一样的，但它是不能被回滚的。</p>
<h3 id="隐式提交"><a href="#隐式提交" class="headerlink" title="隐式提交"></a>隐式提交</h3><p>隐式提交（implicit commit）并不是某个存储引擎偷偷在后台提交，而是 MySQL 服务器在执行这些语句时，<strong>在语法分析&#x2F;执行阶段主动调用了事务提交</strong>。其原理可以概括为以下几点：</p>
<p><strong>元数据一致性要求</strong></p>
<p>DDL（Data Definition Language，定义性语言）操作例如 <code>CREATE TABLE</code>、<code>ALTER TABLE</code> 等，会修改数据库的元数据（数据字典）——表结构、索引信息、权限信息……这些修改必须在干净的事务边界上进行，否则如果与正在进行的事务混合，元数据和事务日志就可能出现不一致。因此，服务器在处理 DDL 之前，会先隐式地提交（COMMIT）当前事务，确保所有已做的数据修改都已持久化且可见；DDL 执行完毕后，又会隐式提交，以将新的元数据生效并释放所有表级锁。</p>
<p><strong>存储引擎锁与全局锁</strong></p>
<p>DDL 通常需要获取表级甚至元数据级的全局锁（例如 metadata lock），而 InnoDB 行事务的 MVCC、锁粒度等是在行和页级别管理的。为了避免长事务与元数据锁冲突，MySQL 设计为：</p>
<ul>
<li><strong>DDL 前自动提交</strong>，这样旧事务内的锁都释放掉，DDL 能顺利抢到元数据锁；</li>
<li><strong>DDL 后自动提交</strong>，这样新事务再去访问时就能看到最新结构。</li>
</ul>
<p><strong>隐式提交的实现机制</strong></p>
<p>在 MySQL 源码里，SQL 解析器（SQL layer）会为特定的语句类型（DDL、某些管理语句）打上 autocommit 标志或直接在执行函数里调用 thd-&gt;commit()：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 伪代码，执行 DDL 时 </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">statement_is_ddl</span>(stmt)) &#123; </span><br><span class="line"></span><br><span class="line"> thd-&gt;<span class="built_in">commit</span>();      <span class="comment">// 隐式提交前一个事务 </span></span><br><span class="line"> <span class="built_in">execute_ddl</span>(stmt);    <span class="comment">// 改变元数据 </span></span><br><span class="line"> thd-&gt;<span class="built_in">commit</span>();      <span class="comment">// 隐式提交以生效并释放锁 </span></span><br><span class="line"></span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>

<p>对于 <code>TRUNCATE TABLE</code> 这类内部实现成 DROP + CREATE 的操作，同样也在前后各一次 <code>commit()</code>，所以即使在显式事务中执行，也马上结束当前事务。</p>
<p><strong>与普通 DML 的区别</strong></p>
<p>普通的 DML 如 INSERT&#x2F;UPDATE&#x2F;DELETE，在显式事务中只会被存入 redo&#x2F;undo 日志缓冲，真正刷盘并提交则取决于 <code>innodb_flush_log_at_trx_commit</code>、COMMIT 语句或自动提交设置。它们不会在执行时强制触发存储引擎层面的全局提交。</p>
<h2 id="对于事务操作的统计"><a href="#对于事务操作的统计" class="headerlink" title="对于事务操作的统计"></a>对于事务操作的统计</h2><p>由于 InnoDB 存储引擎是支持事务的，因此 InnoDB 存储引擎的应用需要在考虑每秒请求数（Questions Per Second, QPS）的同时，也应该关注每秒事务处理的能力（Transactions Per Second, TPS）。计算 TPS 的方法是：(com_commit + com_rollback) &#x2F; 时间。</p>
<p>但要使用这种方法，前提是<strong>所有的事务都必须是显式提交</strong>的；如果存在隐式提交或隐式回滚（默认 <code>autocommit=1</code>），这些操作不会计入 <code>com_commit</code> 和 <code>com_rollback</code> 这两个状态变量中。例如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SHOW</span> <span class="keyword">GLOBAL</span> STATUS <span class="keyword">LIKE</span> <span class="string">&#x27;com_commit&#x27;</span>\G</span><br><span class="line"></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">Variable_name: Com_commit</span><br><span class="line"><span class="keyword">Value</span>: <span class="number">5</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> t <span class="keyword">SELECT</span> <span class="number">3</span>;</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line">Records: <span class="number">1</span> Duplicates: <span class="number">0</span> Warnings: <span class="number">0</span></span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> t\G</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">a: <span class="number">1</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">2.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">a: <span class="number">2</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">3.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">a: <span class="number">3</span></span><br><span class="line"><span class="number">3</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SHOW</span> <span class="keyword">GLOBAL</span> STATUS <span class="keyword">LIKE</span> <span class="string">&#x27;com_commit&#x27;</span>\G</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">Variable_name: Com_commit</span><br><span class="line"><span class="keyword">Value</span>: <span class="number">5</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<p>可以看到，尽管插入了第三条记录，但 <code>com_commit</code> 的值仍然保持 5，没有增加。这是因为默认情况下每条 INSERT 都在隐式事务中执行（<code>autocommit=1</code>），而隐式提交不计入 <code>com_commit</code>。</p>
<h2 id="事务原理"><a href="#事务原理" class="headerlink" title="事务原理"></a>事务原理</h2><p>事务隔离性由锁来实现。原子性、持久性通过数据库的 redo log 和 undo log 来完成，一致性则由其他三种特性的共同实现来保证。redo log 称为重做日志，用来保证事务的原子性和持久性。undo log 用来保证事务的一致性。</p>
<p>有人或许会认为 undo 是 redo 的逆过程，其实不然。redo 和 undo 的作用都可以视为是一种恢复操作；redo 恢复提交事务修改的页操作，而 undo 回滚行记录到某个特定版本。因此两者记录的内容不同，redo 通常是物理日志，记录的是页的物理修改操作。undo 是逻辑日志，根据行记录进行记录。</p>
<h3 id="redo-log-持久性"><a href="#redo-log-持久性" class="headerlink" title="redo log &#x3D;&gt; 持久性"></a>redo log &#x3D;&gt; 持久性</h3><p>重做日志用来实现事务的持久性，即事务 ACID 中的D。其由两部分组成：一是内存中的重做日志缓冲（redo log buffer），其是易失的；二是重做日志文件（redo log file），其是持久的。InnoDB 是事务的存储引擎，其通过 Force Log at Commit 机制实现事务的持久性，即当事务提交（COMMIT）时，必须先将该事务的所有日志写入到重做日志文件进行持久化，待事务的 COMMIT 操作完成才算完成。这里的日志是指重做日志，在 InnoDB 存储引擎中，由 redo log 和 undo log 两部分组成。redo log 用来保证事务的持久性，undo log 用来帮助事务回滚及MVCC的功能。redo log 基本上都是顺序写的，在数据库运行时不需要对 redo log 文件进行读取操作；undo log 是需要进行随机读写的。</p>
<p>为了确保每次日志都写入重做日志文件，在每次将重做日志缓冲写入重做日志文件后，InnoDB 存储引擎都需要调用一次 fsync 操作。由于重做日志文件打开并没有使用 <code>O_DIRECT</code> 选项，因此重做日志先写入文件系统缓存；为了确保重做日志写入磁盘，必须进行一次 fsync 操作。由于 fsync 的效率取决于磁盘的性能，因此磁盘的性能决定了事务提交的性能，也就是数据库的性能。</p>
<p>InnoDB 存储引擎允许用户手工设置非持久化的情况发生，以此提高数据库的性能。即当事务提交时，日志不写入重做日志文件，而是等待一个时间周期后再执行 fsync 操作。由于并非强制在事务提交时进行一次 fsync 操作，这可以显著提高数据库的性能，但是当数据库发生宕机时，由于部分日志未刷新到磁盘，因此会丢失最后一段时间的事务。</p>
<p>参数 <code>innodb_flush_log_at_trx_commit</code> 用来控制重做日志刷新到磁盘的策略。该参数的默认值为 1，表示事务提交时必须调用一次 fsync 操作。还可以设置该参数的值为 0 和 2。0 表示事务提交时不进行写入重做日志操作，这个操作仅在 master thread 中完成，而 master thread 中每 1 秒会进行一次重做日志文件的 fsync 操作；2 表示事务提交时将重做日志写入文件系统缓存，不进行 fsync 操作。在这个设置下，当 MySQL 数据库发生宕机而操作系统不发生宕机时，并不会导致事务的丢失；而当操作系统宕机时，重启数据库后会丢失未从文件系统缓存刷新到重做日志文件的那部分事务。</p>
<p><img src="/../../images/MySQL/mysql_redo_fsync.drawio.png" alt="img"></p>
<p>在 MySQL 数据库中还有一种二进制日志（binlog），其用来进行 POINT-IN-TIME（PIT）的恢复及主从复制（Replication）环境的建立。从表面上看其和重做日志非常相似，都是记录了对于数据库操作的日志。然而，从本质上来看，两者有着非常大的不同。首先，重做日志是在 InnoDB 存储引擎层产生，而二进制日志是在 MySQL 数据库的上层产生的，并且二进制日志不仅仅针对 InnoDB 存储引擎，MySQL 数据库中的任何存储引擎对于数据库的更改都会产生二进制日志。</p>
<p>其次，两种日志记录的内容形式不同。MySQL 数据库上层的二进制日志是一种逻辑日志，其记录的是对应的 SQL 语句。而 InnoDB 存储引擎层面的重做日志是物理格式日志，其记录的是对于每个页的修改。</p>
<p>此外，两种日志记录写入磁盘的时间点不同，如下图所示。二进制日志只在事务提交完成后进行一次写入。而 InnoDB 存储引擎的重做日志在事务进行中不断地被写入，这表现为日志并不是随事务提交的顺序进行写入的。</p>
<p><img src="/../../images/MySQL/mysql_redo_bin.drawio.png" alt="img"></p>
<p>从上图中可以看到，二进制日志仅在事务提交时记录，并且对于每一个事务，仅包含对应事务的一个日志。而对于 InnoDB 存储引擎的重做日志，由于其记录的是物理操作日志，因此每个事务对应多个日志条目，并且事务的重做日志写入是并发的，并非在事务提交时写入，故其在文件中记录的顺序并非事务开始的顺序。*T1、*T2、*T3 表示的是事务提交时的日志。</p>
<h4 id="log-block"><a href="#log-block" class="headerlink" title="log block"></a>log block</h4><p>在 InnoDB 存储引擎中，重做日志都是以 512 字节进行存储的。这意味着重做日志缓冲、重做日志文件都是以块的方式进行保存的，称之为重做日志块，每块的大小为 512 字节。</p>
<p>若一个页中产生的重做日志数量大于 512 字节，那么需要分割为多个重做日志块进行存储。此外，由于重做日志块的大小和磁盘扇区大小一样，都是 512 字节，因此重做日志的写入可以保证原子性，不需要 doublewrite 技术。</p>
<p>重做日志除了日志本身之外，还由日志块头及日志块尾两部分组成。重做日志块头一共占用 12 字节，重做日志块尾占用 8 字节。故每个重做日志块实际可以存储的大小为 492 字节（512 – 12 – 8）。下图显示了重做日志块缓冲的结构。</p>
<p><img src="/../../images/MySQL/mysql_redo_block.drawio.png" alt="img"></p>
<p>log block header 由 4 部分组成，如下表所示：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>占用字节</th>
</tr>
</thead>
<tbody><tr>
<td>LOG_BLOCK_HDR_NO</td>
<td>4</td>
</tr>
<tr>
<td>LOG_BLOCK_HDR_DATA_LEN</td>
<td>2</td>
</tr>
<tr>
<td>LOG_BLOCK_FIRST_REC_GROUP</td>
<td>2</td>
</tr>
<tr>
<td>LOG_BLOCK_CHECKPOINT_NO</td>
<td>4</td>
</tr>
</tbody></table>
<p>log buffer 是由 log block 组成，在内部 log buffer 就好似一个数组，因此 <code>LOG_BLOCK_HDR_NO</code> 用来标记这个数组中的位置。其是递增并且循环使用的，占用 4 个字节，但是由于第一位用来判断是否是 flush bit，所以最大值为 2 G。</p>
<p><code>LOG_BLOCK_HDR_DATA_LEN</code>（2 字节）表示 log block 所占用的大小。当 log block 被写满时，该值为 0x200，表示使用全部 log block 空间，即占用 512 字节。</p>
<p><code>LOG_BLOCK_FIRST_REC_GROUP</code>（2 字节）表示 log block 中第一个日志所在的偏移量。如果该值的大小和 <code>LOG_BLOCK_HDR_DATA_LEN</code> 相同，则表示当前 log block 不包含新的日志。</p>
<p>例如：事务 T1 的重做日志 占用 762 字节，事务 T2 的重做日志占用 100 字节。由于每个 log block 实际只能保存 492 字节（512 − 12 − 8），其在 log buffer 中的情况如下图所示。<br><img src="/../../images/MySQL/mysql_redo_block_example.drawio.png" alt="img"></p>
<p>可以观察到，由于事务 T1 的重做日志占用 792 字节，因此需要占用两个 log block。</p>
<p>在第一个 log block 中，<code>LOG_BLOCK_FIRST_REC_GROUP</code> 为 12，即此 block 中第一个日志的起始位置。</p>
<p>在第二个 log block 中，由于它包含了之前事务 T1 的剩余日志，事务 T2 的日志才是该 block 中第一个日志，因此该 log block 的 <code>LOG_BLOCK_FIRST_REC_GROUP</code> 为 282（270 + 12）。</p>
<p><code>LOG_BLOCK_CHECKPOINT_NO</code>（4 字节）表示该 log block 最后被写入时的检查点（checkpoint）编号。</p>
<p>log block tailer 只由 1 个字段组成（如下表所示），其值与 <code>LOG_BLOCK_HDR_NO</code> 相同，并在函数 <code>log_block_init</code> 中被初始化。</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>大小（字节）</th>
</tr>
</thead>
<tbody><tr>
<td>LOG_BLOCK_TRL_NO</td>
<td>4</td>
</tr>
</tbody></table>
<h4 id="log-group"><a href="#log-group" class="headerlink" title="log group"></a>log group</h4><p>log group 为重做日志组，其中有多个重做日志文件。虽然源码里支持镜像多组 log group 的功能，但官方屏蔽了镜像功能，实际上只有一组文件集合。</p>
<p>log group 是一个逻辑上的概念，并没有一个实际存储的物理文件来表示 log group 信息。log group 由多个重做日志文件组成，每个 log group 中的日志文件大小是相同的，且在 InnoDB 1.2 版本之前，重做日志文件的总大小要小于 4 GB（不能等于 4 GB）。从 InnoDB 1.2 版本开始，重做日志文件总大小的限制提高为了 512 GB。</p>
<p>重做日志文件中存储的就是之前在 log buffer 中保存的 log block，因此其也是根据块的方式进行物理存储管理，每个块的大小与 log block 一样，同样为 512 字节。在 InnoDB 存储引擎运行过程中，log buffer 会根据一定的规则将内存中的 log block 刷新到磁盘。这个规则具体是：</p>
<ul>
<li>事务提交时</li>
<li>当 log buffer 中有一半的内存空间已经被使用时</li>
<li>log checkpoint 时</li>
</ul>
<p>对于 log block 的写入追加（append）在 redo log file 的最后部分，当一个 redo log file 被写满时，会接着写入下一个 redo log file，其使用方式为 round-robin。</p>
<p>虽然 log block 总是在 redo log file 的最后部分进行写入，有的读者可能认为对 redo log file 的写入都是顺序的。其实不然，因为 redo log file 除了保存 log buffer 刷新到磁盘的 log block，还保存了一些其他的信息，这些信息一共占用 2 KB 大小，即每个 redo log file 的前 2 KB 部分不保存 log block 的信息。对于 log group 中的第一个 redo log file，其前 2 KB 的部分保存 4 个 512 字节大小的块，其中存放的内容如下表所示。</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>大小（字节）</th>
</tr>
</thead>
<tbody><tr>
<td>log file header</td>
<td>512</td>
</tr>
<tr>
<td>checkpoint1</td>
<td>512</td>
</tr>
<tr>
<td>空</td>
<td>512</td>
</tr>
<tr>
<td>checkpoint2</td>
<td>512</td>
</tr>
</tbody></table>
<p>需要特别注意的是，上述信息仅在每个 log group 的第一个 redo log file 中进行存储。</p>
<p>log group 中的其余 redo log file 仅保留这些空间，但不保存上述信息。正因为保存了这些信息，就意味着对 redo log file 的写入并不是完全顺序的。因为其除了 log block 的写入操作，还需要更新前 2 KB 部分的信息，这些信息对于 InnoDB 存储引擎的恢复操作来说非常关键和重要。</p>
<p>故 log group 与 redo log file 之间的关系如下图所示。</p>
<p><img src="/../../images/MySQL/mysql_redo_group.drawio.png" alt="img"></p>
<p>在 log file header 后面的部分为 InnoDB 存储引擎保存的 checkpoint（检查点）值，其设计是交替写入，这样的设计避免了因介质失败导致无法找到可用的 checkpoint 的情况。</p>
<p>具象一点就是，第一次写 checkpoint 时，写入 Slot A；下一次写 checkpoint 时，写入 Slot B；再下一次，又回到写 Slot A……如此循环。</p>
<p>为什么要这样做？</p>
<ul>
<li>避免写一半后丢失：如果只有一个槽，刚写入还没刷完，突然停电或磁盘故障，这个槽可能只写了一半，里面的值就坏了。</li>
<li>保证总有一个有效副本：交替写入意味着每次只有一个槽被覆盖，另一个槽保存的是上一次写入的、完整且可靠的检查点值。即便一个槽在写入时被破坏，另外一个槽里还有上一次的有效值。</li>
</ul>
<p>恢复时的处理<br>在数据库启动恢复阶段，InnoDB 会读取这两个槽的内容，选择最新且完整的那个作为真正的 checkpoint，从那里开始重做日志的回放，保证不会因为写损坏而找不到有效的检查点。</p>
<h4 id="重做日志格式"><a href="#重做日志格式" class="headerlink" title="重做日志格式"></a>重做日志格式</h4><p>不同的数据库操作会有对应的重做日志格式。此外，由于 InnoDB 存储引擎的存储管理是基于页的，故其重做日志格式也是基于页的。虽然有着不同的重做日志格式，但它们具有通用的头部格式，如下图所示：</p>
<p><img src="/../../images/MySQL/mysql_redo_layout.drawio.png" alt="img"></p>
<p>通用头部格式由以下 3 部分组成：</p>
<ol>
<li><code>redo_log_type</code>：重做日志的类型。</li>
<li><code>space</code>：表空间的 ID。</li>
<li><code>page_no</code>：页的偏移量。</li>
</ol>
<p>之后的 redo log body 的部分，根据重做日志类型的不同，会有不同的存储内容。例如，对于页上记录的插入和删除操作，分别对应下图所示的格式：</p>
<p><img src="/../../images/MySQL/mysql_redo_body.drawio.png" alt="img"></p>
<h4 id="LSN"><a href="#LSN" class="headerlink" title="LSN"></a>LSN</h4><p>LSN 是 Log Sequence Number 的缩写，代表日志序列号。在 InnoDB 存储引擎中，LSN 占用 8 字节，并且单调递增。LSN 的含义包括：</p>
<ul>
<li>重做日志已写入的总字节数；</li>
<li>checkpoint 所在位置；</li>
<li>页的版本。</li>
</ul>
<p>LSN 记录了事务写入重做日志的累计字节数。例如：</p>
<ul>
<li>如果当前 LSN 为 1000，事务 T1 又写入了 100 字节的重做日志，则 LSN 更新为 1100；</li>
<li>接着事务 T2 写入 200 字节，则 LSN 更新为 1300。</li>
</ul>
<p>除了记录在重做日志文件中，每个数据页的页头也保存了一个 <code>FIL_PAGE_LSN</code> 值，它表示该页最后一次刷新的 LSN。恢复时，InnoDB 会比较重做日志中记录的 LSN 与页头中的 <code>FIL_PAGE_LSN</code>：</p>
<ul>
<li>如果页头 LSN 小于重做日志中的 LSN，就需要应用重做日志；</li>
<li>否则说明该页已经被刷新到最新，无需重做。</li>
</ul>
<p>查看当前 LSN：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SHOW</span> ENGINE INNODB STATUS\G</span><br><span class="line">…</span><br><span class="line"><span class="comment">--- LOG ---</span></span><br><span class="line">Log sequence number <span class="number">113047174608</span></span><br><span class="line">Log flushed up <span class="keyword">to</span> <span class="number">113047174608</span></span><br><span class="line"><span class="keyword">Last</span> checkpoint <span class="keyword">at</span> <span class="number">113047174608</span></span><br><span class="line"><span class="number">0</span> pending log writes, <span class="number">0</span> pending chkp writes</span><br><span class="line"><span class="number">142</span> log i<span class="operator">/</span>o<span class="string">&#x27;s done, 0.00 log i/o&#x27;</span>s<span class="operator">/</span><span class="keyword">second</span></span><br><span class="line">…</span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<p>以上结果的参数如下：</p>
<p>Log sequence number：当前的 LSN</p>
<p>Log flushed up to：已刷新到重做日志文件的 LSN</p>
<p>Last checkpoint at：已同步到磁盘的 LSN</p>
<p>虽然在上面的例子中，Log sequence number 和 Log flushed up to 的值是相同的，但是在实际生产环境中，该值有可能是不同的。因为在一个事务中从日志缓冲刷新到重做日志文件并不只是在事务提交时发生，每秒都会有从日志缓冲刷新到重做日志文件的动作。下面是在生产环境下重做日志的信息的示例。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SHOW</span> ENGINE INNODB STATUS\G</span><br><span class="line">…</span><br><span class="line"><span class="comment">--- LOG ---</span></span><br><span class="line">Log sequence number <span class="number">203318213447</span></span><br><span class="line">Log flushed up <span class="keyword">to</span> <span class="number">203318213326</span></span><br><span class="line"><span class="keyword">Last</span> checkpoint <span class="keyword">at</span> <span class="number">203252831194</span></span><br><span class="line"><span class="number">1</span> pending log writes, <span class="number">0</span> pending chkp writes</span><br><span class="line"><span class="number">103447</span> log i<span class="operator">/</span>o<span class="string">&#x27;s done, 7.00 log i/o&#x27;</span>s<span class="operator">/</span><span class="keyword">second</span></span><br><span class="line">…</span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<p>所以，redo log 的刷盘时机有以下 4 种：</p>
<ol>
<li>提交时：保证事务持久性；</li>
<li>超时周期：（默认 1s）定时写入，防止长时间积压；</li>
<li>缓冲区半满：防止 buffer 溢出；</li>
<li>检查点：保证恢复一致性。</li>
</ol>
<h4 id="恢复"><a href="#恢复" class="headerlink" title="恢复"></a>恢复</h4><p>InnoDB 存储引擎在启动时，不管上次数据库运行时是否正常关闭，都会尝试进行恢复操作。因为重做日志记录的是物理日志，因此恢复的速度比逻辑日志（如二进制日志）要快很多。与此同时，InnoDB 存储引擎自身也对恢复进行了优化，例如顺序读取和并行应用重做日志，这样可以进一步提高数据库恢复的速度。</p>
<p>由于 checkpoint 表示已刷新到磁盘页上的 LSN，因此在恢复过程中仅需应用从 checkpoint 开始的日志部分。</p>
<p>假设数据库崩溃时，checkpoint 的 LSN 为 10000；重做日志当前已写到 LSN 13000；那么恢复时只需重做 LSN 10000 到 13000 范围内的日志。</p>
<p><img src="/../../images/MySQL/mysql_redo_recovery.drawio.png" alt="img"></p>
<p>InnoDB 存储引擎的重做日志是物理日志，因此其恢复速度较之二进制日志恢复快得多。例如对于 INSERT 操作，其记录的是每个页上的变化。对于下面的表：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> t (</span><br><span class="line"> a <span class="type">INT</span>,</span><br><span class="line"> b <span class="type">INT</span>,</span><br><span class="line"> <span class="keyword">PRIMARY KEY</span>(a),</span><br><span class="line"> KEY(b)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>若执行 SQL 语句：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT INTO</span> t <span class="keyword">SELECT</span> <span class="number">1</span>, <span class="number">2</span>;</span><br></pre></td></tr></table></figure>

<p>由于需要对聚集索引页和辅助索引页进行操作，其记录的重做日志大致为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">page(2,3), offset 32, value 1,2  # 聚集索引</span><br><span class="line"></span><br><span class="line">page(2,4), offset 64, value 2   # 辅助索引</span><br></pre></td></tr></table></figure>

<p>上图中的 <code>page(x,y)</code> 代表表空间 x 中的页 y。</p>
<p>可以看到记录的是页的物理修改操作，若插入涉及 B+ 树的 split，可能会有更多的页需要记录日志。此外，由于重做日志是物理日志，因此其是幂等的。幂等的概念如下：</p>
<p>$$f(f(x)) &#x3D; f(x)$$</p>
<p>有的人错误地认为只要将二进制日志的格式设置为 ROW，那么二进制日志也是幂等的。这显然是错误的。举个简单的例子，INSERT 操作在二进制日志中就不是幂等的：重复执行可能会插入多条重复的记录。而上述 INSERT 操作的重做日志是幂等的。</p>
<h3 id="undo-log-原子性"><a href="#undo-log-原子性" class="headerlink" title="undo log &#x3D;&gt; 原子性"></a>undo log &#x3D;&gt; 原子性</h3><p>重做日志记录了事务的行为，可以很好地通过其对页进行“重做”操作。但是事务有时还需要进行回滚操作，这时就需要 undo。因此在对数据库进行修改时，InnoDB 存储引擎不但会产生 redo，还会产生一定量的 undo。这样如果用户执行的事务或语句由于某种原因失败了，又或者用户用一条 ROLLBACK 语句请求回滚，就可以利用这些 undo 信息将数据回滚到修改之前的样子。</p>
<p>redo 存放在重做日志文件中，与 redo 不同，undo 存放在数据库内部的一个特殊段中，这个段称为 undo 段（undo segment）。undo 段位于共享表空间内。也就是说，一个共享表空间 <code>ibdata1</code> 里可以包含多个 undo segment，每个 segment 又由一系列 undo log page 组成。</p>
<p>很多人以为 undo 是把数据页整个地回滚到某个时刻的样子，就像把一整张纸翻到以前的版本。实际上并不是这样！</p>
<p>undo 记录的是对每条记录所做修改的逆操作：比如把一个 INSERT 反做成 DELETE，把一个 UPDATE 反做成把旧值写回去。它并不保存整页的“图片”或快照，而是保存每个操作的前后值，对操作本身做逆向处理。</p>
<p>为什么不能物理地整页回滚？</p>
<p>在真正的数据库中，常常有 大量并发事务 同时在操作：</p>
<ul>
<li><p>事务 A 在这一页上修改了第 3 行和第 7 行；</p>
</li>
<li><p>同时事务 B 也在这一页上修改了第 10 行和第 15 行；如果把整页恢复到事务 A 开始时的版本，那么事务 B 对第 10、15 行的修改就一并被移除了，破坏了 B 的工作。</p>
</li>
</ul>
<p>因此，InnoDB 在回滚时，不会把页面还原成某个历史时刻的完全镜像，而是针对事务 A 做的那些修改，逐条执行逆操作，只撤销 A 做的改动，保留其他事务（如 B）在同一页上的修改。</p>
<p>此外，假设用户执行了一个 INSERT 10W 条记录的事务，这个事务会导致分配一个新的段，即表空间会增大。在用户执行 <code>ROLLBACK</code> 时，会将插入的事务进行回滚，但是表空间的大小并不会因此而收缩。在内部把这些插入的行逻辑删除。回滚不会缩小表空间文件，它只是把数据逻辑地撤销，保留了原先为这些数据分配的物理页，用于后续的存储需求。这样避免了频繁的文件尺寸变动，也利于性能和空间重用。</p>
<p>因此，当 InnoDB 存储引擎回滚时，它实际上做的是与之前相反的工作。对于每个 INSERT，InnoDB 存储引擎会完成一个 DELETE；对于每个 DELETE，InnoDB 存储引擎会执行一个 INSERT；对于每个 UPDATE，InnoDB 存储引擎会执行一个相反的 UPDATE，将修改前的行放回去。</p>
<p>除了回滚操作，undo 的另一个作用是 MVCC，即在 InnoDB 存储引擎中 MVCC 的实现是通过 undo 来完成。当用户读取一行记录时，若该记录已经被其他事务占用，当前事务可以通过 undo 读取之前的行版本信息，以此实现非锁定读取。</p>
<p>最为重要的一点是，undo log 会产生 redo log，也就是 undo log 的产生会伴随着 redo log 的产生，这是因为 undo log 也需要持久性的保护。</p>
<h4 id="undo-日志存储管理"><a href="#undo-日志存储管理" class="headerlink" title="undo 日志存储管理"></a>undo 日志存储管理</h4><p>InnoDB 存储引擎对 undo 的管理同样采用段的方式。但是这个段和之前介绍的段有所不同。首先 InnoDB 存储引擎有 rollback segment，每个 rollback segment 记录了 1024 个 undo log segment，而在每个 undo log segment 段中进行 undo 页的申请。共享表空间偏移量为 5 的页 <code>（0, 5）</code> 记录了所有 rollback segment header 所在的页，这个页的类型为 <code>FIL_PAGE_TYPE_SYS</code>。</p>
<p>在 InnoDB1.1 版本之前（不包括 1.1 版本），只有一个 rollback segment，因此支持同时在线的事务限制为 1024。虽然对绝大多数的应用来说都已经够用，但不管怎么说这是一个瓶颈。从 1.1 版本开始 InnoDB 支持最大 128 个 rollback segment，故其支持同时在线的事务限制提高到了 128 × 1024。</p>
<p>虽然 InnoDB1.1 版本支持了 128 个 rollback segment，但是这些 rollback segment 都存储于共享表空间中。从 InnoDB1.2 版本开始，可通过参数对 rollback segment 做进一步的设置。这些参数包括： </p>
<ol>
<li><code>innodb_undo_directory</code>；</li>
<li><code>innodb_undo_logs</code>；</li>
<li><code>innodb_undo_tablespaces</code>。</li>
</ol>
<p>参数 <code>innodb_undo_directory</code> 用于设置 rollback segment 文件所在的路径。这意味着 rollback segment 可以存放在共享表空间以外的位置，即可以设置为独立表空间。该参数的默认值为 <code>“.”</code>，表示当前 InnoDB 存储引擎的目录。</p>
<p>参数 <code>innodb_undo_logs</code> 用来设置 rollback segment 的个数，默认值为 128。在 InnoDB1.2 版本中，该参数用来替换之前版本的参数 <code>innodb_rollback_segments</code>。</p>
<p>参数 <code>innodb_undo_tablespaces</code> 用来设置构成 rollback segment 文件的数量，这样 rollback segment 可以较为平均地分布在多个文件中。设置该参数后，会在路径 <code>innodb_undo_directory</code> 看到以 <code>undo</code> 为前缀的文件，该文件就代表一个 rollback segment。下图显示了由 3 个文件组成的 rollback segment。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SHOW</span> VARIABLES <span class="keyword">LIKE</span> <span class="string">&#x27;innodb_undo%&#x27;</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+----------------+</span></span><br><span class="line"><span class="operator">|</span> Variable_name      <span class="operator">|</span> <span class="keyword">Value</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+----------------+</span></span><br><span class="line"><span class="operator">|</span> innodb_undo_directory  <span class="operator">|</span> .       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> innodb_undo_logs    <span class="operator">|</span> <span class="number">128</span>      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> innodb_undo_tablespaces <span class="operator">|</span> <span class="number">3</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+----------------+</span></span><br><span class="line"><span class="number">3</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SHOW</span> VARIABLES <span class="keyword">LIKE</span> <span class="string">&#x27;datadir&#x27;</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">---------------+---------------------------------+</span></span><br><span class="line"><span class="operator">|</span> Variable_name <span class="operator">|</span> <span class="keyword">Value</span>              <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------+---------------------------------+</span></span><br><span class="line"><span class="operator">|</span> datadir    <span class="operator">|</span> <span class="operator">/</span>Users<span class="operator">/</span>david<span class="operator">/</span>mysql_data<span class="operator">/</span>data<span class="operator">/</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------+---------------------------------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">system</span> ls <span class="operator">-</span>lh <span class="operator">/</span>Users<span class="operator">/</span>david<span class="operator">/</span>mysql_data<span class="operator">/</span>data<span class="operator">/</span>undo<span class="operator">*</span></span><br><span class="line"><span class="operator">-</span>rw<span class="operator">-</span>rw<span class="comment">---- 1 david staff 10M 11 22 16:55 /Users/david/mysql_data/data/undo001</span></span><br><span class="line"><span class="operator">-</span>rw<span class="operator">-</span>rw<span class="comment">---- 1 david staff 10M 11 22 16:51 /Users/david/mysql_data/data/undo002</span></span><br><span class="line"><span class="operator">-</span>rw<span class="operator">-</span>rw<span class="comment">---- 1 david staff 10M 11 22 16:51 /Users/david/mysql_data/data/undo003</span></span><br></pre></td></tr></table></figure>

<p>需要特别注意的是，事务在 undo log segment 分配页并写入 undo log 的这个过程同样需要写入重做日志。当事务提交时，InnoDB 存储引擎会做以下两件事情：</p>
<ul>
<li>将 undo log 放入列表中，以供之后的 purge 操作； </li>
<li>判断 undo log 所在的页是否可以重用，若可以则分配给下个事务使用。</li>
</ul>
<p>事务提交后并不能马上删除 undo log 及 undo log 所在的页。这是因为可能还有其他事务需要通过 undo log 来得到行记录之前的版本。故事务提交时将 undo log 放入一个链表中，是否可以最终删除 undo log 及其所在页由 purge 线程来判断。</p>
<p>此外，若为每一个事务分配一个单独的 undo 页会非常浪费存储空间，特别是对于 OLTP 的应用类型。因为在事务提交时，可能并不能马上释放页。假设某应用的删除和更新操作的 TPS（transactions per second）为 1000，为每个事务分配一个 undo 页，那么一分钟就需要 1000*60 页，大约需要的存储空间为 1 GB。若每秒的 purge 页的数量为 20，这样的设计对磁盘空间有着相当高的要求。</p>
<p>因此，在 InnoDB 存储引擎的设计中对 undo 页可以进行重用。具体来说，当事务提交时，首先将 undo log 放入链表中，然后判断该 undo 页的使用空间是否小于 3&#x2F;4，若是则表示该 undo 页可以被重用，之后新的 undo log 记录就在该页的后面。由于存放 undo log 的列表是以记录组织的，而 undo 页可能存放着不同事务的 undo log，因此 purge 操作需要涉及磁盘的离散读取，是一个相对较慢的过程。</p>
<p>具象一点就是，InnoDB 里维护了一条 undo log 链表，链表里的每个节点对应一条 undo 记录（即某次对某行的前镜像）。这些节点并不是按事务或者按页顺序排列，而是按操作顺序串成一串——也就是一条操作一条记录地组织。因此，一个物理的 undo page（4KB 或 16KB）上，可能混杂了多个事务在不同时间写入的 undo 记录。</p>
<p>当后台 purge 线程要清理某个事务的 undo 记录（即判断哪些 undo 可以安全丢弃），它会按链表顺序走：</p>
<ol>
<li>找到这条事务的第一个 undo 记录在链表里的位置。</li>
<li>沿着链表往下走，一条一条检查：这条记录是不是该事务的？如果是，就删掉；如果不是，就跳过。</li>
<li>对应的，每读一条 undo 记录，就要去读它所在的那页（undo page）——而这些记录分散在不同的页面上。</li>
</ol>
<h4 id="undo-log-格式"><a href="#undo-log-格式" class="headerlink" title="undo log 格式"></a>undo log 格式</h4><p>在 InnoDB 存储引擎中，undo log 分为：</p>
<ol>
<li>insert undo log；</li>
<li>update undo log。</li>
</ol>
<p>insert undo log 是指在 insert 操作中产生的 undo log。因为 insert 操作的记录，只对事务本身可见，对其他事务不可见（这是事务隔离性的要求），故该 undo log 可以在事务提交后直接删除。不需要进行 purge 操作。</p>
<p>下图显示了 insert undo log 的格式，其中 <code>*</code> 表示对存储的字段进行了压缩。insert undo log 开始的前两个字节 next 记录的是下一个 undo log 的位置，通过该 next 字节可以知道一个 undo log 所占的空间字节数。类似地，尾部的两个字节记录的是 undo log 的开始位置。<code>type_cmpl</code> 占用一个字节，记录的是 undo 的类型，也就是在回滚或 MVCC 回查时应该执行怎样的逆向操作。对于 insert undo log，该值总是为 11。<code>undo_no</code> 记录事务的 ID，table_id 记录 undo log 所对应的表对象。这两个值都是在压缩后保存的。接着的部分记录了所有主键的列和值。在进行 rollback 操作时，根据这些值可以定位到具体的记录，然后进行删除即可。</p>
<p><img src="/../../images/MySQL/mysql_undo_insert.drawio.png" alt="img"></p>
<p>update undo log 记录的是对 delete 和 update 操作产生的 undo log。该 undo log 可能需要提供 MVCC 机制，因此不能在事务提交时就进行删除。提交时放入 undo log 链表，等待 purge 线程进行最后的删除。update undo log 的结构如下图所示。</p>
<p><img src="/../../images/MySQL/mysql_undo_update.drawio.png" alt="img"></p>
<p>update undo log 相对于之前介绍的 insert undo log，记录的内容更多，所需占用的空间也更大。next、start、undo_no、table_id 与之前介绍的 insert undo log 部分相同。这里的 <code>type_cmpl</code>，由于 update undo log 本身还有分类，故其可能的值如下：</p>
<ul>
<li>12 对应 <code>TRX_UNDO_UPD_EXIST_REC</code>，更新 non-delete-mark 的记录，用于 UPDATE 操作的时候生成该类型 undo 日志；</li>
<li>13 对应 <code>TRX_UNDO_UPD_DEL_REC</code>，将 delete 的记录标记为 not delete，用于回滚 DELETE 操作的时候生成该类型 undo 日志； </li>
<li>14 对应 <code>TRX_UNDO_DEL_MARK_REC</code>，将记录标记为 delete，在 DELETE 操作的时候生成该类型 undo 日志。</li>
</ul>
<p>这里梳理一下：</p>
<ul>
<li>初次执行 DELETE时，InnoDB 会打上删除标记，这一步会生成 <code>type_cmpl = 14</code> (<code>TRX_UNDO_DEL_MARK_REC</code>) 的 undo 记录，用于在回滚时撤销“打标记”操作。</li>
<li>当真正执行回滚（或构建 MVCC 快照读需要“回到删除前”）时，InnoDB 必须将该行的删除标记“更新”回可见状态，这时才会写入 <code>type_cmpl = 13</code> (<code>TRX_UNDO_UPD_DEL_REC</code>) 的 undo 记录，用于撤销之前的删除标记 。</li>
</ul>
<p>为什么需要 <code>type_cmpl = 13</code> 这个状态？</p>
<p>当执行 <code>ROLLBACK</code> 或需要 MVCC 快照读回到删除前状态时，InnoDB 必须把 delete‐mark 更新回“未删除”，这一步在引擎层面是一次新的 UPDATE 操作。</p>
<p>接着的部分记录 <code>update_vector</code> 信息，<code>update_vector</code> 表示 update 操作导致发生改变的列。每个修改的列信息都要记录到 undo log 中。对于不同的 undo log 类型，可能还需要记录对索引列所做的修改。</p>
<p>如果回滚操作也失败了，怎么办？</p>
<p>在 MySQL（尤其是 InnoDB）中，ROLLBACK 失败主要出现在两种情况：一是客户端或连接异常导致回滚命令未能到达服务器，二是服务器在执行回滚期间遇到严重内部错误（例如表空间或日志损坏），无法完成回滚动作。针对这两类问题，通常需要先检查错误日志、确认失败原因；若是客户端侧问题，可重连重试或在应用代码中捕获并安全终止事务；若是服务器侧问题，则可能需要使用 <code>innodb_force_recovery</code> 模式跳过故障步骤以启动实例，甚至导出数据、重建表空间或从备份+二进制日志恢复。</p>
<h4 id="查看-undo-日志"><a href="#查看-undo-日志" class="headerlink" title="查看 undo 日志"></a>查看 undo 日志</h4><p>InnoSQL 对 <code>information_schema</code> 进行了扩展，添加了两张数据字典表，这样用户可以非常方便和快捷地查看 undo 的信息。</p>
<p>首先增加的数据字典表为 <code>INNODB_TRX_ROLLBACK_SEGMENT</code>。顾名思义，这个数据字典表用来查看 rollback segment，其表结构如下表所示。</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Type</th>
<th>Null</th>
<th>Key</th>
<th>Default</th>
<th>Extra</th>
</tr>
</thead>
<tbody><tr>
<td>Segment_id</td>
<td>bigint(21) unsigned</td>
<td>NO</td>
<td></td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>space</td>
<td>bigint(21) unsigned</td>
<td>NO</td>
<td></td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>page_no</td>
<td>bigint(21) unsigned</td>
<td>NO</td>
<td></td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>last_page_no</td>
<td>bigint(21) unsigned</td>
<td>YES</td>
<td></td>
<td>NULL</td>
<td></td>
</tr>
<tr>
<td>last_offset</td>
<td>bigint(21) unsigned</td>
<td>NO</td>
<td></td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>last_trx_no</td>
<td>varchar(18)</td>
<td>NO</td>
<td></td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>update_undo_list</td>
<td>bigint(21) unsigned</td>
<td>NO</td>
<td></td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>update_undo_cached</td>
<td>bigint(21) unsigned</td>
<td>NO</td>
<td></td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>insert_undo_list</td>
<td>bigint(21) unsigned</td>
<td>NO</td>
<td></td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>insert_undo_cached</td>
<td>bigint(21) unsigned</td>
<td>NO</td>
<td></td>
<td>0</td>
<td></td>
</tr>
</tbody></table>
<p>例如，可以通过如下命令来查看 rollback segment 所在的页：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> segment_id, space, page_no</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">FROM</span> INNODB_TRX_ROLLBACK_SEGMENT;</span><br><span class="line"><span class="operator">|</span> segment_id <span class="operator">|</span> space <span class="operator">|</span> page_no <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span><span class="comment">------------|-------|---------|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">0</span>          <span class="operator">|</span> <span class="number">0</span>     <span class="operator">|</span> <span class="number">6</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">1</span>          <span class="operator">|</span> <span class="number">0</span>     <span class="operator">|</span> <span class="number">45</span>      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2</span>          <span class="operator">|</span> <span class="number">0</span>     <span class="operator">|</span> <span class="number">46</span>      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> ...        <span class="operator">|</span> ...   <span class="operator">|</span> ...     <span class="operator">|</span></span><br><span class="line"><span class="number">128</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<p>另一张数据字典表为 <code>INNODB_TRX_UNDO</code>，用来记录事务对应的 undo log，方便开发人员详细了解每个事务产生的 undo 量。下面将演示如何使用 <code>INNODB_TRX_UNDO</code> 表。首先根据如下代码创建测试表。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> t (</span><br><span class="line"> a <span class="type">INT</span>,</span><br><span class="line"> b <span class="type">VARCHAR</span>(<span class="number">32</span>),</span><br><span class="line"> <span class="keyword">PRIMARY KEY</span>(a),</span><br><span class="line"> KEY(b)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB;</span><br></pre></td></tr></table></figure>

<p>接着插入一条记录，并尝试通过 INNODB_TRX_UNDO 观察该事务的 undo log 情况：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">BEGIN</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> t <span class="keyword">SELECT</span> <span class="number">1</span>,<span class="string">&#x27;1&#x27;</span>;</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line">Records: <span class="number">1</span> Duplicates: <span class="number">0</span> Warnings: <span class="number">0</span></span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> information_schema.INNODB_TRX_UNDO\G</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line"> trx_id: <span class="number">3001</span></span><br><span class="line"> rseg_id: <span class="number">2</span></span><br><span class="line"> undo_rec_no: <span class="number">0</span></span><br><span class="line"> undo_rec_type: TRX_UNDO_INSERT_REC</span><br><span class="line"> size: <span class="number">12</span></span><br><span class="line"> space: <span class="number">0</span></span><br><span class="line"> page_no: <span class="number">334</span></span><br><span class="line"> <span class="keyword">offset</span>: <span class="number">272</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<p>通过数据字典表可以看到，事务 ID 为 3001，rollback segment 的 ID 为 2，因为是该条事务的第一个操作，故 <code>undo_rec_no</code> 为 0。之后可以看到插入的类型为 <code>TRX_UNDO_INSERT_REC</code>，表示 insert undo log 的大小，占用 12 字节。最后的 space, page_no, offset 表示 undo log 开始的位置。打开文件 ibdata1，定位到页<code>（334，272）</code>，并读取 12 字节，可得到如下内容：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">01 1c 0b 00 16 04 80 00 01 01 10</span><br></pre></td></tr></table></figure>

<p>上述就是 undo log 实际的内容，根据上一小节对 undo log 格式的介绍，可以整理得到：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">01 1c   # 下一个 undo log 的偏移 272+12=0x011c </span><br><span class="line"></span><br><span class="line">0b    # undo log 的类型，TRX_UNDO_INSERT_REC 为 11 </span><br><span class="line"></span><br><span class="line">00    # undo log 的记录，等同于 undo_rec_no </span><br><span class="line"></span><br><span class="line">16 04   # 表的 ID </span><br><span class="line"></span><br><span class="line">80 00 00 01 # 主键的长度 </span><br><span class="line"></span><br><span class="line">01 01 10 # 主键的内容 </span><br></pre></td></tr></table></figure>

<p>此外，由于知道该 undo log 所在的 rollback segment 的 ID 为 2，用户还可以通过数据字典表 <code>INNODB_TRX_ROLLBACK_SEGMENT</code> 来查看当前 rollback segment 的信息，如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> segment_id, insert_undo_list, insert_undo_cached</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span>  <span class="keyword">FROM</span> information_schema.INNODB_TRX_ROLLBACK_SEGMENT</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span>  <span class="keyword">WHERE</span> segment_id<span class="operator">=</span><span class="number">2</span>\G</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line"> segment_id: <span class="number">2</span></span><br><span class="line"> insert_undo_list: <span class="number">1</span></span><br><span class="line"> insert_undo_cached: <span class="number">0</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<p>可以看到 <code>insert_undo_list</code> 为 1。若这时进行事务的 COMMIT 操作，再查看该数据字典表：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">COMMIT</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> segment_id, insert_undo_list, insert_undo_cached</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span>  <span class="keyword">FROM</span> information_schema.INNODB_TRX_ROLLBACK_SEGMENT</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span>  <span class="keyword">WHERE</span> segment_id<span class="operator">=</span><span class="number">2</span>\G</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line"> segment_id: <span class="number">2</span></span><br><span class="line"> insert_undo_list: <span class="number">0</span></span><br><span class="line"> insert_undo_cached: <span class="number">1</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<p>可以发现，<code>insert_undo_list</code> 变为 0，而 <code>insert_undo_cached</code> 增加为 1。这就是前面所介绍的 undo 页重用。下次再有事务需要向该 rollback segment 申请 undo 页时，可以直接使用该页。</p>
<p>接着再来观察 delete 操作产生的 undo log。进行如下操作：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">BEGIN</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">DELETE</span> <span class="keyword">FROM</span> t <span class="keyword">WHERE</span> a<span class="operator">=</span><span class="number">1</span>;</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line">Records: <span class="number">1</span> Duplicates: <span class="number">0</span> Warnings: <span class="number">0</span></span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> information_schema.INNODB_TRX_UNDO\G</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line"> trx_id: <span class="number">3201</span></span><br><span class="line"> rseg_id: <span class="number">2</span></span><br><span class="line"> undo_rec_no: <span class="number">0</span></span><br><span class="line"> undo_rec_type: TRX_UNDO_DEL_MARK_REC</span><br><span class="line"> size: <span class="number">37</span></span><br><span class="line"> space: <span class="number">0</span></span><br><span class="line"> page_no: <span class="number">326</span></span><br><span class="line"> <span class="keyword">offset</span>: <span class="number">620</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<p>用上述同样的方法定位到页 326，偏移量为 620 的位置，得到如下结果：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0518260 00 00 00 00 00 00 00 00 00 00 00 02 91 0e 00 </span><br><span class="line"></span><br><span class="line">0518270 16 00 00 00 30 01 e0 82 00 00 01 4e 01 10 04 </span><br><span class="line"></span><br><span class="line">0518280 80 00 00 01 0c 31 01 02 01 03 01 31 02 6c 00 </span><br><span class="line"></span><br><span class="line">0518290 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00</span><br></pre></td></tr></table></figure>

<p>接着开始整理：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">02 91   # 下一个 undo log 开始位置的偏移量 </span><br><span class="line"></span><br><span class="line">0e    # undo log 类型，TRX_UNDO_DEL_MARK_REC 为 14 </span><br><span class="line"></span><br><span class="line">16 00   # undo no </span><br><span class="line"></span><br><span class="line">00    # table id </span><br><span class="line"></span><br><span class="line">00 00 30 01 # info bits </span><br><span class="line"></span><br><span class="line">e0    # rec 事务 id </span><br><span class="line"></span><br><span class="line">82 00 00 01 # rec 回滚指针 </span><br><span class="line"></span><br><span class="line">04    # 主键长度 </span><br><span class="line"></span><br><span class="line">80 00 00 01 # 主键值 </span><br><span class="line"></span><br><span class="line">0b    # 之后部分的长度 </span><br><span class="line"></span><br><span class="line">04    # 列的位置 </span><br><span class="line"></span><br><span class="line">80 00 00 01 # 列的值 </span><br><span class="line"></span><br><span class="line">03    # 列的位置，前 00～02 为系统列 </span><br><span class="line"></span><br><span class="line">01    # 列的长度 </span><br><span class="line"></span><br><span class="line">31    # 列 b 插入的字符 ‘1’ 的十六进制 </span><br><span class="line"></span><br><span class="line">02 6c   # 开始位置的偏移量</span><br></pre></td></tr></table></figure>

<p>观察 rollback segment 信息，可以看到：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> segment_id, update_undo_list, update_undo_cached</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span>  <span class="keyword">FROM</span> information_schema.INNODB_TRX_ROLLBACK_SEGMENT</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span>  <span class="keyword">WHERE</span> segment_id<span class="operator">=</span><span class="number">2</span>\G</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line"> segment_id: <span class="number">2</span></span><br><span class="line"> update_undo_list: <span class="number">1</span></span><br><span class="line"> update_undo_cached: <span class="number">0</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<p>同样的，在事务提交后，undo 页会放入 cache 列表以供下次重用：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">COMMIT</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> segment_id, update_undo_list, update_undo_cached</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span>  <span class="keyword">FROM</span> information_schema.INNODB_TRX_ROLLBACK_SEGMENT</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span>  <span class="keyword">WHERE</span> segment_id<span class="operator">=</span><span class="number">2</span>\G</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line"> segment_id: <span class="number">2</span></span><br><span class="line"> update_undo_list: <span class="number">0</span></span><br><span class="line"> update_undo_cached: <span class="number">1</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<p>通过上面的例子可以看到，delete 操作并不直接删除记录，只是将记录标记为已删除，也就是将记录的 delete flag 设置为 1，而记录最终的删除是在 purge 操作中完成的。</p>
<p>最后来看 update 操作产生的 undo log 情况。首先再次插入记录 <code>(1, &#39;1&#39;)</code>，然后进行 update 操作，同时通过数据字典表 <code>INNODB_TRX_UNDO</code> 观察 undo log 的情况：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> t <span class="keyword">SELECT</span> <span class="number">1</span>,<span class="string">&#x27;1&#x27;</span>;</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">BEGIN</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">UPDATE</span> t <span class="keyword">SET</span> b<span class="operator">=</span><span class="string">&#x27;2&#x27;</span> <span class="keyword">WHERE</span> a<span class="operator">=</span><span class="number">1</span>;</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"><span class="keyword">Rows</span> matched: <span class="number">1</span> Changed: <span class="number">1</span> Warnings: <span class="number">0</span></span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> information_schema.INNODB_TRX_UNDO\G</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line"> trx_id: <span class="number">3205</span></span><br><span class="line"> rseg_id: <span class="number">5</span></span><br><span class="line"> undo_rec_no: <span class="number">0</span></span><br><span class="line"> undo_rec_type: TRX_UNDO_UPD_EXIST_REC</span><br><span class="line"> size: <span class="number">41</span></span><br><span class="line"> space: <span class="number">0</span></span><br><span class="line"> page_no: <span class="number">318</span></span><br><span class="line"> <span class="keyword">offset</span>: <span class="number">724</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<p>用上述同样的方法定位到页 318，偏移量为 724 的位置，得到如下结果：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">04f82d0 00 00 00 00 02 fd 0c 00 16 00 00 00 00 32 04 e0 </span><br><span class="line"></span><br><span class="line">04f82e0 84 00 00 01 48 01 10 04 80 00 00 01 01 03 01 31 </span><br><span class="line"></span><br><span class="line">04f82f0 00 0b 00 04 80 00 00 01 03 01 31 02 d4 00 00 00 </span><br></pre></td></tr></table></figure>

<p>整理后得到：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">02 fd   # 下一个 undo log 开始位置 </span><br><span class="line"></span><br><span class="line">0c    # undo log 类型，TRX_UNDO_UPD_EXIST_REC 为 12 </span><br><span class="line"></span><br><span class="line">00    # undo no </span><br><span class="line"></span><br><span class="line">16 00   # table id </span><br><span class="line"></span><br><span class="line">00 00 00 32 # info bits </span><br><span class="line"></span><br><span class="line">04 e0   # rec trx id </span><br><span class="line"></span><br><span class="line">84 00 00 01 # rec 回滚指针 </span><br><span class="line"></span><br><span class="line">48 01 10 00 # 主键长度及主键值 </span><br><span class="line"></span><br><span class="line">01 03 01 31 # update_vector 的数目及各列编号和值 </span><br><span class="line"></span><br><span class="line">0b    # 接下去部分占用的字节 </span><br><span class="line"></span><br><span class="line">00 …   # 后续其他列的 old values（略）</span><br></pre></td></tr></table></figure>

<p>上述的例子是更新一个非主键值，若更新的对象是一个主键值，那么其产生的 undo log 完全不同，如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">ROLLBACK</span>;</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">UPDATE</span> t <span class="keyword">SET</span> a<span class="operator">=</span><span class="number">2</span> <span class="keyword">WHERE</span> a<span class="operator">=</span><span class="number">1</span>;</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"><span class="keyword">Rows</span> matched: <span class="number">1</span> Changed: <span class="number">1</span> Warnings: <span class="number">0</span></span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> information_schema.INNODB_TRX_UNDO</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">ORDER</span> <span class="keyword">BY</span> undo_rec_no\G</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line"> trx_id: <span class="number">320</span>F</span><br><span class="line"> rseg_id: <span class="number">11</span></span><br><span class="line"> undo_rec_no: <span class="number">0</span></span><br><span class="line"> undo_rec_type: TRX_UNDO_DEL_MARK_REC</span><br><span class="line"> size: <span class="number">37</span></span><br><span class="line"> space: <span class="number">0</span></span><br><span class="line"> page_no: <span class="number">324</span></span><br><span class="line"> <span class="keyword">offset</span>: <span class="number">492</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">2.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line"> trx_id: <span class="number">320</span>F</span><br><span class="line"> rseg_id: <span class="number">11</span></span><br><span class="line"> undo_rec_no: <span class="number">1</span></span><br><span class="line"> undo_rec_type: TRX_UNDO_INSERT_REC</span><br><span class="line"> size: <span class="number">12</span></span><br><span class="line"> space: <span class="number">0</span></span><br><span class="line"> page_no: <span class="number">336</span></span><br><span class="line"> <span class="keyword">offset</span>: <span class="number">272</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<p>可以看到，update 主键的操作其实分两步完成。首先将原主键记录标记为已删除，因此需要产生一个类型为 <code>TRX_UNDO_DEL_MARK_REC</code> 的 undo log，之后插入一条新的记录，因此需要产生一个类型为 <code>TRX_UNDO_INSERT_REC</code> 的 undo log。<code>undo_rec_no</code> 显示了产生日志的步数。对 undo log 不再详细进行分析，相关内容和之前介绍并无不同。</p>
<p>为什么主键值更新需要两阶段操作？</p>
<p>在 InnoDB 中，主键不仅是逻辑上的唯一标识，还决定了行在聚簇索引中的物理位置。当主键值发生改变时，MySQL 无法就地修改这一物理位置，也无法仅更新聚簇索引条目的关键字而保留其余数据和二级索引结构。因此，InnoDB 对主键的更新会被分成两阶段：先对旧记录打删除标记，再插入一条带新主键的记录，这样既能保证数据一致性，又能正确维护所有关联的索引。</p>
<p>但是，辅助索引的更新，虽然在逻辑上也等同于删除旧的索引条目＋插入新的索引条目，但 InnoDB 在内部并<strong>不会把它拆成两个分离的 undo&#x2F;redo 阶段</strong>，而是当作一次“更新”来处理，并由同一条 <strong>update undo log</strong>（<code>TRX_UNDO_UPD_EXIST_REC</code>）和对应的 redo 记录一次性完成。</p>
<h4 id="purge"><a href="#purge" class="headerlink" title="purge"></a>purge</h4><p>delete 和 update 操作可能并不直接删除原有的数据。例如，对之前的表 t 执行如下的 SQL 语句：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> t <span class="keyword">WHERE</span> a<span class="operator">=</span><span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<p>表 t 上列 a 有聚簇索引，列 b 上有辅助索引。对于上述的 delete 操作，通过前面关于 undo log 的介绍已经知道仅是将主键列等于 1 的记录 delete flag 设置为 1，记录并没有被删除，即记录还是存在于 B+ 树中。其次，对辅助索引上 a 等于 1、b 等于 1 的记录同样没有做任何处理，甚至没有产生 undo log。而真正删除这行记录的操作其实被延时了，最终在 purge 操作中完成。</p>
<p>purge 用于最终完成 delete 和 update 操作。这样设计是因为 InnoDB 存储引擎支持 MVCC，所以记录不能在事务提交时立即进行处理。这时其他事务可能正在引用该行，故 InnoDB 存储引擎需要保存记录之前的版本，而是否可以删除该记录通过 purge 来进行判断。若该记录已不被任何其他事务引用，那么就可以进行真正的 delete 操作。可见，purge 操作是清理之前的 delete 和 update 操作，将上述操作最终完成。而实际上执行的操作为 delete 操作，清理之前记录的版本。</p>
<p>之前已经介绍过，为了节省存储空间，InnoDB 存储引擎的 undo log 设计是这样的：一个页上允许多个事务的 undo log 存在。虽然这不代表事务在全局过程中提交的顺序，但是后面的事务产生的 undo log 总在最后。此外，InnoDB 存储引擎还有一个 history 列表，它根据事务提交的顺序，将 undo log 进行链接。</p>
<p>下图中，history list 表示按照事务提交的顺序将 undo log 进行组织。在 InnoDB 存储引擎的设计中，先提交的事务总在尾端。undo page 存放了 undo log，由于可以重用，因此一个 undo page 中可能存放了多个不同事务的 undo log。trx5 的灰色阴影表示该 undo log 还被其他事务引用。</p>
<p><img src="/../../images/MySQL/mysql_undo_history.drawio.png" alt="img"></p>
<p>在执行 purge 的过程中，InnoDB 存储引擎首先从 history list 中找到第一个需要被清理的记录，这里为 trx1，清理之后 InnoDB 存储引擎会在 trx1 的 undo log 所在的页中继续寻找是否存在可以被清理的记录，这里会找到事务 trx3，接着找到 trx5，但是发现 trx5 被其他事务引用而不能清理，故会再次去 history list 中查找，发现此时最尾端的记录为 trx2，接着找到 trx2 所在的页，然后依次再把事务 trx6、trx4 的记录进行清理。 </p>
<p>由于 undo page2 中所有的页都被清理了，因此该 undo page 可以被重用。 </p>
<p>InnoDB 存储引擎这种先从 history list 中找 undo log，然后再从 undo page 中找 undo log 的设计模式是为了避免大量的随机读取操作，从而提高 purge 的效率。 </p>
<p>全局动态参数 <code>innodb_purge_batch_size</code> 用来设置每次 purge 操作需要清理的 undo page 数量。在 InnoDB 1.2 之前，该参数的默认值为 20。而从 1.2 版本开始，该参数的默认值为 300。通常来说，该参数设置得越大，每次回收的 undo page 也就越多，这样可供重用的 undo page 就越多，减少了磁盘存储空间与分配的开销。不过，若该参数设置得太大，则每次需要 purge 处理更多的 undo page，从而导致 CPU 和磁盘 I&#x2F;O 过于集中于对 undo log 的处理，使性能下降。因此对该参数的调整需要由有经验的 DBA 来操作，并且需要长期观察数据库的运行状态。正如官方的 MySQL 数据库手册所说的，普通用户不需要调整该参数。</p>
<p>当 InnoDB 存储引擎的压力非常大时，并不能高效地进行 purge 操作。那么 history list 的长度会变得越来越长。全局动态参数 <code>innodb_max_purge_lag</code> 用来控制 history list 的长度，若长度大于该参数时，其会延缓 DML 的操作。该参数默认值为 0，表示不对 history list 做任何限制。当大于 0 时，就会延缓 DML 的操作，其延缓的算法为：</p>
<p>$$delay &#x3D; ((length(history_list) – innodb_max_purge_lag) * 10) – 5$$</p>
<p>delay 的单位是毫秒。此外，需要特别注意的是，delay 的对象是行，而不是一个 DML 操作。例如当一个 update 操作需要更新 5 行数据时，每行数据的操作都会被 delay，故总的延时时间为 <code>5 * delay</code>。而 delay 的统计会在每一次 purge 操作完成后，重新进行计算。</p>
<p>InnoDB 1.2 版本引入了新的全局动态参数 <code>innodb_max_purge_lag_delay</code>，其用来控制 delay 的最大毫秒数。也就是说当上述计算得到的 delay 值大于该参数时，将 delay 设置为 <code>innodb_max_purge_lag_delay</code>，避免由于 purge 操作缓慢导致其他 SQL 线程出现无限制的等待。</p>
<h4 id="group-commit"><a href="#group-commit" class="headerlink" title="group commit"></a>group commit</h4><p>若事务为非只读事务，则每次事务提交时需要进行一次 fsync 操作，以此保证重做日志都已写入磁盘。当数据库发生宕机时，可以通过重做日志进行恢复。虽然固态硬盘的出现提高了磁盘的性能，然而磁盘的 fsync 性能是有限的。为了提高磁盘 fsync 的效率，目前数据库都提供了 group commit 的功能，即一次 fsync 可以刷新确保多个事务日志被写入文件。对于 InnoDB 存储引擎来说，事务提交时会进行两个阶段的操作：</p>
<ol>
<li>修改内存中事务对应的信息，并且将日志写入重做日志缓冲。 </li>
<li>调用 fsync 将确保日志都从重做日志缓冲冲写入磁盘。</li>
</ol>
<p>步骤 2）相对于步骤 1）是一个较慢的过程，这是因为存储引擎需要与磁盘打交道。但当有事务进行这个过程时，其他事务可以进行步骤 1）的操作，正在提交的事务完成提交操作后，再次进行步骤 2）时，可以将多个事务的重做日志通过一次 fsync 刷新到磁盘，这样就大大地减少了磁盘的压力，从而提高了数据库的整体性能。对于写入或更新较为频繁的操作，group commit 的效果尤为明显。</p>
<p>然而在 InnoDB 1.2 版本之前，在开启二进制日志后，InnoDB 存储引擎的 group commit 功能会失效，从而导致性能的下降。并且在在线环境多使用 replication 环境，因此二进制日志的选项基本都为开启状态，因此这个问题尤为显著。</p>
<p>导致这个问题的原因是在开启二进制日志后，为了保证存储引擎层中的事务和二进制日志的一致性，二者之间使用了两阶段事务，其步骤如下：</p>
<ol>
<li>当事务提交时 InnoDB 会将事务的 prepare 记录写入 redo 日志缓冲并持久化到磁盘。</li>
<li>MySQL 数据库上层写入二进制日志。 </li>
<li>InnoDB 存储引擎层将日志写入重做日志文件。 <ol>
<li>修改内存中事务对应的信息，并且将日志写入重做日志缓冲。 </li>
<li>调用 fsync 将确保日志都从重做日志缓冲冲写入磁盘。</li>
</ol>
</li>
</ol>
<p>一旦步骤 2）中的操作完成，就确保了事务的提交，即使在执行步骤 3）时数据库发生了宕机。此外需要注意的是，每个步骤都需要进行一次 fsync 操作才能保证上下两层数据的一致性。步骤 2）的 fsync 由参数 <code>sync_binlog</code> 控制，步骤 3）的 fsync 由参数 <code>innodb_flush_log_at_trx_commit</code> 控制。因此上述整个过程如下图所示。</p>
<p><img src="/../../images/MySQL/mysql_group_commit.png" alt="img"></p>
<p>为了保证 MySQL 数据库上层二进制日志的写入顺序和 InnoDB 层的事务提交顺序一致，MySQL 数据库内部使用了 <code>prepare_commit_mutex</code> 这个锁。但是在启用这个锁之后，步骤 3）中的步骤 a）不可在其他事务执行步骤 b）时进行，从而导致了 group commit 失效。</p>
<p>然而，为什么需要保证 MySQL 数据库上层二进制日志的写入顺序和 InnoDB 层的事务提交顺序一致？</p>
<ol>
<li><p>崩溃恢复一致性</p>
<p>如果 Binlog 中记录的提交顺序与 InnoDB 实际提交顺序不一致：</p>
<ul>
<li>在异常崩溃后，InnoDB 会回滚那些 prepare 但未 commit 的事务；</li>
<li>但 Binlog 里可能已记录这些事务，重放时会尝试执行已回滚的事务，导致副本或恢复数据与源实例不吻合。</li>
</ul>
</li>
<li><p>物理备份兼容性</p>
<p>工具如 Percona XtraBackup、InnoDB Hot Backup 在 prepare 阶段会汇总所有未完成事务，并依赖 Binlog 决定哪些事务在恢复时执行提交：</p>
<ul>
<li>若写日志与提交顺序错乱，就无法正确匹配，可能把原本应回滚的事务提交，或把应提交的事务丢弃。</li>
</ul>
</li>
<li><p>主从复制一致性</p>
<p>MySQL 单线程或多线程复制都遵循“在主库上的提交顺序即 Binlog 写入顺序”，备库严格按此顺序重放事务：</p>
<ul>
<li>顺序错乱会让备库先执行后提交的事务，再执行前提交的事务，破坏数据因果关系；</li>
<li>按顺序保证了“复制是严格顺序一致”的模型。</li>
</ul>
</li>
</ol>
<p>这里以备份及恢复为例，例如通过工具 xtrabackup 或者 ibbackup 进行备份，并用来建立 replication。如下图所示：</p>
<p><img src="/../../images/MySQL/mysql_no_commit_mutex.png" alt="img"></p>
<p>因此通过锁 <code>prepare_commit_mutex</code> 以串行的方式来保证顺序性，然而这会使 group commit 无法生效，如下图所示。</p>
<p><img src="/../../images/MySQL/mysql_commit_mutex.png" alt="img"></p>
<p>上图中启用了 <code>prepare_commit_mutex</code>，因此只有当上一个事务 commit 后释放锁，下一个事务才可以进行 prepare 操作，并且在每个事务过程中 bin log 没有 <code>fsync()</code> 的调用。因此，事务的启动顺序对应写入 binlog 中的顺序。此外，由于内存数据写入磁盘的开销很大，如果频繁 <code>fsync()</code> 把日志数据永久写入磁盘，数据库的性能将会急剧下降。此时 MySQL 提供 sync_binlog 参数来设置在产生多少个 binlog 日志后调用一次 <code>fsync()</code>，将二进制日志刷新到磁盘，以提高整体性能。</p>
<p>这个问题最早在 2010 年的 MySQL 数据库大会中提出，Facebook MySQL 技术组、Percona 公司都提出过解决方案。最后由 MariaDB 数据库的开发人员 Kristian Nielsen 完成了最终的“完美”解决方案。在这种情况下，不但 MySQL 数据库上层的二进制日志写入是 group commit 的，InnoDB 存储引擎层也是 group commit 的。此外还移除了原先的锁 <code>prepare_commit_mutex</code>，从而大大提高了数据库的整体性。MySQL 5.6 采用了类似的实现方式，并将其称为 Binary Log Group Commit（BLGC）。</p>
<p>MySQL 5.6 BLGC 的实现方式是将事务提交的过程分为几个步骤来完成，如下图所示。</p>
<p><img src="/../../images/MySQL/mysql_blgc.drawio.png" alt="img"></p>
<p><strong>三阶段提交与队列模型</strong></p>
<p>BLGC 将单次事务提交拆分为三阶段，每阶段各自维护一个队列和对应的处理流程：</p>
<ol>
<li>Flush 阶段（Flush queue）：事务先将各自的 Binlog 缓存（内存 I&#x2F;O cache）写入到文件页缓存中，不立即调用 fsync，仅做写操作；</li>
<li>Sync 阶段（Sync queue）：队列领导者统一调用一次 fsync，根据 sync_binlog 设置决定是否持久化到存储介质；如果 <code>sync_binlog=1</code>，每批次都强制同步；</li>
<li>Commit 阶段（Commit queue）：在 InnoDB 层真正执行 group commit，写入 Redo Log 的 commit 标记，并通知各事务完成提交。</li>
</ol>
<p>Leader &#x2F; Follower 模式：队列中的第一个事务称为 leader，其他事务称为 follower，leader 控制着 follower 的行为。</p>
<p><strong>具体流程</strong></p>
<ol>
<li><p>Flush 阶段</p>
<ul>
<li><p>每个事务将自己的 Binlog 事件追加到线程本地的缓存区；</p>
</li>
<li><p>Leader 在此阶段结束时，将所有 follower 的缓存统一写入到 Binlog 文件的页缓存（内存）中，仅触发一次文件页写操作，无 fsync。</p>
</li>
</ul>
</li>
<li><p>Sync 阶段</p>
<ul>
<li><p>所有线程进入 Sync 队列，并由 Leader 负责后续操作；</p>
</li>
<li><p>Leader 按 sync_binlog 配置调用 fsync。若 sync_binlog&#x3D;1，保证每批次提交后强制持久化；若设置大于 1，则每隔 N 次才 fsync；</p>
</li>
<li><p>同步完成后，Leader 释放文件锁并唤醒所有 Follower，确保它们能看到持久化的数据。</p>
</li>
</ul>
</li>
<li><p>Commit 阶段</p>
<ul>
<li><p>InnoDB Group Commit：Leader 调用 InnoDB 的 group commit 接口，将事务在存储引擎层的提交日志（commit 重做日志）一次性刷入 Redo Log 文件；</p>
</li>
<li><p>释放事务锁；</p>
</li>
<li><p>所有参与事务的线程被唤醒，返回提交成功状态。</p>
</li>
</ul>
</li>
</ol>
<p>为什么 Binary Log Group Commit 能保证 Binlog 写入顺序与 InnoDB 提交顺序严格一致？</p>
<p>inary Log Group Commit 通过在 Flush、Sync、Commit 三个阶段均使用 FIFO 队列，并由队首的 Leader 顺序处理，保证了先进入队列的事务先被 Flush、先被 Sync、先被 Commit 以及在当前阶段完成后按顺序先被传给下一阶段，从而使 Binlog 的写入顺序与 InnoDB 的提交顺序严格一致。</p>
<p>当有一组事务在进行 Commit 阶段时，其他新事务可以进行 Flush 阶段，从而使 group commit 不断生效。当然 group commit 的效果由队列中事务的数量决定，若每次队列中仅有一个事务，那么可能效果和之前差不多，甚至会更差。但当提交的事务越多时，group commit 的效果越明显，数据库性能的提升也就越大。</p>
<p>参数 <code>binlog_max_flush_queue_time</code> 用来控制 Flush 阶段中等待的时间，即使之前的一组事务完成提交，当前一组的事务也不马上进入 Sync 阶段，而是至少需要等待一段时间。这样做的好处是 group commit 的事务数量更多，然而这也可能会导致事务的响应时间变慢。该参数的默认值为 0，且推荐设置依然为 0。除非用户的 MySQL 数据库系统中有着大量的连接（如 100 个连接），并且不断地在进行事务的写入或更新操作。</p>
<h3 id="锁-和-MVCC-隔离性"><a href="#锁-和-MVCC-隔离性" class="headerlink" title="锁 和 MVCC &#x3D;&gt; 隔离性"></a>锁 和 MVCC &#x3D;&gt; 隔离性</h3><blockquote>
<p>锁的内容在其他部分会提到，这里不赘述。</p>
</blockquote>
<p>读操作的类型</p>
<p><strong>当前读：<strong>读取的是记录的</strong>最新版本</strong>，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁。</p>
<p><code>select ... lock in share mode</code>, <code>select ... for update</code>, <code>insert</code>, <code>delete</code> 都是一种当前读。</p>
<p><strong>快照读：<strong>读取的是记录数据的</strong>可见版本</strong>（可能是任一历史版本），不加锁，非阻塞读。简单的 select（不加锁）就是快照读。</p>
<ul>
<li>read committed：每次 <strong>select</strong> 都生成一个快照读。</li>
<li>repeatable read：开启事务后执行第一次 select 语句时快照读（<strong>产生快照</strong>），之后的查询都是读取之前产生的快照。</li>
<li>serializable：通过快照隔离的读视图被放弃，取而代之的是对最新提交数据的锁定式读取。</li>
</ul>
<h3 id="MVCC"><a href="#MVCC" class="headerlink" title="MVCC"></a>MVCC</h3><p>多版本并发控制：通过一定机制生成一个数据请求时间点的一致性数据快照，并用这个快照来提供一定级别（语句级或事务级）的一致性读取。记录的是某个时间点上的数据快照，用来实现不同事务之间数据的隔离性。</p>
<p>它维护一个数据的多个版本，使得读写操作没有冲突，快照读为 MySQL 实现 MVCC 提供了一个<strong>非阻塞读</strong>功能。</p>
<p>MVCC 的实现依赖于数据库的每条记录中的三个隐式字段：</p>
<ol>
<li><code>DB_TRX_ID</code>：记录<strong>最后一次插入或修改该记录</strong>的事务 ID。</li>
<li><code>DB_ROLL_PTR</code>（回滚指针）：指向 undo log 中这条记录的上一个版本。</li>
<li><code>DB_ROW_ID</code>（隐藏主键）：如果表结构未指定主键，将会生成该隐藏字段。</li>
</ol>
<p><img src="/../../images/MySQL/mysql_mvcc_params.drawio.png" alt="img"></p>
<p>undo log（回滚日志）：记录未提交事务，用于事务回滚。</p>
<ul>
<li>insert 时产生的回滚日志只在回滚时需要，可在事务提交后被<strong>立即删除</strong>。</li>
<li>update 或 delete 时产生的回滚日志不仅在回滚时需要，在快照读时也需要，所以不会被立即删除。</li>
</ul>
<p>**undo log 版本链：**不同事务或相同事务对同一条记录进行修改，会导致该记录 undo log 生成一条记录版本的链表，链表头部是最新的旧记录，链表尾部是最早的旧记录。</p>
<p><strong>undo log</strong> 确实会被删除，但只有在<strong>所有可能依赖它的事务都结束之后</strong>才会删除。因此，在事务活跃期间，版本链仍然存在，不会立即消失。</p>
<p><img src="/../../images/MySQL/mysql_undo_chain.drawio.png" alt="img"></p>
<p><strong>ReadView</strong> 是快照读 SQL 执行时 MVCC 提取数据的依据，用于<strong>确定在特定事务中哪些版本的行记录是可见的</strong>，它记录并维护系统当前活跃的未提交事务的 id。ReadView 主要用来处理隔离级别为可重复读和读已提交的情况。因为在这两个隔离级别下，事务在读取数据时，需要保证读取到的数据是一致的，即读取到的数据是在事务开始时的一个快照。包含<strong>四个核心字段</strong>：</p>
<table>
<thead>
<tr>
<th>字段</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>m_ids</td>
<td>当前活跃的事务 ID 集合</td>
</tr>
<tr>
<td>min_trx_id</td>
<td>最小活跃事务 ID</td>
</tr>
<tr>
<td>max_trx_id</td>
<td>预分配事务 ID（当前最大事务 ID + 1）</td>
</tr>
<tr>
<td>creator_trx_id</td>
<td>ReadView 创建者的事务 ID</td>
</tr>
</tbody></table>
<p><strong>版本链访问机制</strong></p>
<p><img src="/../../images/MySQL/mysql_read_view.drawio.png" alt="img"></p>
<p><code>trx_id</code>：特定事务 ID</p>
<ol>
<li><code>trx_id == creator_trx_id</code>：可以访问该版本。</li>
<li><code>trx_id &lt; min_trx_id</code>：可以访问该版本。</li>
<li><code>trx_id &gt; max_trx_id</code>：不可以访问该版本。</li>
<li><code>min_trx_id &lt;= trx_id &lt;= max_trx_id</code>：如果 trx_id 不在 m_ids 中则可以访问该版本。</li>
</ol>
<p>假设读事务开启了一个 ReadView，这个 ReadView 里面记录了当前活跃事务的 ID 列表（444、555、665），以及最小事务 ID（444）和最大事务 ID（666）。当然还有自己的事务 ID 520，也就是 <code>creator_trx_id</code>。它要读的这行数据的写事务 ID 是 x，也就是 <code>DB_TRX_ID</code>。</p>
<ul>
<li>如果 x &#x3D; 110，显然在 ReadView 生成之前就提交了，所以这行数据是可见的。</li>
<li>如果 x &#x3D; 667，显然是未知世界，所以这行数据对读操作是不可见的。</li>
<li>如果 x &#x3D; 519，虽然 519 大于 444 小于 666，但是 519 不在活跃事务列表里，所以这行数据是可见的。因为 519 是在 520 生成 ReadView 之前就提交了。</li>
<li>如果 x &#x3D; 555，虽然 555 大于 444 小于 666，但是 555 在活跃事务列表里，所以这行数据是不可见的。因为 555 不确定有没有提交。</li>
</ul>
<p>需要注意的是，不同隔离级别生成 ReadView 的时机不同：</p>
<ol>
<li>可重复读：在<strong>第一次</strong>读取数据时生成一个 ReadView，这个 ReadView 会一直保持到事务结束，这样可以保证在事务中多次读取同一行数据时，读取到的数据是一致的。</li>
<li>读已提交：<strong>每次</strong>读取数据前都生成一个 ReadView，这样就能保证每次读取的数据都是最新的。</li>
</ol>
<p><strong>多个事务同时操作同一行会发生什么？</strong></p>
<p>多个事务确实可同时操作同一行，但 MVCC 提供了以下机制来处理并发情况，确保数据一致性：</p>
<ul>
<li>读写并发：当一个事务在对某一行数据进行读取时（读操作），即使其他事务正在对该行数据进行写操作（更新或删除），MVCC 仍然允许该事务读取该行的历史版本数据，而不会与写操作发生冲突。读操作不会阻塞写操作，写操作也不会阻塞读操作，这正是 MVCC 并发控制的核心优势之一。</li>
<li>写写并发：当多个事务同时对同一行数据进行写操作时，InnoDB 使用行级锁来控制并发写操作。这意味着，虽然多个事务可以并发读取同一行数据的不同版本，但同一时刻只能有一个事务对该行进行写操作。当一个事务对某一行数据加了排他锁（X 锁），其他事务尝试写入同一行时，会被阻塞，直到该排他锁释放。</li>
<li>事务冲突与回滚：如果多个事务在同一行上发生冲突（例如，事务 A 在修改一行数据时，事务 B 也试图修改同一行数据），事务 B 会等待事务 A 完成。当事务 A 提交后，事务 B 才能继续进行。如果事务 A 回滚，那么事务 B 仍然可以继续修改该行，因为回滚后数据恢复到了事务 A 之前的状态。</li>
</ul>
<p>如果其他三个特性都能够得到保证，那一致性也就能得到保证了。例如：</p>
<ul>
<li>如果一个事务回滚，原子性确保数据库回到之前的状态；</li>
<li>隔离性确保事务之间的干扰最小化，避免不一致；</li>
<li>持久性确保事务提交后修改不会丢失。</li>
</ul>
<h2 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h2><p>在 MySQL 数据库中，InnoDB 存储引擎提供了对 XA 事务的支持，并通过 XA 事务来实现分布式事务。分布式事务指的是允许多个独立的事务资源（transactional resources）参与到一个全局的事务中。事务资源通常是关系型数据库系统，但也可以是其他类型的资源。全局事务要求其中的所有参与事务要么都提交，要么都回滚，这对事务原有的 ACID 要求提出了更高的要求。此外，在使用分布式事务时，InnoDB 存储引擎的事务隔离级别<strong>必须</strong>设置为 <strong>SERIALIZABLE</strong>。</p>
<p>XA 事务允许在不同数据库之间进行分布式事务。比如，一台服务器上运行 MySQL 数据库，另一台服务器上运行 Oracle 数据库，甚至还可能有一台运行 SQL Server 数据库，只要所有参与全局事务的节点都支持 XA 事务即可。分布式事务在银行系统的转账场景中比较常见，例如用户 David 需要从上海的账户转账 10 000 元到北京用户 Mariah 的银行卡中：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># Bank<span class="variable">@Shanghai</span>:</span><br><span class="line"><span class="keyword">UPDATE</span> account <span class="keyword">SET</span> money <span class="operator">=</span> money <span class="operator">-</span> <span class="number">10000</span> <span class="keyword">WHERE</span> <span class="keyword">user</span><span class="operator">=</span><span class="string">&#x27;David&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># Bank<span class="variable">@Beijing</span>:</span><br><span class="line"><span class="keyword">UPDATE</span> account <span class="keyword">SET</span> money <span class="operator">=</span> money <span class="operator">+</span> <span class="number">10000</span> <span class="keyword">WHERE</span> <span class="keyword">user</span><span class="operator">=</span><span class="string">&#x27;Mariah&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>在这种情况下，<strong>一定</strong>需要使用分布式事务来保证数据的安全性。如果操作不能全部提交或全部回滚，那么任何一个节点出现问题都会导致严重后果：要么 David 的账户被扣款但 Mariah 没收到钱，要么 David 的账户没有扣款但 Mariah 收到钱。</p>
<p>XA 事务由以下三部分组成：</p>
<ul>
<li><strong>资源管理器（Resource Manager）</strong>：提供访问事务资源的方法。通常一个数据库就是一个资源管理器。</li>
<li><strong>事务管理器（Transaction Manager）</strong>：协调参与全局事务的各个资源管理器，需要与所有参与的资源管理器通信。</li>
<li><strong>应用程序（Application Program）</strong>：定义事务的边界，指定全局事务中的操作。</li>
</ul>
<p>在 MySQL 的分布式事务中，资源管理器就是 MySQL 数据库，事务管理器通常是连接 MySQL 服务器的客户端。下图展示了一个分布式事务的模型。</p>
<p><img src="/../../images/MySQL/mysql_xa.drawio.png" alt="img"></p>
<p>分布式事务采用两段式提交（two-phase commit）方法：</p>
<ol>
<li>**准备阶段（PREPARE）：**所有参与全局事务的节点开始准备，告诉事务管理器它们已经准备好提交。</li>
<li>**提交&#x2F;回滚阶段（COMMIT or ROLLBACK）：**事务管理器根据各节点的准备情况，通知资源管理器执行 COMMIT 还是 ROLLBACK。如果任何一个节点无法提交，则所有节点都被告知回滚。</li>
</ol>
<p>与本地事务相比，分布式事务多了一次 PREPARE 操作：只有在收到所有节点同意准备的信息后，才执行最终的 COMMIT 或 ROLLBACK。</p>
<p>MySQL 数据库中 XA 事务的 SQL 语法如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">XA &#123;<span class="keyword">START</span><span class="operator">|</span><span class="keyword">BEGIN</span>&#125; xid [<span class="keyword">JOIN</span><span class="operator">|</span>RESUME]</span><br><span class="line"></span><br><span class="line">XA <span class="keyword">END</span> xid [SUSPEND [<span class="keyword">FOR</span> MIGRATE]]</span><br><span class="line"></span><br><span class="line">XA <span class="keyword">PREPARE</span> xid</span><br><span class="line"></span><br><span class="line">XA <span class="keyword">COMMIT</span> xid [<span class="keyword">ONE</span> PHASE]</span><br><span class="line"></span><br><span class="line">XA <span class="keyword">ROLLBACK</span> xid</span><br><span class="line"></span><br><span class="line">XA RECOVER</span><br></pre></td></tr></table></figure>

<p>在单个节点上运行分布式事务意义不大；通常需要通过编程语言来驱动多个节点的分布式事务操作。</p>
<h3 id="内部-XA-事务"><a href="#内部-XA-事务" class="headerlink" title="内部 XA 事务"></a>内部 XA 事务</h3><p>之前讨论的分布式事务是外部事务，即资源管理器是 MySQL 数据库本身。在 MySQL 数据库中还存在另外一种分布式事务，其在存储引擎与插件之间，又或者在存储引擎与存储引擎之间，称之为内部 XA 事务。</p>
<p>最常见的内部 XA 事务存在于 binlog 与 InnoDB 存储引擎之间。由于复制的需要，因此目前绝大多数的数据库都开启了 binlog 功能。在事务提交时，先写二进制日志，再写 InnoDB 存储引擎的重做日志。对上述两个操作的要求也是原子的，即二进制日志和重做日志必须同时写入。若二进制日志先写了，而在写入 InnoDB 存储引擎时发生了宕机，那么 slave 可能会接收到 master 传过去的二进制日志并执行，最终导致主从不一致的情况。如下图所示。</p>
<p><img src="/../../images/MySQL/mysql_internal_xa_a.drawio.png" alt="img"></p>
<p>在上图中，如果执行完 ①、② 后在步骤 ③ 之前 MySQL 数据库发生了宕机，则会发生主从不一致的情况。为了解决这个问题，MySQL 数据库在 binlog 与 InnoDB 存储引擎之间采用 XA 事务。当事务提交时，InnoDB 存储引擎会先做一个 PREPARE 操作，将事务的 xid 写入，接着进行二进制日志的写入，如下图所示。如果在 InnoDB 存储引擎提交前，MySQL 数据库宕机了，那么 MySQL 数据库在重启后会先检查准备的 UXID 事务是否已经提交，若没有，则在存储引擎层再进行一次提交操作。</p>
<p><img src="/../../images/MySQL/mysql_internal_xa_b.drawio.png" alt="img"></p>
<h2 id="不好的事务习惯"><a href="#不好的事务习惯" class="headerlink" title="不好的事务习惯"></a>不好的事务习惯</h2><h3 id="在循环中提交"><a href="#在循环中提交" class="headerlink" title="在循环中提交"></a>在循环中提交</h3><p>开发人员可能会在循环中进行事务的提交，如下（可想象成 Java 中的某个方法）：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">PROCEDURE</span> load1(count <span class="type">INT</span> UNSIGNED)</span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">  <span class="keyword">DECLARE</span> s <span class="type">INT</span> UNSIGNED <span class="keyword">DEFAULT</span> <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">DECLARE</span> c <span class="type">CHAR</span>(<span class="number">80</span>) <span class="keyword">DEFAULT</span> REPEAT(<span class="string">&#x27;a&#x27;</span>,<span class="number">80</span>);</span><br><span class="line">  WHILE s <span class="operator">&lt;=</span> count DO</span><br><span class="line">    <span class="keyword">INSERT INTO</span> t1 <span class="keyword">SELECT</span> <span class="keyword">NULL</span>, c;</span><br><span class="line">    <span class="keyword">COMMIT</span>;</span><br><span class="line">    <span class="keyword">SET</span> s <span class="operator">=</span> s <span class="operator">+</span> <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">END</span> WHILE;</span><br><span class="line"><span class="keyword">END</span>;</span><br></pre></td></tr></table></figure>

<p>其实，在上述的例子中，是否加上提交命令 COMMIT 并不关键。因为 InnoDB 存储引擎默认是自动提交，所以在上述的存储过程中去掉 COMMIT，结果其实是完全一样的。</p>
<p>上面的存储过程存在一个问题，当发生错误时，数据库会停留在一个未知的位置。例如，用户需要插入 10000 条记录，但是在插入 5000 条时，发生了错误，此时前 5000 条记录已经存放在数据库中，那应该怎么处理呢？另一个问题是性能问题，上面两个存储过程都不会比下面的存储过程 load2 快，因为下面的存储过程将所有的 INSERT 都放在一个事务中：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">PROCEDURE</span> load3(count <span class="type">INT</span> UNSIGNED)</span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">  <span class="keyword">DECLARE</span> s <span class="type">INT</span> UNSIGNED <span class="keyword">DEFAULT</span> <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">DECLARE</span> c <span class="type">CHAR</span>(<span class="number">80</span>) <span class="keyword">DEFAULT</span> REPEAT(<span class="string">&#x27;a&#x27;</span>,<span class="number">80</span>);</span><br><span class="line">  <span class="keyword">START</span> TRANSACTION;</span><br><span class="line">  WHILE s <span class="operator">&lt;=</span> count DO</span><br><span class="line">    <span class="keyword">INSERT INTO</span> t1 <span class="keyword">SELECT</span> <span class="keyword">NULL</span>, c;</span><br><span class="line">    <span class="keyword">SET</span> s <span class="operator">=</span> s <span class="operator">+</span> <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">END</span> WHILE;</span><br><span class="line">  <span class="keyword">COMMIT</span>;</span><br><span class="line"><span class="keyword">END</span>;</span><br></pre></td></tr></table></figure>

<p>也就是说，因为每一次提交都要写一次重做日志，存储过程 load1 和 load2 实际写了 10000 次重做日志文件，而对于存储过程 load3 来说，实际上只写了 1 次。</p>
<h3 id="使用自动提交"><a href="#使用自动提交" class="headerlink" title="使用自动提交"></a>使用自动提交</h3><p>MySQL 中默认启用 <strong>autocommit</strong> 模式，意味着每条 DML 语句会被视作单独的事务并在执行后立即提交。这虽然降低了使用门槛，但也容易在批量操作或存储过程中导致不可控的中间状态，并引发性能和一致性问题。通过关闭 autocommit（<code>SET autocommit=0</code>）或显式使用 START TRANSACTION&#x2F;BEGIN 来管理事务，可以将多条操作放入同一个事务，从而在发生错误时统一回滚，并显著减少重做日志的写入次数。不同客户端 API（如 C API、Python API）对 autocommit 的默认行为各不相同，应用开发时需特别留意并在程序端明确控制事务边界。</p>
<h3 id="使用自动回滚"><a href="#使用自动回滚" class="headerlink" title="使用自动回滚"></a>使用自动回滚</h3><p>在存储过程中，通过 <code>DECLARE EXIT HANDLER FOR SQLEXCEPTION ROLLBACK;</code> 定义了一个针对任意 SQL 异常的退出型处理器，一旦发生错误便自动执行 ROLLBACK，无需显式再调用回滚语句。虽然自动回滚保证了数据一致性，但存储过程本身并不会向调用者返回错误信息。所以我们应将事务控制下放到应用程序一侧，既能保证回滚，也能捕获数据库抛出的错误编码与描述。</p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>分库分表</title>
    <url>/undefined/MySQL/2024/11/25/MySQL/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><p>分库分表主要是为了解决单库单表在海量数据和高并发场景下的性能瓶颈：当数据量达到千万级甚至亿级时，单表查询效率和索引更新速度都会明显下降，备份恢复也变得极其缓慢；而在高并发写入时，单实例的 CPU、内存、I&#x2F;O 资源易成为瓶颈，锁竞争也会导致事务阻塞。通过将大表拆成多张子表、或将数据分散到多个数据库实例，不仅能降低单表、单库的数据规模，提升读写性能，还能分散并发压力、减少锁冲突，从而显著提高系统的可用性和扩展能力。</p>
<p>垂直分库通过将不同业务模块或功能独立到各自的数据库，既降低了数据之间的耦合度，又提升了整体可用性；水平分库则将同一业务的数据按一定策略分散到多台实例，分担了单库的 CPU、I&#x2F;O 和网络压力；垂直分表是把表中不同类型的数据拆分到多张表中，进一步削弱耦合；水平分表则把一张大表按范围或哈希划分成多张子表，从而减少索引深度并加快查询。</p>
<p>若仍使用单库单表模式，会因热点数据频繁访问导致缓冲区不足、磁盘 I&#x2F;O 激增，又因大量请求而引发网络带宽瓶颈，此外 SQL 处理也会占用过多 CPU 资源，最终形成性能瓶颈。分库分表的核心思想就是通过分散存储，将单一数据库或表的数据规模控制在可承载范围内，进而显著缓解 I&#x2F;O、CPU 和网络方面的压力。</p>
<h2 id="拆分策略"><a href="#拆分策略" class="headerlink" title="拆分策略"></a>拆分策略</h2><h3 id="垂直拆分"><a href="#垂直拆分" class="headerlink" title="垂直拆分"></a>垂直拆分</h3><p>垂直拆分主要包括两种形式：<strong>垂直分库</strong>和<strong>垂直分表</strong>。其中，垂直分库是以表为单位、根据业务模块将不同的表拆分到各自独立的数据库实例中，使得每个库只包含某一类业务的表，从而降低数据耦合度并提升可用性；而垂直分表则是以字段为依据，将同一张宽表中访问频次不同或性质相异的字段拆分到多张子表，通过主键—外键关联保持数据完整性，以减小单表宽度、优化查询性能。在实践中，垂直分库常用于按业务边界隔离数据，而垂直分表则侧重于对单表内部结构的精细化拆分，两者结合能够更好地满足系统的可扩展性与维护性需求。</p>
<p><img src="/../../images/MySQL/mysql_partition_v.drawio.png" alt="img"></p>
<h3 id="水平拆分"><a href="#水平拆分" class="headerlink" title="水平拆分"></a>水平拆分</h3><p>水平拆分是一种以<strong>行</strong>为单位对数据进行切割的策略：水平分库是将同一表的若干行数据按照某种分片键（如用户ID范围或哈希）分散到多个数据库实例，每个实例存储一部分数据，从而分担 CPU、I&#x2F;O 和网络负载；而水平分表则是在同一数据库实例内部将表数据行按相同策略分布到多张结构相同的子表中，以减少单表的索引层数，提升查询性能和并发处理能力。无论是分库还是分表，都可通过范围切片、哈希切片或列表切片等算法来保证数据的均衡分布，进一步降低锁竞争与热点访问问题。</p>
<p>在业界，这种做法通常也被称为分片（sharding），每个分片可以是独立的数据存储节点。此外，在云服务环境下，水平分区是实现水平扩展（scale-out）的核心方式，通过动态增加分片或实例来处理更大规模的请求和数据量；它还能与读写分离、缓存策略等机制结合，共同构建高可用、高性能的数据库架构。</p>
<p><img src="/../../images/MySQL/mysql_partition_h.drawio.png" alt="img"></p>
<h3 id="水平分表的路由方式"><a href="#水平分表的路由方式" class="headerlink" title="水平分表的路由方式"></a>水平分表的路由方式</h3><p>要实现水平分表，必须设计一个路由策略，根据<strong>分片键</strong>（Sharding Key）决定每条记录应写入哪张子表。理想的分片键应该具备以下特征：</p>
<p>一是<strong>高区分度</strong>，使数据均匀分布，避免某些表过热或过载；</p>
<p>二是<strong>查询频率高</strong>，优先选取常在 WHERE 条件中出现的字段，以确保绝大多数查询能直接定位到目标表，提升查询效率；</p>
<p>三是<strong>写入频率高</strong>，将频繁更新或插入的字段作为分片键，有助于将写负载均衡地分散到各个子表，从而减少单表写入瓶颈。</p>
<p>范围路由、哈希路由和配置路由是水平分表中最常用的三种策略。</p>
<p>范围路由通过将分片键按值的连续区间映射到不同的表，例如按时间戳或订单号切分，优势在于实现简单且可以平滑扩容，但容易出现部分分片数据过多的倾斜问题。</p>
<p><img src="/../../images/MySQL/mysql_partition_range.drawio.png" alt="img"></p>
<p>哈希路由则对分片键取哈希值并取模分表，可以较均匀地分散数据，避免单表热点，但执行范围查询时需要访问多个分片，查询性能有所下降。</p>
<p><img src="/../../images/MySQL/mysql_partition_hash.drawio.png" alt="img"></p>
<p>配置路由则通过维护一张映射表，显式指定每个分片键对应的目标表，灵活性最高，能够应对分片键分布不均或规则多变的场景，但需要额外的配置表来管理路由映射，运维成本和复杂度也相对更高。</p>
<p><img src="/../../images/MySQL/mysql_partition_route.drawio.png" alt="img"></p>
<p>以上的路由方式可以根据场景的不同组合使用，比如：首先根据业务维度（如订单月份）将数据划分到不同的<strong>分组</strong>，每个分组再映射到若干<strong>物理节点</strong>，形成按月分组的“范围切分”策略。然后在每个分组内部，对分片键（如 orderId）计算哈希并取模，将其均匀分配到该组的各节点上，兼顾了哈希路由的负载均衡效果。</p>
<h3 id="不停机扩容"><a href="#不停机扩容" class="headerlink" title="不停机扩容"></a>不停机扩容</h3><p>不停机扩容通常分为三个阶段，以确保旧库和新库在业务不中断的情况下平滑过渡。</p>
<p>第一阶段是<strong>在线双写、老库查询</strong>：在此阶段，先在新环境中建立与旧库完全相同的库表结构，然后将所有新增写操作同时写入旧库和新库，业务查询仍然走旧库；接着，通过专用迁移程序对旧库中的历史数据进行全量迁移，并通过定时校验任务对比新旧库的数据一致性，实时补齐任何差异。</p>
<p><img src="/../../images/MySQL/mysql_partition_scale1.drawio.png" alt="img"></p>
<p>第二阶段是<strong>完成同步并切换读流量</strong>：当确认历史数据已经成功迁移且新库中的写入与旧库始终保持一致后，就可以将所有读操作从旧库切换到新库，从而开始验证新库的查询性能和稳定性。</p>
<p><img src="/../../images/MySQL/mysql_partition_scale2.drawio.png" alt="img"></p>
<p>第三阶段是<strong>停止旧库写入并下线</strong>：在确认旧库不再接收任何新写后，需要等待一段时间以清空剩余连接与缓冲，然后可以安全地关闭或拆除旧库，实现真正的无缝下线。通过这种三阶段流程，在整个扩容过程中既保证了业务的连续性，也维持了数据的一致性和可用性。</p>
<p><img src="/../../images/MySQL/mysql_partition_scale3.drawio.png" alt="img"></p>
<p>尽管在线双写与写时复制在延迟复制、零停机思想上有交集，但它们在层级、触发条件、技术依赖和一致性模型上都有本质区别。在线双写更适合数据库扩容与数据迁移场景；写时复制则是操作系统与存储层面优化内存和文件复制的通用技术。两者均为提升可用性和性能的重要手段，但并非同一机制。</p>
<h2 id="分库分表的问题"><a href="#分库分表的问题" class="headerlink" title="分库分表的问题"></a>分库分表的问题</h2><p>在分库后，单机事务的强一致性优势不再适用，必须引入分布式事务（如两阶段提交或 TCC）来保证跨库的事务完整性；同时，由于数据库实例被拆分，原生的跨库 JOIN 无法直接执行，只能在业务代码中先查询一个库的数据再查询另一个库并进行合并，或通过冗余字段将常用关联信息（如名称）复制到当前表，减少关联请求；另一种思路是利用 binlog 同步等机制将需要跨库关联的数据异构到 Elasticsearch 等专用存储，再由 ES 实现联合查询。</p>
<p>在分表场景下，跨分片的聚合计算（如 COUNT、ORDER BY、GROUP BY）只能通过业务端或中间件对各分表结果进行汇总、排序与分页才能实现；同时，需要在切分前对数据迁移、容量规划及未来扩容的可行性进行充分评估，以避免二次拆分带来的复杂度和风险。更重要的是，表被水平切分后已不能再依赖数据库自身的自增主键机制来保证全局唯一性，常见的替代方案包括：设置不同的自增步长与初始值（例如三张表分别以步长 3、初始值 1、2、3 生成 ID），从而避免冲突；使用 UUID 生成全局唯一主键，但要警惕随机主键可能导致 B-Tree 页分裂、写放大和性能下降；或者采用分布式 ID 生成算法（如 Twitter Snowflake），通过时间戳、节点 ID 及序列号的组合方式高效生成可排序的全局唯一 ID，兼顾性能与一致性。</p>
<p>更多内容可参考：</p>
<ul>
<li><a href="https://developer.aliyun.com/article/1232122">基因法与倒排索引在MySQL分库分表的应用</a></li>
<li><a href="https://developer.aliyun.com/article/1627841">百亿级分片，如何设计基因算法？</a></li>
<li><a href="https://mp.weixin.qq.com/s/xGYM0pXAHfaLMpTxBJvLBg">百亿级存储，怎么设计？只是分库分表？</a></li>
</ul>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>备份与恢复</title>
    <url>/undefined/MySQL/2024/11/29/MySQL/%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><p>数据库的备份与恢复是一项最基本的操作与工作。在意外情况下（如服务器宕机、磁盘损坏、RAID 卡损坏等）要保证数据不丢失，或者是最小程度地丢失，每个开发者应该时刻关心所负责的数据库备份情况。</p>
<p>可以根据不同的类型来划分备份的方法。根据备份的方法不同可以将备份分为：</p>
<ul>
<li>Hot Backup（热备）</li>
<li>Cold Backup（冷备）</li>
<li>Warm Backup（温备）</li>
</ul>
<p><strong>Hot Backup</strong> 是指数据库运行中直接备份，对正在运行的数据库操作没有任何的影响。这种方式在 MySQL 官方手册中称为 <strong>Online Backup（在线备份）</strong>。<strong>Cold Backup</strong> 是指备份操作是在数据库停止的情况下，这种备份最为简单，一般只需要复制相关的数据库物理文件即可。这种方式在 MySQL 官方手册中称为 <strong>Offline Backup（离线备份）</strong>。<strong>Warm Backup</strong> 备份同样是在数据库运行中进行的，但是会对当前数据库的操作有所影响，如加一个全局读锁以保证备份数据的一致性。</p>
<p>按照备份后文件的内容，备份又可以分为：</p>
<ul>
<li>逻辑备份</li>
<li>裸文件备份</li>
</ul>
<p>在 MySQL 数据库中，逻辑备份是指备份出的文件内容是可读的，一般是文本文件。内容一般是一条条 SQL 语句，或者是表内实际数据组成。如 mysqldump 和 <code>SELECT * INTO OUTFILE</code> 的方法。这类方法的好处是可以观察导出文件的内容，一般适用于数据库的升级、迁移等工作。但其缺点是恢复所需要的时间往往较长。</p>
<p>裸文件备份是指复制数据库的物理文件，既可以是在数据库运行中的复制（如 ibbackup, xtrabackup 这些工具），也可以是在数据库停止运行时直接的数据文件复制。这类备份的恢复时间往往较逻辑备份短很多。</p>
<p>若按照备份数据库的内容来分，备份又可以分为：</p>
<ul>
<li>完全备份</li>
<li>增量备份</li>
<li>日志备份</li>
</ul>
<p><strong>完全备份</strong> 是指对数据库进行一个完整的备份。<strong>增量备份</strong> 是指在上次完全备份的基础上，对下次更改的数据进行备份。<strong>日志备份</strong> 主要是指对 MySQL 数据库二进制日志的备份，通过对一个完全备份做完二进制日志的重做（replay）来完成数据库的 point-in-time 的恢复工作。MySQL 数据库复制（replication）的原理就是异步实时地将二进制日志重做传送并应用到从（slave&#x2F;standby）数据库。</p>
<p>对于 MySQL 数据库来说，官方没有提供真正的增量备份的方法，大部分是通过二进制日志完成增量备份的工作。这种备份较之真正的增量备份来说，效率还是很低的。假设有一个 100GB 的数据库，要通过二进制日志完成备份，可能同一个页面要执行十多次的 SQL 语句完成真正做的工作。但是对于真正的增量备份来说，只需要记录当前页或最后的检查点的 LSN，如果大于之前全备时的 LSN，则备份该页，否则不用备份，这大大加快了备份的速度和恢复的时间，同时这也是 xtrabackup 工具增量备份的原理。</p>
<p>此外还需要理解数据库备份的一致性，这种备份要求在备份的时候数据在这一时间点上是一致的。举例来说，在一个网络游戏中有一个玩家购买了道具，这个事务的过程是：先扣除相应的金钱，然后向其装备表中插入道具，确保扣费和得到道具是互相一致的。否则，在恢复时，可能出现金钱被扣除了而道具丢失的问题。</p>
<p>对于 InnoDB 存储引擎来说，因为其支持 MVCC 功能，因此实现一致的备份比较简单。用户可以先开启一个事务，然后导出一组相关的表，最后提交。当然用户的事务隔离级别必须设置为 <strong>REPEATABLE READ</strong>，这种做法就可以给出一个完美的一致性备份。然而这个方法的前提是需要用户事先设计应用程序。对于上述的购买道具的过程，不可以分为两个事务来完成，如一个完成扣费，一个完成道具的购买。若备份读操作发生在这两者之间，则由于逻辑设计的问题，导致备份出的数据依然不是一致的。</p>
<p>对于 mysqldump 备份工具来说，可以通过添加 <code>--single-transaction</code> 选项获得 InnoDB 存储引擎的一致性备份，原理和之前所说的相同，也就是，这时的备份是在一个执行时间很长的只读事务中完成的，来保证所有导出的表处于同一时间点的数据视图中。另外，对于 InnoDB 存储引擎的备份，务必加上 -<code>-single-transaction</code> 的选项。如果不加这个选项，mysqldump 会对每个表分别 <code>LOCK TABLES</code> 并导出，会导致数据之间不一致（因为表导出存在先后顺序，前面表导出完了，后面表导出前可能已经被修改）。</p>
<p>最后，任何时候都需要做好远程异地备份，也就是容灾的防范。只是同一机房的两台服务器的备份是远远不够的。</p>
<h2 id="冷备份"><a href="#冷备份" class="headerlink" title="冷备份"></a>冷备份</h2><p>对于 <strong>InnoDB 存储引擎</strong> 的冷备非常简单，只需要备份 MySQL 数据库的 frm 文件、共享表空间文件、独立表空间文件（<code>*.ibd</code>）、重做日志文件。另外建议定期备份 MySQL 数据库的配置文件 <code>my.cnf</code>，这样有利于恢复的操作。</p>
<p>通常我们会写一个脚本来进行冷备的操作，可能还会对备份完成的数据库进行打包和压缩。关键在于不要遗漏原本需要备份的物理文件，如共享表空间和重做日志文件，少了这些文件可能数据库都无法启动。另一种经常发生的情况是由于磁盘空间已满而导致的备份失败，我们可能习惯性地认为运行脚本的备份是没有问题的，少了检验的机制。</p>
<p>正如前面所说的，在同一台机器上对数据库进行冷备是远远不够的，至少还需要将本地产生的备份存放到一台远程的服务器中，确保不会因为本地数据库的宕机而影响备份文件的使用。</p>
<p>冷备的优点是：</p>
<ul>
<li>备份简单，只要复制相关文件即可。</li>
<li>备份文件易于在不同操作系统、不同 MySQL 版本上进行恢复。</li>
<li>恢复相当简单，只需要把文件恢复到指定位置即可。</li>
<li>恢复速度快，不需要执行任何 SQL 语句，也不需要重建索引。</li>
</ul>
<p>冷备的缺点是：</p>
<ul>
<li>InnoDB 存储引擎冷备的文件通常比逻辑文件大很多，因为表空间中存放着很多其他的数据，如 undo 区、插入缓冲等信息。</li>
<li>冷备也不总是可以轻易地跨平台。操作系统、MySQL 的版本、文件大小写敏感和浮点数格式都可能成为问题。</li>
</ul>
<h2 id="逻辑备份"><a href="#逻辑备份" class="headerlink" title="逻辑备份"></a>逻辑备份</h2><h3 id="mysqldump"><a href="#mysqldump" class="headerlink" title="mysqldump"></a>mysqldump</h3><p>mysqldump 是 MySQL 官方提供的逻辑备份工具，用于将数据库中的结构和数据导出为 SQL 语句或其它文本格式，便于恢复、迁移或复制库。它支持单库、多库、单表或全库的备份，也能生成 CSV、XML 等格式文件。导出的文件可以在目标服务器上直接重执行，从而重建原始数据库对象和数据。</p>
<p>基本语法：<code>mysqldump [连接选项] [备份选项] 库名 [表名...] &gt; 备份文件.sql</code></p>
<p>如果要备份单库，可使用：<code>mysqldump -u root -p --single-transaction mydb &gt; mydb_backup.sql</code></p>
<p>如果要备份多库，可使用：<code>mysqldump -u root -p --databases db1 db2 &gt; multi_backup.sql</code></p>
<p>如果要备份全库，可使用：<code>mysqldump -u root -p --all-databases &gt; alldb.sql</code></p>
<p>如果是备份单表并按条件导出，可使用：<code>mysqldump -u root -p mydb orders --where=&quot;order_date &gt;= &#39;2025-01-01&#39;&quot; &gt; orders_jan.sql</code></p>
<p>如果是流式压缩备份，可使用：<code>mysqldump -u root -p mydb | gzip &gt; mydb.sql.gz</code></p>
<p>如果要恢复数据，可使用：<code>mysql -u root -p mydb &lt; mydb_backup.sql</code></p>
<h3 id="mysqlpump"><a href="#mysqlpump" class="headerlink" title="mysqlpump"></a>mysqlpump</h3><p>mysqlpump 采用队列 + 线程模型，对象级并行：</p>
<ul>
<li><strong>队列</strong>：可通过 <code>--parallel-schemas</code> 创建多个队列，每个队列可绑定一个或多个数据库。<ul>
<li><strong>线程</strong>：在每个队列下可指定线程数（<code>--default-parallelism</code>），对同一队列内的对象（表、视图、存储过程等）并行导出。</li>
</ul>
</li>
</ul>
<p>导出对象为一系列可执行的 SQL 语句，包括 CREATE、INSERT、GRANT、CREATE TRIGGER&#x2F;EVENT 等，可跨平台重现数据库结构与数据。</p>
<p>支持对象过滤：通过 <code>--exclude-databases</code>、<code>--include-tables</code>、<code>--exclude-users</code> 等选项灵活选择导出范围。</p>
<p>如果要全库并行备份，可使用：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysqlpump \</span><br><span class="line"> --default-parallelism=4 \</span><br><span class="line"> --parallel-schemas=2 \</span><br><span class="line"> --add-drop-database \</span><br><span class="line"> --routines --triggers --events \</span><br><span class="line"> --users \</span><br><span class="line"> --compress \</span><br><span class="line"> --exclude-databases=information_schema,performance_schema \</span><br><span class="line"><span class="meta prompt_"> &gt; </span><span class="language-bash">full_backup.sql.gz</span></span><br></pre></td></tr></table></figure>

<p>恢复的操作和 mysqldump 的方法一致。</p>
<h3 id="SELECT-…-INTO-OUTFILE"><a href="#SELECT-…-INTO-OUTFILE" class="headerlink" title="SELECT … INTO OUTFILE"></a>SELECT … INTO OUTFILE</h3><p><code>SELECT … INTO OUTFILE</code> 用于将查询结果直接写入服务器主机上的文件，生成的文件可用于后续的批量导入或数据交换。该语句创建的文件必须在服务器文件系统中不存在，并且需要具备 FILE 权限才可执行。</p>
<p>如果要导出为 CSV 格式，可使用：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> customer_id, firstname, surname</span><br><span class="line"><span class="keyword">INTO</span> OUTFILE <span class="string">&#x27;/var/lib/mysql-files/customers.csv&#x27;</span></span><br><span class="line">FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line">OPTIONALLY ENCLOSED <span class="keyword">BY</span> <span class="string">&#x27;&quot;&#x27;</span></span><br><span class="line">LINES TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;\n&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>如果要恢复备份，可使用：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">LOAD DATA INFILE <span class="string">&#x27;/var/lib/mysql-files/customers.csv&#x27;</span></span><br><span class="line"><span class="keyword">INTO</span> <span class="keyword">TABLE</span> mytable</span><br><span class="line">FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;\t&#x27;</span></span><br><span class="line">LINES TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;\n&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>或者</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysqlimport \</span><br><span class="line"> --local \              </span><br><span class="line"> --fields-terminated-by=&#x27;,&#x27; \</span><br><span class="line"> --fields-enclosed-by=&#x27;&quot;&#x27; \</span><br><span class="line"> --lines-terminated-by=&#x27;\r\n&#x27; \</span><br><span class="line"> -u 用户 -p 数据库名 /var/lib/mysql-files/customers.csv</span><br></pre></td></tr></table></figure>

<h2 id="二进制日志的备份"><a href="#二进制日志的备份" class="headerlink" title="二进制日志的备份"></a>二进制日志的备份</h2><p>二进制日志是 MySQL 实现 point-in-time 恢复和异步复制的关键：</p>
<p>point-in-time 恢复：在发生故障后，可以将完全备份与二进制日志配合，重放指定时间段或位置的变更，实现回滚到任意时间点。<br>复制：主库将写入的二进制日志发送给从库，从库重放日志以保持数据同步。</p>
<p>默认情况下 MySQL 并不启用二进制日志，必须在 <code>my.cnf</code> 中添加：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">log-bin = mysql-bin</span><br></pre></td></tr></table></figure>

<p>仅启用 log-bin 不够保险，建议在 <code>my.cnf</code> 中也加上：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">log<span class="operator">-</span>bin <span class="operator">=</span> mysql<span class="operator">-</span>bin</span><br><span class="line">sync_binlog <span class="operator">=</span> <span class="number">1</span></span><br><span class="line">innodb_support_xa <span class="operator">=</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p><code>sync_binlog=1</code>：每次提交时强制将二进制日志刷盘，防止故障时丢失已提交的事务。</p>
<p><code>innodb_support_xa=1</code>：开启 InnoDB 的 XA（分布式事务）支持，保证 binlog 与 InnoDB redo-log 在发生崩溃恢复时的一致性。</p>
<p>在备份二进制日志文件前，可通过 FLUSH LOGS 关闭当前日志文件并新建一个 binlog 文件，便于把之前那些日志一起备份。之后将 <code>mysql-bin.00000*</code> 等文件拷贝到安全位置，与完全备份一起存档。</p>
<p><strong>恢复二进制日志</strong></p>
<p><code>shell&gt; mysqlbinlog [options] mysql-bin.000001 | mysql -u root -p test</code> 可以将指定日志内容通过管道重放到目标库 test。<br>如果要同时恢复多文件，可以使用：<code>shell&gt; mysqlbinlog mysql-bin.00000[1-10] | mysql -u root -p test</code></p>
<p>先导出再 SOURCE 导入：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">shell<span class="operator">&gt;</span> mysqlbinlog mysql<span class="operator">-</span>bin<span class="number">.000001</span> <span class="operator">&gt;</span> <span class="operator">/</span>tmp<span class="operator">/</span>stmts.sql</span><br><span class="line">shell<span class="operator">&gt;</span> mysqlbinlog mysql<span class="operator">-</span>bin<span class="number">.000002</span> <span class="operator">&gt;&gt;</span> <span class="operator">/</span>tmp<span class="operator">/</span>stmts.sql</span><br><span class="line">shell<span class="operator">&gt;</span> mysql <span class="operator">-</span>u root <span class="operator">-</span>p <span class="operator">-</span>e &quot;SOURCE /tmp/stmts.sql&quot;</span><br></pre></td></tr></table></figure>

<p>我们也可以指定恢复的起始点：</p>
<p>按照偏移量：<code>mysqlbinlog --start-position=107856 mysql-bin.000001 | mysql -u root -p test</code></p>
<p>按照时间：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysqlbinlog <span class="comment">--start-datetime=&quot;2025-06-14 12:00:00&quot; \</span></span><br><span class="line">       			<span class="comment">--stop-datetime=&quot;2025-06-14 18:00:00&quot; \</span></span><br><span class="line">       			mysql<span class="operator">-</span>bin<span class="number">.000001</span> <span class="operator">|</span> mysql <span class="operator">-</span>u root <span class="operator">-</span>p test</span><br></pre></td></tr></table></figure>

<p>偏移量和时间选项的效果类似，都能实现仅重放二进制日志的部分内容。</p>
<h2 id="热备份"><a href="#热备份" class="headerlink" title="热备份"></a>热备份</h2><h3 id="ibbackup"><a href="#ibbackup" class="headerlink" title="ibbackup"></a>ibbackup</h3><p>ibbackup 是 InnoDB 存储引擎官方提供的热备工具，可以同时备份 MyISAM 存储引擎和 InnoDB 存储引擎表。对于 InnoDB 存储引擎表，其备份工作原理如下：</p>
<ol>
<li>记录备份开始时，InnoDB 存储引擎重做日志文件检查点的 LSN。</li>
<li>复制共享表空间文件以及独立表空间文件。</li>
<li>记录复制完表空间文件后，InnoDB 存储引擎重做日志文件检查点的 LSN。</li>
<li>复制在备份时产生的重做日志。</li>
</ol>
<p>对于事务型数据库，如 Microsoft SQL Server 数据库和 Oracle 数据库，热备的原理大致相同。可以发现，在备份期间不会对数据库本身有任何影响，所做操作只是复制数据库文件，因此任何对数据库的正常操作都是允许的，不会被阻塞。</p>
<p>ibbackup 的优点有：</p>
<ul>
<li>在线备份，不阻塞任何 SQL 语句。</li>
<li>备份性能好，实质上是复制数据库文件和重做日志文件。</li>
<li>支持压缩备份，通过选项可实现不同级别的压缩。</li>
<li>跨平台支持，可运行于 Linux、Windows 及主流 UNIX 平台。</li>
</ul>
<p>ibbackup 对 InnoDB 存储引擎表的恢复步骤为：</p>
<ol>
<li>恢复表空间文件。</li>
<li>应用重做日志文件。</li>
</ol>
<p>ibbackup 提供了一种高性能的热备方式，是 InnoDB 存储引擎备份的首选方式。不过它是收费软件，并非免费。好在开源社区力量强大，Percona 公司推出了开源、免费的 XtraBackup 热备工具，它不仅实现了 ibbackup 的所有功能，还扩展了真正的增量备份能力。因此，更好的选择是使用 XtraBackup 来完成热备工作。</p>
<p>XtraBackup 文档请参考：<a href="https://docs.percona.com/percona-xtrabackup/8.4/">https://docs.percona.com/percona-xtrabackup/8.4/</a></p>
<h2 id="快照备份"><a href="#快照备份" class="headerlink" title="快照备份"></a>快照备份</h2><p>MySQL 数据库本身不支持快照功能，因此快照备份是指通过文件系统支持的快照功能对数据库进行备份。备份的前提是将所有数据库文件放在同一个文件分区中，然后对该分区进行快照操作。支持快照功能的文件系统和设备包括 FreeBSD 的 UFS 文件系统、Solaris 的 ZFS 文件系统、GNU&#x2F;Linux 的逻辑管理器（Logical Volume Manager，LVM）等。这里以 LVM 为例进行介绍。</p>
<p>LVM 是 LINUX 系统下对磁盘分区进行管理的一种机制。LVM 在硬盘和分区之上建立一个逻辑层，来提高磁盘分区管理的灵活性。管理员可以通过 LVM 系统轻松管理磁盘分区，例如，将若干个磁盘分区连接为一个整体的卷组（Volume Group），形成一个存储池。管理员可以在卷组上随意创建逻辑卷（Logical Volumes），并进一步在逻辑卷上创建文件系统。管理人员通过 LVM 可以方便地调整卷组的大小，并且可以对磁盘存储按照组的方式进行命名、管理和分配。简单地说，用户可以通过 LVM 由物理块设备（如硬盘等）创建物理卷，由一个或多个物理卷创建卷组，最后从卷组中创建任意个逻辑卷（不超过卷组大小），如下图所示。</p>
<p><img src="/../../images/MySQL/mysql_backup_snap.png" alt="img"></p>
<p>下图显示了由多块物理磁盘分区组成的逻辑卷 LV0。</p>
<p><img src="/../../images/MySQL/mysql_backup_LV0.drawio.png" alt="img"></p>
<ul>
<li><strong>Physical disk 0</strong> 拥有分区 <code>/dev/hda1</code>, <code>/dev/hda2</code>, <code>/dev/hda3</code>, <code>/dev/hda4</code>；</li>
<li><strong>Physical disk 1</strong> 拥有分区 <code>/dev/hdb</code>；</li>
<li><strong>Physical disk 2</strong> 拥有分区 <code>/dev/hdd</code>。</li>
</ul>
<p>这些所有物理分区一起被加入到卷组 VG0 中，VG0 上划分出一个逻辑卷 LV0（图中左侧已分配区域），其余空间则作为 free space（图中右侧虚线区域）可供以后创建更多逻辑卷或扩展现有逻辑卷使用。</p>
<p>LVM 使用了写时复制（Copy-on-write）技术来创建快照。当创建一个快照时，仅复制原始卷中数据的元数据，并不会有数据的物理操作，因此快照的创建过程是非常快的。当快照创建完成，原始卷上有写操作时，快照会跟踪原始卷块的改变，将要改变的数据在改变之前复制到快照预留的空间里，因此这个原理的实现叫做写时复制。而对于快照的读取操作，如果读取的数据块是创建快照后没有修改过的，那么会将读取操作直接定向到原始卷上；如果读取的是已修改过的块，则将读取保存在快照中该块在原始卷上改变之前的数据。因此，采用写时复制机制保证了读取快照时得到的数据与快照创建时一致。</p>
<p>下图显示了 LVM 的快照读取，可见 B 区块被修改了，因此历史数据放入了快照区域。读取快照数据时，A、C、D 块还是从原有卷中读取，而 B 块就需要从快照读取了。</p>
<p><img src="/../../images/MySQL/mysql_backup_LVM.drawio.png" alt="img"></p>
<p>快照在最初创建时总是很小，当数据源卷的数据不断被修改时，这些数据才会放入快照空间，这时快照的大小才会慢慢增大。</p>
<p>为了让快照包含所有必要的数据，只要把 InnoDB 的所有相关文件（共享表空间文件、独立表空间文件、redo log 文件等）都放在同一个逻辑卷里。创建快照时，就会对整个逻辑卷进行一次时间点一致性的镜像。</p>
<p>在创建和使用 LVM 快照备份时，MySQL &#x2F; InnoDB 不需要停机，应用仍可以继续正常读写。虽然备份过程中还有写操作在往磁盘上提交，但快照机制会保证备份那一刻的数据完整性，不会捕获到部分写入的脏状态。</p>
<p>当你用 LVM 快照恢复文件后，InnoDB 会像意外断电重启那样：自动扫描数据页和 redo log，决定哪些事务需要重做或回滚，最后恢复到一个一致的、可用的数据库状态。因此，用 LVM 快照做备份，恢复后就像给数据库做了一次意外重启，但数据完全一致且不会丢失已提交的事务。</p>
<h2 id="复制"><a href="#复制" class="headerlink" title="复制"></a>复制</h2><p>复制（replication）是 MySQL 数据库提供的一种高可用高性能的解决方案，一般用来建立大型的应用。总体来说，replication 的工作原理分为以下 3 个步骤：</p>
<p>1）主服务器把数据更改记录到二进制日志中。</p>
<p>2）从服务器把主服务器的二进制日志复制到自己的中继日志（relay log）中。</p>
<p>3）从服务器重做中继日志中的日志项，把更改应用到自己的数据库上，以达到数据的最终一致性。</p>
<p>复制的工作原理并不复杂，其实就是一个完全备份加上二进制日志备份的还原。不同的是这个二进制日志的还原操作基本上实时在进行中。这里特别需要注意的是，复制不是完全实时地进行同步，而是异步实时。这中间存在主从服务器之间的执行延时，如果主服务器的压力很大，则可能导致主从服务器延时较大。复制的工作原理如下图所示。</p>
<p><img src="/../../images/MySQL/mysql_replic_ms.drawio.png" alt="img"></p>
<p>从服务器有 2 个线程，一个是 I&#x2F;O 线程，负责读取主服务器的二进制日志，并将其保存为中继日志；另一个是 SQL 线程，复制执行中继日志。因此如果查看一个从服务器的状态，应该可以看到类似如下内容：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SHOW</span> <span class="keyword">FULL</span> PROCESSLIST\G</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">  Id: <span class="number">1</span></span><br><span class="line">  <span class="keyword">User</span>: <span class="keyword">system</span> <span class="keyword">user</span></span><br><span class="line">  Host:</span><br><span class="line">  db: <span class="keyword">NULL</span></span><br><span class="line">	Command: <span class="keyword">Connect</span></span><br><span class="line">  <span class="type">Time</span>: <span class="number">6501</span></span><br><span class="line"> 	State: Waiting <span class="keyword">for</span> master <span class="keyword">to</span> send event</span><br><span class="line">  Info: <span class="keyword">NULL</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">2.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">  Id: <span class="number">2</span></span><br><span class="line">  <span class="keyword">User</span>: <span class="keyword">system</span> <span class="keyword">user</span></span><br><span class="line">  Host:</span><br><span class="line">  db: <span class="keyword">NULL</span></span><br><span class="line">	Command: <span class="keyword">Connect</span></span><br><span class="line">  <span class="type">Time</span>: <span class="number">0</span></span><br><span class="line"> 	State: Has read <span class="keyword">all</span> relay log; waiting <span class="keyword">for</span> the slave I<span class="operator">/</span>O thread <span class="keyword">to</span> <span class="keyword">update</span> it</span><br><span class="line">  Info: <span class="keyword">NULL</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">3.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">  Id: <span class="number">206</span></span><br><span class="line">  <span class="keyword">User</span>: root</span><br><span class="line">  Host: localhost</span><br><span class="line">  db: <span class="keyword">NULL</span></span><br><span class="line">	Command: Query</span><br><span class="line">  <span class="type">Time</span>: <span class="number">0</span></span><br><span class="line"> 	State: <span class="keyword">NULL</span></span><br><span class="line">  Info: <span class="keyword">SHOW</span> <span class="keyword">FULL</span> PROCESSLIST</span><br><span class="line"><span class="number">3</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<p>可以看到 ID 为 1 的线程就是 I&#x2F;O 线程，当前的状态是等待主服务器发送二进制日志。 </p>
<p>ID 为 2 的线程是 SQL 线程，负责读取中继日志并执行。目前的状态是已读取所有的中继日志，等待中继日志被 I&#x2F;O 线程更新。 </p>
<p>在 replication 的主服务器上应该可以看到一个线程负责发送二进制日志，类似内容如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SHOW</span> <span class="keyword">FULL</span> PROCESSLIST\G </span><br><span class="line">…… </span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">65.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> </span><br><span class="line">  Id: <span class="number">26541</span> </span><br><span class="line">  <span class="keyword">User</span>: rep </span><br><span class="line">  Host: <span class="number">192.168</span><span class="number">.190</span><span class="number">.98</span>:<span class="number">39549</span> </span><br><span class="line">  db: <span class="keyword">NULL</span> </span><br><span class="line">	Command: Binlog Dump </span><br><span class="line">  <span class="type">Time</span>: <span class="number">6857</span> </span><br><span class="line"> 	State: Has sent <span class="keyword">all</span> binlog <span class="keyword">to</span> slave; waiting <span class="keyword">for</span> binlog <span class="keyword">to</span> be updated </span><br><span class="line">  Info: <span class="keyword">NULL</span> </span><br><span class="line">…… </span><br></pre></td></tr></table></figure>

<p>之前提到 MySQL 的复制是异步实时的，并非完全的主从同步。若用户要想得知当前的延迟，可以通过命令 <code>SHOW SLAVE STATUS</code> 和 <code>SHOW MASTER STATUS</code> 得知。</p>
<p>示例：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SHOW</span> SLAVE STATUS\G</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">   Slave_IO_State: Waiting <span class="keyword">for</span> master <span class="keyword">to</span> send event</span><br><span class="line">   Master_Host: <span class="number">192.168</span><span class="number">.190</span><span class="number">.10</span></span><br><span class="line">   Master_User: rep</span><br><span class="line">   Master_Port: <span class="number">3306</span></span><br><span class="line">   Connect_Retry: <span class="number">60</span></span><br><span class="line">   Master_Log_File: mysql<span class="operator">-</span>bin<span class="number">.000007</span></span><br><span class="line">   Read_Master_Log_Pos: <span class="number">555176471</span></span><br><span class="line">   Relay_Log_File: gamedb<span class="operator">-</span>relay<span class="operator">-</span>bin<span class="number">.000048</span></span><br><span class="line">   Relay_Log_Pos: <span class="number">224355889</span></span><br><span class="line">   Relay_Master_Log_File: mysql<span class="operator">-</span>bin<span class="number">.000007</span></span><br><span class="line">   Slave_IO_Running: Yes</span><br><span class="line">   Slave_SQL_Running: Yes</span><br><span class="line">   Replicate_Do_DB:</span><br><span class="line">   Replicate_Ignore_DB:</span><br><span class="line">   Replicate_Do_Table:</span><br><span class="line">   Replicate_Ignore_Table:</span><br><span class="line">   Replicate_Wild_Do_Table:</span><br><span class="line">	 Replicate_Wild_Ignore_Table: mysql.<span class="operator">%</span>,DBA.<span class="operator">%</span></span><br><span class="line">   Last_Errno: <span class="number">0</span></span><br><span class="line">   Last_Error:</span><br><span class="line">   Skip_Counter: <span class="number">0</span></span><br><span class="line">   Exec_Master_Log_Pos: <span class="number">555176471</span></span><br><span class="line">   Relay_Log_Space: <span class="number">224356045</span></span><br><span class="line">   Until_Condition: <span class="keyword">None</span></span><br><span class="line">   Until_Log_File:</span><br><span class="line">   Until_Log_Pos: <span class="number">0</span></span><br><span class="line">   Master_SSL_Allowed: <span class="keyword">No</span></span><br><span class="line">   Master_SSL_CA_File:</span><br><span class="line">   Master_SSL_CA_Path:</span><br><span class="line">   Master_SSL_Cert:</span><br><span class="line">   Master_SSL_Cipher:</span><br><span class="line">   Master_SSL_Key:</span><br><span class="line"> 	 Seconds_Behind_Master: <span class="number">0</span></span><br><span class="line">	 Master_SSL_Verify_Server_Cert: <span class="keyword">No</span></span><br><span class="line">   Last_IO_Errno: <span class="number">0</span></span><br><span class="line">   Last_IO_Error:</span><br><span class="line">   Last_SQL_Errno: <span class="number">0</span></span><br><span class="line">   Last_SQL_Error:</span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<p>以上结果中的各个字段的含义如下所示：</p>
<table>
<thead>
<tr>
<th><strong>变量</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td>Slave_IO_State</td>
<td>当前 I&#x2F;O 线程的状态，此例为 “Waiting for master to send event”（等待主库发送新的 binlog 事件）</td>
</tr>
<tr>
<td>Master_Log_File</td>
<td>当前从库正在读取的主库 binlog 文件名，本例为 mysql-bin.000007</td>
</tr>
<tr>
<td>Read_Master_Log_Pos</td>
<td>从库已读取到的主库 binlog 偏移位置（字节）；本例 555176471 表示已读入约 529 MB（555176471&#x2F;1024²）</td>
</tr>
<tr>
<td>Relay_Master_Log_File</td>
<td>从库中继日志对应的主库 binlog 文件名</td>
</tr>
<tr>
<td>Relay_Log_File</td>
<td>当前写入的中继日志文件名</td>
</tr>
<tr>
<td>Relay_Log_Pos</td>
<td>已执行到中继日志的偏移位置（字节）</td>
</tr>
<tr>
<td>Slave_IO_Running</td>
<td>从库 I&#x2F;O 线程运行状态，YES 表示正常</td>
</tr>
<tr>
<td>Slave_SQL_Running</td>
<td>从库 SQL 线程运行状态，YES 表示正常</td>
</tr>
<tr>
<td>Exec_Master_Log_Pos</td>
<td>SQL 线程已执行到的主库 binlog 偏移位置；Read_Master_Log_Pos - Exec_Master_Log_Pos 即 I&#x2F;O 与 SQL 线程之间的“字节延迟”</td>
</tr>
</tbody></table>
<p><code>SHOW MASTER STATUS</code> 可以用来查看主服务器中二进制日志的状态，如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SHOW</span> MASTER STATUS\G</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line"> File: mysql<span class="operator">-</span>bin<span class="number">.000007</span></span><br><span class="line"> Position: <span class="number">606181078</span></span><br><span class="line"> Binlog_Do_DB:</span><br><span class="line"> Binlog_Ignore_DB:</span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.01</span> sec)</span><br></pre></td></tr></table></figure>

<p>可以看到，当前二进制日志记录了偏移量 606181078 的位置，该值减去这一时间点时从服务器上的 <code>Read_Master_Log_Pos</code>，就可以得知 I&#x2F;O 线程的延时。</p>
<p>，用户不应仅监控从服务器上 I&#x2F;O 线程和 SQL 线程是否运行正常，同时也应监控从服务器与主服务器之间的延迟，确保从服务器上的数据尽可能接近主服务器上的状态。</p>
<h3 id="快照-复制的备份架构"><a href="#快照-复制的备份架构" class="headerlink" title="快照 + 复制的备份架构"></a>快照 + 复制的备份架构</h3><p>复制可以用来作为备份，但功能不仅限于备份，其主要功能如下： </p>
<ul>
<li>数据分布。由于 MySQL 数据库提供的复制并不需要很大的带宽要求，因此可以在不同的数据中心之间实现数据的复制。 </li>
<li>读取的负载平衡。通过建立多个从服务器，可将读取平均地分布到这些从服务器中，并且减少了主服务器的压力。一般通过 DNS 的 Round-Robin 和 Linux 的 LVS 功能都可以实现负载平衡。 </li>
<li>数据库备份。复制对备份很有帮助，但是从服务器不是备份，不能完全代替备份。 </li>
<li>高可用性和故障转移。通过复制建立的从服务器有助于故障转移，减少故障的停机时间和恢复时间。</li>
</ul>
<p>可见，只是用复制来进行备份是远远不够的。也就是说，<strong>仅靠主从复制无法完全防护数据丢失或误操作</strong>，需要结合<strong>从库的存储快照</strong>和<strong>二进制日志重放</strong>来实现对任意时间点的恢复与一致性保障。</p>
<p>假设当前应用采用了主从的复制架构，从服务器作为备份。此时，一个开发人员执行了误操作，如 <code>DROP DATABASE</code> 或 <code>DROP TABLE</code>，这时从服务器也跟着运行了。用户怎样从从服务器进行恢复呢？ </p>
<p>因此，一个比较好的方法是通过对从服务器上的数据库所在分区做快照，以此来避免误操作对复制造成影响。当发生主服务器上的误操作时，只需要将从服务器上的快照进行恢复，然后再根据二进制日志进行 point-in-time 的恢复即可。因此快照 + 复制的备份架构如下图所示。 </p>
<p><img src="/../../images/MySQL/mysql_replic_snap_binlog.drawio.png" alt="img"></p>
<p>还有一些其他的方法来调整复制，比如采用延时复制，即间歇性地开启从服务器上的同步，保证大约一小时的延时，可对抗误操作。这的确也是一个方法，只是数据库在高峰和非高峰期间每小时产生的二进制日志量是不同的，用户很难精确地控制。另外，这种方法也不能完全起到对误操作的防范作用。 </p>
<p>此外，建议在从服务器上启用 read-only 选项，这样能保证从服务器上的数据仅与主服务器进行同步，避免其他线程修改数据。如： </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">read-only</span><br></pre></td></tr></table></figure>

<p>在启用 read-only 选项后，如果操作从服务器的用户没有 SUPER 权限，则对从服务器进行任何的修改操作会抛出一个错误，如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> z <span class="keyword">SELECT</span> <span class="number">2</span>; </span><br><span class="line">ERROR <span class="number">1290</span> (HY000): The MySQL server <span class="keyword">is</span> <span class="keyword">running</span> <span class="keyword">with</span> the <span class="comment">--read-only option so it cannot execute this statement</span></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>多表查询</title>
    <url>/undefined/MySQL/2024/09/22/MySQL/%E5%A4%9A%E8%A1%A8%E6%9F%A5%E8%AF%A2/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h1 id="多表关系"><a href="#多表关系" class="headerlink" title="多表关系"></a>多表关系</h1><ul>
<li>一对多：在多的一方建立外键，指向一的一方的主键。如：部门-员工。</li>
<li>多对多：建立第三张中间表，其中至少包含两个外键，分别关联两方主键。如：学生-课程。</li>
<li>一对一：用于单表拆分，将一张表的基础字段放在一张表中，其他详情字段放在另一张表中，以提升操作效率。在任意一方加入外键，关联另一方的主键，并且设置外键为唯一（UNIQUE） 。</li>
</ul>
<blockquote>
<p>[!NOTE]</p>
<p>在多表查询时，需要消除无效的笛卡尔积。</p>
</blockquote>
<h1 id="连接查询"><a href="#连接查询" class="headerlink" title="连接查询"></a>连接查询</h1><h2 id="内连接"><a href="#内连接" class="headerlink" title="内连接"></a>内连接</h2><p>相当于查询两张表交集部分数据。</p>
<ul>
<li>隐式内连接：<code>SELECT 字段列表 FROM 表1，表2 WHERE 条件;</code></li>
<li>显式内连接 ：<code>SELECT 字段列表 FROM 表1 [INNER] JOIN 表2 ON 连接条件;</code></li>
</ul>
<h2 id="外连接"><a href="#外连接" class="headerlink" title="外连接"></a>外连接</h2><p>左外连接：查询左表所有数据，以及两张表交集部分数据。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> 字段列表 <span class="keyword">FROM</span> 表<span class="number">1</span> <span class="keyword">LEFT</span> [<span class="keyword">OUTER</span>] <span class="keyword">JOIN</span> 表<span class="number">2</span> <span class="keyword">ON</span> 条件;</span><br></pre></td></tr></table></figure>

<p>右外连接：查询右表所有数据，以及两张表交集部分数据。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> 字段列表 <span class="keyword">FROM</span> 表<span class="number">1</span> <span class="keyword">RIGHT</span> [<span class="keyword">OUTER</span>] <span class="keyword">JOIN</span> 表<span class="number">2</span> <span class="keyword">ON</span> 条件;</span><br></pre></td></tr></table></figure>

<p>自连接：当前表与自身的连接查询，必须使用表别名。可以是内连接，也可以是外连接。</p>
<p>联合查询：把多次查询的结果合并以形成一个新的查询结果集。不使用 ALL 的时候，有去重效果。联合查询的多张表之间的列数和字段类型需要<strong>保持一致</strong>。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> 字段列表 <span class="keyword">FROM</span> 表<span class="number">1</span> <span class="keyword">UNION</span> [<span class="keyword">ALL</span>] <span class="keyword">SELECT</span> 字段列表 <span class="keyword">FROM</span> 表<span class="number">2</span>;</span><br></pre></td></tr></table></figure>

<h1 id="子查询"><a href="#子查询" class="headerlink" title="子查询"></a>子查询</h1><p>SQL语句中嵌套 SELECT 语句，外部语句可以是 INSERT&#x2F;UPDATE&#x2F;DELETE&#x2F;SELECT 中任何一个。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> 表名 <span class="keyword">WHERE</span> col <span class="operator">=</span> (<span class="keyword">SELECT</span> col <span class="keyword">FROM</span> 表<span class="number">2</span>);</span><br></pre></td></tr></table></figure>

<h2 id="子查询种类"><a href="#子查询种类" class="headerlink" title="子查询种类"></a>子查询种类</h2><p>根据结果</p>
<ul>
<li>标量子查询：返回结果是单个值。</li>
<li>列子查询：返回结果是一列。</li>
<li>行子查询：返回结果是一行（可以是多列）。</li>
<li>表子查询：返回结果是多行多列。</li>
</ul>
<p>根据位置：WHERE 之后，FROM 之后，SELECT 之后。</p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>性能调优</title>
    <url>/undefined/MySQL/2024/12/04/MySQL/%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h2 id="选择合适的-CPU"><a href="#选择合适的-CPU" class="headerlink" title="选择合适的 CPU"></a>选择合适的 CPU</h2><p>一般而言，当前数据库的应用类型可分为两大类：OLTP（Online Transaction Processing，在线事务处理）和 OLAP（Online Analytical Processing，在线分析处理）。这是两种截然不同的数据库应用。OLAP 多用于数据仓库或数据集中，一般需要执行复杂的 SQL 语句来进行查询；OLTP 多用于日常的事务性应用中，如银行交易、在线商品交易、Blog、网络游戏等应用。相对于 OLAP，OLTP 应用中的数据库容量较小。</p>
<p>InnoDB 存储引擎一般都应用于 OLTP 的数据库应用，这种应用的特点如下：</p>
<ul>
<li>用户操作的并发量大；</li>
<li>事务处理的时间一般比较短；</li>
<li>查询的语句较为简单，一般走索引；</li>
<li>复杂的查询较少。</li>
</ul>
<p>可以看出，OLTP 的数据库应用本身对 CPU 的要求并不是很高，因为复杂的查询（如排序、连接等）非常耗费 CPU，而这些操作在 OLTP 应用中较少发生。因此，可以说：<strong>OLAP</strong> 是 <strong>CPU 密集型</strong>的操作，<strong>OLTP</strong> 是 <strong>I&#x2F;O 密集型</strong>的操作。建议在采购服务器时，将更多注意力放在 I&#x2F;O 性能的配置上。</p>
<p><strong>OLTP 为主</strong>：优先关注存储子系统性能，CPU 核数 4–8 核即可满足大多数场景，多核有助于并发连接处理；单语句并行受限于 MySQL 内核，需依赖多会话并发提升吞吐。</p>
<p><strong>OLAP 为主</strong>：建议选用多核高主频机器，如 16–32 核以上，同时配合支持并行查询的引擎（Aurora&#x2F;MySQL HeatWave）以充分发挥 CPU 性能。</p>
<p>为了支持多核应用，我们可以考虑 InnoDB 并行特性与调优：</p>
<p><strong>并行 I&#x2F;O 线程</strong></p>
<ul>
<li><p><code>innodb_read_io_threads</code> 与 <code>innodb_write_io_threads</code> 默认均为 4，或为可用逻辑处理器数的一半，且最小为 4；可手动增至与 CPU 核数相同，提升 I&#x2F;O 吞吐。</p>
</li>
<li><p>合理设置范围为 1–64，具体值需结合存储性能与并发需求测试。</p>
</li>
</ul>
<p><strong>并行索引扫描</strong></p>
<p>MySQL 8.0.14 起支持 <code>innodb_parallel_read_threads</code>，可并行扫描聚簇索引子树，加速诸如 <code>CHECK TABLE</code>、<code>COUNT(*)</code> 等操作。默认值为可用 CPU 数，或根据系统特性自动调整；在多核机上带来显著读取性能提升。</p>
<p><strong>并行 DDL 构建</strong></p>
<p>从 MySQL 8.0.27 起，<code>innodb_ddl_threads</code> 使在线创建二级索引时可并发执行多线程，显著缩短大表的 DDL 时间。</p>
<h2 id="内存的重要性"><a href="#内存的重要性" class="headerlink" title="内存的重要性"></a>内存的重要性</h2><p>InnoDB 将数据和索引缓存在一个很大的缓冲池中，即 InnoDB Buffer Pool。因此，内存的大小直接影响了数据库的性能。</p>
<p>Percona 公司的 CTO Vadim 对此做了一次测试，以此反映内存的重要性：数据和索引总大小为 18 GB，然后将缓冲池的大小分别设为 2 GB、4 GB、6 GB、8 GB、10 GB、12 GB、14 GB、16 GB、18 GB、20 GB、22 GB，再进行 sysbench 的测试。可以发现，随着缓冲池的增大，测试结果 TPS（Transactions Per Second）会线性增长。当缓冲池增大到 20 GB 和 22 GB 时，数据库的性能有了极大的提高，因为此时缓冲池的大小已经大于数据文件本身的大小，所有对数据文件的操作都可以在内存中进行。因此，这时的性能应该是最优的，再增大缓冲池并不能再提高数据库的性能。</p>
<p>所以，<strong>应该在开发应用前预估活跃数据库的大小是多少，并以此确定数据库服务器内存的大小。当然，要使用更多的内存还必须使用 64 位的操作系统。</strong></p>
<p>如何判断当前数据库的内存是否已经达到瓶颈了呢？可以通过查看当前服务器的状态，比较物理磁盘的读取和内存读取的比例来判断缓冲池的命中率，通常 InnoDB 存储引擎的缓冲池命中率不应该小于 99%，如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SHOW</span> <span class="keyword">GLOBAL</span> STATUS <span class="keyword">LIKE</span> <span class="string">&#x27;innodb%read%&#x27;</span>\G</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">Variable_name: Innodb_buffer_pool_read_ahead</span><br><span class="line"><span class="keyword">Value</span>: <span class="number">0</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">2.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">Variable_name: Innodb_buffer_pool_read_ahead_evicted</span><br><span class="line"><span class="keyword">Value</span>: <span class="number">0</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">3.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">Variable_name: Innodb_buffer_pool_read_requests</span><br><span class="line"><span class="keyword">Value</span>: <span class="number">167051313</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">4.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">Variable_name: Innodb_buffer_pool_reads</span><br><span class="line"><span class="keyword">Value</span>: <span class="number">129236</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">5.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">Variable_name: Innodb_data_pending_reads</span><br><span class="line"><span class="keyword">Value</span>: <span class="number">0</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">6.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">Variable_name: Innodb_data_read</span><br><span class="line"><span class="keyword">Value</span>: <span class="number">2135642112</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">7.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">Variable_name: Innodb_data_reads</span><br><span class="line"><span class="keyword">Value</span>: <span class="number">130309</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">8.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">Variable_name: Innodb_pages_read</span><br><span class="line"><span class="keyword">Value</span>: <span class="number">130215</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">9.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">Variable_name: Innodb_rows_read</span><br><span class="line"><span class="keyword">Value</span>: <span class="number">17651085</span></span><br><span class="line"><span class="number">9</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<p>上述参数的具体含义如下表所示：</p>
<table>
<thead>
<tr>
<th><strong>参数</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td>Innodb_buffer_pool_reads</td>
<td>表示从物理磁盘读取页的次数</td>
</tr>
<tr>
<td>Innodb_buffer_pool_read_ahead</td>
<td>预读的次数</td>
</tr>
<tr>
<td>Innodb_buffer_pool_read_ahead_evicted</td>
<td>预读的页，但是没有被读取就从缓冲池中被替换的页的数量，一般用来判断预读的效率</td>
</tr>
<tr>
<td>Innodb_buffer_pool_read_requests</td>
<td>从缓冲池中读取页的次数</td>
</tr>
<tr>
<td>Innodb_data_read</td>
<td>总共读入的字节数</td>
</tr>
<tr>
<td>Innodb_data_reads</td>
<td>发起读请求的次数，每次读取可能需要读取多个页</td>
</tr>
</tbody></table>
<p>以下公式可以计算各种对缓冲池的操作：<br>$$\text{缓冲池命中率} &#x3D;<br>  \frac{\text{Innodb_buffer_pool_read_requests}}<br>       {\text{Innodb_buffer_pool_read_requests} + \text{Innodb_buffer_pool_read_ahead} + \text{Innodb_buffer_pool_reads}}$$<br>$$\text{平均每次读取的字节数} &#x3D;<br>  \frac{\text{Innodb_data_read}}{\text{Innodb_data_reads}}$$</p>
<p>从上面的例子看，<code>缓冲池命中率 = 167 051 313 / (167 051 313 + 129 236 + 0) ≈ 99.92%</code>。</p>
<p>即使缓冲池的大小已经大于数据库文件的大小，这也并不意味着没有磁盘操作。数据库的缓冲池只是一个用来存放热点的区域，后台的线程还负责将脏页异步地写入到磁盘。此外，每次事务提交时还需要将日志写入重做日志文件。</p>
<h2 id="硬盘的选择"><a href="#硬盘的选择" class="headerlink" title="硬盘的选择"></a>硬盘的选择</h2><h3 id="传统机械硬盘（HDD）"><a href="#传统机械硬盘（HDD）" class="headerlink" title="传统机械硬盘（HDD）"></a>传统机械硬盘（HDD）</h3><p>在现代数据库系统中，存储子系统的性能直接影响到应用的响应速度和吞吐能力。传统机械硬盘依赖旋转盘片和寻道臂，虽然成熟稳定，却在随机访问场景中存在较高的延迟；固态硬盘以闪存为存储介质，通过消除机械部件带来了数百倍的随机 I&#x2F;O 性能提升；而 NVMe 接口的固态硬盘则更进一步，通过 PCIe 通道实现更低的延迟和更高的并发吞吐。针对这些不同类型的硬盘，MySQL 提供了多项优化参数和社区方案，以充分利用闪存特性并扩展内存缓冲池，从而在 OLTP 和 OLAP 场景中都能获得优异的数据库性能。</p>
<p>传统机械硬盘的主要性能指标包括寻道时间和转速。寻道时间指从发出读写指令到磁头到达目标扇区所需的时间，目前高端 SAS 硬盘的平均寻道时间约为三毫秒；转速以每分钟转数（RPM）计量，常见值为 7200RPM 和 15000RPM。由于机械硬盘在数据访问时需要进行磁头定位和盘片旋转，随机 I&#x2F;O 操作的响应时间通常在数毫秒级别，而顺序读写则能达到上百兆字节每秒的吞吐。为提高性能和可靠性，生产环境中常将多块机械硬盘通过 RAID 0 或 RAID 10 组合，以提升顺序吞吐和分散热点。</p>
<h3 id="固态硬盘"><a href="#固态硬盘" class="headerlink" title="固态硬盘"></a>固态硬盘</h3><p>固态硬盘，也称基于闪存的固态硬盘，是近年来出现的一种新型存储设备，它内部由闪存颗粒（Flash Memory）组成，具有低延迟、低功耗和抗震性等优点。传统机械硬盘依赖磁头寻道和旋转延迟，固态硬盘无需机械移动部件，因而能提供一致的随机访问时间，一般小于0.1毫秒。闪存中的数据不可直接覆盖写入，只能通过扇区（sector）或块级的擦除（erase）操作来重写，在擦除前需要先对整个擦除块进行擦除，该擦除块大小通常是128KB或256KB，并且每个擦除块有写入次数的寿命限制，需要配合垃圾回收和磨损均衡算法来解决写入次数限制问题。固态硬盘的控制器会将主机的逻辑地址映射成实际的物理地址，写操作同时需要更新映射表，带来额外的开销，但相对于机械硬盘的寻道和旋转延迟，这些开销仍然较低。</p>
<p>在数据库领域，尤其是 MySQL 的 InnoDB 存储引擎中，充分利用固态硬盘所带来的高 IOPS 特性是提升性能的重要手段之一。在 InnoDB 中，可以通过调整 <code>innodb_io_capacity</code> 和 <code>innodb_io_capacity_max</code> 参数来控制后台 I&#x2F;O 的并发数和速率，使得刷新操作更加均匀且高效，对于 SSD 存储，一般建议将这两个参数设置为几万甚至更高的值，以充分发挥闪存的并行读写能力。除此之外，还可以使用 InnoDB 8.0 系列中提供的 L2 Cache 解决方案，将 SSD 作为二级缓存层，以进一步扩充内存缓冲池的容量，从而降低对主存的依赖并提升数据库整体吞吐量。Facebook 推出的 Flash Cache 和 Percona 的 Flashcache 等方案也能在操作系统层面提供类似功能，但 InnoDB 原生的 L2 Cache 与存储引擎深度集成，能够获得更好的效果。</p>
<p>优化 InnoDB 磁盘 I&#x2F;O 还可以从以下几个方面入手：首先，将 <code>innodb_buffer_pool_size</code> 设置为系统内存的 50% 到 75%，这样大部分热数据可以缓存在内存中，减少对磁盘的访问需求。其次，将 <code>innodb_flush_method</code> 设置为 O_DIRECT，避免文件系统缓存与 InnoDB 缓冲池之间的双重缓存带来的不必要 I&#x2F;O 开销。再者，根据操作系统和硬件特性，选择合适的 I&#x2F;O 调度器，例如在 Linux 上使用 noop 或 deadline 调度器，以减少调度延迟并配合 SSD 的并行特性。另外，当系统物理内存充足时，应尽量避免使用交换空间，因为即使是 SSD，频繁的交换也会缩短其寿命并带来不必要的写放大效应。</p>
<h2 id="操作系统的选择"><a href="#操作系统的选择" class="headerlink" title="操作系统的选择"></a>操作系统的选择</h2><p>操作系统的选择和调优对数据库的响应速度、并发处理能力以及 I&#x2F;O 性能具有至关重要的影响。合适的 OS 及其配置不仅能够发挥底层硬件的最大性能，还能减少不必要的系统开销，从而提升 MySQL 的整体吞吐量与稳定性。</p>
<p><strong>Linux vs. Windows vs. BSD</strong></p>
<ul>
<li>Linux：MySQL 在 Linux&#x2F;Unix 平台上经过了长期优化，社区与厂商（包括 Oracle）主要以 Linux 为开发和测试环境，因此在性能和兼容性方面通常优于 Windows。Linux 的轻量内核和丰富的工具链也有助于更精细的调优和故障排查。</li>
<li>Windows：尽管 MySQL 支持 Windows，但在高并发、大规模生产环境下，不如 Linux 稳定，且 Windows Server 的授权费用和系统开销较高。</li>
<li>BSD&#x2F;macOS：较少用于生产环境，社区支持与文档相对有限，调优经验不如 Linux 丰富。</li>
</ul>
<p>Linux 发行版与版本选择</p>
<p>发行版推荐</p>
<ul>
<li>RHEL 及衍生版（CentOS、Rocky Linux、Oracle Linux）：长期支持（LTS）版本稳定，企业级特性丰富，文档与社区调优经验充足。</li>
<li>Debian&#x2F;Ubuntu Server：包管理灵活，社区活跃，适合快速迭代与测试环境；Ubuntu LTS 版本也可用于生产，但需注意内核参数差异。</li>
<li>其他（SUSE、Arch 等）：在特定场景下可用，但社区调优资料相对较少。</li>
</ul>
<p>内核版本的话，优先选择稳定的 LTS 内核（如 5.x 系列），以获得长期安全和性能更新；可根据硬件特性（如最新 NVMe SSD）适当测试更高版本内核的性能优势。</p>
<h2 id="文件系统的选择"><a href="#文件系统的选择" class="headerlink" title="文件系统的选择"></a>文件系统的选择</h2><p>不同文件系统在并发 I&#x2F;O 性能、数据完整性保障、快照支持和对闪存设备的优化上各有侧重。一般而言，若以大文件吞吐和并发写入为主，可优先考虑 XFS；若追求成熟稳定和通用场景，可选用 ext4；若需要原生快照、子卷和校验功能，可考虑 Btrfs；若对数据完整性和自我修复有极致需求，可采用 ZFS；若存储介质为 NAND 闪存且写放大需严格控制，则 F2FS 是最佳方案。</p>
<p>在需要处理海量大文件或日志聚合的场景下，XFS 拥有优异的并发写入性能和在线扩展能力，能够在多线程写入时保持稳定吞吐。</p>
<p>对于大量小文件的创建、删除和元数据访问，ext4 表现更加均衡，元数据操作延迟较低，且社区支持度极高。</p>
<p>Btrfs 和 ZFS 均内置数据与元数据校验和机制，可以在读写时检测并自动修复错误，显著提高数据完整性保障。</p>
<p>ZFS 采用 Copy-On-Write 事务模型，所有写入先在新块上完成，元数据与数据层层校验后再引用，有助于避免因崩溃导致的不一致状态。</p>
<p>Btrfs 原生支持轻量级子卷与快照，通过写时复制技术，创建快照几乎零成本，便于在线备份和回滚。</p>
<p>ZFS 快照同样高效，一旦创建可立即生效且节省空间，并可通过 zfs send&#x2F;recv 在集群或异地环境中可靠地迁移数据集。</p>
<p>Btrfs 支持透明在线压缩，既能节省存储空间，也能降低 SSD 写入量；ZFS 则提供多种压缩算法（如 LZ4），可根据性能与压缩率需求灵活选择。</p>
<p>F2FS 是针对 NAND 闪存设计的日志结构文件系统，通过减少写放大和高效的清理机制，提高中低端 SSD 和 eMMC 的使用寿命与性能。</p>
<h2 id="RAID-的设置"><a href="#RAID-的设置" class="headerlink" title="RAID 的设置"></a>RAID 的设置</h2><p>RAID（Redundant Array of Independent Disks，独立磁盘冗余阵列）的基本思想就是把多个相对便宜的硬盘组合起来，成为一个磁盘数组，使性能达到甚至超过一个价格昂贵、容量巨大的硬盘。由于将多个硬盘组合成一个逻辑扇区，RAID 看起来就像一个单独的硬盘或逻辑存储单元，因此操作系统只会把它当作一个硬盘。</p>
<p>RAID 的作用是：</p>
<ul>
<li>增强数据集成度；</li>
<li>增强容错功能；</li>
<li>增加处理量或容量。</li>
</ul>
<p>根据不同磁盘的组合方式，常见的 RAID 组合方式可分为 RAID 0、RAID 1、RAID 5、RAID 10 和 RAID 50 等。</p>
<p>RAID 0：将多个磁盘合并成一个大的磁盘，不会有冗余，并行 I&#x2F;O，速度最快。RAID 0 亦称为带区集（Striping），它将多个磁盘并列起来，使之成为一个大磁盘，如下图所示。</p>
<p><img src="/../../images/MySQL/mysql_backup_raid0.drawio.png" alt="img"></p>
<p>在存放数据时，会将数据按磁盘的个数进行分段，同时将这些分段并行写入各个磁盘。所以，在所有的 RAID 级别中，RAID 0 的速度是最快的。但是 RAID 0 没有冗余功能，如果一个磁盘（物理）损坏，则所有的数据都会丢失。</p>
<p>理论上，多磁盘的效能等于（单一磁盘效能）×（磁盘数），但实际会受总线 I&#x2F;O 瓶颈及其他因素的影响，RAID 效能会随边际递减。也就是说，假设一个磁盘的效能是 50 MB&#x2F;s，两个磁盘的 RAID 0 效能约为 96 MB&#x2F;s，三个磁盘的 RAID 0 也许是 130 MB&#x2F;s 而不是理论值 150 MB&#x2F;s。</p>
<p>RAID 1：两组以上的 N 个磁盘相互作为镜像（如下图所示）。在一些多线程操作系统中，RAID 1 能有很好的读取速度，但写入速度略有降低。除非主磁盘和镜像磁盘同时损坏，否则只要有一块磁盘正常就能维持运行，可靠性最高。RAID 1 就是镜像，其原理是在主硬盘上存放数据的同时，也在镜像硬盘上写入相同的数据。当主硬盘（物理）损坏时，镜像硬盘就顶替其工作。由于有镜像磁盘做数据备份，RAID 1 的数据安全性在所有 RAID 级别中最高。但是，无论用多少块磁盘作为 RAID 1，仅有一块磁盘有效，是所有 RAID 级别中磁盘利用率最低的一个级别。</p>
<p><img src="/../../images/MySQL/mysql_backup_raid1.drawio.png" alt="img"></p>
<p>RAID 5：是一种兼顾存储性能、数据安全和存储成本的存储解决方案。它使用 Disk Striping（硬盘分区）技术，至少需要三块硬盘。RAID 5 不对存储的数据进行完整备份，而是将数据和对应的奇偶校验信息存储到 RAID 5 的各个磁盘上，且奇偶校验信息和对应的数据分别存储在不同的磁盘上。当 RAID 5 中的一块磁盘发生故障后，可利用其余磁盘上的数据和奇偶校验信息，恢复丢失的数据。RAID 5 可视为 RAID 0 和 RAID 1 的折中方案，为系统提供数据安全保障，但其安全性低于镜像，磁盘空间利用率高于镜像。RAID 5 具有与 RAID 0 相近的读取速度，只是多了一条奇偶校验信息；写入速度相对较慢，若使用 Write Back 可有所改善。同时，由于多个数据块共用一条奇偶校验信息，RAID 5 的磁盘空间利用率高于 RAID 1，存储成本相对较低。RAID 5 的结构如下图所示。</p>
<p><img src="/../../images/MySQL/mysql_backup_raid5.drawio.png" alt="img"></p>
<p>RAID 10 是先镜像再分区数据，将所有硬盘分为两组，视为 RAID 0 的最低组合，然后将这两组各自视为 RAID 1 运行。RAID 10 有着不错的读取速度，而且拥有比 RAID 0 更高的数据保护性。RAID 01 则与 RAID 10 程序相反，先以 RAID 0 将数据划分到两组硬盘，RAID 1 将所有的硬盘分为两组，变成 RAID 1 的最低组合，而将两组硬盘各自视为 RAID 0 运行。RAID 01 比 RAID 10 有着更快的读写速度，不过也多了一些会让整个硬盘组停止运转的几率，因为只要同一组的硬盘全部损毁，RAID 01 就会停止运作，而 RAID 10 可以在牺牲 RAID 0 的优势下正常运作。RAID 10 巧妙地利用了 RAID 0 的速度及 RAID 1 的安全（保护）两种特性，它的缺点是需要较多的硬盘，因为至少必须拥有四个以上的偶数硬盘才能使用。RAID 10 和 RAID 01 的结构如下图所示。</p>
<p><img src="/../../images/MySQL/mysql_backup_raid10.drawio.png" alt="img"></p>
<p><img src="/../../images/MySQL/mysql_backup_raid01.drawio.png" alt="img"></p>
<p>假设有 4 块磁盘 D0、D1、D2、D3：</p>
<ul>
<li>RAID 01<ul>
<li>条带组 A：D0、D1 做 RAID 0</li>
<li>镜像组 B：D2、D3 做 RAID 0，然后镜像 A←→B</li>
</ul>
</li>
</ul>
<p>一旦 D0、D1 同时损坏，A 组失效，整个逻辑盘挂掉——尽管 D2、D3 还健康，但无法自动接管。</p>
<ul>
<li>RAID 10<ul>
<li>镜像对 1：D0⇄D1 做 RAID 1</li>
<li>镜像对 2：D2⇄D3 做 RAID 1</li>
<li>条带化：将数据交替写到 “对 1” 和 “对 2”</li>
</ul>
</li>
</ul>
<p>即便 D0、D2 同时故障，只要 D1、D3 健康，每个条带仍有一个副本存活，整个卷继续可用。</p>
<p>条带的实现原理如下：系统首先将待存储的数据按预定义的条带大小（如 64 KB、128 KB）切分为若干数据块，每个数据块称为一个“条带”。分割后的条带按照轮询（round-robin）方式依次写入多块磁盘或 SSD。比如，第一条带写入设备 A，第二条带写入设备 B，第三条带再回到设备 A，依此循环。</p>
<p>RAID 50：RAID 50 也被称为镜像阵列条带，由至少六块硬盘组成，像 RAID 0 一样，数据被分区成条带，在同一时间内向多块磁盘写入；像 RAID 5 一样，也是以数据和校验位来保证数据的安全，且校验条带均匀分布在各个磁盘上，其目的是提高 RAID 5 的读写性能。</p>
<p><img src="/../../images/MySQL/mysql_backup_raid50.drawio.png" alt="img"></p>
<p>对于数据库应用来说，RAID 10 是最好的选择，它同时兼顾了 RAID 1 和 RAID 0 的特性。但是，当一个磁盘失效时，性能可能会受到很大的影响，因为条带会成为瓶颈。也就是说，当 RAID 10 中的某块磁盘发生故障时，阵列不会像 RAID 0 那样整体挂掉，但其条带并行度会立刻下降，进而造成 I&#x2F;O 吞吐能力的衰减。具体来说，RAID 10 在正常状态下，将数据在多对镜像组之间条带化写入，可并行利用所有镜像对的读写能力；而一旦某个镜像对失去一块盘，整个镜像对的条带操作只能依赖剩余的单盘，导致该镜像对“窄化”，从而拖慢整组的并行访问速度。</p>
<h3 id="RAID-Write-Back-功能"><a href="#RAID-Write-Back-功能" class="headerlink" title="RAID Write Back 功能"></a>RAID Write Back 功能</h3><p>RAID Write Back 功能是指 RAID 控制器能够将写入的数据放入自身的缓存中，并把它们安排到后面再执行。这样做的好处是，不用等待物理磁盘实际写入的完成，因此写入变得更快了。对于数据库来说，这显得十分重要。例如，对重做日志的写入，在将 <code>sync_binlog</code> 设置为 1 的情况下二进制日志的写入、脏页的刷新等都可以使得性能得到明显的提升。</p>
<p>但是，当操作系统或数据库关机时，Write Back 功能可能会破坏数据库的数据。这是由于已经写入的数据可能还在 RAID 卡的缓存中，数据可能并没有完全写入磁盘，而这时故障发生了。为了解决这个问题，目前大部分的硬件 RAID 卡都提供了电池备份单元 (BBU, Battery Backup Unit)，因此可以放心地开启 Write Back 的功能。不过我发现每台服务器的出厂设置都不相同，应该将 RAID 设置要求告知服务器提供商，开启一些认为需要的参数。</p>
<p>如果没有启用 Write Back 功能，那么在 RAID 卡设置中显示的就是 Write Through。Write Through 没有缓存写入，因此写入性能可能不是很好，但它却是最安全的写入。</p>
<p>即使用户开启了 Write Back 功能，RAID 卡也可能只是在 Write Through 模式下工作。这是因为安全使用 Write Back 的前提是 RAID 卡有电池备份单元。为了确保电池的有效性，RAID 卡会定期检查电池状态，并在电池电量不足时对其进行充电，在充电的这段时间内会将 Write Back 功能切换为最为安全的 Write Through。</p>
<p>用户可以在没有电池备份单元的情况下强制启用 Write Back 功能，也可以在电池充电时强制使用 Write Back 功能，只是写入是不安全的。用户在启用前应该确认这一点，否则不应该在没有电池备份单元的情况下启用 Write Back。</p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>文件</title>
    <url>/undefined/MySQL/2024/10/27/MySQL/%E6%96%87%E4%BB%B6/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><p>MySQL 数据库和 InnoDB 存储引擎表的各种类型文件如下：</p>
<p><strong>参数文件</strong>：告诉 MySQL 实例启动时在哪里可以找到数据库文件，并且指定某些初始化参数，这些参数定义了某种内存结构的大小等设置，还会介绍各种参数的类型。</p>
<p><strong>日志文件</strong>：用来记录 MySQL 实例对某种条件做出响应时写入的文件，如错误日志文件、二进制日志文件、慢查询日志文件、查询日志文件等。</p>
<p><strong>socket 文件</strong>：当用 UNIX 域套接字方式进行连接时需要的文件。</p>
<p><strong>pid 文件</strong>：MySQL 实例的进程 ID 文件。</p>
<p><strong>MySQL 表结构文件</strong>：用来存放 MySQL 表结构定义文件。</p>
<p><strong>存储引擎文件</strong>：由于 MySQL 表存储引擎的关系，每个存储引擎都会有自己的文件来保存各种数据。这些存储引擎真正存储了记录和索引等数据。本章主要介绍与 InnoDB 有关的存储引擎文件。</p>
<h2 id="参数文件"><a href="#参数文件" class="headerlink" title="参数文件"></a>参数文件</h2><p>当 MySQL 实例启动时，数据库会先去读一个配置参数文件，用来寻找数据库的各种文件所在位置以及指定某些初始化参数，这些参数通常定义了某种内存结构有多大等。在默认情况下，MySQL 实例会按照一定的顺序在指定的位置进行读取，用户只需通过命令 mysql –help | grep my.cnf 来寻找即可。</p>
<p>MySQL 实例可以不需要参数文件，这时所有的参数值取决于编译 MySQL 时指定的默认值和源代码中指定参数的默认值。但是，如果 MySQL 实例在默认的数据库库目录下找不到 mysql 系统数据库，则启动同样会失败。</p>
<h3 id="参数类型"><a href="#参数类型" class="headerlink" title="参数类型"></a>参数类型</h3><p>MySQL 数据库中的参数可以分为两类：</p>
<ul>
<li>动态（dynamic）参数</li>
<li>静态（static）参数</li>
</ul>
<p>动态参数意味着可以在 MySQL 实例运行中进行更改，静态参数说明在整个实例生命周期内都不得进行更改，就好像是只读（read only）的。可以通过 SET 命令对动态参数值进行修改，SET 的语法如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SET</span></span><br><span class="line">[<span class="keyword">GLOBAL</span> <span class="operator">|</span> SESSION] system_var_name <span class="operator">=</span> expr</span><br><span class="line"><span class="operator">|</span> [@<span class="variable">@GLOBAL</span>. <span class="operator">|</span> @<span class="variable">@SESSION</span>.] system_var_name <span class="operator">=</span> expr;</span><br></pre></td></tr></table></figure>

<p>这里可以看到 GLOBAL 和 SESSION 关键字，它们表明该参数的修改是基于当前会话还是整个实例的生命周期。有些动态参数只能在会话中进行修改，如 autocommit；而有些参数修改完后，在整个实例生命周期中都会生效，如 <code>binlog_cache_size</code>；而有些参数既可以在会话中又可以在整个实例的生命周期内生效，如 <code>read_buffer_size</code>。</p>
<p>对变量的全局值进行了修改，在这次的实例生命周期内都有有效，但 MySQL 实例本身并不会对参数文件中的该值进行修改。也就是说，在下次启动时 MySQL 实例还是会读取参数文件。若想在数据库实例下一次启动时该参数还是保留为当前修改的值，那么用户必须去修改参数文件。</p>
<h2 id="日志文件"><a href="#日志文件" class="headerlink" title="日志文件"></a>日志文件</h2><p>MySQL 中常见的日志文件有：</p>
<ul>
<li>错误日志</li>
<li>二进制日志</li>
<li>慢查询日志</li>
<li>查询日志</li>
</ul>
<h3 id="错误日志"><a href="#错误日志" class="headerlink" title="错误日志"></a>错误日志</h3><p>错误日志文件对 MySQL 的启动、运行、关闭过程进行了记录。用户在遇到问题时应该首先查看该文件以便定位问题。该文件不仅记录了所有的错误信息，也记录一些警告信息或正确的信息。用户可以通过命令 SHOW VARIABLES LIKE ‘log_error’ 来定位该文件。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">[mysql]<span class="operator">&gt;</span> <span class="keyword">show</span> variables <span class="keyword">like</span> <span class="string">&#x27;log_error&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="operator">|</span> Variable_name <span class="operator">|</span> <span class="keyword">Value</span>              <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="comment">------------- | ------------------ |</span></span><br><span class="line"><span class="operator">|</span> log_error     <span class="operator">|</span> .<span class="operator">/</span>Yihang.local.err <span class="operator">|</span></span><br><span class="line"></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.07</span> sec)</span><br></pre></td></tr></table></figure>

<h3 id="慢查询日志"><a href="#慢查询日志" class="headerlink" title="慢查询日志"></a>慢查询日志</h3><p>慢查询日志（slow log）可帮助用户定位可能存在问题的 SQL 语句，从而进行 SQL 语句层面的优化。例如，可以在 MySQL 启动时设一个阈值，将运行时间超过该值的所有 SQL 语句都记录到慢查询日志文件中。用户每天或每过一段时间对其进行检查，确认是否有 SQL 语句需要进行优化。该阈值可以通过参数 <code>long_query_time</code> 来设置，默认值为 10，代表 10 秒。</p>
<p>这里有两点需要注意。首先，设置 <code>long_query_time</code> 这个阈值后，MySQL 数据库会记录运行时间<strong>超过</strong>该值的所有 SQL 语句，但运行时间<strong>正好等于</strong> <code>long_query_time</code> 的情况并不会被记录。也就是说，在源代码中判断的是大于 <code>long_query_time</code>，而非大于等于。</p>
<p>其次，从 MySQL 5.1 开始，<code>long_query_time</code> 开始以<strong>微秒</strong>记录 SQL 语句运行的时间，此前仅用秒为单位记录。而这样可以更精确地记录 SQL 的运行时间。对用户来说，一条 SQL 语句运行 0.5 秒和 0.05 秒是非常不同的，前者可能已经进行了表扫描，后者可能只是进行了索引查找。</p>
<p>另一个和慢查询日志有关的参数是 <code>log_queries_not_using_indexes</code>，如果运行的 SQL 语句没有使用索引，则 MySQL 同样会将这条 SQL 语句记录到慢查询日志文件。</p>
<p>MySQL 5.6.5 版本开始新增了一个参数 <code>log_throttle_queries_not_using_indexes</code>，用来表示每分钟允许记录到 slow log 的且未使用索引的 SQL 语句的最大次数。该参数默认值为 0，表示没有限制。在生产环境下，如果有大量未使用索引的查询，此类 SQL 会频繁地被记录到 slow log，从而导致日志文件持续膨胀。</p>
<p>用户可以通过慢查询日志找出有问题的 SQL 语句并进行优化。然而，随着 MySQL 服务器运行时间的增加，可能会有越来越多的查询被记录到慢查询日志，此时直接阅读日志文件就显得不够直观。MySQL 提供的 mysqldumpslow 工具可以很好地帮助 DBA 对慢查询日志进行汇总和分析。</p>
<p>MySQL 5.1 开始可以将慢查询的日志记录放入一张表中，这使得用户的查询更加方便和直观。</p>
<p>InnoSQL 版本加强了对于 SQL 语句的捕获方式。在原版 MySQL 的基础上在 slow log 中增加了对逻辑读取（logical reads）和物理读取（physical reads）的统计。这里的物理读取是指从磁盘进行 IO 读取的次数，逻辑读取包含所有的读取，不管是磁盘还是缓冲池。</p>
<p>用户可以通过额外的参数 <code>long_query_io</code> 将超过指定逻辑 IO 次数的 SQL 语句记录到 slow log 中。该值默认为 100，即表示对于逻辑读取次数大于 100 的 SQL 语句，记录到 slow log 中。</p>
<h3 id="查询日志"><a href="#查询日志" class="headerlink" title="查询日志"></a>查询日志</h3><p>查询日志记录了所有对 MySQL 数据库请求的信息，无论这些请求是否得到了正确的执行。默认文件名为：<code>&lt;主机名&gt;.log</code>。</p>
<h3 id="二进制日志"><a href="#二进制日志" class="headerlink" title="二进制日志"></a>二进制日志</h3><p>二进制日志（binary log）记录了对 MySQL 数据库执行更改的所有操作，但是不包括 SELECT 和 SHOW 这类操作，因为这类操作对数据本身并没有修改。然而，若操作本身并没有导致数据库发生变化，那么该操作可能也会写入二进制日志，但是这种情况只会发生在 <code>binlog_format</code> 参数的值为 ROW 的情况下。</p>
<p><strong>Statement-Based Logging (SBL)</strong> 下，<strong>所有</strong> DML&#x2F;DDL 语句均写入二进制日志，无论它们是否实际修改了任何行。</p>
<p><strong>Row-Based Logging (RBL)</strong> 下，只有<strong>真正产生行变更</strong>的事件才写入二进制日志；如果一条语句对零行生效，就<strong>不会</strong>产生相应的行事件。</p>
<p>如果用户想记录 SELECT 和 SHOW 操作，那只能使用查询日志，而不是二进制日志。此外，二进制日志还包括了执行数据库更改操作的时间等其他额外信息。总的来说，二进制日志主要有以下几种作用：</p>
<ul>
<li>恢复（recovery）：某些数据的恢复需要二进制日志，例如，在一个数据库全备文件恢复后，用户可以通过二进制日志进行 point-in-time 的恢复。</li>
<li>复制（replication）：其原理与恢复类似，通过复制和执行二进制日志使一台远程的 MySQL 数据库（一般称为 slave 或 standby）与一台 MySQL 数据库（一般称为 master 或 primary）进行实时同步。</li>
<li>审计（audit）：用户可以通过二进制日志中的信息进行审计，判断是否有对数据库进行注入的攻击。</li>
</ul>
<p>以下配置文件的参数影响着二进制日志记录的信息和行为：</p>
<ul>
<li><code>max_binlog_size</code> </li>
<li><code>binlog_cache_size</code> </li>
<li><code>sync_binlog</code> </li>
<li><code>binlog-do-db</code> </li>
<li><code>binlog-ignore-db</code> </li>
<li><code>log-slave-update</code> </li>
<li><code>binlog_format</code></li>
</ul>
<p>参数 <code>max_binlog_size</code> 指定了单个二进制日志文件的最大值，如果超过该值，则产生新的二进制日志文件，后缀名加 1，并记录到 .index 文件。从 MySQL 5.0 开始的默认值为 1073741824，代表 1 G（在之前版本中 <code>max_binlog_size</code> 默认大小为 1.1 G）。</p>
<p>当使用事务的存储引擎（如 InnoDB 存储引擎）时，所有未提交（uncommitted）的二进制日志会被记录到一个缓冲中去，等该事务提交（committed）时再将缓冲中的二进制日志写入二进制日志文件，而该缓冲的大小由 <code>binlog_cache_size</code> 决定，默认大小为 32K。此外，binlog_cache_size 是基于会话（session）的，也就是说，当一个线程开始一个事务时，MySQL 会自动分配一个大小为 <code>binlog_cache_size</code> 的缓冲，因此该值的设置需要相当小心，不能设置过大。当一个事务的记录大于设置的 <code>binlog_cache_size</code> 时，MySQL 会把缓冲中的日志写入一个临时文件中，因此该值又不能设置得过小。</p>
<p>在默认情况下，二进制日志并不是在每次写的时候同步到磁盘（用户可以理解为缓冲写）。因此，当数据库所在操作系统发生宕机时，可能会有最后一部分数据没有写入二进制日志文件中，这会给恢复和复制带来问题。参数 <code>sync_binlog=[N]</code> 表示每写缓冲多少次就同步到磁盘。如果将 N 设为 1，即 <code>sync_binlog=1</code> 表示采用同步写磁盘的方式来写二进制日志，这时写操作不再使用操作系统的缓冲来写二进制日志。<code>sync_binlog</code> 的默认值为 0，如果使用 InnoDB 存储引擎进行复制，并且想得到最大的高可用性，建议将该值设为 1。不过该值为 0 时，的确会对数据库的 I&#x2F;O 系统带来一定的影响。</p>
<p>但是，即使将 sync_binlog 设为 1，还是会有一种情况导致问题的发生。当使用 InnoDB 存储引擎时，在一个事务发出 COMMIT 动作之前，由于 <code>sync_binlog=1</code>，因此会将二进制日志立即写入磁盘。如果这时已经写入了二进制日志，但是提交还没有发生，并且此时发生了宕机，那么在 MySQL 数据库下次启动时，由于 COMMIT 操作并没有发生，这个事务会被回滚。但是二进制日志已经记录了该事务信息，不能被回滚。这个问题可以通过将参数 <code>innodb_support_xa</code> 设为 1 来解决，虽然 <code>innodb_support_xa</code> 与 XA 事务有关，但它同时也确保了二进制日志和 InnoDB 存储引擎数据文件的同步。</p>
<p>参数 <code>binlog-do-db</code> 和 <code>binlog-ignore-db</code> 表示需要写入或忽略写入哪些库的日志。默认为空，表示需要同步所有库的日志到二进制日志。</p>
<p>如果当前数据库是复制中的 slave 角色，则它不会将从 master 取得并执行的二进制日志写入自己的二进制日志文件中去。如果需要写入，要设置 <code>log-slave-update</code>。如果需要搭建 master⇒slave⇒slave 架构的复制，则必须设置该参数。</p>
<p><code>binlog_format</code> 参数十分重要，它影响了记录二进制日志的格式。在 MySQL 5.1 版本之前，没有这个参数，因此所有二进制日志文件的格式都是基于 SQL 语句（statement）级别的。同时，对于复制也有一定要求。例如在主服务器上运行 rand、uuid 等函数，或者使用触发器等操作，这些都可能会导致主从服务器上表中数据的不一致（not sync）。<a id='why_rr'>另一个影响是，你会发现 InnoDB 存储引擎的默认事务隔离级别是 REPEATABLE READ。</a>这其实也是因为二进制日志文件格式的关系：如果使用 READ COMMITTED 的事务隔离级别，会出现类似“丢失更新”的现象，从而导致主从数据库上的数据不一致。具体细节如下：</p>
<p>存在表 t1，定义如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> t1 (</span><br><span class="line">   a <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>, </span><br><span class="line">   b <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>, </span><br><span class="line">   KEY a (a) </span><br><span class="line">  ) ENGINE<span class="operator">=</span>InnoDB <span class="keyword">DEFAULT</span> CHARSET<span class="operator">=</span>latin1; </span><br><span class="line"><span class="keyword">insert into</span> t1 <span class="keyword">values</span>(<span class="number">10</span>,<span class="number">2</span>),(<span class="number">20</span>,<span class="number">1</span>);</span><br></pre></td></tr></table></figure>

<p>接着开始执行两个事务的写操作：</p>
<table>
<thead>
<tr>
<th>时序</th>
<th>事务1</th>
<th>事务2</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>set session transaction isolation level read committed;</td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>set autocommit&#x3D;0;</td>
<td></td>
</tr>
<tr>
<td>3</td>
<td>UPDATE t1 SET a&#x3D;11 where b&#x3D;2;</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td></td>
<td>set session transaction isolation level read committed;</td>
</tr>
<tr>
<td>5</td>
<td></td>
<td>set autocommit&#x3D;0;</td>
</tr>
<tr>
<td>6</td>
<td></td>
<td>UPDATE t1 SET b&#x3D;2 where b&#x3D;1;</td>
</tr>
<tr>
<td>7</td>
<td></td>
<td>COMMIT;</td>
</tr>
<tr>
<td>8</td>
<td>COMMIT;</td>
<td></td>
</tr>
</tbody></table>
<p>以上两个事务执行之后，数据库里面的记录会变成（11，2）和（20，2）。</p>
<p>因为事务的隔离级别是 read committed，所以，事务 1 在更新时，只会对 b &#x3D; 2 这行加上行级锁，不会影响到事务 2 对 b &#x3D; 1 这行的写操作。</p>
<p>以上两个事务执行完成之后，会在 binlog 中记录两条记录，因为事务 2 先提交，所以 <code>UPDATE t1 SET b=2 where b=1;</code> 会被优先记录，然后再记录 <code>UPDATE t1 SET a=11 where b=2;</code>。</p>
<p>binlog 同步到备从库之后，SQL语句回放时，会先执行 <code>UPDATE t1 SET b=2 where b=1;</code>，再执行 <code>UPDATE t1 SET a=11 where b=2;</code>。</p>
<p>这时候，数据库中的数据就会变成（11，2）和（11，2）。这就导致主库和备库的数据不一致了！！！</p>
<p>为了避免这种问题的发生，MySQL 就把数据库的默认隔离级别设置成了 Repeatable Read。</p>
<p>因为 Repetable Read 下，MySQL 在更新数据的时候不仅对更新的行加行级锁，还会增加 gap lock。同样是上面的例子，在事务 2 执行的时候，因为事务 1 增加了 gap lock，就会导致事务执行被卡住，需要等事务 1 提交或者回滚后才能继续执行。</p>
<p>除了设置默认的隔离级别外，MySQL 还在当使用 STATEMENT 格式的 binlog 的情况下，禁止设置 READ COMMITTED 作为事务隔离级别。</p>
<p>MySQL 5.1 开始引入了 <code>binlog_format</code> 参数，该参数可设的值有：STATEMENT、ROW 和 MIXED。</p>
<p>(1) STATEMENT 格式：二进制日志文件记录的是日志的逻辑 SQL 语句。</p>
<p>(2) ROW 格式下，二进制日志记录的不再是简单的 SQL 语句了，而是记录表的行更改情况。同时，对上述提及的 STATEMENT 格式下复制的问题予以解决。从 MySQL 5.1 版本开始，如果设置了 <code>binlog_format</code> 为 ROW，可以将 InnoDB 的事务隔离级别设为 READ COMMITTED，以获得更好的并发性。</p>
<p>(3) MIXED 格式下，MySQL 默认采用 STATEMENT 格式进行二进制日志文件的记录，但是在一些情况下会使用 ROW 格式，可能的情况有：</p>
<ul>
<li>使用了 <code>UUID()</code>、<code>USER()</code>、<code>CURRENT_USER()</code>、<code>FOUND_ROWS()</code>、<code>ROW_COUNT()</code> 等不确定函数。</li>
<li>使用了 INSERT DELAY 语句。</li>
<li>使用了用户定义函数（UDF）。</li>
<li>使用了临时表（temporary table）。</li>
</ul>
<p><code>binlog_format</code> 是动态参数，因此可以在数据库运行环境下进行更改。当然，也可以将全局的 <code>binlog_format</code> 设置为想要的格式，不过通常这个操作会带来问题，运行时要确保更改后不会对复制带来影响。在通常情况下，我们将参数 <code>binlog_format</code> 设置为 ROW，这可以为数据库的恢复和复制带来更好的可靠性。但是不能忽略的一点是，这会带来二进制文件大小的增加，有些语句下的 ROW 格式可能需要更大的容量。也就是说将参数 <code>binlog_format</code> 设置为 ROW，会对磁盘空间要求有一定的增加。而由于复制是采用传输二进制日志方式实现的，因此复制的网络开销也有所增加。</p>
<p>二进制日志文件的文件格式为二进制（好像有点废话），不能像错误日志文件、慢查询日志文件那样用 cat、head、tail 等命令来看查看。要查看二进制日志文件的内容，必须通过 MySQL 提供的工具 mysqlbinlog。</p>
<p>示例：</p>
<p>执行的 SQL 为：<code>UPDATE users SET age = age + 1 WHERE id = 100;</code></p>
<p><code>binlog_format=STATEMENT</code> 时的 binlog 输出（可读）：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># at 234</span><br><span class="line">#240523 15:00:01 server id 1 end_log_pos 345 Query  thread_id=7 exec_time=0 error_code=0</span><br><span class="line">SET TIMESTAMP=1716495601/*!*/;</span><br><span class="line">UPDATE users SET age = age + 1 WHERE id = 100/*!*/;</span><br></pre></td></tr></table></figure>

<p><code>binlog_format=ROW</code> 时的 binlog 输出（不可读）：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># at 456</span><br><span class="line">#240523 15:00:02 server id 1 end_log_pos 567 Table_map: `test`.`users` mapped to number 108</span><br><span class="line"># at 567</span><br><span class="line">#240523 15:00:02 server id 1 end_log_pos 678 Update_rows: table id 108 flags: STMT_END_F</span><br><span class="line">### UPDATE `test`.`users`</span><br><span class="line">### WHERE</span><br><span class="line">###  @1=100 /* id */</span><br><span class="line">###  @2=20 /* age (原值) */</span><br><span class="line">### SET</span><br><span class="line">###  @1=100</span><br><span class="line">###  @2=21 /* age (新值) */</span><br></pre></td></tr></table></figure>

<p>因此，在 ROW 格式下，binlog 中对于一个简单的更新操作记录了整个行额所有字段的更改信息。这也解释了为什么 ROW 格式下的 binlog 对磁盘空间要求有一定的增加。</p>
<h2 id="套接字文件"><a href="#套接字文件" class="headerlink" title="套接字文件"></a>套接字文件</h2><p>在 UNIX 系统下本地连接 MySQL 可以采用 UNIX 域套接字方式，这种方式需要一个套接字（socket）文件。套接字文件可由参数 socket 控制。一般在 <code>/tmp</code> 目录下，名为 <code>mysql.sock</code>。</p>
<h2 id="pid-文件"><a href="#pid-文件" class="headerlink" title="pid 文件"></a>pid 文件</h2><p>当 MySQL 实例启动时，会将自己的进程 ID 写入一个文件中——该文件即为 pid 文件并且可由参数 <code>pid_file</code> 控制，默认位于数据库目录下，文件名为主机名 <code>.pid</code>。</p>
<h2 id="表结构定义文件"><a href="#表结构定义文件" class="headerlink" title="表结构定义文件"></a>表结构定义文件</h2><p>因为 MySQL 插件式存储引擎的体系结构的关系，MySQL 数据的存储是根据表进行的，每个表都会有与之对应的文件。但不论表采用何种存储引擎，MySQL 都有一个以 <code>.frm</code> 为后缀名的文件，这个文件记录了该表的表结构定义。</p>
<p><code>.frm</code> 还用来存放视图的定义，如用户创建了一个 <code>v_a</code> 视图，那么对应地会产生一个 <code>v_a.frm</code> 文件，用来记录视图的定义。该文件是文本文件，可以直接使用 <code>cat</code> 命令进行查看。</p>
<h2 id="InnoDB-存储引擎文件"><a href="#InnoDB-存储引擎文件" class="headerlink" title="InnoDB 存储引擎文件"></a>InnoDB 存储引擎文件</h2><p>之前介绍的文件都是 MySQL 数据库本身的文件，和存储引擎无关。除了这些文件外，每个表存储引擎还有其自己独有的文件，包括重做日志文件、表空间文件。</p>
<h3 id="表空间文件"><a href="#表空间文件" class="headerlink" title="表空间文件"></a>表空间文件</h3><p>InnoDB 采用将存储的数据按表空间（tablespace）进行存放的设计。在默认配置下会有一个初始大小为 10MB，名为 ibdata1 的文件。该文件就是默认的表空间文件（tablespace file），用户可以通过参数 <code>innodb_data_file_path</code> 对其进行设置，格式如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">innodb_data_file_path=datafile_spec1[;datafile_spec2]...</span><br></pre></td></tr></table></figure>

<p>用户可以通过多个文件组成一个表空间，同时制定文件的属性，如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">innodb_data_file_path = /db/ibdata1:2000M;/dr2/db/ibdata2:2000M:autoextend</span><br></pre></td></tr></table></figure>

<p>这里将 <code>/db/ibdata1</code> 和 <code>/dr2/db/ibdata2</code> 两个文件用于组成表空间。若这两个文件位于不同的磁盘上，磁盘的负载可能被平均，因此可以提高数据库的整体性能。同时，两个文件的文件名后都跟了属性，表示文件 ibdata1 的大小为 2000MB，文件 ibdata2 的大小为 2000MB，如果用完了这 2000MB，该文件可以自动增长（autoextend）。</p>
<p>设置 <code>innodb_data_file_path</code> 参数后，所有基于 InnoDB 存储引擎的表的数据都会记录到该共享表空间中。若设置了参数 <code>innodb_file_per_table</code>，则用户可以将每个基于 InnoDB 存储引擎的表生成一个独立表空间。独立表空间的命名规则为：表名 <code>.ibd</code>。需要注意的是，这些单独的表空间文件仅存储该表的数据、索引和插入缓冲 BITMAP 等信息，其余信息还是存放在默认的表空间中。</p>
<p>下图展示了 InnoDB 对于文件的存储方式：</p>
<p><img src="/../../images/MySQL/mysql_tablespace.drawio.png" alt="img"></p>
<h3 id="Redo-日志文件"><a href="#Redo-日志文件" class="headerlink" title="Redo 日志文件"></a>Redo 日志文件</h3><p>在默认情况下，在 InnoDB 存储引擎的数据目录下会有两个名为 <code>ib_logfile0</code> 和 <code>ib_logfile1</code> 的文件。</p>
<p>当实例或介质失败时，重做日志文件就能派上用场。例如，数据库由于所在主机掉电导致实例失败，InnoDB 存储引擎会使用 Redo 日志恢复到掉电前的时刻，以此来保证数据的完整性。</p>
<p>每个 InnoDB 存储引擎至少有 1 个 Redo 日志文件组，每个文件组下至少有 2 个 Redo 日志文件，如默认的 <code>ib_logfile0</code> 和 <code>ib_logfile1</code>。为了得到更高的可靠性，用户可以设置多个镜像日志组，将不同的文件组放在不同的磁盘上，以此提高 Redo 日志的高可用性。在日志组中每个 Redo 日志文件的大小一致，并以循环写入的方式运行。InnoDB 存储引擎先写 Redo 日志文件 1，当达到文件的最后时，会切换至 Redo 日志文件 2，再当重做日志文件 2 也被写满时，会再切换到 Redo 日志文件 1 中。</p>
<p>下列参数影响着 Redo 日志文件的属性：</p>
<ul>
<li><code>innodb_log_file_size</code></li>
<li><code>innodb_log_files_in_group</code></li>
<li><code>innodb_mirrored_log_groups</code></li>
<li><code>innodb_log_group_home_dir</code></li>
</ul>
<p>参数 <code>innodb_log_file_size</code> 指定每个 Redo 日志文件的大小。在 InnoDB 1.2.x 版本之前，Redo 日志文件总的大小不得大于等于 4GB，而 1.2.x 版本将该限制扩大为了 512GB。</p>
<p>参数 <code>innodb_log_files_in_group</code> 指定了日志文件组中 Redo 日志文件的数量，默认为 2。</p>
<p>参数 <code>innodb_mirrored_log_groups</code> 指定了日志镜像文件组的数量，默认为 1，表示只有一个日志文件组，没有镜像。若磁盘本身已经做了高可用的方案，如磁盘阵列，那么可以不开启 Redo 日志镜像的功能。</p>
<p>最后，参数 <code>innodb_log_group_home_dir</code> 指定了日志文件组所在路径，默认为 <code>./</code>，表示在 MySQL 数据库的数据目录下。</p>
<p>Redo 日志文件的大小设置对于 InnoDB 存储引擎的性能有着非常大的影响。一方面 Redo 日志文件不能设置得太大，如果设置得很大，在恢复时可能需要很长的时间；另一方面又不能设置得太小了，否则可能导致一个事务的日志需要多次切换 Redo 日志文件。此外，Redo 日志文件太小会导致频繁地发生 async checkpoint，导致性能的抖动。因为，如果 Redo 日志文件大小超过最大容量则必须将缓冲池中脏页列表（flush list）中的部分脏数据写回磁盘，这时会导致用户线程的阻塞。</p>
<p>Redo 日志和二进制日志有什么区别？</p>
<p>首先，二进制日志会记录所有与 MySQL 数据库有关的日志记录，包括 InnoDB、MyISAM、Heap 等其他存储引擎的日志。而 InnoDB 存储引擎的 Redo 日志只记录有关该存储引擎本身的事务日志。</p>
<p>其次，记录的内容不同。无论用户将二进制日志文件记录的格式设为 STATEMENT 还是 ROW，又或者是 MIXED，其记录的都是关于一个事务的具体操作内容，即该日志是逻辑日志。而 InnoDB 存储引擎的 Redo 日志文件记录的是关于每个页（Page）的更改的物理情况。</p>
<p>此外，写入的时间也不同，二进制日志文件仅在事务提交前进行提交，即只写磁盘一次，不论这时该事务多大。而在事务进行的过程中，却不断有 Redo 日志条目（redo entry）被写入到 Redo 日志文件中。</p>
<p>Redo 日志条目的结构如下：</p>
<p><img src="/../../images/MySQL/mysql_redo_item.drawio.png" alt="img"></p>
<p>上图中 Redo 日志条目是由 4 个部分组成：</p>
<ul>
<li><code>redo_log_type</code> 占用 1 字节，表示重做日志的类型。</li>
<li><code>space</code> 表示表空间的 ID，但采用压缩的方式，因此占用的空间可能小于 4 字节。</li>
<li><code>page_no</code> 表示页的偏移量，同样采用压缩的方式。</li>
<li><code>redo_log_body</code> 表示每个重做日志的数据部分，恢复时需要调用相应的函数进行解析。</li>
</ul>
<p>写入重做日志文件的操作不是直接写，而是先写入一个重做日志缓冲中，然后按照一定的条件顺序地写入日志文件。下图是 Redo 日志的写入过程：</p>
<p><img src="/../../images/MySQL/mysql_arch_redo.drawio.png" alt="img"></p>
<p>从重做日志缓冲往磁盘写入时是按 512 字节，也就是一个扇区的大小进行写入。因为在传统的磁盘存储设备中，扇区是最小的物理写入单位。当操作系统或数据库系统请求写入数据时，磁盘控制器会确保整个扇区的数据要么被完整地写入，要么在发生故障（如断电）时不进行任何写入。这种机制确保了写入操作的原子性，即不会出现撕裂写（torn write）的情况，因此在重做日志的写入过程中不需要有 doublewrite。</p>
<p>前面提到了从日志缓冲写入磁盘上的重做日志文件是按一定条件进行的，那这些条件有哪些呢？我们知道在主线程中每秒会将重做日志缓冲写入磁盘的重做日志文件中，不论事务是否已经提交。另一个触发写磁盘的过程是由参数 <code>innodb_flush_log_at_trx_commit</code> 控制，表示在提交操作时，处理重做日志的方式。</p>
<p>参数 <code>innodb_flush_log_at_trx_commit</code> 的有效值有 0、1、2。</p>
<p>0 代表当提交事务时，并不将事务的重做日志写入磁盘上的日志文件，而是等待主线程每秒的刷新。1 和 2 不同的地方在于：</p>
<ul>
<li>1 表示在执行 commit 时将重做日志缓冲同步写到磁盘，即伴有 fsync 的调用。</li>
<li>2 表示将重做日志异步写到磁盘，即写到文件系统的缓存中。因此不能完全保证在执行 commit 时肯定会写入重做日志文件，只是有这个动作发生。</li>
</ul>
<p>因此为了保证事务的 ACID 中的持久性，<strong>必须将</strong> <strong><code>innodb_flush_log_at_trx_commit</code></strong> <strong>设置为 1</strong>，也就是每当有事务提交，就必须确保事务已经写入重做日志文件。那当数据库因为意外发生宕机时，可以通过重做日志文件恢复，并保证可以恢复已经提交的事务。</p>
<p>而将重做日志文件设置为 0 或 2，<strong>都有可能发生恢复时部分事务的丢失</strong>。不同之处在于，设置为 2 时，当 MySQL 数据库发生宕机而操作系统及服务器并没有发生宕机时，由于此时未写入磁盘的事务日志保存在文件系统缓存中，当恢复时同样能保证数据不丢失。</p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>常用函数</title>
    <url>/undefined/MySQL/2024/09/14/MySQL/%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h1 id="字符串函数"><a href="#字符串函数" class="headerlink" title="字符串函数"></a>字符串函数</h1><ul>
<li>CONCAT(S1, S2, …) 字符串拼接；</li>
<li>LOWER(str) 小写转换；</li>
<li>UPPER(str) 大写转换；</li>
<li>LPAD(str, n, pad) 左填充，用字符串 pad 对 str 左边进行填充，直到长度为 n；</li>
<li>RPAD(str, n, pad) 右填充，用字符串 pad 对 str 右边进行填充，直到长度为 n；</li>
<li>TRIM(str) 去掉字符串头部和尾部的空格；</li>
<li>SUBSTRING(str, start, len) 返回字符串 str 从 start 位置起的 len 长度的字符串，<strong>需要注意的是字符索引是从1开始的。</strong></li>
</ul>
<h1 id="数值函数"><a href="#数值函数" class="headerlink" title="数值函数"></a>数值函数</h1><ul>
<li>CEIL(x) 向上取整；</li>
<li>FLOOR(x) 向下取整；</li>
<li>MOD(x, y) 返回 x&#x2F;y 的模；</li>
<li>RAND() 返回0～1的随机数；</li>
<li>ROUND(x, y) 求参数 x 四舍五入的值并保留 y 位小数。</li>
</ul>
<h1 id="日期函数"><a href="#日期函数" class="headerlink" title="日期函数"></a>日期函数</h1><ul>
<li>CURDATE() 当前日期；</li>
<li>CURTIME() 当前时间；</li>
<li>NOW() 当前日期和时间；</li>
<li>YEAR(date) 获取指定 date 的年份；</li>
<li>MONTH(date) 获取指定 date 的月份；</li>
<li>DAY(date) 获取指定 date 的日期；</li>
<li>DATE_ADD(date, INTERVAL expr type) 返回一个日期&#x2F;时间值加上一个时间间隔 expr 后的时间值；</li>
<li>DATEDIFF(date1, date2) 返回起始时间 date1 和结束时间 date2 之间的天数。</li>
</ul>
<h1 id="流程函数"><a href="#流程函数" class="headerlink" title="流程函数"></a>流程函数</h1><ul>
<li>IF(value, t, f) 如果 value 为真，返回 t，否则返回 f；</li>
<li>IFNULL(value1, value2) 如果 value1 不为空，返回 value1，否则返回 value2；</li>
<li>CASE WHEN [val1] THEN [res1] … ELSE [default] END 如果 val1 为 true，返回 res1，… 否则返回 default 默认值；</li>
<li>CASE [expr] WHEN [val1] THEN [res1] … ELSE [default] END 如果 expr 的值等于 val1，返回 res1, … 否则返回 default 默认值。</li>
</ul>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>存储引擎</title>
    <url>/undefined/MySQL/2024/10/05/MySQL/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><p>存储引擎是存储、更新或查询数据、以及建立索引等技术的实现方式。存储引擎是<strong>基于表</strong>的，而不是基于库的，因此存储引擎也可被称为表类型。</p>
<p>指定存储引擎：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> 表名 (</span><br><span class="line">	...</span><br><span class="line">) ENGINE <span class="operator">=</span> INNODB ...;</span><br></pre></td></tr></table></figure>

<p>查看当前数据库支持的存储引擎：<code>SHOW ENGINES;</code></p>
<p>存储引擎特点</p>
<p><img src="/../../images/MySQL/storage_engine.png" alt="img"></p>
<h2 id="InnoDB"><a href="#InnoDB" class="headerlink" title="InnoDB"></a>InnoDB</h2><p>它是一个兼顾<strong>高可靠性和高性能</strong>的通用存储引擎。</p>
<p>特点</p>
<ul>
<li>DML 操作遵循 ACID 模型，支持事务。</li>
<li>行级锁提高并发访问性能。</li>
<li>支持外键 FOREIGN KEY 约束，保证数据的完整性和正确性。</li>
<li>支持非锁定读，即默认读取操作不会产生锁。</li>
</ul>
<p>InnoDB 引擎中有多个内存块，这些内存块组成了一个大的内存池，负责如下工作：</p>
<ol>
<li>维护所有进程或线程需要访问的多个内部数据结构。</li>
<li>缓存磁盘上的数据，方便快速读取，同时再对磁盘文件的数据修改之前在这里缓存。</li>
<li>Redo 日志缓冲。</li>
<li>…</li>
</ol>
<p><img src="/../../images/MySQL/storage_engine_mem_pool.drawio.png" alt="img"></p>
<p>上图中，后台线程的主要作用是刷新内存中的数据，保证缓冲池中缓存的是最新的数据，此外将已修改的数据文件刷新到磁盘，同时保证在数据库发生异常的情况下 InnoDB 能恢复到正常运行状态。</p>
<h3 id="后台线程"><a href="#后台线程" class="headerlink" title="后台线程"></a>后台线程</h3><p>InnoDB 存储引擎是多线程模型，因此有多个不同的后台线程，负责不同的任务：</p>
<ol>
<li><p>Master Thread</p>
<p>Master Thread 是一个非常核心的后台线程，主要负责将缓冲池中的数据异步刷新到磁盘，保证一致性，包括脏页的刷新、合并更改缓冲区、回收 Undo 页等。</p>
</li>
<li><p>IO Thread</p>
<p>InnoDB 中大量使用了 AIO 来处理写 IO 请求，这样可以极大提高数据库的性能。而 IO Thread 主要负责这些 IO 请求的回调处理。</p>
</li>
<li><p>Purge Thread</p>
<p>事务被提交后，其所使用的 Undo 日志可能不再被需要，因此引入 Purge Thread 来回收已经使用并被分配的 Undo 页。</p>
</li>
<li><p>Page Cleaner Thread</p>
<p>作用是将之前版本中脏页的刷新操作都放入到单独的线程中来完成，用于减轻元 Master Thread 的工作以及对于用户查询线程的阻塞。</p>
</li>
</ol>
<h3 id="Checkpoint"><a href="#Checkpoint" class="headerlink" title="Checkpoint"></a>Checkpoint</h3><p>缓冲池的设计目的是为了协调 CPU 速度和磁盘速度的鸿沟。但是如果每次一个页只要的发生变化，都要将脏页刷新到磁盘的话，那开销将非常大。而且如果从缓冲池刷新页到磁盘的磁盘过程中发生了宕机，那么数据无法恢复，因此 InnoDB 采用了 Write Ahead Log 策略，也就是当事务提交时，先写 Redo 日志再修改页。</p>
<p>如果 Redo 日志可以无限增大，并且缓冲池也足够大。那么我们无需将缓冲池中的脏页刷回磁盘。但是我们做不到，因为大容量内存很少见，而且维护人员需要时刻监测 Redo 日志的积累量是否超过磁盘空间阈值，此外宕机之后大量 Redo 日志的重放非常耗时，因此我们需要 Checkpoint 解决这些问题：</p>
<ol>
<li>缩短数据库的恢复时间；</li>
<li>缓冲池不够用时，将脏页刷回磁盘；</li>
<li>Redo 日志不可用时，刷新脏页。</li>
</ol>
<p>因此，当数据库发⽣宕机时， 数据库不需要重做所有的⽇志，因为 Checkpoint 之前的页都已经刷新回磁盘。故数据库只需对 Checkpoint 后的重做⽇志进⾏恢复。这样就⼤⼤缩短了恢复的时间。</p>
<p>此外，当缓冲池不够⽤时，根据 LRU 算法会淘汰最近最少使⽤的页，若此页为脏页，那么需要强制执⾏ Checkpoint，将脏页刷回磁盘。</p>
<p>重做日志出现不可用的情况是因为当前事务数据库系统对重做日志的设计都是循环使用的，并不是让其无限增大的。重做日志可以被重用的部分是指这些重做日志已经不再需要，即当数据库发生宕机时，数据库恢复操作不需要这部分的重做日志，因此这部分就可以被覆盖重用。若此时重做日志还需要继续使用不可被覆盖的部分，那么必须强制产生 Checkpoint，将缓冲池中的页至少刷新到当前重做日志的位置。</p>
<p>InnoDB 是通过 LSN（Log Sequence Number）来标记版本的，而 LSN 是 8 字节的数字。每个页有 LSN，重做日志中也有 LSN，Checkpoint 也有 LSN。</p>
<p>InnoDB 存储引擎内部，有两种 Checkpoint：</p>
<ol>
<li>Sharp Checkpoint；</li>
<li>Fuzzy Checkpoint。</li>
</ol>
<p>Sharp Checkpoint 发生在数据库关闭时将所有的脏页都刷新回磁盘，这是默认的工作方式。</p>
<p>但是若数据库在运行时也使用 Sharp Checkpoint，那么数据库的可用性就会受到大大影响，故在 InnoDB 存储引擎内部常使用 Fuzzy Checkpoint 进行页的刷新，即只刷新一部分脏页，而不是刷新所有的脏页回磁盘。</p>
<p>InnoDB 存储引擎中可能会生成如下几种情况的 Fuzzy Checkpoint：</p>
<ul>
<li>Master Thread Checkpoint；</li>
<li>FLUSH_LRU_LIST Checkpoint；</li>
<li>Async&#x2F;Sync Flush Checkpoint；</li>
<li>Dirty Page too much Checkpoint。</li>
</ul>
<p>Master Thread 中发生的 Checkpoint，差不多以每秒或每十秒的速度从缓冲池的脏页列表中刷新一定比例的页回磁盘。这个过程是异步的，即此时 InnoDB 存储引擎可以进行其他的操作，用户查询线程不会阻塞。</p>
<p><strong>FLUSH_LRU_LIST Checkpoint</strong> 是因为 InnoDB 存储引擎要保证 LRU 列表中需要有不多于 100 个空闲页可供使用。倘若没有 100 个可用空闲页，那么 InnoDB 会将 LRU 列表尾端的页移除。如果这些页中有脏页，那么需要进行 Checkpoint，而这些页是来自 LRU 列表的，因此称为 FLUSH_LRU_LIST Checkpoint。之后，这些检查被放在了一个单独的 Page Cleaner 线程中进行。</p>
<p><strong>Async&#x2F;Sync Flush Checkpoint</strong> 指的是重做日志文件不可用的情况，这时需要强制将一些页刷新回磁盘，而此时脏页是从脏页列表中选取的。</p>
<p>若将已经写到重做日志的 LSN 记为 <code>redo_lsn</code>，将已经刷新回磁盘最新页的 LSN 记为 <code>checkpoint_lsn</code>，则可定义：</p>
<p>$$checkpoint_age &#x3D; redo_lsn - checkpoint_lsn$$</p>
<p>再定义以下的变量：</p>
<p>$$async_water_mark &#x3D; 75% * total_redo_log_file_size$$</p>
<p>$$sync_water_mark &#x3D; 90% * total_redo_log_file_size$$</p>
<p>若每个重做日志文件的大小为 1GB，并且定义了两个重做日志文件，则重做日志文件的总大小为 2GB。那么 <code>async_water_mark=1.5GB</code>，<code>sync_water_mark=1.8GB</code>，则：</p>
<ul>
<li>当 <code>checkpoint_age &lt; async_water_mark</code> 时，不需要刷新任何脏页到磁盘；</li>
<li>当 <code>async_water_mark &lt; checkpoint_age &lt; sync_water_mark</code> 时触发 <strong>Async Flush</strong>，从 Flush 列表中刷新足够的脏页回磁盘，使得刷新后满足 <code>checkpoint_age &lt; async_water_mark</code>；</li>
<li><code>checkpoint_age &gt; sync_water_mark</code> 这种情况一般很少发生，除非设置的重做日志文件大小小，并且在进行类似 LOAD DATA 或 BULK INSERT 操作。此时触发 <strong>Sync Flush</strong> 操作，从 Flush 列表中刷新足够的脏页回磁盘，使得刷新后满足 <code>checkpoint_age &lt; async_water_mark</code>。</li>
</ul>
<p>之后，这部分刷新操作同样被放入到 Page Cleaner 线程中，所以再也不会阻塞用户查询线程。</p>
<p>最后一种 Checkpoint 的情况是 <strong>Dirty Page too much</strong>，即脏页的数量太多，导致 InnoDB 存储引擎强制进行 Checkpoint。其目的的总结来说是为了<strong>保证缓冲池中有足够可用的页</strong>。其可由参数 innodb_max_dirty_pages_pct 控制，<code>innodb_max_dirty_pages_pct</code> 值为 75 表示，当缓冲池中脏页的数量占比 <strong>75%</strong> 时，强制进行 Checkpoint，刷新一部分的脏页到磁盘。</p>
<h3 id="Master-Thread"><a href="#Master-Thread" class="headerlink" title="Master Thread"></a>Master Thread</h3><p>InnoDB 存储引擎的主要工作都是在一个<strong>单独的后台线程 Master Thread</strong> 中完成的。具体的演化过程请参考 MySQL 技术内幕的 36-45 页。</p>
<h3 id="关键底层特性"><a href="#关键底层特性" class="headerlink" title="关键底层特性"></a>关键底层特性</h3><ul>
<li>插入缓冲</li>
<li>两次写</li>
<li>自适应哈希索引</li>
<li>异步 IO</li>
<li>刷新临接页</li>
</ul>
<h4 id="插入缓冲"><a href="#插入缓冲" class="headerlink" title="插入缓冲"></a>插入缓冲</h4><p>InnoDB 中，主键是行唯一的标识符，通常应用程序中行记录的插入是按照主键递增的顺序来进行的（AUTO_INCREMENT），因此插入聚集索引一般是顺序的，无需磁盘随机读取。但是，一张表上可能存在多个非聚集切非唯一的二级索引，再进行插入操作的时候，数据页的存放还是按照主键顺序存放的，但是对于非聚集非唯一的索引而言，叶子节点的插入一般来说就不再是顺序的了，也就是会出现随机访问，除了日期之类的递增列的索引。</p>
<p>因此 InnoDB 中设计了插入缓冲：对于非狙击索引的插入和更新操作，不是每一次直接插入到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，若在，则直接插入，若不在，则先放入到一个插入缓冲中，然后再以一定频率和情况进行插入缓冲和二级索引页的合并操作，这时通常能将多个插入操作合并到一个操作中，极大提高了对于非聚集索引插入的性能。</p>
<p>为什么插入缓冲不操作唯一索引？</p>
<p>因为如果要对唯一索引进行操作，不论是插入、删除还是更新，都需要到索引页中判断要操作的记录的唯一性，这又会导致随机访问的发生，从而导致插入缓冲失去意义。</p>
<p>插入缓冲是一棵 B+ 树，并且该树数据库全局中只有一棵，负责对所有表的二级索引进行插入操作的缓存。该树被放在共享表空间中，即 ibdata1 中。 因此，试图通过独⽴表空间 ibd ⽂件恢复表中数据时，往往会导致 CHECK TABLE 失败。这是因为表的辅助索引中的数据可能还在 InsertBuffer 中，也就是共享表空间中，所以通过 ibd ⽂件进⾏恢复后，还需要进⾏ REPAIR TABLE 操作来重建表上所有的辅助索引。</p>
<p>该树中的非叶子节点存放的是查询的 search key，也就是索引键（在 Insert Buffer B + 树中，二级索引页根据（ space, offset ）都已排序好），其结构如下：</p>
<p><img src="/../../images/MySQL/storage_engine_insert_buf_non_leaf.drawio.png" alt="img"></p>
<p>searchkey ⼀共占⽤ 9 个字节，其中 space 表⽰待插⼈记录所在表的表空间 id，在 InnoDB 存储引擎中，每个表有⼀个唯⼀的 spaceid，可以通过 spaceid 查询得知是哪张表。space 占⽤ 4 字节。marker 占⽤ 1 字节，它是⽤来兼容⽼版本的 Insert Buffer。offset 表⽰页所在的偏移量，占⽤ 4 字节。</p>
<p>当⼀个辅助索引要插入到页（ space, offset ）时，如果这个页不在缓冲池中，那么 InnoDB ⾸先根据上述规则构造⼀个 searchkey，接下来查询 InsertBuffer 这棵 B+树，然后再将这条记录插⼊到 Insert Buffer 的叶⼦节点中。</p>
<p>对于插⼊到 Insert Buffer 叶⼦节点的记录，并不是直接将待插入的记录插入，⽽是需要根据如下规则进⾏构造：</p>
<p><img src="/../../images/MySQL/storage_engine_insert_buf_leaf.drawio.png" alt="img"></p>
<p>上图是 Insert Buffer 叶子节点中的记录结构，其中 space、marker、offset 字段和之前的含义一致，一共 9 字节。metadata 占用 4 字节，其存储内容如下：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>字节</th>
</tr>
</thead>
<tbody><tr>
<td>IBUF_REC_OFFSET_COUNT</td>
<td>2</td>
</tr>
<tr>
<td>IBUF_REC_OFFSET_TYPE</td>
<td>1</td>
</tr>
<tr>
<td>IBUF_REC_OFFSET_FLAGS</td>
<td>1</td>
</tr>
</tbody></table>
<p><code>IBUF_REC_OFFSET_COUNT</code> 记录进入 Insert Buffer 的顺序，并且通过这个顺序才能得到正确的值。</p>
<p>从第 5 个字段开始，就是实际插入记录的各个字段，因此较原插入记录，Insert Buffer 中的叶子节点中的记录需要额外 13 字节的开销。</p>
<p>当启用 Change Buffer（Insert Buffer 升级）后，InnoDB 不会立即将对非聚集索引页的修改（插入、删除、更新）同步到该页上，而是将修改记录缓存到一个 Insert Buffer 中。这种做法虽然减少了大量随机 I&#x2F;O，但带来两个问题：</p>
<ol>
<li>何时合并？ 合并时要把哪些缓冲修改应用到目标页？</li>
<li>是否还有可用空间？ 只有当目标页有足够剩余空间时，才允许新的修改进入缓冲，否则要避免膨胀页大小。</li>
</ol>
<p>为此，引入了 bitmap 页面来快速回答这两类问题，而无需读取整个索引页。</p>
<p>每个 bitmap 页描述一组连续的二级索引页。在常见的 16 KB 页大小下，一个 bitmap 页能跟踪 16 384 个索引页（即 256 个区）。每个 Insert Buffer Bitmap 页是 16384 个页中的第⼆个页。每个被跟踪的索引页对应 4 位信息，如下：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>大小（bit）</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>IBUF_BITMAP_FREE</td>
<td>2</td>
<td>表示该辅助索引页中的可用空间数量，可取值为：<br>• 0 表示无可用剩余空间<br>• 1 表示剩余空间大于 1&#x2F;32 页（512 字节）<br>• 2 表示剩余空间大于 1&#x2F;16 页<br>• 3 表示剩余空间大于 1&#x2F;8 页</td>
</tr>
<tr>
<td>IBUF_BITMAP_BUFFERED</td>
<td>1</td>
<td>1 表示该辅助索引页有记录被缓存至 Insert Buffer B+ 树中</td>
</tr>
<tr>
<td>IBUF_BITMAP_IBUF</td>
<td>1</td>
<td>1 表示该页为 Insert Buffer B+ 树的索引页</td>
</tr>
</tbody></table>
<p> Merge Insert Buffer 的操作可能发⽣在以下⼏种情况下：</p>
<ol>
<li>当某个二级索引页被读取到缓冲池时，立即应用该页所有挂起的缓冲修改；</li>
<li>当 Insert Buffer Bitmap 检测到某页可用空间不足，必须先合并才能继续缓冲新的修改；</li>
<li>Master Thread 循环检测并执行各种维护任务，包括 Change Buffer 的合并操作。</li>
</ol>
<p>对第二点进行补充：若 Bitmap 显示该页剩余可用空间 ≥ 阈值（默认为页大小的 1&#x2F;32），则直接将修改写入 Change Buffer；否则，视为可用空间不足，需要<strong>先合并</strong>该页在 Change Buffer 中的所有挂起修改，再重新计算空间后才能缓冲。</p>
<p>在 Master Thread 中，执行 merge 操作的不止是一个页，而是根据 <code>srv_innodb_io_capacity</code> 的百分比来决定真正要合并多少个辅助索引页。但 InnoDB 存储引擎又是根据怎样的算法来得知需要合并的辅助索引页？</p>
<p>解决方案是随机选页策略：</p>
<ul>
<li>随机起点：Master Thread 在 Change Buffer 树中随机挑选一个页（或一个树节点），然后从该页开始，按内部顺序（通常是树结构中后继页）依次读取所需数量的页来合并。</li>
<li>保证覆盖全树：通过每次随机的起点，随着时间推移，整个 B+ 树中的所有页都会被均匀地触及，避免固定区段被长时间忽略。</li>
<li>批量合并：从选中的起点开始，连续取出 N 页（N 由 I&#x2F;O 预算决定）进行条目合并和写回。</li>
</ul>
<p>在 merge 时，如果要进行 merge 的条目已经被删除，此时可以直接丢弃已被 Insert&#x2F;Change Buffer 存储的对应数据记录。</p>
<p><strong>为什么不按顺序选页？</strong></p>
<p>按 <code>(space, offset)</code> 排序：理论上可以从最小的表空间 ID（space）和页号（offset）开始，按顺序扫描整个 B+ 树。</p>
<p>公平性问题：如果总是从头开始，前面页的挂起修改会被反复优先处理，而后面页可能长时间得不到合并。</p>
<p>更改缓冲</p>
<p>更改缓冲是插入缓冲的升级版，因为它可以对 DML 操作（增删改）进行缓冲。更改缓冲的适用对象仍然是非唯一的二级索引。</p>
<p><code>innodb_change_buffering</code> 控制 Change Buffer 的行为，默认值为 all，表示所有类型的插入、更新和删除操作都会使用 Change Buffer。可选值包括：</p>
<ul>
<li>none：禁用 Change Buffer。</li>
<li>inserts：仅缓存插入操作。</li>
<li>deletes：仅缓存删除操作。</li>
<li>changes：缓存插入和删除操作。</li>
<li>all：缓存所有支持的操作。</li>
</ul>
<h4 id="双写"><a href="#双写" class="headerlink" title="双写"></a>双写</h4><p>双写为 InnoDB 带来了数据页写磁盘的可靠性。</p>
<p>当发生数据库宕机时，可能 InnoDB 存储引擎正在写入某个页到表中，而这个页只写了一部分，比如 16 KB 的页，只写了前 4 KB，之后就发生了宕机，这种情况被称为部分写失效（partial page write）。在 InnoDB 存储引擎未使用 doublewrite 技术前，曾经出现过因为部分写失效而导致数据丢失的情况。</p>
<p>有人会想，如果发生写失效，可以通过重做日志进行恢复。这是一个办法。但是必须清楚地认识到，重做日志中记录的是对页的物理操作，比如偏移量 800，写入 <code>aaaa</code> 记录。如果这个页本身已经发生了损坏，再对其进行重做是没有意义的。这就是说，在应用重做日志前，用户需要一个页的副本，当页写失效时，先通过页的副本来还原该页，再进行重做，这就是 doublewrite。</p>
<p>当 InnoDB 将脏页写回磁盘时，如果发生意外宕机（如断电、进程被杀），可能只写入了页面的一部分字节，这称为部分写失效（partial page write）。此时磁盘上的原始页已损坏，内部结构（例如记录边界、checksum、LSN 等）不再正确。InnoDB 的 Redo Log 仅记录对特定行或特定偏移的修改差分，并不包含整页的镜像。因此，如果缺少干净的起始页，应用这些差分时就无从下手——就像没有原图就没法正确贴修补片一样。</p>
<p>doublewrite 由两部分组成：一部分是内存中的 doublewrite buffer，大小为 2 MB；另一部分是物理磁盘上共享表空间中连续的 128 个页，即 2 个区（extent），大小同样为 2 MB。</p>
<p>在后台线程对缓冲池的脏页进行刷回磁盘的时候，并不是直接写入表空间文件，而是先通过 memcpy 将数据页复制到内存中的 doublewrite buffer，它被划分为两段，每段约 1 MB，InnoDB 按连续顺序调用 <code>write()</code> 将第一段写入 OS 页缓存，再调用 <code>fsync()</code> 强制落盘，然后对第二段重复相同操作。在这个过程中，由于 doublewrite 页面在磁盘上是连续存放的，因此写入是顺序 I&#x2F;O，性能损耗也相对可控。在完成 doublewrite 页的安全落盘之后，再将磁盘的 doublewrite 中的页面按各自原始逻辑位置分散写入 .ibd 或共享表空间文件；这一步 I&#x2F;O 是随机分布的。</p>
<p><img src="/../../images/MySQL/storage_engine_dbwr.drawio.png" alt="img"></p>
<p>fsync 是一个 POSIX 系统调用，用于强制操作系统将指定文件的所有已修改数据块及其元数据，从内核缓冲区刷写（flush）到物理存储设备，并在返回之前<strong>阻塞</strong>直到存储设备确认写入完成。</p>
<p>如果操作系统在将页写入磁盘的过程中发生了崩溃，在恢复过程中，InnoDB 可从共享表空间中的 doublewrite 中找到该页的一个副本，将其复制到表空间文件并应用 Redo 日志。</p>
<p>注意：有些文件系统如 AFS 提供了部分写失效的防范机制，因此在这种情况下，无需启动 doublewrite。</p>
<p><strong>为什么数据页会被先写入双写缓冲，而不是直接被写入数据文件？</strong></p>
<p>直接写入数据文件时，部分写失效问题更加严重，因为数据文件中的数据页分布是<strong>随机的</strong>，不同的数据页可能在磁盘的不同区域，而不是连续存放。因此，直接写入这些随机分布的页时，我们需要花费更多的时间，发生部分写失效的风险更高。而双写缓冲区是一个专门设计的区域，确保每次写入是<strong>连续的、顺序的</strong>，它使得内存中的数据能在最短的时间内被写入磁盘，从而大大减少了部分写失效的风险。</p>
<h4 id="自适应哈希索引"><a href="#自适应哈希索引" class="headerlink" title="自适应哈希索引"></a>自适应哈希索引</h4><p>哈希（hash）是一种非常快的查找方法，在一般情况下这种查找的时间复杂度为 O(1)，即一般仅需一次查找就能定位数据。而 B+ 树的查找次数，取决于 B+ 树的高度，在生产环境中， B+ 树的高度一般为 3 ～ 4 层，故需要 3 ～ 4 次的查询。</p>
<p>InnoDB 存储引擎会监控对表上各索引页的查询。如果观察到建立哈希索引可以带来速度提升，则建立哈希索引，称之为自适应哈希索引（Adaptive Hash Index，AHI）。AHI 是通过缓冲池的 B+ 树页构造而来，因此建立的速度很快，而且不需要对整张表构建哈希索引。InnoDB 存储引擎会自动根据访问的频率和模式来自动地为某些热点页建立哈希索引。</p>
<p>AHI 有一个要求，即对这个页的连续访问模式必须是一样的。例如对于 (a, b) 这样的联合索引页，其访问模式可以是以下情况：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WHERE</span> a<span class="operator">=</span>xxx</span><br><span class="line"><span class="comment">-- 或者</span></span><br><span class="line"><span class="keyword">WHERE</span> a<span class="operator">=</span>xxx <span class="keyword">and</span> b<span class="operator">=</span>xxx</span><br></pre></td></tr></table></figure>

<p>访问模式一样指的是查询的条件一样，若交替进行上述两种查询，那么 InnoDB 存储引擎不会对该页构造 AHI。此外 AHI 还有如下的要求：</p>
<ul>
<li>以该模式访问了 100 次；</li>
<li>页通过该模式访问了 N 次，其中 <code>N = 页中记录 * 1/16</code>。</li>
</ul>
<p>仅当上述两项同时满足，且访问模式一致时，才会触发 AHI 的构建。<code>同一模式访问次数 ≥ 100</code>：保证该模式不是偶发的短时热点。<code>页访问次数 ≥ R / 16</code>：保证该模式命中足够多的行数，是真正的页级热点。</p>
<p>当你交替执行两种不同的访问模式（<code>WHERE a=xxx</code> 和 <code>WHERE a=xxx AND b=xxx</code>），即使每种模式单独都达到了 100 次，也仍然<strong>不会</strong>触发 AHI 的构建。</p>
<h4 id="异步-IO"><a href="#异步-IO" class="headerlink" title="异步 IO"></a>异步 IO</h4><p>同步 I&#x2F;O：每次调用 <code>read()</code>&#x2F;<code>write()</code> 后，调用线程必须阻塞等待 I&#x2F;O 完成，才能继续下一步操作。</p>
<p>异步 I&#x2F;O (AIO)：调用线程可连续调用多次 <code>io_submit()</code>，将多个 I&#x2F;O 请求并行提交给内核，而不必等待每次完成。内核或专门的 I&#x2F;O 线程池负责实际读写，完成后通过回调或事件 (<code>io_getevents</code>) 通知应用。</p>
<p>AIO 的另一个优势是可以进行 IO Merge 操作，也就是将多个 IO 合并为 1 个 IO，这样可以提高 IOPS 的性能。例如用户需要访问页的 <code>(space, page_no)</code> 为：<code>(8, 6), (8, 7), (8, 8)</code>。每个页的大小为 16KB，那么同步 IO 需要进行 3 次 IO 操作。而 AIO 会判断到这三个页是连续的（显然可以通过 <code>(space, page_no)</code> 得知）。因此 AIO 底层会发送一个 IO 请求，从 <code>(8, 6)</code> 开始，读取 48KB 的页。</p>
<h4 id="刷新邻接页"><a href="#刷新邻接页" class="headerlink" title="刷新邻接页"></a>刷新邻接页</h4><p>在刷新某个脏页时，同时检查并一起刷新该页所在区（extent）中的所有其它脏页，从而通过 AIO（异步 I&#x2F;O）将多个小的写操作合并成一次较大的顺序 I&#x2F;O。</p>
<p>为什么要刷新邻接页？</p>
<ul>
<li><strong>顺序 I&#x2F;O 合并</strong>：在刷新单页时，如果只发出一个 16 KB 的写请求，操作系统与硬盘可能会进行一次小随机写；若同时将同一区中其他脏页一起刷新，就能将多次 16 KB 的写请求合并为一次大块的顺序写，从而利用顺序带宽、<strong>减少磁盘的寻道开销</strong>。</li>
<li><strong>AIO 效果</strong>：配合异步 I&#x2F;O（AIO）提交这些写请求后，硬件&#x2F;内核会自动合并相邻请求为更大块，有效提升 IOPS 和吞吐。</li>
</ul>
<p>如果禁用该功能，则每次仅写出单页，虽然避免了写入无关脏页，但会频繁发生随机写，导致 I&#x2F;O 延迟和写入抖动增大。</p>
<p>示例：在同一个 extent（假设包含页号 0–63）内，页 10、页 12、页 14 已被修改，成为脏页。</p>
<p>禁用刷新邻接页：每次只写出目标脏页本身，不管同一 extent 内是否还有其他脏页。仅页 12 刷入磁盘；页 10 和页 14 保持在缓冲池中，等待下次单独刷新或达到阈值才写入。</p>
<p>启用刷新邻接页：在同一 extent（页 0–63）内，发现目标页 12 后，会顺带把所有脏页（页 10 和页 14）一并写入一次 I&#x2F;O。单次 I&#x2F;O 写出页 10、12、14（共 3 × 16 KB），仅一次寻道即可完成，减少 HDD （硬盘驱动器）随机写的开销。</p>
<h2 id="MyISAM"><a href="#MyISAM" class="headerlink" title="MyISAM"></a>MyISAM</h2><p>它是 MySQL 早期默认的存储引擎。</p>
<p>特点</p>
<ul>
<li><p>不支持事务和外键。</p>
</li>
<li><p>支持表锁，不支持行锁。</p>
</li>
<li><p>访问速度快。</p>
</li>
<li><p>缓冲池只缓存索引文件，而不缓存数据文件。</p>
</li>
</ul>
<p>MyISAM 和 InnoDB 的比较如下表：</p>
<table border="1" cellspacing="0" cellpadding="6">
  <tr>
    <th>项目</th>
    <th>InnoDB</th>
    <th>MyISAM</th>
  </tr>
  <tr>
    <td>存储结构</td>
    <td>
      <code>.frm</code> 存储表定义<br>
      <code>.ibd</code> 存储数据和索引
    </td>
    <td>
      <code>.frm</code> 存储表定义<br>
      <code>.MYD</code> 存储数据<br>
      <code>.MYI</code> 存储索引
    </td>
  </tr>
  <tr>
    <td>事务</td>
    <td>支持（ACID 事务、提交/回滚）</td>
    <td>不支持</td>
  </tr>
  <tr>
    <td>最小锁粒度</td>
    <td>行级锁</td>
    <td>表级锁</td>
  </tr>
  <tr>
    <td>索引类型</td>
    <td>聚簇索引</td>
    <td>非聚簇索引（指向 <code>.MYD</code> 的指针）</td>
  </tr>
  <tr>
    <td>外键</td>
    <td>支持</td>
    <td>不支持</td>
  </tr>
  <tr>
    <td>主键</td>
    <td>可以没有主键</td>
    <td>可以没有主键</td>
  </tr>
  <tr>
    <td>表的具体行数</td>
    <td>需扫描整个表才能返回</td>
    <td>存储在表属性中，查询时可直接返回</td>
  </tr>
</table>

<h2 id="Memory"><a href="#Memory" class="headerlink" title="Memory"></a>Memory</h2><p>该存储引擎的表数据存储在内存中，因此为避免受到硬件问题或断电问题的影响，我们只能将这些表作为临时表或缓存使用。</p>
<p>特点</p>
<ul>
<li><p>内存存储，访问速度快。</p>
</li>
<li><p>默认使用 hash 索引。</p>
</li>
</ul>
<p>以上三种存储引擎的对比如下图：</p>
<p><img src="/../../images/MySQL/engine_3_comp.png" alt="img"></p>
<h2 id="存储引擎选择"><a href="#存储引擎选择" class="headerlink" title="存储引擎选择"></a>存储引擎选择</h2><ul>
<li>InnoDB：<strong>支持事务、外键、行级锁</strong>。如果应用对事务的完整性有比较高的要求，在并发条件下要求数据的一致性，数据操作包含大量的增删改查，那么 InnoDB 存储引擎是比较合适的选择。</li>
<li>MyISAM：如果应用以<strong>读操作和插入操作</strong>为主，只有很少的更新和删除操作，并且对事务的完整性、并发性要求不是很高，那么 MyISAM 是非常合适的（更好的选择是使用 <strong>MongoDB</strong>）。</li>
<li>Memory：将所有数据保存在内存中，访问速度快，通常用于临时表及缓存。缺陷是对表的大小有限制，太大的表无法缓存在内存中，而且无法保障数据的安全性（更好的选择是使用 <strong>Redis</strong>）。</li>
</ul>
<p>除了以上三种引擎，MySQL 还内置了 Archive 和 Federated 等存储引擎。</p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>存储过程</title>
    <url>/undefined/MySQL/2024/10/16/MySQL/%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><p>存储过程是事先经过编译并存储在数据库中的一段 SQL 语句的集合，调用存储过程可以简化应用开发人员的很多工作，减少数据在数据库和应用服务器之间的传输。</p>
<p>特点：</p>
<ol>
<li>封装，复用。</li>
<li>可接收参数，也可返回数据。</li>
<li>减少网络交互，效率提升。</li>
</ol>
<p>创建：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">procedure</span> 存储过程名称(参数列表)</span><br><span class="line"><span class="keyword">begin</span></span><br><span class="line">  <span class="keyword">SQL</span>语句;</span><br><span class="line"><span class="keyword">end</span>;</span><br></pre></td></tr></table></figure>

<p>调用：<code>call 名称(参数列表);</code></p>
<p>查看：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> <span class="keyword">create</span> <span class="keyword">procedure</span> 存储过程名称;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> information_schema.routines <span class="keyword">where</span> routine_schema <span class="operator">=</span> <span class="string">&#x27;xxx&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>删除：<code>drop procedure [if exists] 存储过程名称;</code></p>
<p>在 MySQL 命令行客户端中执行创建存储过程的 SQL 时，需要通过关键字 delimiter 指定 SQL 语句的结束符。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">delimiter $$</span><br><span class="line">create procedure 存储过程名称(参数列表)</span><br><span class="line">begin</span><br><span class="line">  SQL语句;</span><br><span class="line">end $$</span><br></pre></td></tr></table></figure>

<h2 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h2><p><strong>系统变量</strong></p>
<p>由MySQL 服务器提供，属于服务器层面。</p>
<ul>
<li>全局变量（global）</li>
<li>会话变量（session）</li>
</ul>
<p>查看系统变量：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> [session <span class="operator">|</span> <span class="keyword">global</span>] variables;</span><br><span class="line"><span class="keyword">show</span> [session <span class="operator">|</span> <span class="keyword">global</span>] variables <span class="keyword">like</span> <span class="string">&#x27;...&#x27;</span>;</span><br><span class="line"><span class="keyword">select</span> @@[session. <span class="operator">|</span> global.] 系统变量名;</span><br></pre></td></tr></table></figure>

<p>设置系统变量：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> [session <span class="operator">|</span> <span class="keyword">global</span>] 系统变量名 <span class="operator">=</span> 值;</span><br><span class="line"><span class="keyword">set</span> @@[session <span class="operator">|</span> <span class="keyword">global</span>] 系统变量名 <span class="operator">=</span> 值;</span><br></pre></td></tr></table></figure>

<p>如果没有指定 session&#x2F;global，默认是 session，也就是会话变量。</p>
<p>MySQL 服务重新启动之后，所设置的全局参数会失效，要想不失效，可以在 &#x2F;etc&#x2F;my.cnf 中配置。</p>
<p><strong>自定义变量</strong></p>
<p>无需提前声明，格式为 <code>@变量名</code>，作用域为当前连接。</p>
<p>赋值：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> <span class="variable">@var_name</span><span class="operator">=</span>expr [, <span class="variable">@var_name</span><span class="operator">=</span>expr] ...;</span><br><span class="line"><span class="keyword">set</span> <span class="variable">@var_name</span>:<span class="operator">=</span>expr [, <span class="variable">@var_name</span>:<span class="operator">=</span>expr] ...;</span><br><span class="line"><span class="keyword">select</span> <span class="variable">@var_name</span>:<span class="operator">=</span>expr [, <span class="variable">@var_name</span>:<span class="operator">=</span>expr] ...;</span><br><span class="line"><span class="keyword">select</span> 字段名 <span class="keyword">into</span> <span class="variable">@var_name</span> <span class="keyword">from</span> 表名; <span class="comment">-- 把从表中获取的数据赋值给变量</span></span><br></pre></td></tr></table></figure>

<p>使用：<code>select @var_name;</code></p>
<p>用户定义的变量无需对其进行声明或初始化，只不过获取到的值为 NULL，但是不会报错。</p>
<p><strong>局部变量</strong></p>
<p>在局部生效的变量，访问之前需要先通过 declare 声明，可用作存储过程的局部变量和输入参数，作为局部变量的话，范围是在 <code>begin … end</code> 块内。</p>
<p>声明：<code>declare 变量名 变量类型 [default ...];</code></p>
<p>赋值：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> 变量名 <span class="operator">=</span> 值;</span><br><span class="line"><span class="keyword">set</span> 变量名 :<span class="operator">=</span> 值;</span><br><span class="line"><span class="keyword">select</span> 字段名 <span class="keyword">into</span> 变量名 <span class="keyword">from</span> 表名 ...;</span><br></pre></td></tr></table></figure>

<h2 id="IF"><a href="#IF" class="headerlink" title="IF"></a>IF</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">If 条件<span class="number">1</span> <span class="keyword">then</span></span><br><span class="line">...</span><br><span class="line">Elseif 条件<span class="number">2</span> <span class="keyword">then</span></span><br><span class="line">...</span><br><span class="line"><span class="keyword">Else</span></span><br><span class="line">...</span><br><span class="line"><span class="keyword">End</span> If</span><br></pre></td></tr></table></figure>

<h2 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h2><p>类型</p>
<ul>
<li>IN：输入参数。</li>
<li>OUT：输出参数。</li>
<li>INOUT：输入输出参数皆可。</li>
</ul>
<p>用法</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">procedure</span> 存储过程名称([<span class="keyword">IN</span><span class="operator">/</span><span class="keyword">OUT</span><span class="operator">/</span><span class="keyword">INOUT</span> 参数名 参数类型])</span><br><span class="line"><span class="keyword">begin</span></span><br><span class="line">  <span class="keyword">SQL</span> 语句</span><br><span class="line"><span class="keyword">end</span>;</span><br></pre></td></tr></table></figure>

<h2 id="case"><a href="#case" class="headerlink" title="case"></a>case</h2><p>语法 1</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> case_value</span><br><span class="line"><span class="keyword">when</span> value1 <span class="keyword">then</span> statement_list1</span><br><span class="line">[<span class="keyword">when</span> value2 <span class="keyword">then</span> statement_list2] ...</span><br><span class="line">[<span class="keyword">else</span> statement_list]</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">case</span>;</span><br></pre></td></tr></table></figure>

<p>语法 2</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span></span><br><span class="line"><span class="keyword">when</span> search_condition1 <span class="keyword">then</span> statement_list1</span><br><span class="line">[<span class="keyword">when</span> search_condition2 <span class="keyword">then</span> statement_list2] ...</span><br><span class="line">[<span class="keyword">else</span> statement_list]</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">case</span>;</span><br></pre></td></tr></table></figure>

<h2 id="while"><a href="#while" class="headerlink" title="while"></a>while</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">while 条件 do</span><br><span class="line">  <span class="keyword">SQL</span> 语句</span><br><span class="line"><span class="keyword">end</span> while;</span><br></pre></td></tr></table></figure>

<h2 id="repeat"><a href="#repeat" class="headerlink" title="repeat"></a>repeat</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">repeat</span><br><span class="line">  <span class="keyword">SQL</span> 语句</span><br><span class="line">until 条件</span><br><span class="line"><span class="keyword">end</span> repeat;</span><br></pre></td></tr></table></figure>

<h2 id="loop"><a href="#loop" class="headerlink" title="loop"></a>loop</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">[label]: loop</span><br><span class="line">	<span class="keyword">SQL</span> 语句</span><br><span class="line"><span class="keyword">end</span> loop [label];</span><br></pre></td></tr></table></figure>

<p><code>leave label;</code> 退出指定标记的循环体（类似于 break）<br><code>iterate label;</code> 直接进入下一次循环（类似于 continue）</p>
<h2 id="游标"><a href="#游标" class="headerlink" title="游标"></a>游标</h2><p>用来存储查询结果集的数据类型，在存储过程和函数中可以使用游标对结果集进行循环处理。</p>
<ul>
<li>声明游标：<code>declare 游标名称 cursor for 查询语句;</code></li>
<li>打开游标：<code>open 游标名称;</code></li>
<li>获取游标记录：<code>fetch 游标名称 into 变量 [, 变量];</code></li>
<li>关闭游标：<code>close 游标名称;</code></li>
</ul>
<h2 id="条件处理程序"><a href="#条件处理程序" class="headerlink" title="条件处理程序"></a>条件处理程序</h2><p>用来定义在流程控制结构执行过程中遇到问题时相应的处理步骤。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">declare</span> handler_action handler <span class="keyword">for</span> condition_value [, condition_value]... statement;</span><br></pre></td></tr></table></figure>

<ul>
<li>handler action:<ul>
<li><code>continue</code>：继续执行当前程序。</li>
<li><code>exit</code>：终止执行当前程序。</li>
</ul>
</li>
<li><code>condition_value</code><ul>
<li><code>SQLSTATE sqlstate_value</code>：状态码，如 02000。</li>
<li><code>SQLWARNING</code>：所有以 01 开头的 SQLSTATE 代码的简写。</li>
<li><code>NOTFOUND</code>：所有以 02 开头的 SQLSTATE 代码的简写。</li>
<li><code>SQLEXCEPTION</code>：所有没有被 SQLWARNING 和 NOTFOUND 捕获的 SQLSTATE 代码的简写。</li>
</ul>
</li>
</ul>
<p>例子：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">declare</span> exit handler <span class="keyword">for</span> <span class="keyword">SQLSTATE</span> <span class="string">&#x27;02000&#x27;</span> <span class="keyword">close</span> u_cursor;</span><br></pre></td></tr></table></figure>

<p>该 SQL 声明了一个条件处理程序，当满足SQL 状态码为 02000 时，先关闭游标，然后执行退出操作。</p>
<p>存储函数是有返回值的存储过程，参数只能是 IN 类型的。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">function</span> 存储函数名称([参数列表])</span><br><span class="line"><span class="keyword">returns</span> type [characteristic ...]</span><br><span class="line"><span class="keyword">begin</span></span><br><span class="line">  <span class="keyword">SQL</span>语句;</span><br><span class="line">  <span class="keyword">return</span> ...;</span><br><span class="line"><span class="keyword">end</span>;</span><br></pre></td></tr></table></figure>

<p>characteristic 说明：</p>
<ul>
<li>deterministic：返回值类型和传入值类型相同。</li>
<li>NO SQL：不包含 SQL 语句。</li>
<li>READS SQL DATA： 只包含读取数据的 SQL 语句，不包含修改数据的 SQL 语句。</li>
</ul>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>日志</title>
    <url>/undefined/MySQL/2024/10/22/MySQL/%E6%97%A5%E5%BF%97/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><p><strong>错误日志（Error Log）</strong> 用于记录在服务 <strong>启动、运行及停止</strong> 过程中遇到的各种错误信息。该日志功能默认启用，且默认保存在 Linux 系统的 <code>/var/log/mysqld.log</code>（或 <code>/var/log/mysql/error.log</code>）路径下，也可能在 data 目录中以主机名为 .err 后缀的文件方式存在。若想查看或修改该路径，可通过 MySQL 命令：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SHOW</span> VARIABLES <span class="keyword">LIKE</span> <span class="string">&#x27;%log_error%&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>该命令会显示当前 log_error 变量的值，即错误日志所在路径。如果该变量为空，通常默认日志会被输出到 stderr，或由系统服务（如 systemd）转至系统日志（如 <code>/var/log/messages</code> 或由 journalctl 管理）。</p>
<p><strong>二进制日志（Binary Log）</strong> 会记录所有成功执行的 <strong>DDL</strong>（结构定义语句）和 <strong>DML</strong>（数据操作语句），但不会包含纯查询类语句（如 SELECT、SHOW）。它以 <strong>Event</strong> 形式记录，并且保存每条语句执行的时间戳。默认情况下启用二进制日志，并常用于数据备份以及主从复制场景。</p>
<p>二进制日志系统包括两类文件：</p>
<ul>
<li><strong>索引文件（.index）</strong>：跟踪所有二进制日志文件的路径；</li>
<li><strong>日志文件（形如 .00000*）</strong>：具体记录 DDL 与 DML 的事件。</li>
</ul>
<p>日志的记录格式有三种：</p>
<ul>
<li><strong>STATEMENT</strong>：以文本形式记录每条 SQL，并不包含事务上下文、权限或系统状态；</li>
<li><strong>ROW</strong>：以二进制形式记录行数据的变化（旧值和新值）；</li>
<li><strong>MIXED</strong>（MySQL 8.0 以上默认）：通常使用 STATEMENT，在涉及非确定性函数（如 <code>NOW()</code>、<code>UUID()</code> 等）时自动切换到 ROW 格式。</li>
</ul>
<p>针对日志清理，常用命令如下：</p>
<ul>
<li><code>RESET BINARY LOGS;</code>（或旧版本的 <code>RESET MASTER;</code>）将删除所有二进制日志，并将索引重置，只保留一个新的空日志文件（编号从 .000001 开始）；</li>
<li><code>PURGE BINARY LOGS TO &#39;binlog.xxx&#39;;</code> 删除指定日志文件之前的所有日志；</li>
<li><code>PURGE BINARY LOGS BEFORE &#39;YYYY‑MM‑DD hh:mm:ss&#39;;</code> 删除该时间之前生成的所有日志。</li>
</ul>
<p>此外，可以设置系统变量（如 <code>binlog_expire_logs_seconds</code> 或旧版的 <code>expire_logs_days</code>）实现自动清理过期日志，默认保留期为 30 天。</p>
<p>更多关于 binlog 的信息，可参考：<a href="https://www.cnblogs.com/rickiyang/p/13841811.html">https://www.cnblogs.com/rickiyang/p/13841811.html</a></p>
<p><strong>二进制日志（binlog）</strong> 功能可以通过在 <code>my.cnf</code> 或启动参数中设置来进行全面配置，下面是一些常用选项与管理方法：</p>
<p>启用与路径配置：<code>log‑bin=/home/mysql/binlog/</code></p>
<p>该参数不仅开启 binlog 功能，还指定日志文件的存放目录。如果不指定路径，MySQL 默认将日志保存在数据目录，并以主机名或 binlog 为基础名生成一系列 <code>.00000*</code> 日志文件。</p>
<p>文件大小与保留周期：</p>
<ul>
<li><code>max_binlog_size=104857600</code> 将单个日志文件最大限制为 100 MB。</li>
<li><code>expire_logs_days=7</code> 设置日志自动保留时限为 7 天，超过该时长的日志文件会被系统定期清理。</li>
</ul>
<p>过滤数据库：</p>
<p>可以通过以下参数控制哪些库的更新被记录到 binlog：</p>
<ul>
<li><code>binlog-do-db=db_name</code>：仅记录指定数据库的变更。</li>
<li><code>binlog-ignore-db=db_name</code>：忽略指定数据库的更新，不写入日志。</li>
</ul>
<p>同步策略：</p>
<p><code>sync_binlog=0</code> 表示不强制让 MySQL 将日志立即同步到磁盘，交由操作系统定期执行。该配置提高性能，但在主机崩溃时可能丢失最后一部分日志；若设为 1，则在每次提交时都 fsync，一致性高但性能略受影响。</p>
<p>查看当前设置：</p>
<p>可以执行以下命令确认配置状态：</p>
<ul>
<li><code>SHOW BINARY LOGS;</code>：列出当前所有 binlog 文件；</li>
<li><code>SHOW MASTER STATUS;</code>：查看主服务器正在使用的最新日志名称与位置；</li>
<li><code>SHOW VARIABLES LIKE &#39;%log_bin%&#39;;</code>：确认二进制日志是否已启用及其路径；</li>
<li><code>SHOW VARIABLES LIKE &#39;%binlog_format%&#39;;</code>：查看当前记录格式（STATEMENT、ROW 或 MIXED）；</li>
<li><code>SHOW VARIABLES LIKE &#39;%binlog_expire_logs_seconds%&#39;;</code>：检查自动过期设置（通常是以秒为单位）。</li>
</ul>
<p>手动恢复流程：</p>
<ol>
<li>停止 MySQL 服务；</li>
<li>利用 mysqlbinlog 工具分析 <code>.00000*</code> 中的日志，确认误操作发生前的起始与结束位置；</li>
<li>清空当前数据库以准备恢复；</li>
<li>执行命令：<code>mysqlbinlog --start-position=xxx --stop-position=yyy bin-log.00000x &gt; recover.sql</code>，其中 start-position 为误操作前最近一次安全点，stop-position 为误前最后一条正常语句的位置；</li>
<li>将导出的 recover.sql 文件导入数据库，恢复指定段的变更。</li>
</ol>
<p><strong>一般查询日志</strong>记录了MySQL 服务器的<strong>所有连接信息</strong>和客户端的<strong>所有操作语句</strong>，默认是不开启的。</p>
<p><strong>慢查询日志</strong>用于记录执行时间超过 <code>long_query_time</code>（默认 10 秒）并且扫描记录数不少于 <code>min_examined_row_limit</code> 的 SQL 语句，以帮助识别并优化效率低下的查询。注意，这一功能默认处于关闭状态，开启后不包含管理语句（如 ALTER、CREATE INDEX）及未使用索引的查询，除非你通过以下两个系统变量特别配置：</p>
<ul>
<li><code>log_slow_admin_statements</code>：启用后，允许记录管理类语句；</li>
<li><code>log_queries_not_using_indexes</code>：启用后，记录所有不使用索引的查询（并不限于慢查询）。</li>
</ul>
<p>日志触发条件的判断顺序如下（MySQL 8.0+）：</p>
<ol>
<li>是不是管理语句，或已启用 <code>log_slow_admin_statements</code>；</li>
<li>查询执行时间 ≥ long_query_time，或启用 <code>log_queries_not_using_indexes</code> 并且未使用索引；</li>
<li>扫描的行数 ≥ min_examined_row_limit；</li>
<li>若启用了该选项，还会受 <code>log_throttle_queries_not_using_indexes</code>（对未用索引查询加速限流）的影响。</li>
</ol>
<p>简而言之，慢查询日志只有在 SQL 足够慢或扫描量大时才会记录，且默认不记录管理或索引缺失的语句，除非明确启用相关变量。若需全面监控优化目标，建议根据实际情况调整这三项核心参数。</p>
<p><strong>重做日志（redo log）</strong> 专门记录已提交事务所做的页面级别修改，以确保在崩溃或异常关机后能够快速恢复数据一致性。与完整行记录不同，redo log 只保存页号（Page ID）和偏移量（Offset）处的数据从旧值到新值的变化，例如在页面 12345 的偏移量 256 位置，将值从 25 修改为 30，既紧凑又高效。这些日志文件通常组成一个循环队列：当当前日志文件写满后，InnoDB 会切换到下一个文件，直到用尽后再回到第一个文件，覆盖最早的日志。</p>
<p>其工作流程如下：</p>
<ol>
<li><strong>事务开始与修改缓冲</strong>：当事务对表中数据进行修改时，InnoDB 先将修改记录写入内存中的 redo log buffer；</li>
<li><strong>事务提交与刷盘</strong>：提交时，buffer 中的内容根据 <code>innodb_flush_log_at_trx_commit</code> 参数设置，或直接刷入磁盘（值为 1）、或先写入操作系统缓冲区后由系统决定何时落盘（值为 2）、或不强制落盘以提升性能但有丢失风险（值为 0）；</li>
<li><strong>Checkpoint 协同</strong>：后台 Checkpoint 进程周期性地将内存中的脏数据页同步到表空间文件（<code>*.ibd</code>），并将对应的 redo log 日志标记为可覆写，维持循环日志的持续运作。</li>
</ol>
<p>通过这种设计，InnoDB 能够在最短时间内重做已提交的事务修改，快速恢复数据库到故障发生前的一致状态。</p>
<p>假设在表空间 <strong>1</strong> 中，对页 <strong>42</strong> 的偏移 <strong>128</strong> 处的某条记录的第 <strong>3</strong> 个字段（如 age）执行更新，将其从 <strong>25</strong> 改为 <strong>30</strong>，则对应的 redo 日志项可示意如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[MLOG_REC_UPDATE_IN_PLACE]</span><br><span class="line">Type:        MLOG_REC_UPDATE_IN_PLACE</span><br><span class="line">Space ID:      1</span><br><span class="line">Page Number:    42</span><br><span class="line">Record Offset:   128</span><br><span class="line">Update Field Count: 1</span><br><span class="line"> └ Field Number:   3</span><br><span class="line">  Field Data Length: 4</span><br><span class="line">  Field Data:    0x0000001E</span><br></pre></td></tr></table></figure>

<p>binlog 和 redo log 的区别如下表：</p>
<p><img src="/../../images/MySQL/redo_bin_comp.png" alt="img"></p>
<p><strong>回滚日志（Undo Log）</strong> 用于在事务回滚和多版本并发控制（MVCC）中保存数据修改前的旧值。当事务开始时，InnoDB 会初始化事务上下文；在执行更新、删除等修改操作时，它首先将当前行的原始数据写入 undo log，同时将对应的物理改动记录到内存中的 redo log buffer；如果事务提交，则会将 redo 日志刷新到磁盘，并将该事务所产生的 undo 日志标记为无效，待后台清理；若事务选择回滚，则 InnoDB 会读取 undo log 中的旧值，将数据恢复到修改前的状态，并在回滚完成后清理相关的 redo 日志。这样既保证了未提交事务的可回滚性，也为 MVCC 提供了版本快照支持。</p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>约束</title>
    <url>/undefined/MySQL/2024/09/18/MySQL/%E7%BA%A6%E6%9D%9F/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><p>作用于表中字段上的规则，用于<strong>限制</strong>存储在表中的数据，保证表中数据的正确性、有效性和完整性。</p>
<ul>
<li>NOT NULL 非空约束</li>
<li>UNIQUE 唯一约束</li>
<li>PRIMARY KEY 主键约束</li>
<li>DEFAULT 默认约束</li>
<li>CHECK 检查约束</li>
<li>FOREIGN KEY 外键约束：让两张表的数据之间建立连接，具有外键的表是子表。</li>
</ul>
<p>声明外键：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> 表名 (</span><br><span class="line">  字段名 数据类型,</span><br><span class="line">  [<span class="keyword">CONSTRAINT</span>] [外键名称] <span class="keyword">FOREIGN KEY</span> (外键字段名) <span class="keyword">REFERENCES</span> 主表 (主表列名)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">ALTER TABLE</span> 表名 <span class="keyword">ADD CONSTRAINT</span> 外键名称 <span class="keyword">FOREIGN KEY</span> (外键字段名) <span class="keyword">REFERENCES</span> 主表 (主表列名);</span><br></pre></td></tr></table></figure>

<p>删除外键：<code>ALTER TABLE 表名 DROP FOREIGN KEY 外键名称;</code></p>
<p>删除&#x2F;更新行为：</p>
<ul>
<li>NO ACTION 在父表中删除&#x2F;更新对应记录时，首先检查该记录是否有对应外键，如果有则不允许删除&#x2F;更新。（与RESTRICT一致）</li>
<li>RESTRICT</li>
<li>CASCADE 在父表中删除&#x2F;更新对应记录时，首先检查该记录是否有对应外键：如果有，也删除&#x2F;更新外键在子表中的记录。</li>
<li>SET NULL 在父表中删除对应记录时，首先检查该记录是否有对应外键：如果有，设置子表中该外键值为 null （要求外键允许取 null）。</li>
<li>SET DEFAULT 父表数据变更时，子表将外键列设置成一个默认的值（InnoDB不支持）。</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER TABLE</span> 表名 <span class="keyword">ADD CONSTRAINT</span> 外键名称 <span class="keyword">FOREIGN KEY</span> (外键字段) <span class="keyword">REFERENCES</span> 主表名 (主表字段名) <span class="keyword">ON</span> <span class="keyword">UPDATE</span> [更新行为] <span class="keyword">ON</span> <span class="keyword">DELETE</span> [删除行为];</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>视图</title>
    <url>/undefined/MySQL/2024/10/11/MySQL/%E8%A7%86%E5%9B%BE/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><p>在 MySQL 数据库中，视图（View）是一个命名的虚表，它由一个 SQL 查询来定义，可以当做表使用。与持久表（permanent table）不同的是，视图中的数据没有实际的物理存储。也就是说视图中的数据并不在数据库中实际存在，行和列的数据来自定义视图的查询中使用的表，在使用视图时动态生成的。</p>
<p>视图只保存了查询的 SQL 逻辑，不保存查询结果。</p>
<h2 id="视图的作用"><a href="#视图的作用" class="headerlink" title="视图的作用"></a>视图的作用</h2><p>视图在数据库中发挥着重要的作用。视图的主要用途之一是被用做一个抽象装置，特别是对于一些应用程序，程序本身不需要关心基表（base table）的结构，只需要按照视图定义来取数据或更新数据；因此，视图同时在一定程度上起到一个安全层的作用。</p>
<p>MySQL 数据库 DBA 的一个常用的命令是 SHOW TABLES，该命令会显示出当前数据库下所有的表。但因为视图是虚表，同样被作为表显示出来。若用户只想查看当前架构下的基表，可以通过 information_schema 架构下的 TABLES 表来查询，并搜索表类型为 BASE TABLE 的表。</p>
<p>要想查看视图的一些元数据（meta data），可以访问 information_schema 架构下的 VIEWS 表，该表给出了视图的详细信息，包括视图定义者（definer）、定义内容、是否是可更新视图、字符集等。</p>
<p>创建：<code>create [or replace] view 视图名称 as select 语句 [with cascaded | local check option];</code></p>
<p>查询：</p>
<ul>
<li>查看创建视图的语句：<code>show create view 视图名称;</code></li>
<li>查看视图数据：<code>select * from 视图名称...;</code></li>
</ul>
<p>修改：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> [<span class="keyword">or</span> replace] <span class="keyword">view</span> 视图名称 <span class="keyword">as</span> <span class="keyword">select</span> 语句 [<span class="keyword">with</span> <span class="keyword">cascaded</span> <span class="operator">|</span> <span class="keyword">local</span> <span class="keyword">check</span> option];</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">view</span> 视图名称 <span class="keyword">as</span> <span class="keyword">select</span> 语句 [<span class="keyword">with</span> <span class="keyword">cascaded</span> <span class="operator">|</span> <span class="keyword">local</span> <span class="keyword">check</span> option];</span><br><span class="line"># 实际上数据行是被插入了基表当中</span><br><span class="line"><span class="keyword">insert into</span> 视图名称 <span class="keyword">values</span>(col1, col2, ...); </span><br></pre></td></tr></table></figure>

<p>删除：<code>drop view [if exist] 视图名称;</code></p>
<h2 id="视图的检查选项"><a href="#视图的检查选项" class="headerlink" title="视图的检查选项"></a>视图的检查选项</h2><p>当时用 <code>with check option</code> 子句创建视图时，MySQL 会通过视图检查正在更改的每一行，以使其符合视图的定义。MySQL 允许基于一个视图创建另一个视图，还会依赖视图中的规则以保持一致性。MySQL 提供了两个选项确定检查范围：cascaded 和 local，默认值为 cascaded。</p>
<h2 id="视图的更新"><a href="#视图的更新" class="headerlink" title="视图的更新"></a>视图的更新</h2><p>要使视图可更新，视图中的行与基础表中的行之间必须存在一对一的关系。</p>
<p>如果视图包含以下任何一项，该视图不可更新：</p>
<ul>
<li>聚合函数或窗口函数：<code>sum()</code>，<code>min()</code>，<code>max()</code>，<code>count()</code>；</li>
<li><code>distinct</code>；</li>
<li><code>group by</code>；</li>
<li><code>having</code>；</li>
<li><code>union</code> 或 <code>union all</code>。</li>
</ul>
<p>视图可以简化用户对数据的理解，以及简化操作。</p>
<p>通过视图，用户只能查询和修改他们所能见到的数据。</p>
<p>视图帮助用户屏蔽真实表结构变化带来的影响。</p>
<h2 id="物化视图"><a href="#物化视图" class="headerlink" title="物化视图"></a>物化视图</h2><p>Oracle 数据库支持物化视图——该视图不是基于基表的虚表，而是根据基表实际存在的实表，即物化视图的数据存储在非易失的存储设备上。物化视图可用于预先计算并保存多表的连接（JOIN）或聚集（GROUP BY）等耗时较多的 SQL 操作结果。这样，在执行复杂查询时，就可以避免进行这些时耗的操作，从而快速得到结果。物化视图的好处是对于一些复杂的统计类查询能直接给出结果。在 Microsoft SQL Server 数据库中，称这种视图为索引视图。</p>
<p>在 Oracle 数据库中，物化视图的创建方式包括以下两种：</p>
<ul>
<li><code>BUILD IMMEDIATE</code></li>
<li><code>BUILD DEFERRED</code></li>
</ul>
<p><code>BUILD IMMEDIATE</code> 是默认的创建方式，在创建物化视图的时候就生成数据，而 <code>BUILD DEFERRED</code> 则在创建物化视图时不生成数据，以后根据需要再生成数据。</p>
<p>查询重写是指当对物化视图的基表进行查询时，数据库会自动判断能否通过查询物化视图来直接得到最终的结果，如果可以，则避免了聚集或连接等这类较为复杂的 SQL 操作，直接从已经计算好的物化视图中得到所需的数据。</p>
<p>物化视图的刷新是指当基表发生了 DML 操作后，物化视图何时采用哪种方式和基表进行同步。刷新模式有两种：</p>
<ul>
<li><code>ON DEMAND</code></li>
<li><code>ON COMMIT</code></li>
</ul>
<p><code>ON DEMAND</code> 意味着物化视图在用户需要的时候进行刷新，ON COMMIT 意味着物化视图在对基表的 DML 操作提交的同时进行刷新。</p>
<p>而刷新的方法有四种：</p>
<ul>
<li><code>FAST</code></li>
<li><code>COMPLETE</code></li>
<li><code>FORCE</code></li>
<li><code>NEVER</code></li>
</ul>
<p>FAST 刷新采用增量刷新，只刷新自上次刷新以来进行的修改。COMPLETE 刷新是对整个物化视图进行完全的刷新。如果选择 FORCE 方式，则数据库在刷新时会去判断是否可以进行快速刷新，如果可以，则采用 FAST 方式，否则采用 COMPLETE 的方式。NEVER 是指物化视图不进行任何刷新。</p>
<p><strong>MySQL 数据库本身并不支持物化视图</strong>，换句话说，MySQL 数据库中的视图总是虚拟的。但是用户可以通过一些机制来实现物化视图的功能。例如要创建一个 ON DEMAND 的物化视图还是比较简单的，用户只需定时把数据导入到另一张表。</p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>索引</title>
    <url>/undefined/MySQL/2024/10/30/MySQL/%E7%B4%A2%E5%BC%95/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><p>索引是一种可以帮助 MySQL 高效获取数据的数据结构，也是有序结构。</p>
<p>优点</p>
<ul>
<li>提高数据检索效率，降低数据库 I&#x2F;O 成本。</li>
<li>通过索引列对数据进行排序，降低数据排序成本，降低 CPU 的消耗。</li>
</ul>
<p>缺点</p>
<ul>
<li>占用空间。</li>
<li>降低了更新表的效率，如 INSERT、UPDATE、DELETE。</li>
</ul>
<p>因此，若索引太多，应用程序的性能可能会受到影响。而索引太少，对查询性能又会产生影响。要找到一个合适的平衡点，这对应用程序的性能至关重要。</p>
<h2 id="索引结构"><a href="#索引结构" class="headerlink" title="索引结构"></a>索引结构</h2><p>MySQL 索引是在引擎层实现的，不同的存储引擎支持不同的索引结构。</p>
<table>
<thead>
<tr>
<th>索引结构</th>
<th>描述</th>
<th>InnoDB</th>
<th>MyISAM</th>
<th>Memory</th>
</tr>
</thead>
<tbody><tr>
<td>B+Tree 索引</td>
<td>最常见的索引类型，大部分引擎支持 B+Tree索引</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
</tr>
<tr>
<td>Hash 索引</td>
<td>底层数据结构由哈希表实现，只有精确匹配索引列的查询才有效，不支持查询范围</td>
<td>不支持</td>
<td>不支持</td>
<td>支持</td>
</tr>
<tr>
<td>R-Tree 空间索引</td>
<td>空间索引是 MyISAM 引擎的一个特殊索引类型，主要用于地理空间数据类型</td>
<td>不支持</td>
<td>支持</td>
<td>不支持</td>
</tr>
<tr>
<td>Full-Text 全文索引</td>
<td>一种通过建立倒排索引来快速匹配文档的方式</td>
<td>5.6版本之后支持</td>
<td>支持</td>
<td>不支持</td>
</tr>
</tbody></table>
<h2 id="InnoDB-索引分类"><a href="#InnoDB-索引分类" class="headerlink" title="InnoDB 索引分类"></a>InnoDB 索引分类</h2><p><img src="/../../images/MySQL/index_type.png" alt="img"></p>
<table>
<thead>
<tr>
<th>索引类别</th>
<th>含义</th>
<th>特点</th>
<th>关键字</th>
</tr>
</thead>
<tbody><tr>
<td>主键索引</td>
<td>针对表中<strong>主键</strong>创建的索引</td>
<td>默认自动创建，只能有一个</td>
<td>PRIMARY</td>
</tr>
<tr>
<td>唯一索引</td>
<td><strong>避免</strong>同一个表中某数据列中的值<strong>重复</strong></td>
<td>可以有多个</td>
<td>UNIQUE</td>
</tr>
<tr>
<td>常规索引</td>
<td>快速定位特定数据</td>
<td>可以有多个</td>
<td></td>
</tr>
<tr>
<td>全文索引</td>
<td><strong>查找</strong>文本中的<strong>关键字</strong>，而不是比较索引中的值</td>
<td>可以有多个</td>
<td>FULLTEXT</td>
</tr>
</tbody></table>
<p>根据索引存储形式，可分为以下两种：</p>
<table>
<thead>
<tr>
<th>分类</th>
<th>含义</th>
<th>特点</th>
</tr>
</thead>
<tbody><tr>
<td>聚集索引</td>
<td><strong>将数据存储与索引放到了一块</strong>，索引结构的叶子节点保存了行数据</td>
<td>必须有，而且只有一个</td>
</tr>
<tr>
<td>二级索引</td>
<td><strong>将数据与索引分开存储</strong>，索引结构的叶子节点关联的是对应的<strong>主键</strong></td>
<td>可以存在多个</td>
</tr>
</tbody></table>
<p>InnoDB 支持以下索引：</p>
<ul>
<li>B+ 树索引</li>
<li>全文索引</li>
<li>自适应 Hash 索引</li>
</ul>
<p>B+ 树索引就是传统意义上的索引，这是目前关系型数据库系统中查找最为高效且被认为有效的索引。B+ 树索引的构造类似于二叉树，根据键值（Key Value）快速找到数据。B+ 树索引能找到的只是被查找数据所在的页。然后数据库通过把页读入到内存，再在内存中进行查找，最后得到要查找的数据。</p>
<p>整体流程：</p>
<p>B+ 树 Root &#x3D;&gt; B+ 树索引节点 &#x3D;&gt; B+ 树叶子节点 &#x3D;&gt; Page Directory 中的一个 Slot &#x3D;&gt; 目标行数据。</p>
<p>InnoDB 存储引擎支持的哈希索引是自适应的，InnoDB 存储引擎会根据表的使用情况自动为表生成哈希索引，不能人为干预是否在一张表中生成哈希索引。</p>
<p>InnoDB 的主键使用的是聚簇索引，而 MyISAM 中，不管是主键索引还是二级索引使用的都是非聚簇索引。</p>
<p>InnoDB 中的全表扫描会顺序读取聚集索引上的数据页（即叶子节点），等价于按主键顺序逐行扫描表中所有行。</p>
<h2 id="全表扫描"><a href="#全表扫描" class="headerlink" title="全表扫描"></a>全表扫描</h2><p>在 InnoDB 中，一条简单的 <code>SELECT * FROM A</code> 在执行时会经过以下几层，才能把表 A 中的每一行读出来。下面分段结合关键源码，逐步说明一个典型的全表扫描流程。</p>
<p><strong>一、Handler 接口</strong>：<code>ha_rnd_next</code> 循环读取</p>
<p><code>TableScanIterator::Read()</code> 中：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> ((tmp = <span class="built_in">table</span>()-&gt;file-&gt;<span class="built_in">ha_rnd_next</span>(m_record))) &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (tmp == HA_ERR_RECORD_DELETED &amp;&amp; !<span class="built_in">thd</span>()-&gt;killed) <span class="keyword">continue</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">HandleError</span>(tmp);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><p><code>ha_rnd_next(m_record)</code>：MySQL 存储引擎统一接口，每次调用读一行到 <code>m_record</code>。</p>
</li>
<li><p>跳过 DELETED：MyISAM 在并发删时会返回 <code>HA_ERR_RECORD_DELETED</code>，此处跳过。</p>
</li>
<li><p>返回码：0 表示成功取到一行；非 0 则调用 <code>HandleError(tmp)</code> 终止扫描。</p>
</li>
</ul>
<p>对于 InnoDB，<code>ha_rnd_next</code> 内部实现为：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">handler::ha_rnd_next</span><span class="params">(uchar *buf)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">MYSQL_TABLE_IO_WAIT</span>(..., &#123; result = <span class="built_in">rnd_next</span>(buf); &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!result &amp;&amp; m_update_generated_read_fields)</span><br><span class="line"></span><br><span class="line">      <span class="built_in">update_generated_read_fields</span>(buf, table);</span><br><span class="line"></span><br><span class="line">  table-&gt;<span class="built_in">set_row_status_from_handler</span>(result);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>二、InnoDB 读取流程</strong>：<code>rnd_next</code> → <code>general_fetch</code> → <code>row_search_mvcc</code></p>
<p><code>rnd_next(buf)</code> 中的核心调用如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (m_start_of_scan) &#123;</span><br><span class="line"></span><br><span class="line">  error = <span class="built_in">index_first</span>(buf);</span><br><span class="line"></span><br><span class="line">  m_start_of_scan = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"></span><br><span class="line">  error = <span class="built_in">general_fetch</span>(buf, ROW_SEL_NEXT, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> error;</span><br></pre></td></tr></table></figure>

<ul>
<li>首次扫描 调用 <code>index_first(buf)</code> 定位到最左叶节点的第一条记录；</li>
<li>后续扫描 一律调用 <code>general_fetch</code>。</li>
</ul>
<p><code>general_fetch(buf, ROW_SEL_NEXT, 0)</code> 中的核心调用如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (!intrinsic) <span class="comment">// 普通表</span></span><br><span class="line"></span><br><span class="line">  ret = <span class="built_in">row_search_mvcc</span>(buf, PAGE_CUR_UNSUPP, m_prebuilt, <span class="number">0</span>, ROW_SEL_NEXT);</span><br><span class="line"></span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 再把 dberr_t 转成 MySQL 错误码返回给 rnd_next</span></span><br></pre></td></tr></table></figure>

<p>row_search_mvcc</p>
<p><code>row_search_mvcc</code> 中的核心调用如下：</p>
<ul>
<li>首次 (<code>direction == 0</code>)：构造或恢复一个 B-树游标 pcur，调用 <code>pcur-&gt;open_no_init()</code>（或 <code>open_at_side</code>）从根节点一路走到左最叶，定位第一条记录。</li>
<li>后续 (<code>direction == ROW_SEL_NEXT</code>)：直接在叶节点上调用 <code>pcur-&gt;move_to_next(&amp;mtr)</code>，利用叶节点之间的双向链表遍历下一条记录，无需再从根节点重查。</li>
<li>循环过滤（<code>rec_loop</code>）：<ul>
<li>跳过 infimum&#x2F;supremum 伪记录，检查页内偏移合法性；</li>
<li>MVCC 版本检查：如果当前版本不可见，调用 undo log 回溯到可见版本；</li>
<li>删除标记：跳过 delete-marked；</li>
<li>索引条件下推（此例没有 WHERE，相当于 <code>match_mode == 0</code>，所有行都通过）；</li>
<li>转换格式：调用 <code>row_sel_store_mysql_rec(buf, …)</code> 将内部二进制行转成 MySQL 客户端格式；</li>
<li>预取缓存：若启用缓存则放入队列，否则直接写入 buf 并 <code>return DB_SUCCESS</code>。</li>
</ul>
</li>
<li>退出：当 <code>move_to_next</code> 返回 false（无更多记录），函数最终返回 <code>DB_END_OF_INDEX</code> 或 <code>DB_RECORD_NOT_FOUND</code>，上层映射为 <code>HA_ERR_END_OF_FILE</code>。</li>
</ul>
<p>在 <code>row_search_mvcc</code> 的整个执行过程中，游标（pcur）的状态会在多处被保存和恢复，其核心目的有两个：</p>
<ol>
<li>跨页扫描时保持定位：当 B- 树叶节点遍历到一页的末尾，需要切换到下一页时，InnoDB 会提交当前 mini-transaction（<code>mtr_commit(&amp;mtr)</code>）并重新开启一个新的 mini-transaction（mtr_start(&amp;mtr)）。提交会释放当前页面的读锁（latch），以避免死锁或锁的过度持有。但一旦释放，就无法再在页内继续定位，于是必须在释放前存储当前位置，切换后再恢复，才能从下一个页的正确位置继续扫描。</li>
<li>出现锁等待或错误时的回退：如果在给某条记录加锁过程中遇到锁等待（<code>DB_LOCK_WAIT</code>）或其他可重试的错误，函数会<ul>
<li>在释放 mini-transaction、让出 latch 之前存储游标位置，</li>
<li>等待锁或错误解决后，再恢复游标，继续当前记录或下一条记录的扫描，保证最终不会漏读也不重复读。</li>
</ul>
</li>
</ol>
<p><strong>完整调用链一览</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql_select()</span><br><span class="line"> └─ join_read_table() / read_table_rows()</span><br><span class="line">   	└─ handler::ha_rnd_next(buf)</span><br><span class="line">       └─ rnd_next(buf)</span><br><span class="line">          ├─ index_first(buf)     // 第一次，从根到左叶</span><br><span class="line">          └─ general_fetch(buf,…)  // 后续，调用 row_search_mvcc</span><br><span class="line">         		 └─ row_search_mvcc(buf,…)</span><br><span class="line">                ├─ pcur-&gt;open_no_init()   // 定位（首次）</span><br><span class="line">                ├─ pcur-&gt;move_to_next()   // 遍历（后续）</span><br><span class="line">                └─ row_sel_store_mysql_rec // 转换格式</span><br></pre></td></tr></table></figure>

<p>此外，整个过程主要涉及两类锁：</p>
<p><strong>元数据锁（MDL，Metadata Lock）</strong></p>
<ul>
<li><code>MDL_SHARED_READ</code>：在执行任何 SELECT 时，MySQL 都会在打开表的时候对表结构加一个元数据读锁，类型叫 <code>MDL_SHARED_READ</code>。<ul>
<li>作用：保证在查询进行时，表定义（DDL）不会被改动（比如 <code>ALTER TABLE</code>）。</li>
<li>持续时间：从打开表到查询结束（<code>close_tables()</code>）为止。</li>
</ul>
</li>
</ul>
<p><strong>InnoDB 内部的短期页锁（Latch）与 MVCC</strong></p>
<ul>
<li>页锁（Page Latch）：为了从缓冲池安全地读取 B+ 树节点和行记录，InnoDB 在内存页上会拿短期的读或写 latch（互斥锁），确保数据页在读取&#x2F;解码时不被并发修改。<ul>
<li>这不是 SQL 层面的锁，你在 <code>SHOW ENGINE INNODB STATUS</code> 能看到它们，但在 <code>SHOW OPEN TABLES</code> 或 <code>INFORMATION_SCHEMA.INNODB_TRX</code> 中看不到。</li>
</ul>
</li>
<li>MVCC 版本控制：<strong>默认一致性读不会向行上加记录锁或间隙锁</strong>；它通过读视图加上 undo log 回溯来返回符合快照的行版本。<ul>
<li>不产生任何行锁，也不会阻塞并发的 UPDATE&#x2F;DELETE。</li>
<li>只有在遇到刚提交的、版本不可见的行时，InnoDB 会临时读取 undo log 中的旧版本，但这也是通过读取 undo 区块，不会在真正的索引上留下锁。</li>
</ul>
</li>
</ul>
<p>而且需要注意的是，整个流程中的数据是被一条条地读取并存储到 Record Buffer 中的，这就是 Valcano 风格的 pull-based Iteration Model 的体现。</p>
<h3 id="并行化增强"><a href="#并行化增强" class="headerlink" title="并行化增强"></a>并行化增强</h3><p>我们可以对全表扫描进行<strong>并行化增强</strong>。因为 MySQL 在 InnoDB 层引入了并行扫描功能，用于加速需要全表扫描的操作，该功能自 8.0.14 版本开始支持，通过将 B+ 树划分为多个子树并由多个工作线程并行扫描来实现。要启用并行全表扫描，只需将会话级或全局变量 <code>innodb_parallel_read_threads</code> 设置为大于 1 的值，MySQL 会根据该值和实际子树数量来决定并行线程数。</p>
<p>配置参数 <code>innodb_parallel_read_threads</code>：</p>
<ul>
<li>作用：控制 InnoDB 层并行扫描主键索引时的线程数，仅支持主键（聚簇索引）扫描，不支持二级索引扫描。</li>
<li>默认值：默认值为可用逻辑处理器数除以 8，至少 4；MySQL 8.4 之前始终为 4。</li>
<li>范围：1 至 256，总线程数上限为 256（跨所有会话）; 达到上限后会话会回退到单线程扫描。</li>
</ul>
<p>动态修改：支持会话级和全局级动态设置，例如：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">SET GLOBAL innodb_parallel_read_threads = 16;</span><br><span class="line">SET SESSION innodb_parallel_read_threads = 8;</span><br></pre></td></tr></table></figure>

<p>然后执行需要全表扫描的 SQL 即可利用并行扫描。</p>
<h3 id="其他相关参数"><a href="#其他相关参数" class="headerlink" title="其他相关参数"></a>其他相关参数</h3><ul>
<li><code>innodb_ddl_threads</code>：控制并行创建二级索引或重建表时的排序和 B+ 树构建线程数。</li>
<li><code>innodb_ddl_buffer_size</code>：并行 DDL 操作的排序缓冲区总大小，应配合 <code>innodb_parallel_read_threads</code> 一同调优。</li>
</ul>
<h4 id="并行扫描原理"><a href="#并行扫描原理" class="headerlink" title="并行扫描原理"></a>并行扫描原理</h4><p>MySQL 并行查询实际上是对 B+ 树的并行扫描。核心流程如下：</p>
<ol>
<li>调用扫描接口：用户线程执行如 <code>SELECT COUNT(*)</code> 等语句后，进入 InnoDB 并行扫描逻辑，从 <code>row_scan_index_for_mysql</code> 接口开始分发任务。</li>
<li>预分片（coarse-grained sharding）：用户线程先对整个聚簇索引做粗粒度分片，将每个子树（Range），由 <code>[start, end)</code> 两个游标标记，放入任务队列。其中分片的步骤如下：<ol>
<li>用户线程在预分片期间对整个索引加 INDEX S 锁，并对根页加 ROOT PAGE S 锁，确保树在分片时不会发生页分裂或新增子树。 </li>
<li>根页每条记录都包含一个指向子树的指针。用户线程依次读取这些指针，对应第 i 条指针即第 i 个子树。</li>
<li>对于每个指针，沿 B+ 树从该指针所在页向下定位到最左叶记录。</li>
<li>在遍历过程中，对每个经过的页加 S 锁，定位完成后创建一个 Iter，其中包含原始记录指针 <code>m_rec</code> 和持久化游标 <code>m_pcur</code>，用于后续线程快速定位。</li>
</ol>
</li>
<li>创建工作线程：根据 <code>innodb_parallel_read_threads</code> 值启动相应数量的工作线程，然后等待所有工作线程完成。</li>
<li>工作线程取任务：每个工作线程从队列中取出一个 Range，如粒度过大（分片数 ＞ 线程数）则再基于该 RANGE 的键值范围按同样方式二次切分，然后依次扫描该范围内的记录，通过内部函数 <code>row_search_mvcc</code> 获取每条记录并执行回调（如计数或检查）。</li>
<li>结果汇总：各线程扫描完毕后，用户线程收集各子树的统计结果或校验结果，并返回给 SERVER 层。</li>
</ol>
<h4 id="分片（Sharding）机制"><a href="#分片（Sharding）机制" class="headerlink" title="分片（Sharding）机制"></a>分片（Sharding）机制</h4><p>并行扫描将 B+ 树划分为多个子树，每个子树对应一个 RANGE 结构体：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">RANGE</span> &#123;</span><br><span class="line"> Iter start; <span class="comment">// 子树起始记录位置</span></span><br><span class="line"> Iter end;  <span class="comment">// 子树结束记录位置（右开区间）</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>其中 Iter 包含了记录指针和 B+ 树游标，用于定位扫描边界。工作线程可对粒度过大的 Range 再次细分，以提高负载均衡。</p>
<p>Iter 的结构如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/** Boundary of the range to scan. */</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Iter</span> &#123;</span><br><span class="line"> <span class="comment">/** Destructor. */</span></span><br><span class="line"> ~<span class="built_in">Iter</span>();</span><br><span class="line"> <span class="comment">/** Heap used to allocate m_rec, m_tuple and m_pcur. */</span></span><br><span class="line"> <span class="type">mem_heap_t</span> *m_heap&#123;&#125;;   <span class="comment">// 分配迭代所需内存（记录副本、tuple、游标等）</span></span><br><span class="line"> <span class="comment">/** m_rec column offsets. */</span></span><br><span class="line"> <span class="type">const</span> ulint *m_offsets&#123;&#125;; <span class="comment">// 原始记录中各列的偏移数组</span></span><br><span class="line"> <span class="comment">/** Start scanning from this key. Raw data of the row. */</span></span><br><span class="line"> <span class="type">const</span> <span class="type">rec_t</span> *m_rec&#123;&#125;;   <span class="comment">// 指向边界记录的原始数据</span></span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Tuple representation inside m_rec,</span></span><br><span class="line"><span class="comment">  * for two Iter instances in a range m_tuple will be [first-&gt;m_tuple, second-&gt;m_tuple).</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="type">const</span> <span class="type">dtuple_t</span> *m_tuple&#123;&#125;; <span class="comment">// m_rec 对应的解析后 tuple，方便按列访问</span></span><br><span class="line"> <span class="comment">/** Persistent cursor. */</span></span><br><span class="line"> <span class="type">btr_pcur_t</span> *m_pcur&#123;&#125;;   <span class="comment">// 用于快速定位 m_rec 所在页的 B+ 树游标</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="字段说明"><a href="#字段说明" class="headerlink" title="字段说明"></a>字段说明</h3><ol>
<li><code>m_heap</code>：用于在堆上分配和管理该 Iter 所需的临时内存，包括存放记录副本、tuple 结构和游标状态等。</li>
<li><code>m_offsets</code>：指向一组 ulint，用于记录 m_rec 中每列在页面上的偏移位置，以便快速定位列值。</li>
<li><code>m_rec</code>：原始记录指针（raw record），标记分片边界的具体行数据。</li>
<li><code>m_tuple</code>：m_rec 的逻辑封装（<code>dtuple_t</code>），两端 Iter 的 <code>m_tuple</code> 共同定义了扫描区间；扫描时常直接基于 <code>m_tuple</code> 进行比较和移动。</li>
<li><code>m_pcur</code>：持久化游标（<code>btr_pcur_t*</code>），用于记录定位 <code>m_rec</code> 所在页面和行号，后续扫描可通过该游标快速恢复上次位置，而无需从根节点重定位。</li>
</ol>
<h4 id="支持的语句类型"><a href="#支持的语句类型" class="headerlink" title="支持的语句类型"></a>支持的语句类型</h4><p>目前，InnoDB 并行扫描支持以下全表操作场景：</p>
<ul>
<li><code>SELECT COUNT(*) FROM table1;</code> 完整扫描主键索引并行计数。</li>
<li><code>CHECK TABLE table1;</code> 第二次扫描主键索引时可并行校验。</li>
<li><code>CREATE INDEX … ON table1</code> &#x2F; <code>ALTER TABLE … ADD INDEX …</code> 扫描和排序阶段支持并行，B+ 树构建阶段仍为单线程。</li>
<li><code>ALTER TABLE … ENGINE=InnoDB</code> &#x2F; <code>OPTIMIZE TABLE</code> 重建表阶段扫描主键索引不并行，排序和索引构建支持并行。</li>
</ul>
<h4 id="限制与注意事项"><a href="#限制与注意事项" class="headerlink" title="限制与注意事项"></a>限制与注意事项</h4><ul>
<li>并行扫描仅适用于主键索引，不支持二级索引扫描或包含虚拟列、全文索引、空间索引的表。</li>
<li>并行线程读取的数据页会被放到缓冲池 LRU 链表尾部，避免在扫描时占用过多热页。</li>
<li>当并行线程数超过子树数量时，实际使用的线程数取两者中的最小值。</li>
</ul>
<h2 id="B-树索引"><a href="#B-树索引" class="headerlink" title="B+ 树索引"></a>B+ 树索引</h2><p>B+ 树是为磁盘或其他直接存取辅助设备设计的一种自平衡的多路查找树。在 B+ 树中，所有记录节点都是按键值的大小顺序放在同一层的叶子节点上，由各叶子节点指针进行连接。</p>
<p>B+ 树的非叶子节点只存储键值，不存储数据，而叶子节点存储了所有的数据，并且构成了一个有序双向链表。因此，范围查询时就可以直接通过叶子节点间的指针顺序访问整个查询范围内的所有记录，而无需对树进行多次遍历。</p>
<p>在B+ 树的实现中，节点的大小往往被设计为与磁盘页大小相同（或者是其整数倍）。相比于 B 树（非叶子节点中存储指针和数据），B+ 树的非叶子节点能够存储更多的指针，提升索引查找的效率并且减少磁盘 I&#x2F;O 次数，因为每次从磁盘中加载的节点携带了更多的指针信息。</p>
<p>以下是 B-Tree 的结构（绿色代表子节点的地址，黄色代表记录的主键，红色代表单条记录中除主键外的数据，之后的图也是如此）：</p>
<p><img src="/../../images/MySQL/mysql_index_bt.drawio.png" alt="img"></p>
<p>B-Tree可视化：<a href="https://www.cs.usfca.edu/~galles/visualization/BTree.html">B-Tree Visualization</a></p>
<p>以下是 B+ 树的结构：</p>
<p><img src="/../../images/MySQL/mysql_index_bpt.drawio.png" alt="img"></p>
<p>B+ 树可视化：<a href="https://www.cs.usfca.edu/~galles/visualization/BPlusTree.html">B+ Tree Visualization</a></p>
<p>也就是说，MySQL 索引数据结构在经典 B-Tree 的基础上，增加了一个指向相邻左右叶子节点的链表指针，形成了双向循环链表，这样可以方便范围查询和反向遍历。</p>
<p>如果需要在 B+树中从大值向小值进行范围查询，可以按以下步骤操作：</p>
<ul>
<li>定位到最右侧节点：首先，找到包含最大值的叶子节点。这通常通过从根节点开始向右遍历树的方式实现。</li>
<li>反向遍历：一旦定位到了最右侧的叶子节点，可以利用叶节点间的双向链表向左遍历。</li>
</ul>
<p><a href="https://www.cnblogs.com/rjzheng/p/12316685.html">为什么Mongodb索引用B树，而MySQL用B+树?</a>：在关系型数据库中，遍历操作比较常见，因此采用 B+ 树作为索引比较合适。而在非关系型数据库中，单一查询比较常见，因此采用 B 树作为索引比较合适。</p>
<p>B+ 树对于 B 树的优势：</p>
<ol>
<li>更高的查询效率： B+ 树叶子节点的双向链表使得范围查询时无需从根节点开始进行多次索引查询，只需顺序遍历双向链表即可。</li>
<li>更高的空间利用率：B+ 树非叶子节点只存储指针，使得单个节点能够存储更多的指针只指向子节点，且单次磁盘 I&#x2F;O 读取更多信息，减少 I&#x2F;O 读取次数。</li>
<li>更稳定的查询效率：B+ 树叶子节点深度相同，数据查询路径长度相同。</li>
</ol>
<p>B+ 树对于二叉树的优势：</p>
<ol>
<li>B+ 树的每个节点可以有 m 个子节点，而红黑树和二叉平衡树都只有 2 个。</li>
<li>普通二叉树存在退化的情况，如果它退化成链表，就相当于全表扫描。</li>
<li>读取数据的时候，是从磁盘先读到内存。平衡二叉树的每个节点只存储一个键值和数据，而 B+ 树可以存储更多的节点数据，树的高度也会降低，因此读取磁盘的次数就会下降，查询效率就快。</li>
</ol>
<p>为什么 InnoDB 存储引擎选择使用 B+Tree 索引结构？</p>
<ol>
<li>相比于二叉树（顺序插入数据行的情况下会退化成链表），B+Tree 更平衡，层级更少，搜索效率高。</li>
<li>就B-Tree（或 BST）而言，无论叶子节点还是非叶子节点都会保留数据，这样导致一页中存储的键减少，指针也减少了，要保存大量数据，只能增加树的高度，导致性能降低。</li>
<li>相比于 Hash 索引，B+Tree 支持范围匹配及排序操作。</li>
</ol>
<p>一棵 B+ 树能存储多少数据？</p>
<p>假如我们的主键 ID 是 bigint 类型，长度为 8 个字节。指针大小在 InnoDB 源码中设置为 6 字节，这样一共 14 字节。所以非叶子节点(一页)可以存储 $16384&#x2F;14&#x3D;1170$ 个这样的单元(键值+指针)。</p>
<p>一个指针指向一个存放记录的页，一页可以放 16 条数据，树深度为 2 的时候，可以存放 $1170*16&#x3D;18720$ 条数据。</p>
<p>同理，树深度为 3 的时候，可以存储的数据为 $1170<em>1170</em>16&#x3D;21902400$ 条记录。</p>
<p>理论上，在 InnoDB 存储引擎中，B+树的高度一般为 2-4 层，就可以满足千万级数据的存储。查找数据的时候，一次页的查找代表一次 IO，当我们通过主键索引查询的时候，最多只需要 2-4 次 IO 就可以了。</p>
<h3 id="B-树的插入操作"><a href="#B-树的插入操作" class="headerlink" title="B+ 树的插入操作"></a>B+ 树的插入操作</h3><p>B+ 树的插入必须保证插入后叶子节点中的记录依然排序，同时需要考虑插入到 B+ 树的三种情况，每种情况都可能会导致不同的插入算法。具体如下：</p>
<p>叶子节点未满，索引节点未满：直接将记录插入到目标叶子节点的合适位置（保持有序）。</p>
<p>叶子节点已满，索引节点未满：</p>
<ul>
<li>拆分叶子节点为左右两个节点。</li>
<li>将中间键值提升为分隔键，插入到父级索引页。</li>
<li>原叶子节点中：<ul>
<li>小于中间键值的记录 → 左侧新页；</li>
<li>大于等于中间键值的记录 → 右侧新页。</li>
</ul>
</li>
</ul>
<p>叶子节点和索引节点都已满：</p>
<ul>
<li><p>拆分叶子节点（Leaf Page）：</p>
<ul>
<li>小于中间键值的记录 → 左页；</li>
<li>大于等于中间键值的记录 → 右页；</li>
</ul>
</li>
<li><p>将中间键值提升为分隔键，插入到父级索引页。</p>
</li>
<li><p>由于父级索引页也已满，继续处理其溢出：</p>
<ul>
<li>拆分 Index Page：<ul>
<li>小于中间索引值的记录 → 左侧索引页；</li>
<li>大于中间索引值的记录 → 右侧索引页；</li>
</ul>
</li>
<li>将新的中间索引项继续提升到上一层索引页中。</li>
</ul>
</li>
<li><p>若上一层索引页仍满，则继续递归，直到根节点；若根节点也满，最终会导致根节点分裂，树高度增加。</p>
</li>
</ul>
<p>因此，不管怎么变化，B+ 树总是会保持平衡。但是为了保持平衡，对于新插入的键值可能需要做大量的拆分页操作。因为 B+ 树结构主要用于磁盘，页的拆分意味着磁盘的操作，所以应当在可能的情况下尽量减少页的拆分操作。因此，B+ 树同样提供了类似于平衡二叉树的旋转功能。</p>
<p>旋转发生在叶子页（Leaf Page）已经满，但其左右兄弟节点没有满的情况下。这时 B+ 树并不会急于做拆分页的操作，而是将记录移到所在页的兄弟节点上。在通常情况下，会首先检查左兄弟以执行旋转操作。在下面的例子中：若插入键值 70，B+ 树并不会立即拆分叶子节点，而是先做旋转操作。</p>
<p><img src="/../../images/MySQL/mysql_index_insert.drawio.png" alt="img"></p>
<p>我们可以看到，旋转操作使得 B+ 树减少了一次页的拆分操作，同时这棵 B+ 树的高度依然为 2。</p>
<h3 id="B-树的删除操作"><a href="#B-树的删除操作" class="headerlink" title="B+ 树的删除操作"></a>B+ 树的删除操作</h3><p>B+ 树使用填充因子（fill factor）来控制树的删除变化，50% 是填充因子可设的最小值。B+ 树的删除操作同样必须保证删除后叶子节点中的记录依然排序。与插入一样，B+ 树的删除操作同样需要考虑三种情况，根据填充因子的变化来衡量是否需要进行节点合并或旋转操作。</p>
<table>
<thead>
<tr>
<th>叶子节点小于填充因子</th>
<th>中间节点小于填充因子</th>
<th>操作</th>
</tr>
</thead>
<tbody><tr>
<td>No</td>
<td>No</td>
<td>直接将记录从叶子节点删除，如果该节点还是 Index Page 的节点，用该节点的右兄弟节点代替</td>
</tr>
<tr>
<td>Yes</td>
<td>No</td>
<td>合并叶子节点和它的兄弟节点，同时更新对应的 Index Page</td>
</tr>
<tr>
<td>Yes</td>
<td>Yes</td>
<td>1. 合并叶子节点和它的兄弟节点  <br>2. 更新对应的 Index Page  <br>3. 合并 Index Page 和它的兄弟节点</td>
</tr>
</tbody></table>
<p>对于第一种情况的后半部分的解释：</p>
<p>在以下 B+ 树中（这里省去叶节点之间的指针），我们删除键值为 25 的记录，因为该值也是 Index Page 中的值，所以在删除之后，需要将 25 的右兄弟节点的 28 更新到 Index Page 中。</p>
<p><img src="/../../images/MySQL/mysql_index_bt_del.drawio.png" alt="img"></p>
<p>以下是删除之后的 B+ 树。</p>
<p><img src="/../../images/MySQL/mysql_index_bt_deled.drawio.png" alt="img"></p>
<p>这时，如果删除 Leaf Page 中键值为 60 的记录，那么 Fill Factor 小于 50%，需要做合并操作；同样，在删除 Index Page 中相关记录后，需要做 Index Page 的合并操作。结果如下：</p>
<p><img src="/../../images/MySQL/mysql_index_del_merge.drawio.png" alt="img"></p>
<p>注意：页面合并时，<strong>首先</strong>尝试与<strong>左侧</strong>直接相邻的兄弟页合并；仅在左侧不符合条件时，才会检查右侧兄弟页。如果左右两侧都没有足够的空间容纳当前页的所有记录，合并操作将不会执行，页面将保持“半空”状态，直到后续操作（如父节点合并或树高度调整）触发新的重组逻辑。合并成功后，还需在父节点中删除对应的指针条目，并在必要时向上递归合并或降高。</p>
<h3 id="聚集索引"><a href="#聚集索引" class="headerlink" title="聚集索引"></a>聚集索引</h3><p>数据库中的 B+ 树索引可以分为聚集索引（clustered index）和辅助索引（secondary index）。但是无论是聚集索引还是辅助索引，其内部结构都是 B+ 树，即高度平衡的，且叶子节点存放所有的数据。聚集索引与辅助索引的不同之处在于：叶子节点存放的是否是一整行的信息。</p>
<p>之前已经介绍过，InnoDB 存储引擎表是索引组织表，即表中数据按照主键顺序存放。而聚集索引就是按照每张表的主键构造一棵 B+ 树，同时叶子子节点中存放的即为整张表的行记录数据，也将聚集索引的叶子节点称为数据页。聚集索引的这个特性决定了索引组织表中数据也是索引的一部分。同 B+ 树数据结构一样，每个数据页都通过一个双向链表来进行链接。</p>
<p>由于实际的数据页只能按照一棵 B+ 树进行排序，因此每张表只能拥有一个聚集索引。在多数情况下，查询优化器倾向于采用聚集索引。因为聚集索引能够在 B+ 树索引的叶子节点上直接找到数据。此外，由于定义了数据的逻辑顺序，聚集索引能够特别快速地访问针对范围值的查询。查询优化器能够快速发现某一段范围的数据页需要扫描。</p>
<p>例如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> t (</span><br><span class="line"> a <span class="type">INT</span> <span class="keyword">NOT NULL</span>,</span><br><span class="line"> b <span class="type">VARCHAR</span>(<span class="number">8000</span>),</span><br><span class="line"> c <span class="type">INT</span> <span class="keyword">NOT NULL</span>,</span><br><span class="line"> <span class="keyword">PRIMARY KEY</span> (a),</span><br><span class="line"> KEY idx_c (c)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB;</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT INTO</span> t <span class="keyword">SELECT</span> <span class="number">1</span>, REPEAT(<span class="string">&#x27;a&#x27;</span>, <span class="number">7000</span>), <span class="number">-1</span>;</span><br><span class="line"><span class="keyword">INSERT INTO</span> t <span class="keyword">SELECT</span> <span class="number">2</span>, REPEAT(<span class="string">&#x27;a&#x27;</span>, <span class="number">7000</span>), <span class="number">-2</span>;</span><br><span class="line"><span class="keyword">INSERT INTO</span> t <span class="keyword">SELECT</span> <span class="number">3</span>, REPEAT(<span class="string">&#x27;a&#x27;</span>, <span class="number">7000</span>), <span class="number">-3</span>;</span><br><span class="line"><span class="keyword">INSERT INTO</span> t <span class="keyword">SELECT</span> <span class="number">4</span>, REPEAT(<span class="string">&#x27;a&#x27;</span>, <span class="number">7000</span>), <span class="number">-4</span>;</span><br></pre></td></tr></table></figure>

<p>我们可以发现数据页上存放的是完整的每行记录，而在非数据页的索引页中，存放的仅仅是键值及指向数据页的偏移量，而不是一个完整的行记录。具体结构如下：</p>
<p><img src="/../../images/MySQL/mysql_index_cluster.drawio.png" alt="img"></p>
<p>许多资料会说：聚集索引按照顺序物理地存储数据。但是试想一下，如果聚集索引必须按照特定顺序存放物理记录，则维护成本显得非常之高。所以，聚集索引的存储并不是物理上连续的，而是逻辑上连续的。这其中有两点： </p>
<ol>
<li>前面说过的页通过双向链表链接，页按照主键的顺序排列； </li>
<li>每个页中的记录也是通过双向链表进行维护的，物理存储上可以不按主键存放。</li>
</ol>
<p>说白了，就是在物理存储时，不同页和页内记录的数据块可以散布在数据文件各处，通过上述链表结构保证逻辑遍历顺序，从而大幅降低维护开销。</p>
<p>聚集索引的另一个好处是，它对于主键的排序查找和范围查找速度非常快。叶子节点的数据就是用户所要查询的数据。</p>
<p>还有就是范围查询（range query），即如果要查找主键某一范围内的数据，通过叶子节点的上层中间节点就可以得到页的范围，之后直接读取数据页即可。</p>
<p>此外，聚集索引存在如下选取规则：</p>
<ul>
<li>如果存在主键，主键索引就是聚集索引。</li>
<li>如果不存在主键，将使用第一个遇到的唯一索引作为聚集索引。</li>
<li>如果既没有主键也没有合适的唯一索引，则自动生成一个以单调递增的 row ID 作为键的隐藏聚集索引。</li>
</ul>
<h3 id="辅助索引"><a href="#辅助索引" class="headerlink" title="辅助索引"></a>辅助索引</h3><p><img src="/../../images/MySQL/mysql_index_sec.drawio.png" alt="img"></p>
<p>对于辅助索引（Secondary Index，也称非聚集索引），叶子节点并不包含行记录的全部数据。也就是说，叶子节点除了包含键值以外，每个叶子节点中的索引行中还包含了一个书签。该书签用来告诉 InnoDB 存储引擎哪里可以找到与该索引行对应的行数据。由于 InnoDB 存储引擎表是索引组织表，因此辅助索引的书签就是相应行数据在聚集索引中的聚集索引键。</p>
<p>辅助索引的存在并不影响数据在聚集索引中的组织，因此每张表上可以有多个辅助索引。当通过辅助索引来寻找数据时，InnoDB 存储引擎会：</p>
<ol>
<li>遍历辅助索引树，到达叶子节点后获得对应行的聚集索引键；</li>
<li>再通过聚集索引树查找该主键，定位到完整的行记录所在的数据页。</li>
</ol>
<p>举例来说，如果辅助索引树的高度为 3，则需要 3 次查找才能找到指定的主键；若聚集索引树的高度也为 3，则还需要额外 3 次查找才能在聚集索引中定位到完整行的数据页。因此，总共需要 6 次逻辑 I&#x2F;O 访问，才能得到最终的数据页。</p>
<p>示例：</p>
<p>在之前的表 t 上新增一列 c，并对列 c 创建聚集索引：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">ALTER TABLE</span> t</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">ADD</span> c <span class="type">INT</span> <span class="keyword">NOT NULL</span>;</span><br><span class="line">Query OK, <span class="number">4</span> <span class="keyword">rows</span> affected (<span class="number">0.24</span> sec)</span><br><span class="line">Records: <span class="number">4</span> Duplicates: <span class="number">0</span> Warnings: <span class="number">0</span></span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">UPDATE</span> t <span class="keyword">SET</span> c <span class="operator">=</span> <span class="number">0</span> <span class="operator">-</span> a;</span><br><span class="line">Query OK, <span class="number">4</span> <span class="keyword">rows</span> affected (<span class="number">0.04</span> sec)</span><br><span class="line"><span class="keyword">Rows</span> matched: <span class="number">4</span> Changed: <span class="number">4</span> Warnings: <span class="number">0</span></span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">ALTER TABLE</span> t <span class="keyword">ADD</span> KEY idx_c (c);</span><br><span class="line">Query OK, <span class="number">4</span> <span class="keyword">rows</span> affected (<span class="number">0.28</span> sec)</span><br><span class="line">Records: <span class="number">4</span> Duplicates: <span class="number">0</span> Warnings: <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>更改之后的索引结构如下：</p>
<p><img src="/../../images/MySQL/mysql_index_sec_clu.drawio.png" alt="img"></p>
<p>上图显示了表 t 中辅助索引 <code>idx_c</code> 和聚集索引的关系。可以看到辅助索引的叶子节点中包含了列 c 的值和主键的值。因为这里的键值为负值，所以会发现以 <code>7f ff ff ff</code> 的方式进行内部存储。7（0111）最高位为 0，代表负值，实际的值应该取反后加 1，即得 -1。</p>
<h3 id="B-树索引的分裂"><a href="#B-树索引的分裂" class="headerlink" title="B+ 树索引的分裂"></a>B+ 树索引的分裂</h3><p>之前介绍的 B+ 树分裂是最为简单的一种情况，这和数据库中 B+ 树索引的实际情况可能略有不同，因为并未涉及并发，而这才是 B+ 树索引实现中最为困难的部分。</p>
<p>B+ 树索引页的分裂并不总是从页的中间记录开始，这样可能会导致页空间的浪费。例如下面的记录：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1, 2, 3, 4, 5, 6, 7, 8, 9</span><br></pre></td></tr></table></figure>

<p>插入是根据自增顺序进行的，若此时插入第 10 条记录后需要进行页的分裂操作，那么根据之前介绍的分裂方法，会将记录 5 作为分裂点记录，分裂后得到下面两个页：</p>
<p>Page 1: <code>1, 2, 3, 4</code>；</p>
<p>Page 2: <code>5, 6, 7, 8, 9, 10</code>。</p>
<p>由于插入是顺序的，P1 这个页将不会再有新记录被插入，从而导致空间浪费；而 P2 又会再次进行分裂。</p>
<p>InnoDB 存储引擎的 Page Header 中有以下几个部分用来保存在页中记录插入的顺序信息：</p>
<ul>
<li><code>PAGE_LAST_INSERT</code></li>
<li><code>PAGE_DIRECTION</code></li>
<li><code>PAGE_N_DIRECTION</code></li>
</ul>
<p>通过这些信息，InnoDB 存储引擎可以决定是向左还是向右进行分裂，同时决定将分裂点记录为哪一个。若插入是随机的，则取页中的中间记录作为分裂点记录，这和之前介绍的相同。若往同一方向进行插入的记录数量为 5，并且目前已定位（cursor）到的记录（该记录为待插入记录的前一条记录）之后还有 3 条记录，则分裂点记录为定位到的记录后的第三条记录；否则，分裂点记录就是待插入的记录。</p>
<p>示例：</p>
<p>下面来看一个向右分裂的例子，并且定位到的记录之后还有 3 条记录，则分裂点记录如下：</p>
<p><img src="/../../images/MySQL/mysql_index_before_split.drawio.png" alt="img"></p>
<p>分裂后的结果如下：</p>
<p><img src="/../../images/MySQL/mysql_index_after_split.drawio.png" alt="img"></p>
<p>接着是分裂点就为插入记录本身：</p>
<p><img src="/../../images/MySQL/mysql_index_split_self.drawio.png" alt="img"></p>
<h3 id="B-树的管理"><a href="#B-树的管理" class="headerlink" title="B+ 树的管理"></a>B+ 树的管理</h3><h4 id="索引管理"><a href="#索引管理" class="headerlink" title="索引管理"></a>索引管理</h4><p>索引的创建和删除可以通过两种方法，一种是 ALTER TABLE，另一种是 CREATE&#x2F;DROP INDEX。通过 ALTER TABLE 创建索引的语法为：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER TABLE</span> tbl_name</span><br><span class="line"><span class="keyword">ADD</span> [INDEX<span class="operator">|</span>KEY] [index_name]</span><br><span class="line">[index_type] (index_col_name, ...) [index_option] ...</span><br><span class="line"></span><br><span class="line"><span class="keyword">ALTER TABLE</span> tbl_name</span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">PRIMARY KEY</span> <span class="operator">|</span> <span class="keyword">DROP</span> &#123;INDEX<span class="operator">|</span>KEY&#125; index_name</span><br></pre></td></tr></table></figure>

<p>CREATE&#x2F;DROP INDEX 的语法同样很简单：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> [<span class="keyword">UNIQUE</span>] INDEX index_name</span><br><span class="line">[index_type] <span class="keyword">ON</span> tbl_name (index_col_name, ...)</span><br><span class="line"></span><br><span class="line"><span class="keyword">DROP</span> INDEX index_name <span class="keyword">ON</span> tbl_name</span><br></pre></td></tr></table></figure>

<p>用户可以设置对整个列的数据进行索引，也可以只索引一列的开头部分数据，如前面创建的表 t，列 b 为 <code>varchar(8000)</code>，但是用户可以只索引前 100 个字段，如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">ALTER TABLE</span> t</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">ADD</span> KEY idx_b (b(<span class="number">100</span>));</span><br><span class="line">Query OK, <span class="number">4</span> <span class="keyword">rows</span> affected (<span class="number">0.32</span> sec)</span><br><span class="line">Records: <span class="number">4</span> Duplicates: <span class="number">0</span> Warnings: <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>若用户想要查看表中索引的信息，可以使用命令 SHOW INDEX。我们以主键列为例，结果如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SHOW</span> INDEX <span class="keyword">FROM</span> t\G;</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">    <span class="keyword">Table</span>: t</span><br><span class="line">    Non_unique: <span class="number">0</span></span><br><span class="line">    Key_name: <span class="keyword">PRIMARY</span></span><br><span class="line">    Seq_in_index: <span class="number">1</span></span><br><span class="line">    Column_name: a</span><br><span class="line">    <span class="keyword">Collation</span>: A</span><br><span class="line">    <span class="keyword">Cardinality</span>: <span class="number">2</span></span><br><span class="line">    Sub_part: <span class="keyword">NULL</span></span><br><span class="line">    Packed: <span class="keyword">NULL</span></span><br><span class="line">    <span class="keyword">Null</span>: </span><br><span class="line">    Index_type: BTREE</span><br><span class="line">    Comment: </span><br><span class="line">…</span><br></pre></td></tr></table></figure>

<p>以上结果中每列的含义如下：</p>
<p><strong><code>Table</code></strong>：索引所在的表名。</p>
<p><strong><code>Non_unique</code></strong>：非唯一的索引，可以看到 primary key 是 0，因为必须是唯一的。</p>
<p><strong><code>Key_name</code></strong>：索引的名字，用户可以通过这个名字来执行 DROP INDEX。</p>
<p><strong><code>Seq_in_index</code></strong>：索引中该列的位置，如果看联合索引 idx_a_c 就比较直观了。</p>
<p><strong><code>Column_name</code></strong>：索引列的名称。</p>
<p><strong><code>Collation</code></strong>：列以什么方式存储在索引中。可以是 A 或 NULL。B+ 树索引总是 A，即排序的。如果使用了 Heap 存储引擎，并且建立了 Hash 索引，这里就会显示 NULL 了。因为 Hash 根据 Hash 桶存放索引数据，而不是对数据进行排序。</p>
<p><strong><code>Cardinality</code></strong>：非常关键的值，表示索引中唯一值的数目的估计值。Cardinality 表的行数应尽可能接近 1，如果非常小，那么用户需要考虑是否可以删除此索引。</p>
<p><strong><code>Sub_part</code></strong>：是否是列的部分被索引。如果看到 <code>idx_b</code> 这个索引，这里显示 100，表示只对 b 列的前 100 字符进行索引。如果索引整个列，则该字段为 NULL。</p>
<p><strong><code>Packed</code></strong>：关键字如何被压缩。如果没有被压缩，则为 NULL。</p>
<p><strong><code>Null</code></strong>：是否索引的列含有 NULL 值。可以看到 <code>idx_b</code> 这里为 Yes，因为定义的列 b 允许 NULL 值。</p>
<p><strong><code>Index_type</code></strong>：索引的类型。InnoDB 存储引擎只支持 B+ 树索引，所以这里显示的都是 BTREE。</p>
<p><strong><code>Comment</code></strong>：注释。</p>
<p>Cardinality 值非常关键，优化器会根据这个值来判断是否使用这个索引。但是这个值并不是实时更新的，即并非每次索引的更新都会更新该值，因为这样代价太大了。因此这个值是不太准确的，只是一个大概的值。上面显示的结果主键的 Cardinality 为 2，但是很显然我们表中有 4 条记录，这个值应该是 4。如果需要更新索引 Cardinality 的信息，可以使用 <code>ANALYZE TABLE</code> 命令。</p>
<p>另一个问题是 MySQL 数据库对于 Cardinality 计数的问题，在运行一段时间后，可能会看到下面的结果：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">show</span> index <span class="keyword">from</span> Profile\G;</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">    <span class="keyword">Table</span>: Profile</span><br><span class="line">    Non_unique: <span class="number">0</span></span><br><span class="line">    Key_name: UserName</span><br><span class="line">    Seq_in_index: <span class="number">1</span></span><br><span class="line">    Column_name: username</span><br><span class="line">    <span class="keyword">Collation</span>: A</span><br><span class="line">    <span class="keyword">Cardinality</span>: <span class="keyword">NULL</span></span><br><span class="line">    Sub_part: <span class="keyword">NULL</span></span><br><span class="line">    Packed: <span class="keyword">NULL</span></span><br><span class="line">    <span class="keyword">Null</span>: </span><br><span class="line">    Index_type: BTREE</span><br><span class="line">    Comment: </span><br></pre></td></tr></table></figure>

<p><strong>Cardinality</strong> 为 NULL，在某些情况下可能会发生索引建立了却没有用到的情况。或者对两条基本一样的语句执行 EXPLAIN，但是最终出来的结果不一样：一个使用索引，另外一个使用全表扫描。</p>
<p>这时最好的解决办法就是做一次 <code>ANALYZE TABLE</code> 的操作。因此建议在一个非高峰时间，对应用程序下的几张核心表做 <code>ANALYZE TABLE</code> 操作，这能使优化器和索引更好地为你工作。</p>
<h4 id="Fast-Index-Creation"><a href="#Fast-Index-Creation" class="headerlink" title="Fast Index Creation"></a>Fast Index Creation</h4><p>MySQL 5.5 版本之前（不包括 5.5）存在的一个普遍被人诟病的问题是 MySQL 数据库对于索引的添加或者删除的这类 DDL 操作，MySQL 数据库的操作过程是：</p>
<ul>
<li>首先创建一张新的临时表，表结构为通过命令 ALTER TABLE 新定义的结构。</li>
<li>然后把原表中数据导入到临时表。</li>
<li>接着删除原表。</li>
<li>最后把临时表重名为原来的表名。</li>
</ul>
<p>可以发现，若用户对一张大表进行索引的添加和删除操作，那么会花费很长的时间。更关键的是，若有大量事务需要访问正在被修改的表，这意味着数据库服务不可用。</p>
<p><strong>InnoDB</strong> 存储引擎从 <strong>InnoDB 1.0.x</strong> 版本开始支持一种称为 <strong>Fast Index Creation（快速索引创建）</strong> 的索引创建方式——简称 <strong>FIC</strong>。</p>
<p>对于辅助索引的创建，InnoDB 存储引擎会对创建索引的表加上一个 <strong>S 锁</strong>。在创建的过程中，不需要重建表，因此速度较之前提高很多，并且数据库的可用性也得到了提高。<br> 删除辅助索引操作就更简单了，InnoDB 存储引擎只需更新内部视图，并将辅助索引的空间标记为可用，同时触发 MySQL 数据库内部视图上对该索引定义即可以。</p>
<p>这里需要特别注意的是，临时表的创建路径是通过参数 tmpdir 进行设置的。用户必须保证 tmpdir 有足够的空间可以存放临时表，否则会导致创建索引失败。</p>
<p>由于 FIC 在索引的创建中对表加上了 S 锁，因此在创建的过程中只能对该表进行 <strong>读操作</strong>，若有大量的事务需要对目标表进行写操作，那么数据库的服务同样不可用。此外，FIC 方法只限用于 <strong>辅助索引</strong>，对于主键的创建和删除同样需要重建一张表。</p>
<h4 id="Online-Schema-Change"><a href="#Online-Schema-Change" class="headerlink" title="Online Schema Change"></a>Online Schema Change</h4><p>Online Schema Change（OSC）是一种用于 <strong>在线执行 MySQL DDL 操作</strong> 的技术，最早由 Facebook 推出并开源，旨在解决传统 DDL 操作期间数据库不可用的问题。通过 OSC，用户可以在 <strong>不中断业务访问的前提下</strong> 对表结构进行修改，如添加索引、修改字段等。</p>
<p>其核心思想是通过复制原表结构创建一张临时表，并在数据迁移和结构变更过程中，借助触发器记录原表的变更操作（DML）。在数据导入和变更同步完成后，再将原表与新表进行原子性换名操作，从而实现无缝切换。</p>
<h4 id="Online-DDL"><a href="#Online-DDL" class="headerlink" title="Online DDL"></a>Online DDL</h4><p>虽然 FIC 可以让 InnoDB 存储引擎避免创建临时表，从而提高索引创建的效率，但正如前面章节所说的，索引创建时会阻塞表上的 DML 操作。OSC 虽然解决了上述的部分问题，但还是有很大的局限性。</p>
<p>MySQL 从 5.6 版本开始支持 <strong>Online DDL（在线数据定义）</strong> 操作，其允许在辅助索引创建的同时，还允许其他诸如 INSERT、UPDATE、DELETE 这类 DML 操作，这极大地提高了 MySQL 数据库在生产环境中的可用性。</p>
<p>此外，不仅是辅助索引，以下几类 DDL 操作都可以通过“在线”的方式进行操作：</p>
<ul>
<li><p>辅助索引的创建与删除</p>
</li>
<li><p>改变自增长值</p>
</li>
<li><p>添加或删除外键约束</p>
</li>
<li><p>列的重命名</p>
</li>
</ul>
<p>通过新的 <code>ALTER TABLE</code> 语法，用户可以选择索引的创建方式：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER TABLE</span> tbl_name</span><br><span class="line"><span class="keyword">ADD</span> [INDEX<span class="operator">|</span>KEY] [index_name]</span><br><span class="line">[index_type] (index_col_name,...) [index_option] ...</span><br><span class="line">ALGORITHM [<span class="operator">=</span>] &#123;<span class="keyword">DEFAULT</span><span class="operator">|</span>INPLACE<span class="operator">|</span><span class="keyword">COPY</span>&#125;</span><br><span class="line">LOCK [<span class="operator">=</span>] &#123;<span class="keyword">DEFAULT</span><span class="operator">|</span><span class="keyword">NONE</span><span class="operator">|</span>SHARED<span class="operator">|</span>EXCLUSIVE&#125;</span><br></pre></td></tr></table></figure>

<p><strong>ALGORITHM</strong> 指定了创建或删除索引的算法：</p>
<ul>
<li>COPY 表示按 MySQL 5.1 版本之前的工作模式，即创建临时表的方式。</li>
<li>INPLACE 表示索引创建或删除操作不需要创建临时表。</li>
<li>DEFAULT 表示根据参数 <code>old_alter_table</code> 判断是否使用 INPLACE 或 COPY 算法，默认值为 OFF，即采用 INPLACE 方式。</li>
</ul>
<p>LOCK 部分表示在创建或删除索引时对表加锁的情况，可选值包括：</p>
<ol>
<li>**NONE：**执行索引创建或删除操作时，对目标表不添加任何锁，即事务仍然可以进行读写操作，不会受到阻塞。因此该模式可以获得最大的并发度。</li>
<li>**SHARE：**与 FIC 类似，执行索引创建或删除操作时，对目标表加上一个 S 锁。对于读操作不影响，但会阻塞写操作。</li>
<li>**EXCLUSIVE：**执行索引创建或删除操作时，对目标表加上一个 X 锁。此时所有事务都不能进行，等同于 COPY 方式运行时的状态，但不需要创建临时表。</li>
<li>**DEFAULT：**默认模式下，系统会判断当前操作是否可以使用 NONE 模式，若不能，则判断是否可以使用 SHARE，最后才判断是否可以使用 EXCLUSIVE 模式。DEFAULT 会根据当前事务的最大并发性来自动选择 DDL 执行的锁定模式。</li>
</ol>
<p>InnoDB 存储引擎在执行 Online DDL 的过程中，会将 INSERT、UPDATE、DELETE 等 DML 操作的日志写入一个缓冲区，待索引创建完成后再将这些日志应用到表上，以此保证数据一致性。</p>
<p>这个缓冲区的大小由参数 <code>innodb_online_alter_log_max_size</code> 控制，默认值为<strong>128MB</strong>。若在创建过程中遇到大量写事务，而缓冲区不够，会报错：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Error: 1799 SQLSTATE: HY000 (ER_INNODB_ONLINE_LOG_TOO_BIG)</span><br><span class="line"></span><br><span class="line">Message: Creating index &#x27;idx_aaa&#x27; required more than &#x27;innodb_online_alter_log_max_size&#x27; bytes of modification log. Please try again.</span><br></pre></td></tr></table></figure>

<p>为避免该错误，可通过调整 <code>innodb_online_alter_log_max_size</code> 获取更大的日志缓冲空间。此外，也可以设置 <code>ALTER TABLE 的 LOCK = SHARE</code> 模式，以避免记录过多的 DML 日志。</p>
<p>需要特别注意的是，<strong>在 Online DDL 结束后，MySQL 会通过重放日志达到数据最终一致性</strong>。因此在索引创建过程中，SQL 优化器不会选择正在创建的索引。</p>
<h2 id="Cardinality"><a href="#Cardinality" class="headerlink" title="Cardinality"></a>Cardinality</h2><p>概念：Cardinality ≈ 列中不同值的数量 → 反映列的选择性。</p>
<p>判断索引价值</p>
<ul>
<li><p>高选择性（Cardinality ≈ 表行数）：建 B+ 树索引，能显著加速查询。</p>
</li>
<li><p>低选择性（取值极少，如性别、地区）：索引作用有限，通常不建。</p>
</li>
</ul>
<p>衡量方法：SHOW INDEX 查看 Cardinality；用 Cardinality &#x2F; 总行数 估算选择性。</p>
<p>注意：Cardinality 仅是估值，可能不精确，仍需结合实际查询频率和过滤比例综合判断。</p>
<h3 id="InnoDB-存储引擎的-Cardinality-统计"><a href="#InnoDB-存储引擎的-Cardinality-统计" class="headerlink" title="InnoDB 存储引擎的 Cardinality 统计"></a>InnoDB 存储引擎的 Cardinality 统计</h3><p>InnoDB 不会在每次索引变动时都重新计算 Cardinality，而是通过采样（Sample）方式周期性更新，以避免频繁统计带来的性能开销。更新时机主要有两个条件：</p>
<ol>
<li><p>表中已有数据发生变化占比 ≥ 1&#x2F;16</p>
<ol>
<li>上次统计后，若有至少六分之一的数据被插入或删除，则触发 Cardinality 重新计算。 </li>
<li>目的是：当表数据量大幅变化时，统计结果才会显著偏离实际。</li>
</ol>
</li>
<li><p><code>stat_modified_counter &gt; 2,000,000,000</code> </p>
<ol>
<li>InnoDB 内部维护一个计数器 stat_modified_counter，用于记录自上次索引统计（Cardinality 更新）以来，对表中<strong>单行数据</strong>执行 INSERT&#x2F;UPDATE 之类操作的累计次数；</li>
<li>若对某行数据的更新非常频繁——即使该表总行数未增减，但同一行被多次修改，也会触发 Cardinality 更新； </li>
<li>当 stat_modified_counter 累积值超过 20 亿，则认为存量数据“实质”发生变化，从而重新采样计算。</li>
</ol>
</li>
</ol>
<p>这种双重策略保证在数据量变化大或单行更新极其频繁时，InnoDB 能及时刷新索引选择性估计；平时不会因频繁 INSERT&#x2F;UPDATE 而频繁统计，以降低系统负担。 </p>
<p>InnoDB 通过对 B+ 树叶子页（Leaf Page）进行随机采样，估算索引的 Cardinality 值（不保证精确）。默认采样 8 个叶子页，步骤如下：</p>
<ol>
<li>获取叶子页总数：设定为 A，即 B+ 树索引中叶子节点的总数量。</li>
<li>随机选取 8 个叶子节点：对这 8 个数据页，分别统计每页中不同记录的个数，记为 P1、P2、…、P8。</li>
<li>计算估算值：<code>Cardinality ≈ (P1 + P2 + … + P8) × A / 8</code>。</li>
</ol>
<p>每次采样都可能选到不同的 8 个叶子页，故同一索引的 Cardinality 值会有所波动。也就是说，这是一个估算值，并非精准统计。</p>
<p>当表的叶子页数 ≤ 8 时，InnoDB 默认会对所有叶子页进行采样（即采样页数 ≥ 表叶子页数）。这意味着每次执行索引统计，选到的都是相同的页，导致观测到的 Cardinality 值始终一致。</p>
<p>InnoDB 采样配置</p>
<ol>
<li><p><code>innodb_stats_sample_pages</code></p>
<p>用途：设置每次计算 Cardinality 时要采样的叶子页数量。</p>
<p>默认值：8。</p>
<p>如果将该值调小，采样精度会下降；调大则统计开销增加。</p>
</li>
<li><p><code>innodb_stats_method</code><br>控制统计时对索引列中 NULL 值的处理方式，可选取：</p>
<ul>
<li><p>nulls_equal（默认）：将所有 NULL 视为相同值。</p>
</li>
<li><p>nulls_unequal：将不同 NULL 视为不同值。</p>
</li>
<li><p>nulls_ignored：完全忽略 NULL 记录，不计入不同值。</p>
</li>
</ul>
</li>
</ol>
<p>示例<br>针对某页记录：NULL, NULL, 1, 2, 2, 3, 3, 3</p>
<ul>
<li>nulls_equal → 视为 {NULL, 1, 2, 3}, Cardinality &#x3D; 4</li>
<li>nulls_unequal → 视为 {NULL₁, NULL₂, 1, 2, 3}, Cardinality &#x3D; 5</li>
<li>nulls_ignored → 只计 {1, 2, 3}, Cardinality &#x3D; 3</li>
</ul>
<p>当执行 SQL 语句 <code>ANALYZE TABLE</code>、<code>SHOW TABLE STATUS</code>、<code>SHOW INDEX</code> 以及访问 INFORMATION_SCHEMA 架构下的表 TABLES 和 STATISTICS 时，会导致 InnoDB 存储引擎去重新计算索引的 Cardinality 值。若表中的数据量非常大，并且表中存在多个辅助索引时，执行上述这些操作可能会非常慢。虽然用户可能并不希望去更新 Cardinality 值。</p>
<p>Cardinality 的设置参数如下：</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><strong>innodb_stats_persistent</strong></td>
<td>是否将命令 <code>ANALYZE TABLE</code> 计算得到的 Cardinality 值存放到磁盘上。<br>若是，则这样做的好处是可以减少重新计算每个索引的 Cardinality 值，例如当 MySQL 数据库重启时。此外，用户也可以通过命令 <code>CREATE TABLE</code> 和 <code>ALTER TABLE</code> 的选项 <code>STATS_PERSISTENT</code> 来对每张表进行控制。<br>默认值：OFF</td>
</tr>
<tr>
<td><strong>innodb_stats_on_metadata</strong></td>
<td>当通过命令 <code>SHOW TABLE STATUS</code>、<code>SHOW INDEX</code> 及访问 <code>INFORMATION_SCHEMA</code> 架构下的表 <code>TABLES</code> 和 <code>STATISTICS</code> 时，是否需要重新计算索引的 Cardinality 值。<br>默认值：OFF</td>
</tr>
<tr>
<td><strong>innodb_stats_persistent_sample_pages</strong></td>
<td>若参数 <code>innodb_stats_persistent</code> 设置为 ON，该参数表示 <code>ANALYZE TABLE</code> 更新 Cardinality 值时每次采样页的数量。<br>默认值：20</td>
</tr>
<tr>
<td><strong>innodb_stats_transient_sample_pages</strong></td>
<td>该参数用来取代之前版本的参数 <code>innodb_stats_sample_pages</code>，表示每次采样页的数量。<br>默认值：8</td>
</tr>
</tbody></table>
<p>最后两个参数的区别：</p>
<p><code>persistent_sample_pages</code>：针对持久化统计（<code>ANALYZE TABLE</code> 等）时使用，采样页数较多以提高持久化统计精度。</p>
<p><code>transient_sample_pages</code>：针对临时统计（<code>SHOW INDEX</code>、<code>SHOW TABLE STATUS</code>、<code>INFORMATION_SCHEMA</code> 查询、或 <code>innodb_stats_persistent=OFF</code> 时的抽样）时使用，采样页数较少以减少临时统计的开销。</p>
<h2 id="B-树索引的使用"><a href="#B-树索引的使用" class="headerlink" title="B+ 树索引的使用"></a>B+ 树索引的使用</h2><p>OLTP（联机事务处理）场景下，单次查询通常只访问非常少量的记录（往往 ≤ 10 条，有时甚至只取 1 条）。此时建立的 B+ 树索引主要用于通过主键或少量条件快速定位对应记录。只有当索引能够显著减少 IO、提高查询效率时才有意义，否则即使创建了索引，优化器也可能绕过直接全表扫描。</p>
<p>OLAP（联机分析处理）场景下，查询往往涉及对表中大量数据的聚合与统计，面向决策支持（如按月统计销售额、环比增长等）。此类查询关注宏观视角，索引设计应基于整体分析需求，而非针对单条记录检索。一般情况下，不会对诸如“姓名”等仅偶尔单独查询的字段建立索引；但常见做法是对用作分区或筛选条件的<strong>时间字段</strong>建索引，因为大多数统计都是基于时间维度进行过滤。<br>在多表联接（JOIN）操作中，若使用 Hash Join 等算法，索引的重要性会相对降低，需要结合具体执行计划来权衡是否添加索引。</p>
<p>因此，索引添加策略需 Think Different，结合实际查询特点（选择性、扫描量、计算开销）和执行计划采样结果。</p>
<h3 id="联合索引"><a href="#联合索引" class="headerlink" title="联合索引"></a>联合索引</h3><p>单列索引：一个索引只包含单个列。</p>
<p>联合索引：一个索引包含多个列。</p>
<p>以下代码创建了一张 t 表，并且索引 <code>idx_a_b</code> 是联合索引，联合的列为 <code>(a, b)</code>。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> t (</span><br><span class="line">  a <span class="type">INT</span>,</span><br><span class="line">  b <span class="type">INT</span>,</span><br><span class="line">  <span class="keyword">PRIMARY KEY</span> (a),</span><br><span class="line">  KEY idx_a_b (a, b)</span><br><span class="line">) ENGINE<span class="operator">=</span>INNODB;</span><br></pre></td></tr></table></figure>

<p>该表对应的联合索引结构如下（同样省去叶节点之间的指针）：</p>
<p><img src="/../../images/MySQL/mysql_index_multi.drawio.png" alt="img"></p>
<p>因此，对于查询 <code>SELECT * FROM TABLE WHERE a=xxx and b=xxx</code>，显然是可以使用 <code>(a, b)</code> 这个联合索引的。对于单个 a 列查询 <code>SELECT * FROM TABLE WHERE a=xxx</code>，也可以使用这个 <code>(a, b)</code> 索引。但对于 b 列的查询 <code>SELECT * FROM TABLE WHERE b=xxx</code>，则不可以使用这棵 B+ 树索引。可以发现叶子节点上的 b 值为 1、2、1、4、1、2，显然不是排序的，因此对于 b 列的查询使用不到 <code>(a, b)</code> 的索引。</p>
<p>联合索引的第二个好处是已经对第二个键值进行了排序处理。例如，在很多情况下应用程序都需要查询某个用户的购物情况，并按照时间进行排序，最后取出最近三次的购买记录，这时使用联合索引可以避免多一次的排序操作，因为索引本身在叶子节点已经排好了。</p>
<p>在业务场景中，如果存在多个查询条件，考虑针对查询字段建立索引时，建议建立联合索引，而非单列索引。</p>
<p>多条件联合查询时，MySQL 优化器会评估哪个字段的索引效率更高并且选择对应索引完成本次查询。</p>
<h3 id="覆盖索引"><a href="#覆盖索引" class="headerlink" title="覆盖索引"></a>覆盖索引</h3><p>在 InnoDB 中，覆盖索引（Covering Index）指的是查询只访问辅助索引就能获取所需字段的数据，不需要回表到主键索引（聚集索引）中再取数据。</p>
<p>此外，统计查询也能利用覆盖索引：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> buy_log (</span><br><span class="line">  userid <span class="type">INT</span> UNSIGNED <span class="keyword">NOT NULL</span>,</span><br><span class="line">  buy_date <span class="type">DATE</span></span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="keyword">FROM</span> buy_log;</span><br></pre></td></tr></table></figure>

<p>对于这个 SQL 语句，InnoDB 并不会选择通过查询聚集索引来进行统计，因为 <code>buy_log</code> 表上还有辅助索引，而辅助索引远小于聚集索引，这有助于减少 I&#x2F;O 操作。</p>
<p>而且，对于以下 SQL 语句：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="keyword">FROM</span> buy_log</span><br><span class="line"><span class="keyword">WHERE</span> buy_date <span class="operator">&gt;=</span> <span class="string">&#x27;2011-01-01&#x27;</span> <span class="keyword">AND</span> buy_date <span class="operator">&lt;</span> <span class="string">&#x27;2011-02-01&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>即使查询条件中只用到联合索引的第二列 <code>buy_date</code>，但因为查询是统计操作，且能完全由索引提供数据，优化器依然会选择 <code>(userid, buy_date)</code> 联合索引作为覆盖索引使用。</p>
<h3 id="前缀索引"><a href="#前缀索引" class="headerlink" title="前缀索引"></a>前缀索引</h3><p>当字段类型为 varchar，text 等时，有时候需要索引很长的字符串，这会让索引变得很大，查询时消费大量的磁盘 I&#x2F;O。因此我们可对字符串的<strong>前缀</strong>建立索引，可极大节省索引空间，提高索引效率。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> index idx_xxx <span class="keyword">on</span> table_name(column_name(n));</span><br></pre></td></tr></table></figure>

<p>前缀长度选择：根据索引的选择性（和区分度类似）来决定，选择性是指不重复的索引值和数据表的记录总数的比值，索引选择性越高则查询效率越高（选择性最高为 1）。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="built_in">count</span>(<span class="keyword">distinct</span> email) <span class="operator">/</span> <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">from</span> table_name;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> <span class="built_in">count</span>(<span class="keyword">distinct</span> <span class="built_in">substring</span>(email, <span class="keyword">start</span>, <span class="keyword">end</span>)) <span class="operator">/</span> <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">from</span> table_name;</span><br></pre></td></tr></table></figure>

<p>查询流程</p>
<ol>
<li>构建聚集索引和 email 指定长度的前缀索引。</li>
<li>获取 where 后的条件查询字符串的指定长度的前缀，在对应 email 的索引中匹配获取对应行的 id，回表查询获取完整行。</li>
<li>比较该行中的 email 字符串是否等于查询字符串；如果是，则返回结果，之后查询 B+Tree 中下一个元素是否匹配 email 前缀，重复操作。</li>
<li>组装数据。</li>
</ol>
<h3 id="优化器选择不使用索引的情况"><a href="#优化器选择不使用索引的情况" class="headerlink" title="优化器选择不使用索引的情况"></a>优化器选择不使用索引的情况</h3><p>在某些场景下，即使有可用索引，执行 EXPLAIN 会发现优化器 没有选择索引，而是采用了全表扫描（table scan）或聚集索引扫描（PRIMARY key scan），而不是使用辅助索引。</p>
<p>查询语句如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> orderdetails <span class="keyword">WHERE</span> orderid <span class="operator">&gt;</span> <span class="number">10000</span> <span class="keyword">AND</span> orderid <span class="operator">&lt;</span> <span class="number">102000</span>;</span><br></pre></td></tr></table></figure>

<p>该语句选择扫描聚集索引，也就是全表扫描。</p>
<p>原因分析</p>
<ol>
<li>索引无法覆盖查询字段<ul>
<li>由于 <code>SELECT *</code> 需要返回整行记录，而 OrderID 是辅助索引，无法覆盖所有字段，导致必须回表。</li>
<li>回表的过程需要通过主键访问聚集索引数据页，这会产生额外的 I&#x2F;O。</li>
</ul>
</li>
<li>顺序读 vs 随机读<ul>
<li>聚集索引在磁盘上是物理顺序存储的，直接扫描比辅助索引 + 回表更高效（尤其当命中率低时）。</li>
<li>特别是在机械硬盘环境下，顺序读（聚集索引）性能远优于多次随机读（回表）。</li>
</ul>
</li>
<li>数据访问比例高时<ul>
<li>当查询返回的数据行占总行数较大（例如 &gt;20%）时，优化器认为直接顺序扫描整张表更快。</li>
</ul>
</li>
</ol>
<p>对于机械硬盘来说，顺序读取（聚集索引或全表扫描）远快于随机读（辅助索引 + 回表）。因此，当查询返回的行数占表的较大比例（≈20％ 或更高）时，优化器往往选择全表扫描，而不是使用辅助索引。</p>
<p>如果底层存储是固态硬盘（SSD），随机读性能就足够高，且对性能的影响较小，我们可以强制使用辅助索引来减少扫描行数。</p>
<p><code>USE INDEX</code> 只是告诉优化器可以选择该索引，但实际上优化器还是会根据自己的判断进行选择。</p>
<p><code>FORCE INDEX</code> 则强制优化器必须使用该索引。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">table</span> use index(idx) <span class="keyword">where</span> ...;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">table</span> ignore index(idx) <span class="keyword">where</span> ...;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">table</span> force index(idx) <span class="keyword">where</span> ...;</span><br></pre></td></tr></table></figure>

<h3 id="Multi-Range-Read-MRR-优化"><a href="#Multi-Range-Read-MRR-优化" class="headerlink" title="Multi-Range Read (MRR) 优化"></a>Multi-Range Read (MRR) 优化</h3><p>从 MySQL 5.6.0 开始，InnoDB 和 MyISAM 存储引擎支持 MRR（多范围读取）优化。</p>
<p>目标：尽可能减少磁盘的随机读，将随机访问转换为相对顺序的访问，以提升 I&#x2F;O 密集型查询的性能。</p>
<p>适用场景：对索引范围（range）、引用（ref）或等值引用（<code>eq_ref</code>）类型查询，尤其是在需要根据辅助索引快速定位大量匹配行，然后回表查数据的场景。</p>
<p>MRR 优化的几个好处：</p>
<p><strong>使数据访问变得更顺序</strong></p>
<ul>
<li><p>首先通过辅助索引找出所有符合条件的索引键值，把它们缓存在内存里（已经是按索引顺序排列的）。</p>
</li>
<li><p>然后按照主键（或聚簇索引）顺序对这些键值进行排序，最后再一次性按排好序的顺序访问实际数据页，从而将随机 I&#x2F;O 转为顺序 I&#x2F;O。</p>
</li>
</ul>
<p><strong>减少缓冲池中页被置换的次数</strong></p>
<ul>
<li>由于访问顺序更可预测，针对热点数据页的重复访问更集中，降低了缓存页被逐出后又立刻被读回的情况。</li>
</ul>
<p><strong>批量处理对键值的查询操作</strong></p>
<ul>
<li>将多个单独的索引查找合并成一次批量处理，更好地利用缓存和预取，提高吞吐量。</li>
</ul>
<p>MRR 的工作流程（以 InnoDB 和 MyISAM 为例）</p>
<ol>
<li>收集辅助索引键值<ul>
<li>执行范围或引用类型的索引查找时，先把所有满足条件的辅助索引键值（包含对应的 RowID 或主键）一次性读到一个临时缓冲区中。此时缓冲区中的键值已经是按辅助索引顺序排列的。</li>
</ul>
</li>
<li>对键值进行排序<ul>
<li>根据读到的所有主键（RowID）值，对缓冲区内记录按主键顺序排序（这一步把索引顺序转换为主键顺序）。</li>
</ul>
</li>
<li>按主键顺序批量访问数据页<ul>
<li>根据排好序的主键顺序依次访问 InnoDB&#x2F; MyISAM 数据文件，从而尽可能采用顺序读，减少随机 I&#x2F;O。</li>
</ul>
</li>
<li>注意缓冲池大小的影响<ul>
<li>如果 InnoDB 或 MyISAM 的缓冲池&#x2F;缓存（Buffer Pool &#x2F; Key Cache）足够大，可以一次性容纳整个表或者大部分热数据页，则 MRR 优化效果最明显。</li>
<li>若缓冲池不足以存放大量页，那么在批量读回过程中仍可能引起页被换出和换入，导致性能下降。</li>
</ul>
</li>
</ol>
<p>MRR 还可以将 <strong>复合索引</strong>（联合索引）上的多列范围查询拆分为一系列更细粒度的“键值对”，并对它们批量执行查询，从而在拆分过程中进一步“过滤”掉不符合条件的记录，避免不必要的回表。</p>
<p>假设 t 表有联合索引 <code>(key_part1, key_part2)</code>，当执行以下查询时：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> t</span><br><span class="line"><span class="keyword">WHERE</span> key_part1 <span class="operator">&gt;=</span> <span class="number">1000</span></span><br><span class="line"><span class="keyword">AND</span> key_part1 <span class="operator">&lt;</span> <span class="number">2000</span></span><br><span class="line"><span class="keyword">AND</span> key_part2 <span class="operator">=</span> <span class="number">10000</span>;</span><br></pre></td></tr></table></figure>

<p><strong>若不启用 MRR</strong>，优化器会先做一个 <strong>范围（Range）索引扫描</strong>：</p>
<ol>
<li>从联合索引按照 <code>key_part1 &gt;= 1000 AND key_part1 &lt; 2000</code> 条件，扫描出所有满足第一个条件的叶子节点记录，无视 <code>key_part2</code> 是否等于 10000；</li>
<li>读出这些记录后，再在应用层对 <code>key_part2 = 10000</code> 做过滤。<br> 这种做法可能会将大量 <code>key_part2 ≠ 10000</code> 的行读到缓冲区，却最终被丢弃，导致“无用 I&#x2F;O”。</li>
</ol>
<p><strong>若启用 MRR</strong>，优化器会把原来的查询拆分成一系列“点查”——也就是把范围 <code>[1000, 2000)</code> 细分为多个 <code>(key_part1, key_part2)</code> 对，例如 <code>(1000, 10000)</code>、<code>(1001, 10000)</code>、<code>(1002, 10000)</code> … <code>(1999, 10000)</code>；</p>
<ol>
<li>这些拆分出的 <code>(key_part1, key_part2)</code> 对本质上是更小的等值查询或等值范围查询的组合；</li>
<li>引擎对每个 <code>(key_part1, key_part2)</code> 直接通过索引查找，而不是先把所有 <code>key_part1</code> 的记录读出再过滤 <code>key_part2</code>；</li>
<li>最终在索引页上就能剪掉那些 <code>key_part2 ≠ 10000</code> 的记录，不会将它们读出到排序&#x2F;回表阶段；</li>
<li>这样做等价于把先按 <code>key_part1</code> 范围 → 再过滤 <code>key_part2</code> 改成先将范围拆为 <code>(key_part1, key_part2)</code> → 直接点查，避免无用读。</li>
</ol>
<h3 id="Index-Condition-Pushdown（索引条件下推）"><a href="#Index-Condition-Pushdown（索引条件下推）" class="headerlink" title="Index Condition Pushdown（索引条件下推）"></a>Index Condition Pushdown（索引条件下推）</h3><p>MySQL 数据库会在取出索引的同时判断是否可以进行 WHERE 条件的过滤，也就是将 WHERE 的部分过滤操作放在了存储引擎层。在某些查询下，可以大大减少上层 SQL 层对记录的索取，从而提高数据库的整体性能。</p>
<p>Index Condition Pushdown 优化支持 range、ref、<code>eq_ref</code>、<code>ref_or_null</code> 类型的查询，当前支持 MyISAM 和 InnoDB 存储引擎。当优化器选择 Index Condition Pushdown 优化时，可在执行计划的 Extra 列看到 Using index condition 提示。</p>
<p>假设某张表有联合索引 <code>(zip_code, last_name, first_name)</code>，并且查询语句如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> people</span><br><span class="line"><span class="keyword">WHERE</span> zipcode <span class="operator">=</span> <span class="string">&#x27;95054&#x27;</span></span><br><span class="line"><span class="keyword">AND</span> lastname <span class="keyword">LIKE</span> <span class="string">&#x27;%etrunia%&#x27;</span></span><br><span class="line"><span class="keyword">AND</span> address <span class="keyword">LIKE</span> <span class="string">&#x27;%Main Street%&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>对于上述语句，MySQL 数据库可以通过索引定位 <code>zipcode = &#39;95054&#39;</code> 的记录，但是索引对 WHERE 条件的 <code>lastname LIKE &#39;%etrunia%&#39;</code> 和 <code>address LIKE &#39;%Main Street%&#39;</code> 没有任何帮助。若不支持 Index Condition Pushdown 优化，则数据库需要先通过索引取出所有 <code>zipcode = &#39;95054&#39;</code> 的记录，然后再对这部分记录执行 <code>lastname LIKE &#39;%etrunia%&#39; AND address LIKE &#39;%Main Street%&#39;</code> 的过滤，才能最终得到结果。</p>
<p>若支持 Index Condition Pushdown 优化，则在索引扫描阶段，MySQL 存储引擎会先判断 <code>zipcode = &#39;95054&#39;</code> 这一部分（因为这是索引的第一列条件），然后在“取出”符合该索引前缀的行时，立即在存储引擎层对 <code>lastname LIKE &#39;%etrunia%&#39; AND address LIKE &#39;%Main Street%&#39;</code> 这两个条件进行过滤，只把同时满足三个条件的记录交给上层 SQL 层做最终读取。这样就极大地减少了上层 SQL 层对行的 fetch 次数，从而提高查询效率。当然，WHERE 中被下推的条件必须是“索引范围能够覆盖到”的列，否则无法下推。例如 <code>lastname LIKE &#39;%abc%&#39; 或者 address LIKE &#39;%xyz%&#39;</code> 带有前缀通配符（前面有 %），在大多数情况下并不属于索引可下推的范围；只有当索引是覆盖该列并且能够使用“范围扫描”或“等值比较”时，条件下推才有效。</p>
<h2 id="InnoDB-中的哈希算法"><a href="#InnoDB-中的哈希算法" class="headerlink" title="InnoDB 中的哈希算法"></a>InnoDB 中的哈希算法</h2><p><strong>哈希表基本结构与冲突解决</strong></p>
<ul>
<li>InnoDB 在缓冲池中维护一个哈希表，用于物理页号 → 缓冲池页地址的快速映射。</li>
<li>哈希冲突时采用链表方式：每个缓冲池页有一个指向同一哈希值下链上下一个页的指针，形成冲突链。</li>
</ul>
<p><strong>哈希函数：除法散列法（Division Method）</strong></p>
<ul>
<li>InnoDB 选取的哈希函数为 <strong>除法散列</strong>，即：<br>$hash_value  &#x3D;  K   mod   m$ 其中，<ul>
<li>K 是查询页标识的整数键；</li>
<li>m 是哈希表大小（槽位数）。</li>
</ul>
</li>
<li>为了尽量均匀分布并减少冲突，InnoDB 通常将 m 选为略大于 <code>缓冲池页总数 × 2</code> 的<strong>质数</strong>。<ul>
<li>例如，若 <code>innodb_buffer_pool_size = 10 MB</code>，则缓冲池中总页数约为 $10MB÷16KB&#x3D;640$ 页。</li>
<li>按 2 倍页数原则，需要 $640×2&#x3D;1280$ 个槽位，但 1280 不是质数，于是取下一个比 1280 稍大的质数 1399 作为哈希表槽数。</li>
</ul>
</li>
</ul>
<p><strong>构造查询键 K</strong></p>
<ul>
<li>InnoDB 中，每个页都有两个重要标识：<ol>
<li><strong><code>space_id</code></strong>：表示该页所属的表空间（tablespace）编号；</li>
<li><strong><code>offset</code></strong>：表示该页在表空间内的偏移量（即第几个 16 KB 页）。</li>
</ol>
</li>
<li>InnoDB 将这两个值合并成一个整数键 K，其计算公式通常为：$K  &#x3D;  (space_id  ≪  20)  +  offset$。</li>
<li>得到的 K 用于与哈希表槽数 m 做除法取余运算，确定该页在哈希表中对应的槽。</li>
</ul>
<h3 id="哈希索引"><a href="#哈希索引" class="headerlink" title="哈希索引"></a>哈希索引</h3><p><img src="/../../images/MySQL/mysql_index_hash.drawio.png" alt="img"></p>
<p>该索引采用哈希算法把键值换算成新的 hash 值，映射到对应的位置上，然后存储在 hash 表中。</p>
<ul>
<li>特点<ul>
<li>只能用于对等比较（&#x3D;，in），不支持范围查询（between，&gt;，&lt;，…）；</li>
<li>无法利用索引完成排序操作；</li>
<li>查询效率高，通常只需要一次索引就可以了，效率通常要高于 B+Tree 索引（不发生 hash 冲突的情况下）。</li>
</ul>
</li>
<li>存储引擎支持<ul>
<li>支持 hash 索引的是 Memory 和 NDB 存储引擎，而 InnoDB 中具有<strong>自适应 hash 索引</strong>。</li>
</ul>
</li>
</ul>
<p><strong>Hash 索引和 B+ 树索引的区别</strong></p>
<ol>
<li>B+ 树索引可以进行范围查询，Hash 索引不能。</li>
<li>B+ 树索引支持联合索引的最左侧原则，Hash 索引不支持。</li>
<li>B+ 树索引支持 order by 排序，Hash 索引不支持。</li>
<li>B+ 树使用 like 进行模糊查询的时候，LIKE ‘abc%’ 的话可以起到索引优化的作用，Hash 索引无法进行模糊查询。</li>
<li>Hash 索引在等值查询上比 B+ 树索引效率更高。</li>
</ol>
<h3 id="自适应哈希索引"><a href="#自适应哈希索引" class="headerlink" title="自适应哈希索引"></a>自适应哈希索引</h3><p>自适应哈希索引（Adaptive Hash Index，AHI）是 <strong>InnoDB 存储引擎在运行时自动创建的一种轻量级哈希结构</strong>，用于加速对 B+ 树叶子页中热点记录的等值查找。InnoDB 会监测查询模式，一旦检测到某个叶子页或某条索引项的访问频率过高，便在 Buffer Pool 中为该叶子页构造哈希表节点，使后续对该页的等值查找可以通过哈希函数直接定位，而无需再遍历 B+ 树路径。</p>
<p><strong>适用场景</strong></p>
<ul>
<li>等值查询：AHI 仅对形如 <code>SELECT * FROM table WHERE indexed_col = constant</code> 的等值匹配操作有效。如果是范围查询（BETWEEN、&gt;, &lt; 等）或排序（ORDER BY）、模糊匹配（LIKE ‘%…%’），则不能使用 AHI，只能回退到常规的 B+ 树扫描或其他索引操作。</li>
<li>热点数据页：在大表中，如果某个 B+ 树叶子页承载了大量相同或相近的等值访问（例如同一个二级索引项被频繁查询），AHI 能极大减少 B+ 树遍历的层级开销，将随机 I&#x2F;O 降低为直接在内存哈希表查找。</li>
</ul>
<h2 id="全文检索"><a href="#全文检索" class="headerlink" title="全文检索"></a>全文检索</h2><p>MySQL 的全文检索（Full-Text Search）功能主要基于倒排索引实现，在 MyISAM 和 InnoDB 存储引擎中均提供了不同的支持方式。其核心原理是在数据写入时将文本字段拆分成词汇单元，并建立一个词–文档或词–行号的映射表，从而使得在查询时能够快速检索包含指定关键词的记录。虽然 MySQL 的全文检索功能对于轻量级应用已经十分实用，但与专业搜索引擎（如 Lucene、Solr、Elasticsearch 等）相比，功能较为基础。</p>
<h2 id="创建索引的注意点"><a href="#创建索引的注意点" class="headerlink" title="创建索引的注意点"></a>创建索引的注意点</h2><ul>
<li>使用合适的列作为索引<ul>
<li>经常作为查询条件（WHERE 子句）、排序条件（ORDER BY 子句）、分组条件（GROUP BY 子句）的列是建立索引的好候选。</li>
<li>区分度低（唯一值比例低）的字段，例如性别，不要建索引。</li>
<li>频繁更新的字段，不要作为主键或者索引。</li>
<li>不建议用无序的值(例如身份证、UUID )作为索引，当主键具有不确定性，会造成叶子节点频繁分裂，出现磁盘存储的碎片化。</li>
</ul>
</li>
<li>避免过多的索引<ul>
<li>每个索引都需要占用额外的磁盘空间。</li>
<li>更新表（INSERT、UPDATE、DELETE 操作）时，所有的索引都需要被更新。</li>
<li>维护索引文件需要成本；还会导致页分裂，IO 次数增多。</li>
</ul>
</li>
<li>利用前缀索引和索引列的顺序<ul>
<li>对于字符串类型的列，可以考虑使用前缀索引来减少索引大小。</li>
<li>在创建复合索引时，应该根据查询条件将最常用作过滤条件的列放在前面。</li>
</ul>
</li>
</ul>
<h2 id="使用索引的注意点"><a href="#使用索引的注意点" class="headerlink" title="使用索引的注意点"></a>使用索引的注意点</h2><ul>
<li>最左前缀法则<ul>
<li>如果索引了多列（联合索引），要遵循最左前缀法则。最左前缀法则指的是查询从索引的最左列开始，并且不跳过索引中的列。如果跳过了某一列，索引将部分失效（后面的字段索引失效）。</li>
</ul>
</li>
<li>范围查询<ul>
<li>联合索引中出现范围查询（&gt;, &lt;），范围查询右侧的列索引失效。因为范围查询会存在一次性获取大量符合条件的指针，这些指针指向 B+ 树中的子节点。这些子节点中都可能会包含右侧的列索引键，因此无法使用索引。<strong>规避方法：业务允许的情况下，使用 &gt;&#x3D;, &lt;&#x3D;。</strong></li>
</ul>
</li>
<li>索引列运算：在索引列上进行运算操作（各种函数），索引将失效。</li>
<li>字符串不加引号：使用字符串类型字段时，不加引号（会造成<strong>隐式类型转换</strong>），索引将失效。</li>
<li>模糊查询：如果仅仅是尾部模糊匹配，索引不会失效，如果是<strong>头部模糊匹配</strong>，索引失效。因为索引无法确定开头部分是什么内容。</li>
<li>or 连接的条件：用 or 分割开的条件，如果 or 前面的条件中的列有索引，而后面的列中没有索引，那么涉及的索引都不会被用到。</li>
<li>数据分布的影响<ul>
<li>如果 MySQL 评估使用索引比全表更慢，则不使用索引。</li>
<li>如果某个数据占比小，那么使用索引；否则，使用全表查询。</li>
</ul>
</li>
</ul>
<h2 id="索引设计原则"><a href="#索引设计原则" class="headerlink" title="索引设计原则"></a>索引设计原则</h2><ol>
<li>数据量较大（数据行超过 1M 条），查询操作频繁的表建立索引。</li>
<li>经常作为查询条件（where），排序（order by），分组（group by）操作的字段建立索引。</li>
<li>区分度高的列建立索引（区分度高，索引效率高）。</li>
<li>长字符串、大文本字段建立前缀索引。</li>
<li>尽量使用联合索引（覆盖索引），减少单列索引，避免回表。</li>
<li>控制索引数量，维护大量索引代价高。</li>
<li>如果索引列不能存储 NULL 值，请对其使用 NOT NULL 约束（方便优化器确定哪个索引更高效）。</li>
</ol>
<h2 id="索引失效的情况"><a href="#索引失效的情况" class="headerlink" title="索引失效的情况"></a>索引失效的情况</h2><ul>
<li>在索引列上<strong>使用函数或表达式</strong>，索引可能无法使用，因为数据库无法预先计算出函数或表达式的结果。例如：<code>SELECT * FROM table_name WHERE YEAR(date_column) = 2021</code>。</li>
<li>使用<strong>不等于（&lt;&gt;）或者 NOT 操作</strong>通常会使索引失效，因为它们会扫描全表。</li>
<li>如果 LIKE 的模式串是<strong>以“%”或者“_”开头的</strong>，那么索引也无法使用。例如：<code>SELECT * FROM table_name WHERE column LIKE &#39;%abc&#39;</code>。</li>
<li>如果查询条件中使用了 <strong>OR</strong>，并且 OR 两边的条件分别涉及不同的索引，那么这些索引可能都无法使用。</li>
<li>如果 MySQL 估计使用全表扫描比使用索引更快时（通常是小表或者大部分行都满足 WHERE 子句），也不会使用索引。</li>
<li>联合索引不满足最左前缀原则时，索引会失效。</li>
</ul>
<p><strong>百万级别以上的数据如何删除？</strong></p>
<p>先删除索引，然后删除其中的无用数据，删除完成后重新创建索引。</p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>表</title>
    <url>/undefined/MySQL/2024/11/02/MySQL/%E8%A1%A8/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h2 id="索引组织表"><a href="#索引组织表" class="headerlink" title="索引组织表"></a>索引组织表</h2><p>在 InnoDB 存储引擎中，表都是根据主键顺序组织存放的，这种存储方式的表称为索引组织表（index organized table）。在 InnoDB 存储引擎表中，每张表都有一个主键（Primary Key），如果在创建表时没有显式地定义主键，则 InnoDB 存储引擎会按如下方式选择或创建主键：</p>
<ul>
<li>首先判断表中是否有非空的唯一索引（Unique NOT NULL），如果有，则该列即为主键。</li>
<li>如果不符合上述条件，InnoDB 存储引擎会自动创建一个 6 字节大小的指针。</li>
</ul>
<p>当表中有多个非空唯一索引时，InnoDB 存储引擎将选择建表时第一个定义的非空唯一索引为主键。这里需要非常注意的是，主键的选择依据的是定义索引的顺序，而不是建表时列的顺序。</p>
<p>以下是一个示例：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">CREATE TABLE</span> z (</span><br><span class="line">  a <span class="type">INT</span> <span class="keyword">NOT NULL</span>,</span><br><span class="line">  b <span class="type">INT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  c <span class="type">INT</span> <span class="keyword">NOT NULL</span>,</span><br><span class="line">  d <span class="type">INT</span> <span class="keyword">NOT NULL</span>,</span><br><span class="line">  <span class="keyword">UNIQUE</span> KEY (b),</span><br><span class="line">  <span class="keyword">UNIQUE</span> KEY (d), <span class="keyword">UNIQUE</span> KEY (c)</span><br><span class="line">);</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.02</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> z <span class="keyword">SELECT</span> <span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>;</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line">Records: <span class="number">1</span> Duplicates: <span class="number">0</span> Warnings: <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>虽然 c、d 列都是非空唯一索引， 都可以作为主键的候选，但是在定义的过程中，由于 d 列首先定义为唯一索引，故 InnoDB 存储引擎将其视为主键。</p>
<h2 id="逻辑存储结构"><a href="#逻辑存储结构" class="headerlink" title="逻辑存储结构"></a>逻辑存储结构</h2><p>从 InnoDB 存储引擎的逻辑存储结构看，所有数据都被逻辑地存放在一个空间中，称之为<strong>表空间</strong>（tablespace）。表空间又由<strong>段</strong>（segment）、<strong>区</strong>（extent）、<strong>页</strong>（page）组成。页在一些文档中有时也称为<strong>块</strong>（block），InnoDB 存储引擎的逻辑存储结构大致如下：</p>
<p><img src="/../../images/MySQL/mysql_table_storage.drawio.png" alt="img"></p>
<h3 id="表空间"><a href="#表空间" class="headerlink" title="表空间"></a>表空间</h3><p>表空间可以看做是 InnoDB 存储引擎逻辑结构的最⾼层，所有的数据都存放在表空间中。在默认情况下 InnoDB 存储引擎有一个共享表空间 ibdata1，即所有数据都存放在这个表空间内。如果用户启用了参数 <code>innodb_file_per_table</code>，则每张表内的数据可以单独放到一个表空间内。</p>
<p>如果启用了 <code>innodb_file_per_table</code> 的参数，需要注意的是每张表的表空间内存放的只是数据、索引和插入缓冲 Bitmap 页，其他类的数据，如回滚信息、插入缓冲索引页、系统事务信息、双写缓冲等还是存放在原来的共享表空间内。这同时也说明了另一个问题：即使在启用了参数 <code>innodb_file_per_table</code> 之后，共享表空间还是会不断地增加其大小。</p>
<p>以 Undo 日志为例：在事务提交之前，共享表空间的空间占用会不断增长。而且 InnoDB 存储引擎不会在执行 rollback 时去收缩这个表空间。虽然 InnoDB 不会回收这些空间，但是会自动判断这些 Undo 信息是否还需要，如果不需要，则会将这些空间标记为可用空间，供下次 Undo 使用。</p>
<h3 id="段"><a href="#段" class="headerlink" title="段"></a>段</h3><p>表空间是由多个段组成的，常见的段有<strong>数据段、索引段、回滚段</strong>等。因为前面已经介绍过了 InnoDB 存储引擎表是<strong>索引组织的，因此数据即索引，索引即数据。那么</strong>数据段<strong>即为 B+ 树的</strong>叶子节点**，<strong>索引段</strong>即为 B+ 树的<strong>非索引节点</strong>。<strong>回滚段包含了事务执行过程中用于数据回滚的旧数据</strong>。</p>
<h3 id="区"><a href="#区" class="headerlink" title="区"></a>区</h3><p>段由一个或多个区组成，区通常为 64 个连续的页，也就是总共 <strong>1MB</strong> 的数据。<strong>为了保证页的连续性，InnoDB 存储引擎会一次从磁盘申请 4 ~ 5 个区</strong>。连续的256个数据区为一个数据区组。使用区而非单独的页进行数据分配可优化磁盘操作，<strong>减少索引时磁盘寻道时间</strong>，特别是在大量数据进行读写时。</p>
<p>但是，这里还有这样一个问题：在用户启用了参数 <code>innodb_file_per_table</code> 后，创建的表默认大小是 <strong>96KB</strong>。区中是 64 个连续的页，创建的表的大小至少是 1MB 才对啊？</p>
<p>其实是因为有时我们可能只是创建一个很小的表，只插入一条或几条数据，此时 <strong>直接分配 1MB 区块是很浪费的</strong>，所以在每个段开始时，先最多用 <strong>32 个页大小的碎片页（fragment page）</strong> 来存放<strong>数据（也就是数据页）</strong>；在使用完这些页之后才是 64 个连续页的申请。</p>
<h3 id="页"><a href="#页" class="headerlink" title="页"></a>页</h3><p>页是 InnoDB 存储数据的基本单元，标准大小为 16 KB，索引树上的一个节点就是一个页，也就意味着数据库每次读写都是以 16 KB 为单位的，即一次最少从磁盘中读取 16KB 的数据到内存，一次最少写入 16KB 的数据到磁盘。</p>
<p>在 InnoDB 存储引擎中，常见的页类型有：</p>
<ul>
<li>数据页（B-tree Node）</li>
<li>undo 页（Undo Log Page）</li>
<li>系统页（System Page）</li>
<li>事务数据页（Transaction System Page）</li>
<li>插入缓冲位图页（Insert Buffer Bitmap）</li>
<li>插入缓冲空闲列表页（Insert Buffer Free List）</li>
<li>未压缩的二进制大对象页（Uncompressed BLOB Page）</li>
<li>压缩的二进制大对象页（Compressed BLOB Page）</li>
</ul>
<h3 id="行"><a href="#行" class="headerlink" title="行"></a>行</h3><p>InnoDB 存储引擎是面向<strong>行（row-oriented）的，也就是说数据是按行</strong>进行存放的。每个页存放的行记录也是有硬性定义的，最多允许存放 <strong>16KB &#x2F; 2 ~ 200</strong> 行的记录，即 <strong>7992 行记录</strong>。</p>
<p>这里提到了 row-oriented 的数据库，也就是说，存在有 <strong>column-oriented</strong> 的数据库。</p>
<h2 id="InnoDB-行记录格式"><a href="#InnoDB-行记录格式" class="headerlink" title="InnoDB 行记录格式"></a>InnoDB 行记录格式</h2><p>行数据拥有多中记录格式，如 <strong>COMPACT、REDUNDANT、DYNAMIC</strong> 等。</p>
<table>
<thead>
<tr>
<th>特性</th>
<th>COMPACT 行格式</th>
<th>DYNAMIC 行格式</th>
</tr>
</thead>
<tbody><tr>
<td><strong>共同点</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td>存储引擎</td>
<td>两者均为 InnoDB 存储引擎支持的行格式。</td>
<td>两者均为 InnoDB 存储引擎支持的行格式。</td>
</tr>
<tr>
<td>事务支持</td>
<td>都支持事务和外键。</td>
<td>都支持事务和外键。</td>
</tr>
<tr>
<td>索引支持</td>
<td>支持主键和二级索引。</td>
<td>支持主键和二级索引。</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>特性</th>
<th>COMPACT 行格式</th>
<th>DYNAMIC 行格式</th>
</tr>
</thead>
<tbody><tr>
<td><strong>差异</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td>变长长度列处理</td>
<td>存储变长列的前缀数据在行内（最多 768 字节），超出部分存储在溢出页。</td>
<td>直接将大列数据存储在溢出页，仅在行内存储指向溢出页的 20 字节指针。</td>
</tr>
<tr>
<td>存储效率</td>
<td>对于小的变长数据相对高效，但对于非常大的列可能造成行内存存储不必要的数据。</td>
<td>对于大型 <code>TEXT</code> 和 <code>BLOB</code> 数据更加高效，因为它避免了不必要的前缀存储。</td>
</tr>
<tr>
<td>行存储开销</td>
<td>因为行内存储前缀，可能会导致一些存储开销。</td>
<td>使用指针减少了行内存储的开销，允许更大的行灵活性。</td>
</tr>
<tr>
<td>性能</td>
<td>对于小型数据表现良好，但当数据需要多次读取溢出页时，性能可能降低。</td>
<td>对于大数据读取性能更好，因为减少了对行内存储的负担。</td>
</tr>
<tr>
<td>行碎片化</td>
<td>大量更新可能导致行碎片化，因为行内和溢出页的数据可能分离。</td>
<td>行碎片化问题较少，因为数据更多地存储在溢出页。</td>
</tr>
<tr>
<td>适用场景</td>
<td>适用于包含许多中小型变长列的表，以及需要向后兼容的场合。</td>
<td>适合包含大文本或二进制数据的表，尤其是那些需要高效处理大数据的应用场景。</td>
</tr>
</tbody></table>
<h3 id="COMPACT"><a href="#COMPACT" class="headerlink" title="COMPACT"></a>COMPACT</h3><p>Compact 行记录是在 MySQL 5.0 中引入的，其设计目标是高效地存储数据。一个页中存放的行数据越多，其性能就越高。下图是 Compact 行记录的格式：</p>
<p><img src="/../../images/MySQL/mysql_table_compact.drawio.png" alt="img"></p>
<p>Compact 行记录格式的前部是一个非 NULL 变长字段长度<strong>列表</strong>，并且其是按照列的顺序逆序放置的。其长度为：</p>
<ul>
<li>若列的长度小于 255 字节，用 1 字节表示；</li>
<li>若大于 255 字节，用 2 字节表示。</li>
</ul>
<p>变长字段的长度最大不可以超过 2 字节，这是因在 MySQL 数据库中 VARCHAR 类型的最大长度限制为 65535。变长字段之后的第二个部分是 NULL 标志位，该位指示了该字段中是否有 NULL 值，有则用 1 表示。该部分所占的字节数应为 1 字节。接下来的部分是记录头信息（record header），固定占用 5 字节（40 位），每位的含义如下：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>大小 (bit)</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>（）</td>
<td>1</td>
<td>未知</td>
</tr>
<tr>
<td>（）</td>
<td>1</td>
<td>未知</td>
</tr>
<tr>
<td><code>deleted_flag</code></td>
<td>1</td>
<td>标记该行是否已被删除；被删除的记录会进入垃圾链表，等待新记录覆盖。</td>
</tr>
<tr>
<td><code>min_rec_flag</code></td>
<td>1</td>
<td>若为 1，表示该记录是 B+ 树节点（非叶子层）的最小目录项或 Infimum 记录。</td>
</tr>
<tr>
<td><code>n_owned</code></td>
<td>4</td>
<td>该记录拥有的后续记录数：在稀疏页目录中，一个槽组内最后一条记录的 <code>n_owned</code> 为组内记录数，其它记录为 0。</td>
</tr>
<tr>
<td><code>heap_no</code></td>
<td>13</td>
<td>索引堆中该条记录的序号（相对于同页其它记录的排序位置）。</td>
</tr>
<tr>
<td><code>record_type</code></td>
<td>3</td>
<td>记录类型，000&#x3D;普通行，001&#x3D;B+ 树非叶节点目录项，010&#x3D;Infimum，011&#x3D;Supremum，1xx&#x3D;保留。</td>
</tr>
<tr>
<td><code>next_record</code></td>
<td>16</td>
<td>指向本页中下一条记录头的相对偏移（按主键顺序）。</td>
</tr>
<tr>
<td><strong>Total</strong></td>
<td><strong>40</strong></td>
<td></td>
</tr>
</tbody></table>
<p>最后的部分就是实际存储每个列的数据。需要特别注意的是，<strong>NULL 不占该部分任何空间</strong>，即 NULL 除了占有 NULL 标志位，<strong>实际存储不占有任何空间</strong>。</p>
<p>另外有一点需要注意的是，每行数据除了用户定义的列外，还有两个隐藏列，分别是：</p>
<ul>
<li>事务 ID 列（6 字节）</li>
<li>回滚指针列（7 字节）</li>
</ul>
<p>共计额外占用 13 字节。</p>
<p>若 InnoDB 表没有定义主键，每行还会增加一个 6 字节的 rowid 列。</p>
<p>接下来用一个具体示例来分析 <strong>Compact 行记录</strong> 的内部结构：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">CREATE TABLE</span> mytest (</span><br><span class="line">  t1 <span class="type">VARCHAR</span>(<span class="number">10</span>),</span><br><span class="line">  t2 <span class="type">VARCHAR</span>(<span class="number">10</span>),</span><br><span class="line">  t3 <span class="type">CHAR</span>(<span class="number">10</span>),</span><br><span class="line">  t4 <span class="type">VARCHAR</span>(<span class="number">10</span>)</span><br><span class="line">) ENGINE<span class="operator">=</span>INNODB CHARSET<span class="operator">=</span>LATIN1 ROW_FORMAT<span class="operator">=</span>COMPACT;</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> mytest <span class="keyword">VALUES</span> (<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;bb&#x27;</span>,<span class="string">&#x27;bb&#x27;</span>,<span class="string">&#x27;ccc&#x27;</span>);</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> mytest <span class="keyword">VALUES</span> (<span class="string">&#x27;d&#x27;</span>,<span class="string">&#x27;ee&#x27;</span>,<span class="string">&#x27;ee&#x27;</span>,<span class="string">&#x27;fff&#x27;</span>);</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> mytest <span class="keyword">VALUES</span> (<span class="string">&#x27;d&#x27;</span>,<span class="keyword">NULL</span>,<span class="keyword">NULL</span>,<span class="string">&#x27;fff&#x27;</span>);</span><br></pre></td></tr></table></figure>

<p>表 mytest 有 4 个字段：</p>
<ul>
<li>t1，t2，t4 是 VARCHAR（变长）</li>
<li>t3 是 CHAR（定长）</li>
</ul>
<p>插入三条记录后，查看表空间文件 <code>mytest.ibd</code>。</p>
<p><img src="/../../images/MySQL/mysql_table_bin_data.png" alt="img"></p>
<p>找到某记录存储起点 <code>0x0000c078</code>，解释如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="number">03</span> <span class="number">02</span> <span class="number">01</span>    <span class="comment">-- 变长字段长度列表，逆序</span></span><br><span class="line"></span><br><span class="line"><span class="number">00</span>       <span class="comment">-- NULL 标志位（第一行无 NULL）</span></span><br><span class="line"></span><br><span class="line"><span class="number">00</span> <span class="number">00</span> <span class="number">10</span> <span class="number">00</span> <span class="number">2</span>c   <span class="comment">-- Record Header（5 字节）</span></span><br><span class="line"></span><br><span class="line"><span class="number">00</span> <span class="number">00</span> <span class="number">00</span> <span class="number">2</span>b <span class="number">68</span> <span class="number">00</span> <span class="comment">-- RowID（6 字节）</span></span><br><span class="line"></span><br><span class="line"><span class="number">00</span> <span class="number">00</span> <span class="number">00</span> <span class="number">00</span> <span class="number">06</span> <span class="number">05</span>  <span class="comment">-- Transaction ID（6 字节）</span></span><br><span class="line"></span><br><span class="line"><span class="number">80</span> <span class="number">00</span> <span class="number">00</span> <span class="number">00</span> <span class="number">32</span> <span class="number">01</span> <span class="number">10</span> <span class="comment">-- Roll Pointer（7 字节）</span></span><br></pre></td></tr></table></figure>

<p>接下来是列数据（按顺序）：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="number">61</span>       <span class="comment">-- &#x27;a&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="number">62</span> <span class="number">62</span>     <span class="comment">-- &#x27;bb&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="number">62</span> <span class="number">62</span> <span class="number">20</span> <span class="number">20</span> <span class="number">20</span> <span class="number">20</span> <span class="number">20</span> <span class="number">20</span> <span class="number">20</span> <span class="number">20</span> <span class="comment">-- CHAR 类型需补齐</span></span><br><span class="line"></span><br><span class="line"><span class="number">63</span> <span class="number">63</span> <span class="number">63</span>    <span class="comment">-- &#x27;ccc&#x27;</span></span><br></pre></td></tr></table></figure>

<p>现在第一行数据就展现在用户眼前了。需要注意的是，变长字段长度列表是逆序存放的，因此变长字段长度列表为 <code>03 02 01</code>，而不是 <code>01 02 03</code>。此外还需要注意 InnoDB 每行有隐藏列 TransactionID 和 Roll Pointer。同时可以发现，固定长度 CHAR 字段在未能完全占用其长度空间时，会用 <code>0x20</code> 来进行填充。</p>
<p>接着再来分析下 Record Header 的最后两个字节，这两个字节代表 <code>next_recorder</code>，<code>0x2c</code> 代表下一个记录的偏移量，即当前记录的位置加上偏移量 <code>0x2c</code> 就是下条记录的起始位置。所以 InnoDB 存储引擎在页内部是通过一种链表的结构来串连各个行记录的。</p>
<p>第二行将不做整理，除了 RowID 不同外，它和第一行大同小异。现在来关注有 NULL 值的第三行：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="number">03</span> <span class="number">01</span><span class="comment">/* 变长字段长度列表，逆序 */</span></span><br><span class="line"></span><br><span class="line"><span class="number">06</span>  <span class="comment">/* NULL 标志位，第三行有 NULL 值 */</span></span><br><span class="line"></span><br><span class="line"><span class="number">00</span> <span class="number">00</span> <span class="number">20</span> ff <span class="number">98</span><span class="comment">/* Record Header */</span></span><br><span class="line"></span><br><span class="line"><span class="number">00</span> <span class="number">00</span> <span class="number">00</span> <span class="number">2</span>b <span class="number">68</span> <span class="number">02</span><span class="comment">/* RowID */</span></span><br><span class="line"></span><br><span class="line"><span class="number">00</span> <span class="number">00</span> <span class="number">00</span> <span class="number">00</span> <span class="number">06</span> <span class="number">07</span><span class="comment">/* TransactionID */</span></span><br><span class="line"></span><br><span class="line"><span class="number">80</span> <span class="number">00</span> <span class="number">00</span> <span class="number">00</span> <span class="number">32</span> <span class="number">01</span> <span class="number">10</span><span class="comment">/* Roll Pointer */</span></span><br><span class="line"></span><br><span class="line"><span class="number">64</span><span class="comment">/* 列1 数据 &#x27;d&#x27; */</span></span><br><span class="line"></span><br><span class="line"><span class="number">66</span> <span class="number">66</span> <span class="number">66</span><span class="comment">/* 列4 数据 &#x27;fff&#x27; */</span></span><br></pre></td></tr></table></figure>

<p>第三行有 NULL 值，因此 NULL 标志位不再是 00 而是 06，转换成二进制为 <code>00000110</code>，为 1 的值代表第 2 列和第 3 列的数据为 NULL。在其后存储列数据的部分，用户会发现没有存储 NULL 列，而只存储了第 1 列和第 4 列非 NULL 的值。因此这个例子很好地说明了：不管是 CHAR 类型还是 VARCHAR 类型，在 <strong>Compact 格式下</strong> NULL 值都<strong>不占用任何存储空间</strong>。</p>
<h3 id="行溢出数据"><a href="#行溢出数据" class="headerlink" title="行溢出数据"></a>行溢出数据</h3><p>我们将过大的字段数据存放到溢出页中，目的是让每个数据页能够存储更多的数据行，也就是减少数据页的膨胀和磁盘 I&#x2F;O。</p>
<h4 id="Compact-和-Redundant"><a href="#Compact-和-Redundant" class="headerlink" title="Compact 和 Redundant"></a>Compact 和 Redundant</h4><p>InnoDB 存储引擎可以将一条记录中的某些数据存储在页外的数据页而非页内。一般认为 BLOB，TEXT 这类的大对象列类型的存储会把数据存放在数据页页外。但是，这个理解有点偏差，BLOB 可以不将数据放在溢出页面，而且即便是 VARCHAR 列数据类型，依然有可能被存放为行溢出数据。</p>
<p>首先对 <strong>VARCHAR 数据类型</strong>进行研究。MySQL 数据库的 VARCHAR 类型可以存放 65535 字节。但是，是真的吗？真的可以存放 65535 字节吗？</p>
<p>如果创建 VARCHAR 长度为 65535 的表，用户会得到下面的错误信息：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">CREATE TABLE</span> test (</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> a <span class="type">VARCHAR</span>(<span class="number">65535</span>)</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> ) CHARSET<span class="operator">=</span>latin1 ENGINE<span class="operator">=</span>InnoDB;</span><br><span class="line"></span><br><span class="line">ERROR <span class="number">1118</span> (<span class="number">42000</span>): <span class="type">Row</span> size too large. The maximum <span class="type">row</span> size <span class="keyword">for</span> the used <span class="keyword">table</span> type, <span class="keyword">not</span> counting BLOBs, <span class="keyword">is</span> <span class="number">65535.</span> You have <span class="keyword">to</span> change <span class="keyword">some</span> columns <span class="keyword">to</span> TEXT <span class="keyword">or</span> BLOBs</span><br></pre></td></tr></table></figure>

<p>从错误消息可以看到 <strong>InnoDB 存储引擎并不支持 65535 长度的 VARCHAR</strong>。这是因为还有别的开销，通过实际测试发现，能存储 VARCHAR 类型的最大长度为 <strong>65532</strong>。以上长度的单位都是字节⚠️。</p>
<p>此外需要注意的是，<strong>MySQL 官方手册中定义的 65535 长度是指所有 VARCHAR 列的长度总和</strong>。如果列的长度总和超过这个长度，依然无法创建。</p>
<p>但是有没有想过，InnoDB 存储引擎的页为 <strong>16KB</strong>，即 <strong>16384 字节</strong>，怎么能存放 65532 字节呢？</p>
<p>因此，在一般情况下，InnoDB 存储引擎的数据都是<strong>存放在页类型为 B-tree node</strong> 中。但是当发生<strong>行溢出</strong>时，数据存放在页类型为 <strong>Uncompress BLOB</strong> 页中。</p>
<p>来看下面一个例子：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">CREATE TABLE</span> t (</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> a <span class="type">VARCHAR</span>(<span class="number">65532</span>)</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> ) ENGINE<span class="operator">=</span>InnoDB CHARSET<span class="operator">=</span>latin1;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.15</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> t</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">SELECT</span> REPEAT(<span class="string">&#x27;a&#x27;</span>, <span class="number">65532</span>);</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.08</span> sec)</span><br><span class="line">Records: <span class="number">1</span> Duplicates: <span class="number">0</span> Warnings: <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>在上述例子中，首先创建了一个列 a 长度为 65532 的 VARCHAR 类型表 t，然后插入了列 a 长度为 65532 的记录。我们可查看表文件，内容如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">page offset 00000000, page type &lt;File Space Header&gt; </span><br><span class="line"></span><br><span class="line">page offset 00000001, page type &lt;Insert Buffer Bitmap&gt; </span><br><span class="line"></span><br><span class="line">page offset 00000002, page type &lt;File Segment inode&gt; </span><br><span class="line"></span><br><span class="line">page offset 00000003, page type &lt;B-tree Node&gt;, page level &lt;0000&gt; </span><br><span class="line"></span><br><span class="line">page offset 00000004, page type &lt;Uncompressed BLOB Page&gt; </span><br><span class="line"></span><br><span class="line">page offset 00000005, page type &lt;Uncompressed BLOB Page&gt; </span><br><span class="line"></span><br><span class="line">page offset 00000006, page type &lt;Uncompressed BLOB Page&gt; </span><br><span class="line"></span><br><span class="line">page offset 00000007, page type &lt;Uncompressed BLOB Page&gt; </span><br><span class="line"></span><br><span class="line">Total number of page: 8 </span><br><span class="line"></span><br><span class="line">Insert Buffer Bitmap: 1</span><br><span class="line"></span><br><span class="line">Uncompressed BLOB Page: 4</span><br><span class="line"></span><br><span class="line">File Space Header: 1</span><br><span class="line"></span><br><span class="line">B-tree Node: 1</span><br><span class="line"></span><br><span class="line">File Segment inode: 1</span><br></pre></td></tr></table></figure>

<p>可以观察到表空间中有一个数据页节点 <strong>B-tree Node</strong>，另外有 4 个<strong>未压缩的二进制大对象页（Uncompressed BLOB Page）</strong>。在这些页中才真正存放了 <strong>65532 字节</strong> 的数据。</p>
<p>既然实际存放的数据都在 BLOB 页中，那数据页中又存放了些什么内容呢？</p>
<p><img src="/../../images/MySQL/mysql_table_bin_data2.png" alt="img"></p>
<p>可以看到，从 <code>0x0000c093</code> 到 <code>0x0000c392</code> 数据页中其实只保存了 <code>VARCHAR(65532)</code> 的<strong>前 768 字节的前缀（prefix）数据</strong>（这里都是 <code>&#39;a&#39;</code>），之后是偏移量，指向行溢出页，也就是前面用户看到的 <strong>Uncompressed BLOB Page</strong>。因此，对于行溢出数据，其结构如下图：</p>
<p><img src="/../../images/MySQL/mysql_table_overflow.drawio.png" alt="img"></p>
<p>那么多长的 VARCHAR 是保存在单个数据页中的，从多长开始会保存在 BLOB 页呢？可以这样进行思考：<strong>InnoDB 存储引擎表是索引组织的，即 B+Tree 的结构</strong>，这样每个页中至少应该有两条记录（否则失去了 B+Tree 的意义，变成链表了）。因此，如果页中只能存放下一条记录，那么 InnoDB 存储引擎会自动将行数据存放到<strong>溢出页</strong>中。</p>
<p>考虑下面表的一种情况：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">CREATE TABLE</span> t (</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> a <span class="type">VARCHAR</span>(<span class="number">9000</span>)</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> ) ENGINE<span class="operator">=</span>InnoDB;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.13</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> t</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">SELECT</span> REPEAT(<span class="string">&#x27;a&#x27;</span>, <span class="number">9000</span>);</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.04</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> t</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">SELECT</span> REPEAT(<span class="string">&#x27;a&#x27;</span>, <span class="number">9000</span>);</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.04</span> sec)</span><br></pre></td></tr></table></figure>

<p>表 a 变长字段列的长度为 9000，故能存放在一个数据页中，但是这并不能保证两条长度为 9000 的记录都能存放在一个页中。此时查看磁盘文件，如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">page offset 00000000, page type &lt;File Space Header&gt;</span><br><span class="line"></span><br><span class="line">page offset 00000001, page type &lt;Insert Buffer Bitmap&gt;</span><br><span class="line"></span><br><span class="line">page offset 00000002, page type &lt;File Segment inode&gt;</span><br><span class="line"></span><br><span class="line">page offset 00000003, page type &lt;B-tree Node&gt;, page level &lt;0000&gt;</span><br><span class="line"></span><br><span class="line">page offset 00000004, page type &lt;Uncompressed BLOB Page&gt;</span><br><span class="line"></span><br><span class="line">page offset 00000005, page type &lt;Uncompressed BLOB Page&gt;</span><br><span class="line"></span><br><span class="line">Total number of page: 6</span><br><span class="line"></span><br><span class="line">Insert Buffer Bitmap: 1</span><br><span class="line"></span><br><span class="line">Uncompressed BLOB Page: 2</span><br><span class="line"></span><br><span class="line">File Space Header: 1</span><br><span class="line"></span><br><span class="line">B-tree Node: 1</span><br><span class="line"></span><br><span class="line">File Segment inode: 1</span><br></pre></td></tr></table></figure>

<p>我们可知，确实行数据被存放到<strong>溢出页</strong>中。</p>
<p>但是，如果可以在一个页中至少放入两行数据，那 VARCHAR 类型的行数据就不会存放到 BLOB 页中去。经过多次试验测试，发现这个阈值的长度为 8098。</p>
<p>如用户建立一个列为 <code>VARCHAR(8098)</code> 的表，然后插入 2 条记录：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">CREATE TABLE</span> t (</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> a <span class="type">VARCHAR</span>(<span class="number">8098</span>)</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> ) ENGINE<span class="operator">=</span>InnoDB;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.12</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> t <span class="keyword">SELECT</span> REPEAT(<span class="string">&#x27;a&#x27;</span>, <span class="number">8098</span>);</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.04</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> t <span class="keyword">SELECT</span> REPEAT(<span class="string">&#x27;a&#x27;</span>, <span class="number">8098</span>);</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.03</span> sec)</span><br></pre></td></tr></table></figure>

<p>接着查看磁盘文件，可以发现此时的行记录都是存放在数据页中，而不是在 BLOB 页中。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">page offset 00000000, page type &lt;File Space Header&gt;</span><br><span class="line"></span><br><span class="line">page offset 00000001, page type &lt;Insert Buffer Bitmap&gt;</span><br><span class="line"></span><br><span class="line">page offset 00000002, page type &lt;File Segment inode&gt;</span><br><span class="line"></span><br><span class="line">page offset 00000003, page type &lt;B-tree Node&gt;, page level &lt;0000&gt;</span><br><span class="line"></span><br><span class="line">page offset 00000004, page type &lt;Freshly Allocated Page&gt;</span><br><span class="line"></span><br><span class="line">page offset 00000005, page type &lt;Freshly Allocated Page&gt;</span><br><span class="line"></span><br><span class="line">Total number of page: 6</span><br><span class="line"></span><br><span class="line">Freshly Allocated Page: 2</span><br><span class="line"></span><br><span class="line">Insert Buffer Bitmap: 1</span><br><span class="line"></span><br><span class="line">File Space Header: 1</span><br><span class="line"></span><br><span class="line">B-tree Node: 1</span><br><span class="line"></span><br><span class="line">File Segment inode: 1</span><br></pre></td></tr></table></figure>

<p>另一个问题是，对于 <strong>TEXT 或 BLOB 的数据类型</strong>，用户总是以为它们是存放在 <strong>Uncompressed BLOB Page</strong> 中的，其实这也<strong>不准确</strong>。是否放在数据页中还是 BLOB 页中，和前面讨论的 VARCHAR 一样，<strong>至少保证一个页能存放两条记录</strong>。</p>
<p>当然既然用户使用了 <strong>BLOB</strong> 列类型，一般不可能存放长度这么小的数据。因此在大多数的情况下 <strong>BLOB 的行数据还是会发生行溢出</strong>，<strong>实际数据保存在 BLOB 页中</strong>，数据页只保存数据的前 <strong>768 字节</strong>。</p>
<h4 id="Compressed-和-Dynamic"><a href="#Compressed-和-Dynamic" class="headerlink" title="Compressed 和 Dynamic"></a>Compressed 和 Dynamic</h4><p>InnoDB 1.0.x 版本开始引入了新的文件格式（file format，用户可以理解为新的页格式），以前支持的 Compact 和 Redundant 格式称为 Antelope 文件格式，新的文件格式称为 Barracuda 文件格式。</p>
<p>Barracuda 文件格式下拥有两种新的行记录格式：Compressed 和 Dynamic。</p>
<p>新的两种记录格式对于存放在 BLOB 中的数据采用了<strong>完全的行溢出</strong>方式，如下图：</p>
<p><img src="/../../images/MySQL/mysql_table_off.drawio.png" alt="img"></p>
<p>在数据页中只存放 20 个字节的指针，实际数据都存放在 Off Page 中，而之前的 Compact 和 Redundant 两种格式会存放 768 个前缀字节。</p>
<p>Compressed 行记录格式的另一个功能就是：存储在其中的行数据会以 zlib 的算法进行压缩，因此对于 BLOB、TEXT、VARCHAR 这类大长度类型的数据能进行非常有效的存储。</p>
<h3 id="CHAR-的行结构存储"><a href="#CHAR-的行结构存储" class="headerlink" title="CHAR 的行结构存储"></a>CHAR 的行结构存储</h3><p>通常理解 VARCHAR 是存储变长度的字符类型，CHAR 是存储固定长度的字符类型。而在前面的内容中，我们可以发现每行的变长字段长度的列表<strong>都没有存储</strong> <strong>CHAR</strong> <strong>类型的长度</strong>。</p>
<p>然而，值得注意的是之前给出的两个例子中的字符集都是单字节的 latin1 格式。从 MySQL 4.1 版本开始，CHAR(N) 中的 N 指的是字符的长度，而不是之前版本的字节长度。</p>
<p>也就是说在不同的字符集中，CHAR 类型列内部存储的可能<strong>不是定长的数据</strong>。例如下面的这个示例：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">CREATE TABLE</span> j (</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> a <span class="type">CHAR</span>(<span class="number">2</span>)</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> ) CHARSET<span class="operator">=</span>GBK ENGINE<span class="operator">=</span>InnoDB;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.11</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> j <span class="keyword">SELECT</span> <span class="string">&#x27;ab&#x27;</span>;</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.03</span> sec)</span><br><span class="line">Records: <span class="number">1</span> Duplicates: <span class="number">0</span> Warnings: <span class="number">0</span></span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SET</span> NAMES GBK;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> j <span class="keyword">SELECT</span> <span class="string">&#x27;我们&#x27;</span>;</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.04</span> sec)</span><br><span class="line">Records: <span class="number">1</span> Duplicates: <span class="number">0</span> Warnings: <span class="number">0</span></span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> j <span class="keyword">SELECT</span> <span class="string">&#x27;a&#x27;</span>;</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.03</span> sec)</span><br><span class="line">Records: <span class="number">1</span> Duplicates: <span class="number">0</span> Warnings: <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>在上述例子中，表 j 的字符集是 GBK。用户分别插入了两个字符的数据 ‘ab’ 和 ‘我们’，然后查看所占字节，可得如下结果：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> a,<span class="keyword">CHAR_LENGTH</span>(a),LENGTH(a)</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">FROM</span> j\G;</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">a: ab</span><br><span class="line"><span class="keyword">CHAR_LENGTH</span>(a): <span class="number">2</span></span><br><span class="line">LENGTH(a): <span class="number">2</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">2.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">a: 我们</span><br><span class="line"><span class="keyword">CHAR_LENGTH</span>(a): <span class="number">2</span></span><br><span class="line">LENGTH(a): <span class="number">4</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">3.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">a: a</span><br><span class="line"><span class="keyword">CHAR_LENGTH</span>(a): <span class="number">1</span></span><br><span class="line">LENGTH(a): <span class="number">1</span></span><br><span class="line"><span class="number">3</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<p>通过不同的 CHAR_LENGTH 和 CHAR 函数可以观察到：前两个记录 ‘ab’ 和 ‘我们’ 字符串的长度都是 2。但是内部存储上 ‘ab’ 占用 2 字节，而 ‘我们’ 占用 4 字节。如果通过 HEX 函数查看内部十六进制的存储，可以看到：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> a,HEX(a)</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">FROM</span> j\G;</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">a: ab</span><br><span class="line">HEX(a): <span class="number">6162</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">2.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">a: 我们</span><br><span class="line">HEX(a): CED2C3C7</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">3.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">a: a</span><br><span class="line">HEX(a): <span class="number">61</span></span><br><span class="line"><span class="number">3</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<p>因此对于多字节字符编码，如 GBK、UTF-8 等，的 CHAR 数据类型的存储，InnoDB 存储引擎在内部将其视为<strong>变长字符类型</strong>。<strong>这也就意味着在变长长度列表中会记录</strong> <strong>CHAR</strong> <strong>数据类型的长度。</strong></p>
<p>我们可查看磁盘文件：</p>
<p><img src="/../../images/MySQL/mysql_table_bin_data3.png" alt="img"></p>
<p>整理后可以得到如下结果：</p>
<p>第一行记录：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">02     /* 变长字段长度 2，将 CHAR 视作变长类型 */</span><br><span class="line"></span><br><span class="line">00     /* NULL 标志位 */</span><br><span class="line"></span><br><span class="line">00 00 10 00 1c /* Recoder Header */</span><br><span class="line"></span><br><span class="line">00 00 00 b6 2b 2b /* RowID */</span><br><span class="line"></span><br><span class="line">00 00 00 51 52 da /* TransactionID */</span><br><span class="line"></span><br><span class="line">80 00 00 00 2d 01 10 /* Roll Point */</span><br><span class="line"></span><br><span class="line">61 62   /* 字符 &#x27;ab&#x27; */</span><br></pre></td></tr></table></figure>

<p>第二行记录：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">04     /* 变长字段长度 4，将 CHAR 视作变长类型 */</span><br><span class="line"></span><br><span class="line">00     /* NULL 标志位 */</span><br><span class="line"></span><br><span class="line">00 00 18 ff d5 /* Recoder Header */</span><br><span class="line"></span><br><span class="line">00 00 00 b6 2b 2c /* RowID */</span><br><span class="line"></span><br><span class="line">00 00 00 51 52 db /* TransactionID */</span><br><span class="line"></span><br><span class="line">80 00 00 00 2d 01 10 /* Roll Point */</span><br><span class="line"></span><br><span class="line">c3 d2 c3 c7     /* 字符 &#x27;我们&#x27; */</span><br></pre></td></tr></table></figure>

<p>第三行记录：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">02     /* 变长字段长度 2，将 CHAR 视作变长类型 */</span><br><span class="line"></span><br><span class="line">00     /* NULL 标志位 */</span><br><span class="line"></span><br><span class="line">00 00 20 ff b7 /* Recoder Header */</span><br><span class="line"></span><br><span class="line">00 00 00 b6 2b 2d /* RowID */</span><br><span class="line"></span><br><span class="line">00 00 00 51 53 17 /* TransactionID */</span><br><span class="line"></span><br><span class="line">80 00 00 00 2d 01 10 /* Roll Point */</span><br><span class="line"></span><br><span class="line">61 20   /* 字符 &#x27;a&#x27; */</span><br></pre></td></tr></table></figure>

<p>上述例子清楚地显示了 InnoDB 存储引擎内部对 CHAR 类型在多字节字符集类型的存储。CHAR 类型被明确视为变长字符类型，对于未能占满长度的字符还是填充 <code>0x20</code>。InnoDB 存储引擎内部对字符的存储和我们用 HEX 函数看到的也是一致的。因此可以认为在多字节字符集的情况下，CHAR 和 VARCHAR 的实际行存储基本是没有区别的。</p>
<h2 id="InnoDB-数据页结构"><a href="#InnoDB-数据页结构" class="headerlink" title="InnoDB 数据页结构"></a>InnoDB 数据页结构</h2><p>InnoDB 数据页由以下 7 个部分组成，如下图所示：</p>
<ol>
<li>File Header（文件头）</li>
<li>Page Header（页头）</li>
<li>Infimum 和 Supremum Records</li>
<li>User Records（用户记录，即行记录）</li>
<li>Free Space（空闲空间）</li>
<li>Page Directory（页目录）</li>
<li>File Trailer（文件结尾信息）</li>
</ol>
<p>其中 File Header、Page Header、File Trailer 的大小是固定的，分别为 38、56、8 字节，这些空间用于标记该页的一些信息，如 Checksum、数据页所在 B+ 树索引的层数等。User Records、Free Space、Page Directory 这些部分为实际的行记录存储空间，因此大小是动态的。</p>
<p>下图中具体分析了数据页中的各组成部分：</p>
<p><img src="/../../images/MySQL/mysql_table_page_strct.drawio.png" alt="img"></p>
<h3 id="File-Header"><a href="#File-Header" class="headerlink" title="File Header"></a>File Header</h3><p>File Header 用来记录页的一些头信息，由下图中的 8 个部分组成，共占用 38 字节。</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>大小（字节）</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>FIL_PAGE_SPACE_OR_CHKSUM</code></td>
<td>4</td>
<td>当 MySQL 为 MySQL4.0.14 之前的版本时，该值为 0。在之后的 MySQL 版本中，该值代表页的 checksum 值（—种新的 checksum 值）。</td>
</tr>
<tr>
<td><code>FIL_PAGE_OFFSET</code></td>
<td>4</td>
<td>表空间中页的偏移值。如果独立表空间 <code>a.ibd</code> 的大小为 1GB，如果页的大小为 16KB，那么总共有 65 536 个页。<code>FIL_PAGE_OFFSET</code> 表示该页在所有页中的位置。若此表空间的 ID 为 10，那么搜索页 <code>(10, 1)</code> 就表示查找表 <code>a</code> 中的第二个页。</td>
</tr>
<tr>
<td><code>FIL_PAGE_PREV</code></td>
<td>4</td>
<td>当前页的上一个页，B+Tree 特性决定了叶子节点必须是双向列表。</td>
</tr>
<tr>
<td><code>FIL_PAGE_NEXT</code></td>
<td>4</td>
<td>当前页的下一个页，B+Tree 特性决定了叶子节点必须是双向列表。</td>
</tr>
<tr>
<td><code>FIL_PAGE_LSN</code></td>
<td>8</td>
<td>该值代表该页最后被修改的日志序列位置 LSN（Log Sequence Number）。</td>
</tr>
<tr>
<td><code>FIL_PAGE_TYPE</code></td>
<td>2</td>
<td>InnoDB 存储引擎页的类型。常见的类型见表 4-4。记住 0x45BF，该值代表了存放的是数据页，即实际行记录的存储空间。</td>
</tr>
<tr>
<td><code>FIL_PAGE_FILE_FLUSH_LSN</code></td>
<td>8</td>
<td>该值仅在系统表空间的一个页中定义，代表文件至少被更新到了该 LSN 值。对于独立表空间，该值都为 0。</td>
</tr>
<tr>
<td><code>FIL_PAGE_ARCH_LOG_NO_OR_SPACE_ID</code></td>
<td>4</td>
<td>从 MySQL 4.1 开始，该值代表页属于哪个表空间。</td>
</tr>
</tbody></table>
<p>下图是 InnoDB 中页的类型：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>十六进制</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td><code>FIL_PAGE_INDEX</code></td>
<td><code>0x45BF</code></td>
<td>B+ 树叶节点。</td>
</tr>
<tr>
<td><code>FIL_PAGE_UNDO_LOG</code></td>
<td><code>0x0002</code></td>
<td>Undo Log 页，用于存储事务回滚信息。</td>
</tr>
<tr>
<td><code>FIL_PAGE_INODE</code></td>
<td><code>0x0003</code></td>
<td>INODE 页，管理表空间内数据页的分配情况。</td>
</tr>
<tr>
<td><code>FIL_PAGE_IBUF_FREE_LIST</code></td>
<td><code>0x0004</code></td>
<td>Insert Buffer 空闲列表，记录可用于合并缓冲的空闲页。</td>
</tr>
<tr>
<td><code>FIL_PAGE_TYPE_ALLOCATED</code></td>
<td><code>0x0000</code></td>
<td>已分配页，表示此页是最新分配但尚未使用的页。</td>
</tr>
<tr>
<td><code>FIL_PAGE_IBUF_BITMAP</code></td>
<td><code>0x0005</code></td>
<td>Insert Buffer 位图，用于标记可用于缓存合并的页。</td>
</tr>
<tr>
<td><code>FIL_PAGE_TYPE_SYS</code></td>
<td><code>0x0006</code></td>
<td>系统页，存储 InnoDB 内部元数据。</td>
</tr>
<tr>
<td><code>FIL_PAGE_TYPE_TRX_SYS</code></td>
<td><code>0x0007</code></td>
<td>事务系统数据页，存储事务相关系统信息。</td>
</tr>
<tr>
<td><code>FIL_PAGE_TYPE_FSP_HDR</code></td>
<td><code>0x0008</code></td>
<td>File Space Header，表空间头信息页。</td>
</tr>
<tr>
<td><code>FIL_PAGE_TYPE_XDES</code></td>
<td><code>0x0009</code></td>
<td>扩展描述页，管理区块（extent）使用情况。</td>
</tr>
<tr>
<td><code>FIL_PAGE_TYPE_BLOB</code></td>
<td><code>0x000A</code></td>
<td>BLOB 页，用于存储大文本或二进制数据。</td>
</tr>
</tbody></table>
<h3 id="Page-Header"><a href="#Page-Header" class="headerlink" title="Page Header"></a>Page Header</h3><p>接着 File Header 部分的是 Page Header，该部分用来记录数据页的状态信息，由 14 个部分组成，共占用 56 字节，如下图所示。</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>大小（字节）</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>PAGE_N_DIR_SLOTS</code></td>
<td>2</td>
<td>在 Page Directory（页目录）中的 Slot（槽）数。</td>
</tr>
<tr>
<td><code>PAGE_HEAP_TOP</code></td>
<td>2</td>
<td>堆中第一个记录的指针，记录在页中是根据堆的形式存放的。</td>
</tr>
<tr>
<td><code>PAGE_N_HEAP</code></td>
<td>2</td>
<td>堆中的记录数。共占用 2 字节，但第 15 位用于表示行记录格式。</td>
</tr>
<tr>
<td><code>PAGE_FREE</code></td>
<td>2</td>
<td>指向可重用空间的首指针。</td>
</tr>
<tr>
<td><code>PAGE_GARBAGE</code></td>
<td>2</td>
<td>已删除记录的字节数，即行记录结构中 <code>delete_flag</code> 为 1 的记录大小的总数。</td>
</tr>
<tr>
<td><code>PAGE_LAST_INSERT</code></td>
<td>2</td>
<td>最后插入记录的位置。</td>
</tr>
<tr>
<td><code>PAGE_DIRECTION</code></td>
<td>2</td>
<td>最后插入的方向。可能取值为：<br>• <code>PAGE_LEFT</code> (<code>0x01</code>)<br>• <code>PAGE_RIGHT</code> (<code>0x02</code>)<br>• <code>PAGE_SAME_REC</code> (<code>0x03</code>)<br>• <code>PAGE_SAME_PAGE</code> (<code>0x04</code>)<br>• <code>PAGE_NO_DIRECTION</code> (<code>0x05</code>)</td>
</tr>
<tr>
<td><code>PAGE_N_DIRECTION</code></td>
<td>2</td>
<td>一个方向连续插入记录的数量。</td>
</tr>
<tr>
<td><code>PAGE_N_RECS</code></td>
<td>2</td>
<td>该页中记录的数量。</td>
</tr>
<tr>
<td><code>PAGE_MAX_TRX_ID</code></td>
<td>8</td>
<td>修改当前页的最大事务 ID，注意该值仅在 Secondary Index 中定义。</td>
</tr>
<tr>
<td><code>PAGE_LEVEL</code></td>
<td>2</td>
<td>当前页在索引树中的位置，<code>0x00</code> 表示叶节点，即叶节点总是在第 0 层。</td>
</tr>
<tr>
<td><code>PAGE_INDEX_ID</code></td>
<td>8</td>
<td>索引 ID，表示当前页属于哪个索引。</td>
</tr>
<tr>
<td><code>PAGE_BTR_SEG_LEAF</code></td>
<td>10</td>
<td>B+ 树数据页在叶节点所在段的 segment header 中的位置信息，注意该值仅在 B+ 树的 Root 页中定义。</td>
</tr>
<tr>
<td><code>PAGE_BTR_SEG_TOP</code></td>
<td>10</td>
<td>B+ 树数据页在非叶节点所在段的 segment header 中的位置信息，注意该值仅在 B+ 树的 Root 页中定义。</td>
</tr>
</tbody></table>
<p>需要注意的是，这里的堆结构指的是页内记录的排布方式，并不是数据结构中的堆 heap，也就是在 InnoDB 的一个数据页中，行记录是按照一定规则存储在一个称为“堆”的区域中。这个“堆”具有以下特征：</p>
<ol>
<li>数据页内的记录不是顺序排布，而是通过链表和 slot 引用来组织的；</li>
<li>堆中的第一个 slot 是 Infimum（表示最小值），最后一个是 Supremum（最大值）；</li>
<li>每个记录都包含一个 next record 指针，指向下一条记录；</li>
<li><code>PAGE_HEAP_TOP</code>：表示当前堆的顶部，新的记录一般会存入这里。</li>
</ol>
<p>其次，PAGE_DIRECTION：最后插入的方向，这个属性记录了最后一条插入记录的方向，主要用于优化后续插入操作的位置判断，避免每次都从头或尾查找插入位置。</p>
<p>示例：</p>
<p>假设你有一个数据页，用于存储用户年龄的索引，页中原来已有以下记录（已按顺序）：</p>
<p>[20] -&gt; [30] -&gt; [40] -&gt; [50]</p>
<p>现在你要往页里插入新的值：</p>
<p>情况 1：插入 [45]</p>
<p>它的插入位置在 [40] 和 [50] 之间：</p>
<ul>
<li>InnoDB 在查找插入位置时，可能从 <code>PAGE_LAST_INSERT</code> 指向的上一个插入位置（比如 [30]）出发。</li>
<li>发现现在是往右边插入的，所以：<ul>
<li>设置 PAGE_DIRECTION &#x3D; PAGE_RIGHT（0x02）；</li>
<li>这样下次如果还要插入更大的记录，比如 [48]，就可以直接从 [45] 或 [50] 向右查找，加速插入位置的定位。</li>
</ul>
</li>
</ul>
<p>情况 2：插入 [25]</p>
<ul>
<li>插入位置在 [20] 和 [30] 之间，InnoDB 会发现你是在“往左边插入”，</li>
<li>设置 PAGE_DIRECTION &#x3D; PAGE_LEFT（0x01）；</li>
<li>如果下次你又插入 [22]，系统会直接从上次插入的 [25] 向左找，避免从 Supremum 重新查找。</li>
</ul>
<p>情况 3：乱序插入</p>
<ul>
<li>你现在插入一条 [42]，下一次又插入 [21]，再下一次插入 [51]，插入方向完全没有规律；</li>
<li>InnoDB 会识别到你插入方向变化太频繁，就会设置：<ul>
<li>PAGE_DIRECTION &#x3D; PAGE_NO_DIRECTION（0x05）；</li>
</ul>
</li>
</ul>
<p>这时候优化机制关闭，下次插入位置会重新全页查找。</p>
<h3 id="Infimum-和-Supremum-Record"><a href="#Infimum-和-Supremum-Record" class="headerlink" title="Infimum 和 Supremum Record"></a>Infimum 和 Supremum Record</h3><p>在 InnoDB 存储引擎中，每个数据页中有两个模拟的行记录，用来限定记录的边界。Infimum 记录是比该页中任何主键值都要小的值，Supremum 指比任何可能大的值还要大的值。这两个值在页创建时被建立，并且在任何情况下不会被删除。而且在 InnoDB 中，这两个伪行记录的类型是 Char(8)。下图显示了 Infimum 和 Supremum 记录。</p>
<p><img src="/../../images/MySQL/mysql_table_rec_bound.drawio.png" alt="img"></p>
<h3 id="User-Record-和-Free-Space"><a href="#User-Record-和-Free-Space" class="headerlink" title="User Record 和 Free Space"></a>User Record 和 Free Space</h3><p>User Record 就是之前讨论过的部分，即实际存储行记录的内容。再次强调，InnoDB 存储引擎表总是 B+ 树索引组织的。</p>
<p>Free Space 很明显指的就是空闲空间，同样也是个链表数据结构。在一条记录被删除后，该空间会被加入到空闲链表中。</p>
<h3 id="Page-Directory"><a href="#Page-Directory" class="headerlink" title="Page Directory"></a>Page Directory</h3><p>Page Directory 是 InnoDB 数据页中的一个结构，<strong>用于帮助快速定位页内记录的位置</strong>。它相当于是数据页内部的一个<strong>加速查找索引</strong>，而且是逆序存放的。</p>
<p>和很多人以为的不同，InnoDB 并不是每条记录都在 Page Directory 中有一个指针。</p>
<p>相反，<strong>它是稀疏的目录（sparse directory）</strong>，即：</p>
<ul>
<li>一个槽通常指向一组记录中<strong>最前面的那条</strong>；</li>
<li>这组记录一般有 <strong>4～8 条</strong>，由 <code>n_owned</code> 表示。</li>
</ul>
<p><code>n_owned</code> 是什么？</p>
<p><code>n_owned</code> 表示：<strong>该槽负责的记录数量</strong>。</p>
<p>假设某页中实际有 12 条记录，按主键顺序如下：</p>
<p>a b c d e f g h i j k l</p>
<p>可能在 Page Directory 中只存了以下 3 个槽指针：</p>
<p>Slot 1 -&gt; a</p>
<p>Slot 2 -&gt; e</p>
<p>Slot 3 -&gt; i</p>
<p>这表示：</p>
<p>Slot 1 覆盖记录 a、b、c、d；</p>
<p>Slot 2 覆盖 e、f、g、h；</p>
<p>Slot 3 覆盖 i、j、k、l。</p>
<p>为什么这样做？稀疏目录的好处是什么？</p>
<p>好处是节省空间 + 提高效率：</p>
<ul>
<li>若每条记录都在 Page Directory 里有个槽，占用空间太大；</li>
<li>稀疏存储后，只需要少量槽位，通过<strong>二分查找</strong>就可以迅速定位到一个“接近位置”；</li>
<li>然后用<strong>链表（通过 <code>next_record</code> 指针）继续遍历几条记录</strong>，就能找到目标。</li>
</ul>
<p>查询流程小结</p>
<p>当你需要在页中找一个记录（比如查主键 &#x3D; f）时，流程如下：</p>
<ol>
<li>从 Page Directory 中进行<strong>二分查找</strong>，发现 f 应该在 e 开头的槽中；</li>
<li>然后从 e 出发，<strong>用链表结构沿着 next_record 指针遍历</strong>；</li>
<li>依次到 f，查找成功。</li>
</ol>
<p>⚠️ Page Directory 只是个“粗索引”，最终还要依赖链表来完成精确定位。</p>
<h3 id="File-Trailer"><a href="#File-Trailer" class="headerlink" title="File Trailer"></a>File Trailer</h3><p>为了检测页是否已经完整地写入磁盘（如可能发生的写入过程中磁盘损坏、机器关机等），InnoDB 存储引擎的页中设置了 File Trailer 部分。</p>
<p>File Trailer 只有一个 <code>FIL_PAGE_END_LSN</code> 部分，占用 8 字节。前 4 字节代表该页的 checksum 值，最后 4 字节和 File Header 中的 <code>FIL_PAGE_LSN</code> 相同。将这两个值与 File Header 中的 <code>FIL_PAGE_SPACE_OR_CHKSUM</code> 和 <code>FIL_PAGE_LSN</code> 值进行比较，看是否一致（checksum 的比较需要通过 InnoDB 的 checksum 函数来进行比较，不是简单的等值比较），以此来保证页的完整性（not corrupted）。</p>
<p>在默认配置下，InnoDB 存储引擎每次从磁盘读取一个页就会检测该页的完整性，判断页是否发生 Corrupt，这就是通过 File Trailer 部分进行检测，而该部分的检测会有一定的开销。</p>
<h3 id="InnoDB-数据页结构实例分析"><a href="#InnoDB-数据页结构实例分析" class="headerlink" title="InnoDB 数据页结构实例分析"></a>InnoDB 数据页结构实例分析</h3><p>在 MySQL 技术内幕的这一节中，Record Header 中的最后 2 字节内容代表的是下一行中实际存储数据的部分的初始位置。</p>
<p>以 <code>0000c107</code> 对应的行为例，我们从 0000c100 开始看：因为表中只存在一个 <code>Char(10)</code> 类型的字段，而且字符集是 UTF8，因此 Char 字段会被视为可变字符，并会在行记录的开始记录其长度 0a。之后的 00 代表该行中没有为 NULL 的字段，而且该行中页确实没有 NULL 字段。接着是 5 字节的 Header。之后是主键 00 00 00 05，因为该表中我们指定了主键且主键类型为 INT，因为这里存储的是 4 字节的主键的内容，而不是 6 字节的 ROWID。再就是 6 字节的 Transaction ID 和 7 字节的 Roll Pointer。最后是 10 字节的 Char 字段的数据。一共 34 个字节，正好对应着下一条行数据的实际存储数据的起始位置。Perfecto！</p>
<h2 id="Named-File-Formats-机制"><a href="#Named-File-Formats-机制" class="headerlink" title="Named File Formats 机制"></a>Named File Formats 机制</h2><p>随着 InnoDB 存储引擎的发展，新的页数据结构有时用来支持新的功能特性。例如前面提到的 InnoDB 1.0.x 版本提供了新的页数据结构来支持表压缩功能，完全的溢出（Off page）大变长字符串类型字段的存储。这些新的页数据结构和之前版本的页并不兼容，因此从 InnoDB 1.0.x 版本开始，InnoDB 存储引擎通过 Named File Formats 机制来解决不同版本下页结构兼容性的问题。</p>
<p>InnoDB 存储引擎 1.0.x 版本之前的文件格式（file format）定义为 Antelope，将这个版本支持的文件格式定义为 Barracuda。新的文件格式总是包含之前版本的页格式。图 4-8 显示了 Barracuda 文件格式和 Antelope 文件格式之间的关系，Antelope 文件格式有 Compact 和 Redundant 的行格式，Barracuda 文件格式既包括了 Antelope 所有的文件格式，另外新加入了之前已经提到过的 Compressed 和 Dynamic 行格式。</p>
<p><img src="/../../images/MySQL/mysql_table_named_file.drawio.png" alt="img"></p>
<h2 id="分区表"><a href="#分区表" class="headerlink" title="分区表"></a>分区表</h2><p>分区功能并不是在存储引擎层完成的，因此不是只有 InnoDB 存储引擎支持分区，常见的存储引擎 MyISAM、NDB 等都支持。但也并不是所有的存储引擎都支持，如 CSV、FEDERATED、MERGE 等就不支持。在使用分区功能前，应该对选择的存储引擎对分区的支持有所了解。</p>
<p>MySQL 数据库在 5.1 版本时添加了对分区的支持。分区的过程是将一个表或索引分解为多个更小、更可管理的部分。就访问数据库的应用而言，从逻辑上讲，只有一个表或一个索引，但是在物理上这个表或索引可能由数个小物理分区组组成。每个分区都是独立的对象，可以独自处理，也可以作为一个更大对象的一部分进行处理。</p>
<p>MySQL 数据库支持的分区类型为水平分区，并不支持垂直分区。此外，MySQL 数据库的分区是局部分区索引，一个分区中既存放了数据又存放了索引。而全局分区是指，数据存放在各个分区中，但是所有数据的索引放在一个对象中。目前，MySQL 数据还不支持全局分区。</p>
<p>大多数人会有这样一个误区：只要启用了分区，数据库就会运行得更快。这个结论是存在很多问题的。就我的经验来看，分区可能会给某些 SQL 语句性能带来提高，但是分区主要用于数据库高可用性和性能的管理。在 OLTP 应用中，对于分区的使用应该非常小心。总之，如果只是一味地使用分区，而不理解分区是如何工作的，也不清楚你的应用如何使用分区，那么分区极有可能会对性能产生负面的影响。</p>
<p>目前 MySQL 数据库支持以下几种类型的分区：</p>
<ul>
<li>RANGE 分区：行数据基于属于一个给定连续区间的列值被放入分区。</li>
<li>LIST 分区：和 RANGE 分区类似，只是 LIST 区间内的是离散的值。</li>
<li>HASH 分区：根据用户自己定义的表达式的返回值来进行分区，返回值不能为负数。</li>
<li>KEY 分区：根据 MySQL 数据库提供的哈希函数来进行分区。</li>
</ul>
<p>你不能创建不带索引的分区，如果表中存在主键或唯一索引时，分区列必须是唯一索引的一个组成部分，因此下面创建分区的 SQL 语句会因缺少索引而产生错误：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">create table</span> t1 (id <span class="type">int</span> <span class="keyword">not null</span>, val <span class="type">int</span> <span class="keyword">not null</span>, <span class="keyword">unique</span> key (id)) <span class="keyword">partition</span> <span class="keyword">by</span> hash(val) partitions <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line">ERROR <span class="number">1503</span> (HY000): A <span class="keyword">PRIMARY KEY</span> must include <span class="keyword">all</span> columns <span class="keyword">in</span> the <span class="keyword">table</span><span class="string">&#x27;s partitioning function (prefixed columns are not considered).</span></span><br></pre></td></tr></table></figure>

<p>唯一索引可以是允许 NULL 值的，并且分区列只要是唯一索引的一个组成部分，不需要整个唯一索引列都是分区列。</p>
<p>如果建表时没有指定主键，唯一索引，可以指定任何一个列为分区列。</p>
<h3 id="分区类型"><a href="#分区类型" class="headerlink" title="分区类型"></a>分区类型</h3><h4 id="RANGE-分区"><a href="#RANGE-分区" class="headerlink" title="RANGE 分区"></a>RANGE 分区</h4><p>第一种分区类型是 RANGE 分区，也是最常用的一种分区类型。下面的 CREATE TABLE 语句创建了一个 id 列的区间分区表。当 id 小于 10 时，数据插入 p0 分区；当 id 大于等于 10 小于 20 时，数据插入 p1 分区。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> t(</span><br><span class="line">  id <span class="type">INT</span></span><br><span class="line">) ENGINE<span class="operator">=</span>INNODB</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="keyword">RANGE</span> (id)(</span><br><span class="line">  <span class="keyword">PARTITION</span> p0 <span class="keyword">VALUES</span> LESS THAN (<span class="number">10</span>),</span><br><span class="line">  <span class="keyword">PARTITION</span> p1 <span class="keyword">VALUES</span> LESS THAN (<span class="number">20</span>));</span><br></pre></td></tr></table></figure>

<p>查看表在磁盘上的物理文件，启用分区之后，表不再由一个 ibd 文件组成了，而是由建立分区时的各个分区 ibd 文件组成，如下面的 <code>t#P#p0.ibd</code>、<code>t#P#p1.ibd</code>：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">system <span class="built_in">ls</span> -lh /usr/local/mysql/data/test2/t*</span></span><br><span class="line"></span><br><span class="line">-rw-rw---- 1 mysql mysql 8.4K 7月 31 14:11 /usr/local/mysql/data/test2/t.frm</span><br><span class="line"></span><br><span class="line">-rw-rw---- 1 mysql mysql  28 7月 31 14:11 /usr/local/mysql/data/test2/t.par</span><br><span class="line"></span><br><span class="line">-rw-rw---- 1 mysql mysql  96K 7月 31 14:12 /usr/local/mysql/data/test2/t#P#p0.ibd</span><br><span class="line"></span><br><span class="line">-rw-rw---- 1 mysql mysql  96K 7月 31 14:12 /usr/local/mysql/data/test2/t#P#p1.ibd</span><br></pre></td></tr></table></figure>

<p>接着插入如下数据：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> t <span class="keyword">SELECT</span> <span class="number">9</span>;</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.03</span> sec)</span><br><span class="line">Records: <span class="number">1</span> Duplicates: <span class="number">0</span> Warnings: <span class="number">0</span></span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> t <span class="keyword">SELECT</span> <span class="number">10</span>;</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.03</span> sec)</span><br><span class="line">Records: <span class="number">1</span> Duplicates: <span class="number">0</span> Warnings: <span class="number">0</span></span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> t <span class="keyword">SELECT</span> <span class="number">15</span>;</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.03</span> sec)</span><br><span class="line">Records: <span class="number">1</span> Duplicates: <span class="number">0</span> Warnings: <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>因为表 t 根据列 id 进行分区，所以数据是根据列 id 的值的范围存放在不同的物理文件中的。</p>
<p>由于我们定义了分区，因此对于插入的值应该严格遵守分区的定义，当插入一个不在分区中定义的值时，MySQL 数据库会抛出一个异常。</p>
<h4 id="LIST-分区"><a href="#LIST-分区" class="headerlink" title="LIST 分区"></a>LIST 分区</h4><p>LIST 分区和 RANGE 分区非常相似，只是分区列的值是离散的，而非连续的。如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">CREATE TABLE</span> t (</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> a <span class="type">INT</span>,</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> b <span class="type">INT</span>) ENGINE<span class="operator">=</span>INNODB</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">PARTITION</span> <span class="keyword">BY</span> LIST(b)(</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">PARTITION</span> p0 <span class="keyword">VALUES</span> <span class="keyword">IN</span> (<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">9</span>),</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">PARTITION</span> p1 <span class="keyword">VALUES</span> <span class="keyword">IN</span> (<span class="number">0</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">8</span>)</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> );</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.26</span> sec)</span><br></pre></td></tr></table></figure>

<p>不同于 RANGE 分区中定义的 VALUES LESS THAN 语句，LIST 分区使用 VALUES IN。因为每个分区的值是离散的，因此只能定义值。</p>
<p>在用 INSERT 插入多个行数据的过程中遇到分区未定义的值时，MyISAM 和 InnoDB 存储引擎的处理完全不同。MyISAM 引擎会将之前的行数据都插入，但之后的数据不会被插入。而 InnoDB 存储引擎将其视为一个事务，因此没有任何数据插入。</p>
<h4 id="HASH-分区"><a href="#HASH-分区" class="headerlink" title="HASH 分区"></a>HASH 分区</h4><p>HASH 分区的主要目的是将数据均匀地分配到预定义的各个分区中，以确保每个分区中的数据量大致相同。与 RANGE 和 LIST 分区需要显式指定某个列值或值集合应存储在哪个分区不同，HASH 分区的分配过程由 MySQL 自动完成。用户只需基于用于分区的列，指定一个返回整数的表达式，同时设置表应被划分的分区数量即可。</p>
<p>要使用 HASH 分区来分割一个表，要在 CREATE TABLE 语句上添加一个：<strong>PARTITION BY HASH(expr)</strong> 子句，其中 expr 是一个返回一个整数的表达式。它可以仅仅是字段类型为 MySQL 整型的列名。此外，用户很可能需要在后面再添加一个：PARTITIONS num 子句，其中 num 是一个非负的整数，它表示表将要被分割成分区的数量。如果没有包括一个 PARTITIONS 子句，那么分区的数量将默认为 1。</p>
<p>MySQL 数据库还支持一种称为 LINEAR HASH 的分区，它使用一个更加复杂的算法来确定新行插入到已经分区的表中的位置。它的语法和 HASH 分区的语法相似，只是将关键字 HASH 改为 LINEAR HASH。MySQL 数据库根据以下的方法来进行分区的判断：</p>
<ul>
<li>取大于分区数量 4 的下一个 2 的幂值 V，<code>V = POWER(2, CEILING(LOG(2, num))) = 4</code>；</li>
<li>所在分区 <code>N = YEAR(&#39;2010-04-01&#39;) &amp; (V - 1) = 2</code>。</li>
</ul>
<p>LINEAR HASH 分区的优点在于，增加、删除、合并和拆分分区将变得更加快捷，这有利于处理含有大量数据的表。它的缺点在于，与使用 HASH 分区得到的数据分布相比，各个分区间数据的分布可能不太均衡。</p>
<h4 id="KEY-分区"><a href="#KEY-分区" class="headerlink" title="KEY 分区"></a>KEY 分区</h4><p>KEY 分区和 HASH 分区相似，不同之处在于 HASH 分区使用用户定义的函数进行分区，KEY 分区使用 MySQL 数据库提供的函数进行分区。对于 InnoDB 存储引擎，MySQL 数据库使用其内部的哈希函数，这些函数基于与 <code>PASSWORD()</code> 一样的运算法则。如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">CREATE TABLE</span> t_key (</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> a <span class="type">INT</span>,</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> b DATETIME) ENGINE<span class="operator">=</span>InnoDB</span><br><span class="line"> <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">PARTITION</span> <span class="keyword">BY</span> KEY (b)</span><br><span class="line"> <span class="operator">-</span><span class="operator">&gt;</span> PARTITIONS <span class="number">4</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.43</span> sec)</span><br></pre></td></tr></table></figure>

<p>在 KEY 分区中使用关键字 LINEAR 和在 HASH 分区中使用具有同样的效果，分区的编号是通过 2 的幂算法得到的，而不是通过模数算法。</p>
<h4 id="COLUMNS-分区"><a href="#COLUMNS-分区" class="headerlink" title="COLUMNS 分区"></a>COLUMNS 分区</h4><p>在前面介绍的 RANGE、LIST、HASH 和 KEY 这四种分区中，分区的条件是：数据必须是整型，如果不是整型，那么就需要通过函数将其转化为整型，如 <code>YEAR()</code>、<code>TO_DAYS()</code>、<code>MONTH()</code> 等函数。MySQL 5.5 版本开始支持 COLUMNS 分区，可视为 RANGE 分区和 LIST 分区的一种进化。COLUMNS 分区可以直接使用非整型的数据进行分区，分区根据类型直接比较而得，不需要转化为整型。此外，RANGE COLUMNS 分区可以对多个列的值进行分区。</p>
<p>COLUMNS 分区支持以下的数据类型：</p>
<ul>
<li>所有的整型类型，如 INT、SMALLINT、TINYINT、BIGINT。FLOAT 和 DECIMAL 则不予支持。</li>
<li>日期类型，如 DATE 和 DATETIME。其余的日期类型不予支持。</li>
<li>字符串类型，如 CHAR、VARCHAR、BINARY 和 VARBINARY。BLOB 和 TEXT 类型不予支持。</li>
</ul>
<p>对于日期类型的分区，我们不再需要 <code>YEAR()</code> 和 <code>TO_DAYS()</code> 函数了，而是可以直接使用 COLUMNS，如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> t_columns_range(</span><br><span class="line">  a <span class="type">INT</span>,</span><br><span class="line">  b DATETIME</span><br><span class="line">) ENGINE<span class="operator">=</span>INNODB</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="keyword">RANGE</span> COLUMNS (B)(</span><br><span class="line">  <span class="keyword">PARTITION</span> p0 <span class="keyword">VALUES</span> LESS THAN (<span class="string">&#x27;2009-01-01&#x27;</span>),</span><br><span class="line">  <span class="keyword">PARTITION</span> p1 <span class="keyword">VALUES</span> LESS THAN (<span class="string">&#x27;2010-01-01&#x27;</span>)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>同样可以直接使用字符串的分区：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> customers_1 (</span><br><span class="line">  first_name <span class="type">VARCHAR</span>(<span class="number">25</span>),</span><br><span class="line">  last_name <span class="type">VARCHAR</span>(<span class="number">25</span>),</span><br><span class="line">  street_1 <span class="type">VARCHAR</span>(<span class="number">30</span>),</span><br><span class="line">  street_2 <span class="type">VARCHAR</span>(<span class="number">30</span>),</span><br><span class="line">  city <span class="type">VARCHAR</span>(<span class="number">15</span>),</span><br><span class="line">  renewal <span class="type">DATE</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> LIST COLUMNS(city) (</span><br><span class="line">  <span class="keyword">PARTITION</span> pRegion_1 <span class="keyword">VALUES</span> <span class="keyword">IN</span>(<span class="string">&#x27;Oskarshamn&#x27;</span>, <span class="string">&#x27;Högsby&#x27;</span>, <span class="string">&#x27;Mönsterås&#x27;</span>),</span><br><span class="line">  <span class="keyword">PARTITION</span> pRegion_2 <span class="keyword">VALUES</span> <span class="keyword">IN</span>(<span class="string">&#x27;Vimmerby&#x27;</span>, <span class="string">&#x27;Hultsfred&#x27;</span>, <span class="string">&#x27;Västervik&#x27;</span>),</span><br><span class="line">  <span class="keyword">PARTITION</span> pRegion_3 <span class="keyword">VALUES</span> <span class="keyword">IN</span>(<span class="string">&#x27;Nässjö&#x27;</span>, <span class="string">&#x27;Eksjö&#x27;</span>, <span class="string">&#x27;Vetlanda&#x27;</span>),</span><br><span class="line">  <span class="keyword">PARTITION</span> pRegion_4 <span class="keyword">VALUES</span> <span class="keyword">IN</span>(<span class="string">&#x27;Uppvidinge&#x27;</span>, <span class="string">&#x27;Alvesta&#x27;</span>, <span class="string">&#x27;Växjo&#x27;</span>)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>对于 RANGE COLUMNS 分区，可以使用多个列进行分区，如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> rcx (</span><br><span class="line">  a <span class="type">INT</span>,</span><br><span class="line">  b <span class="type">INT</span>,</span><br><span class="line">  c <span class="type">CHAR</span>(<span class="number">3</span>),</span><br><span class="line">  d <span class="type">INT</span></span><br><span class="line">) Engine<span class="operator">=</span>InnoDB</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="keyword">RANGE</span> COLUMNS(a,d,c) (</span><br><span class="line">  <span class="keyword">PARTITION</span> p0 <span class="keyword">VALUES</span> LESS THAN (<span class="number">5</span>,<span class="number">10</span>,<span class="string">&#x27;ggg&#x27;</span>),</span><br><span class="line">  <span class="keyword">PARTITION</span> p1 <span class="keyword">VALUES</span> LESS THAN (<span class="number">10</span>,<span class="number">20</span>,<span class="string">&#x27;mmmm&#x27;</span>),</span><br><span class="line">  <span class="keyword">PARTITION</span> p2 <span class="keyword">VALUES</span> LESS THAN (<span class="number">15</span>,<span class="number">30</span>,<span class="string">&#x27;sss&#x27;</span>),</span><br><span class="line">  <span class="keyword">PARTITION</span> p3 <span class="keyword">VALUES</span> LESS THAN (MAXVALUE,MAXVALUE,MAXVALUE)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>MySQL 5.5 开始支持 COLUMNS 分区，对于之前的 RANGE 和 LIST 分区，用户可以用 RANGE COLUMNS 和 LIST COLUMNS 分区进行很好的代替。</p>
<h3 id="子分区"><a href="#子分区" class="headerlink" title="子分区"></a>子分区</h3><p>子分区（subpartitioning）是在分区的基础上再进行分区，有时也称这种分区为复合分区（composite partitioning）。MySQL 数据库允许在 RANGE 和 LIST 的分区上再进行 HASH 或 KEY 的子分区，如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">CREATE TABLE</span> ts (a <span class="type">INT</span>, b <span class="type">DATE</span>) ENGINE<span class="operator">=</span>InnoDB</span><br><span class="line"> <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="keyword">RANGE</span> (<span class="keyword">YEAR</span>(b))</span><br><span class="line"> <span class="operator">-</span><span class="operator">&gt;</span> SUBPARTITION <span class="keyword">BY</span> HASH (TO_DAYS(b))</span><br><span class="line"> <span class="operator">-</span><span class="operator">&gt;</span> SUBPARTITIONS <span class="number">2</span> (</span><br><span class="line">   <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">PARTITION</span> p0 <span class="keyword">VALUES</span> LESS THAN (<span class="number">1990</span>),</span><br><span class="line">   <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">PARTITION</span> p1 <span class="keyword">VALUES</span> LESS THAN (<span class="number">2000</span>),</span><br><span class="line">   <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">PARTITION</span> p2 <span class="keyword">VALUES</span> LESS THAN MAXVALUE</span><br><span class="line"> );</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.01</span> sec)</span><br></pre></td></tr></table></figure>

<p>表 ts 被 范围分区成 p0、p1、p2；</p>
<p>每个主分区又被 子分区（HASH） 成两个子分区，比如 p0 变成：p0sp0、p0sp1；</p>
<p>最终形成了 3（主分区） × 2（子分区） &#x3D; 6 个物理分区。</p>
<p>子分区的建立需要注意以下几个问题：</p>
<ul>
<li>每个子分区的数量必须相同。</li>
<li>要在一个分区表的任何分区上使用 SUBPARTITION 来明确定义任何子分区，就必须定义所有的子分区。</li>
<li>每个 SUBPARTITION 子句必须包括子分区的一个名字。</li>
<li>子分区的名字必须是唯一的。</li>
</ul>
<p>子分区可以用于特别大的表，在多个磁盘间分别分配数据和索引。MySQL 本身并不直接支持通过语法控制每个分区或子分区映射到哪个磁盘路径，但你可以通过以下方式间接实现这一点：</p>
<p><strong>操作方法一</strong>：使用多个表空间 + DATA DIRECTORY 和 INDEX DIRECTORY</p>
<p>MyISAM 引擎可以使用如下方式手动指定每个分区&#x2F;子分区存放的目录（通常每个目录挂载不同磁盘）：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> big_table (</span><br><span class="line">  id <span class="type">INT</span>,</span><br><span class="line">  name <span class="type">VARCHAR</span>(<span class="number">100</span>)</span><br><span class="line">)</span><br><span class="line">ENGINE <span class="operator">=</span> MyISAM</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> HASH(id)</span><br><span class="line">PARTITIONS <span class="number">6</span> (</span><br><span class="line">  <span class="keyword">PARTITION</span> p0 DATA DIRECTORY <span class="operator">=</span> <span class="string">&#x27;/disk0/data&#x27;</span> INDEX DIRECTORY <span class="operator">=</span> <span class="string">&#x27;/disk0/index&#x27;</span>,</span><br><span class="line">  <span class="keyword">PARTITION</span> p1 DATA DIRECTORY <span class="operator">=</span> <span class="string">&#x27;/disk1/data&#x27;</span> INDEX DIRECTORY <span class="operator">=</span> <span class="string">&#x27;/disk1/index&#x27;</span>,</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">PARTITION</span> p5 DATA DIRECTORY <span class="operator">=</span> <span class="string">&#x27;/disk5/data&#x27;</span> INDEX DIRECTORY <span class="operator">=</span> <span class="string">&#x27;/disk5/index&#x27;</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>⚠️ 仅支持 MyISAM，不支持 InnoDB。并且要求 innodb_file_per_table&#x3D;OFF，否则无效。</p>
<p><strong>操作方法二</strong>：使用 Linux 下的软链接（适用于 InnoDB）</p>
<p>虽然 InnoDB 不支持 DATA DIRECTORY 语法，但可以使用 软链接 将分区&#x2F;子分区文件（<code>.ibd</code>）手动移动到不同磁盘，如：</p>
<p>步骤：</p>
<p>一、创建分区表（比如在 <code>/var/lib/mysql</code> 中）：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> big_partition (</span><br><span class="line">  id <span class="type">INT</span>,</span><br><span class="line">  dt <span class="type">DATE</span></span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="keyword">RANGE</span> (<span class="keyword">YEAR</span>(dt)) (</span><br><span class="line">  <span class="keyword">PARTITION</span> p0 <span class="keyword">VALUES</span> LESS THAN (<span class="number">2020</span>),</span><br><span class="line">  <span class="keyword">PARTITION</span> p1 <span class="keyword">VALUES</span> LESS THAN (<span class="number">2025</span>)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>二、关闭 MySQL 服务</p>
<p>移动分区数据文件到其他磁盘目录</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mv /var/lib/mysql/db/big_partition#P#p0.ibd /disk0/big_partition#P#p0.ibd</span><br><span class="line"></span><br><span class="line">ln -s /disk0/big_partition#P#p0.ibd /var/lib/mysql/db/big_partition#P#p0.ibd</span><br></pre></td></tr></table></figure>

<p>三、重启 MySQL 服务</p>
<p>⚠️ 你必须启用 <code>innodb_file_per_table=1</code> 且使用独立表空间</p>
<p>操作方法三：使用 LVM 或 RAID 逻辑卷</p>
<p>将多个磁盘组合成一个逻辑卷，然后整个 MySQL 数据目录或表空间都部署在这个卷上，由底层逻辑卷管理器决定调度和负载均衡，对 MySQL 透明。</p>
<h3 id="分区中的-NULL-值"><a href="#分区中的-NULL-值" class="headerlink" title="分区中的 NULL 值"></a>分区中的 NULL 值</h3><p>MySQL 数据库允许对 NULL 值做分区，但是处理的方法与其他数据库可能完全不同。MySQL 数据库的分区是视 NULL 值小于任何一个非 NULL 值，这和 MySQL 数据库中处理 NULL 值的 ORDER BY 操作是一样的。因此对于不同的分区类型，MySQL 数据库对于 NULL 值的处理也是各不相同。</p>
<p>对于 RANGE 分区，如果向分区列插入了 NULL 值，则 MySQL 数据库会将该值放入最左边的分区。例如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">CREATE TABLE</span> t_range(</span><br><span class="line">  a <span class="type">INT</span>,</span><br><span class="line">  b <span class="type">INT</span>) ENGINE<span class="operator">=</span>InnoDB</span><br><span class="line">  <span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="keyword">RANGE</span>(b)(</span><br><span class="line">    <span class="keyword">PARTITION</span> p0 <span class="keyword">VALUES</span> LESS THAN (<span class="number">10</span>),</span><br><span class="line">    <span class="keyword">PARTITION</span> p1 <span class="keyword">VALUES</span> LESS THAN (<span class="number">20</span>),</span><br><span class="line">    <span class="keyword">PARTITION</span> p2 <span class="keyword">VALUES</span> LESS THAN MAXVALUE</span><br><span class="line">  );</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.01</span> sec)</span><br></pre></td></tr></table></figure>

<p>接着向表中插入 <code>(1,1)</code>、<code>(1,NULL)</code> 两条数据，并观察每个分区中记录的数据：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> t_range <span class="keyword">SELECT</span> <span class="number">1</span>,<span class="number">1</span>;</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> t_range <span class="keyword">SELECT</span> <span class="number">1</span>,<span class="keyword">NULL</span>;</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> t_range\G;</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">a: <span class="number">1</span></span><br><span class="line">b: <span class="number">1</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">2.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">a: <span class="number">1</span></span><br><span class="line">b: <span class="keyword">NULL</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<p>可以看到两条数据都放入了 p0 分区，也就是说在 RANGE 分区下，NULL 值会放入最左边的分区中。另外需要注意的是，如果删除 p0 这个分区，删除的将是小于 10 的记录，并且还有 NULL 值的记录，这点非常重要：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">ALTER TABLE</span> t_range <span class="keyword">DROP</span> <span class="keyword">PARTITION</span> p0;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.01</span> sec)</span><br><span class="line">Records: <span class="number">0</span> Duplicates: <span class="number">0</span> Warnings: <span class="number">0</span></span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> t_range;</span><br><span class="line"><span class="keyword">Empty</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<p>在 LIST 分区下要使用 NULL 值，则必须显式地指出哪个分区中放入 NULL 值，否则会报错，如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">CREATE TABLE</span> t_list(</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> a <span class="type">INT</span>,</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> b <span class="type">INT</span>) ENGINE<span class="operator">=</span>INNODB</span><br><span class="line"> <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">PARTITION</span> <span class="keyword">BY</span> LIST(b)(</span><br><span class="line">   <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">PARTITION</span> p0 <span class="keyword">VALUES</span> <span class="keyword">IN</span> (<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">9</span>),</span><br><span class="line">   <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">PARTITION</span> p1 <span class="keyword">VALUES</span> <span class="keyword">IN</span> (<span class="number">0</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">8</span>)</span><br><span class="line"> );</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> t_list <span class="keyword">SELECT</span> <span class="number">1</span>, <span class="keyword">NULL</span>;</span><br><span class="line">ERROR <span class="number">1526</span> (HY000): <span class="keyword">Table</span> has <span class="keyword">no</span> <span class="keyword">partition</span> <span class="keyword">for</span> <span class="keyword">value</span> <span class="keyword">NULL</span></span><br></pre></td></tr></table></figure>

<p>若 p0 分区允许 NULL 值，则插入不会报错：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">CREATE TABLE</span> t_list(</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> a <span class="type">INT</span>,</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> b <span class="type">INT</span>) ENGINE<span class="operator">=</span>INNODB</span><br><span class="line"> <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">PARTITION</span> <span class="keyword">BY</span> LIST(b)(</span><br><span class="line">   <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">PARTITION</span> p0 <span class="keyword">VALUES</span> <span class="keyword">IN</span> (<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">9</span>,<span class="keyword">NULL</span>),</span><br><span class="line">   <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">PARTITION</span> p1 <span class="keyword">VALUES</span> <span class="keyword">IN</span> (<span class="number">0</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">8</span>)</span><br><span class="line"> );</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> t_list <span class="keyword">SELECT</span> <span class="number">1</span>, <span class="keyword">NULL</span>;</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line">Records: <span class="number">1</span> Duplicates: <span class="number">0</span> Warnings: <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>HASH 和 KEY 分区对于 NULL 的处理方式和 RANGE 分区、LIST 分区不一样。任何分区函数都会将含有 NULL 值的记录返回值为 0。例如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">CREATE TABLE</span> t_hash(</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> a <span class="type">INT</span>,</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> b <span class="type">INT</span>) ENGINE<span class="operator">=</span>InnoDB</span><br><span class="line"> <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">PARTITION</span> <span class="keyword">BY</span> HASH(b)</span><br><span class="line"> <span class="operator">-</span><span class="operator">&gt;</span> PARTITIONS <span class="number">4</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> t_hash <span class="keyword">SELECT</span> <span class="number">1</span>,<span class="number">0</span>;</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT INTO</span> t_hash <span class="keyword">SELECT</span> <span class="number">1</span>,<span class="keyword">NULL</span>;</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.01</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> table_name, partition_name, table_rows</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">FROM</span> information_schema.PARTITIONS</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">WHERE</span> table_schema<span class="operator">=</span>DATABASE() <span class="keyword">AND</span> table_name<span class="operator">=</span><span class="string">&#x27;t_hash&#x27;</span>\G;</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">table_name: t_hash</span><br><span class="line">partition_name: p0</span><br><span class="line">table_rows: <span class="number">2</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">2.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">table_name: t_hash</span><br><span class="line">partition_name: p1</span><br><span class="line">table_rows: <span class="number">0</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">3.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">table_name: t_hash</span><br><span class="line">partition_name: p2</span><br><span class="line">table_rows: <span class="number">0</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">4.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">table_name: t_hash</span><br><span class="line">partition_name: p3</span><br><span class="line">table_rows: <span class="number">0</span></span><br><span class="line"><span class="number">4</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<h3 id="分区和性能"><a href="#分区和性能" class="headerlink" title="分区和性能"></a>分区和性能</h3><p>我们常听到开发人员说“对表做个分区”，然后数据库的查询就会快了。这是真的么？实际上可能根本感受不到查询速度的提升，甚至会发现查询速度会明显下降。因此，若要合理使用分区之前，必须了解分区的使用环境。</p>
<p>数据库的应用大致分为两类：一类是 OLTP（在线事务处理），如 Blog、电子商务、网络游戏等；另一类是 OLAP（在线分析处理），如数据仓库、数据挖掘。在一个实际的应用环境中，可能看上去属于 OLTP 的应用，也有 OLAP 的应用。例如游戏平台，玩家操作的数据游戏数据库应用属 OLTP 的，但游戏平台厂商可能需要对玩家产生的日志进行分析，通过分析得到的结果来更好地服务于游戏，预测玩家的行为等，而这却是 OLAP 的应用。</p>
<p>对于 OLAP 的应用，分区的确是可以很好地提高查询的性能，因为 OLAP 应用大多数查询需要频繁地扫描一张很大的表。假设有一张 1 亿行的表，其中有一个时间戳属性列，用户的查询需要从这张表中获取一年的数据。如果按照时间戳进行分区，则只需要扫描相应的区即可，这就是前面介绍的 Partition Pruning 技术。</p>
<p>但对于 OLTP 的应用，分区这时就会小心。在这种应用下，通常不可能会去获取一张大表中 10% 的数据，大家的查询是通过索引定位几条记录即回，而根据 B+ 树结构的原理可知，对于一张大表，一般的 B+ 树需要 2～3 次的磁盘 IO。因此 B+ 树可以很好地完成检索，不需要分区的帮助，并且设计不好的分区会带来严重的性能问题。</p>
<p>我发现很多开发团队会认为含有 1000W 行的表是一张非常巨大的表，所以他们往往会选择采用分区，如对主键做 10 个 HASH 的分区，这样每个分区就只有 100W 的数据；同时他们应该这样更快了，<code>SELECT * FROM t WHERE pk=@pk</code>。但他们没有考虑过这样一种情况：100W 和 1000W 行的数据本身构成的 B+ 树的层级是一样的，而查找都是 2 层。那么上述主键分区的索引并不会带来性能的提升。好吧，如果 1000W 的 B+ 树的高度是 3，100W 的 B+ 树的高度是 2，那么上述主键分区的索引可以避免 1 次 IO，从而提高查询的效率。这没问题，但是张表只有主键索引，没有任何其他的列需要建立查询的。如果还有这样的 SQL 语句：<code>SELECT * FROM TABLE WHERE KEY=@key</code>，这时对于 KEY 的查询要扫描所有的 10 个分区，即使每个分区的查询开销为 2 次 IO，则一共需要 20 次 IO。而对于原来单表的设计，对于 KEY 的整查询只需要 2～3 次 IO。</p>
<p>接着来看如下的表 Profile，根据主键 ID 进行了 HASH 分区，HASH 分区的数据为 10，表 Profile 有接近 1000W 的数据：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">CREATE TABLE</span> `Profile` (</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> `id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT NULL</span> AUTO_INCREMENT,</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> `nickname` <span class="type">varchar</span>(<span class="number">20</span>) <span class="keyword">NOT NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> `password` <span class="type">varchar</span>(<span class="number">32</span>) <span class="keyword">NOT NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> `sex` <span class="type">char</span>(<span class="number">1</span>) <span class="keyword">NOT NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> `rdate` <span class="type">date</span> <span class="keyword">NOT NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;0000-00-00&#x27;</span>,</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">PRIMARY KEY</span> (`id`),</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> KEY `nickname` (`nickname`)</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> ) ENGINE<span class="operator">=</span>InnoDB</span><br><span class="line"> <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">PARTITION</span> <span class="keyword">BY</span> HASH (id)</span><br><span class="line"> <span class="operator">-</span><span class="operator">&gt;</span> PARTITIONS <span class="number">10</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">1.29</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(nickname) <span class="keyword">FROM</span> Profile;</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line"><span class="built_in">count</span>(<span class="number">1</span>): <span class="number">9999248</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">1</span> min <span class="number">24.62</span> sec)</span><br></pre></td></tr></table></figure>

<p>因为是根据 HASH 分区的，所以每个区分的记录数大致是相同的，即数据分布比较均匀：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> table_name, partition_name, table_rows</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">FROM</span> information_schema.PARTITIONS</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">WHERE</span> table_schema<span class="operator">=</span>DATABASE() <span class="keyword">AND</span> table_name<span class="operator">=</span><span class="string">&#x27;Profile&#x27;</span>\G;</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">table_name: Profile</span><br><span class="line">partition_name: p0</span><br><span class="line">table_rows: <span class="number">990703</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">2.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">table_name: Profile</span><br><span class="line">partition_name: p1</span><br><span class="line">table_rows: <span class="number">1086519</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">3.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">table_name: Profile</span><br><span class="line">partition_name: p2</span><br><span class="line">table_rows: <span class="number">976474</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">4.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">table_name: Profile</span><br><span class="line">partition_name: p3</span><br><span class="line">table_rows: <span class="number">986937</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">5.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">table_name: Profile</span><br><span class="line">partition_name: p4</span><br><span class="line">table_rows: <span class="number">993667</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">6.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">table_name: Profile</span><br><span class="line">partition_name: p5</span><br><span class="line">table_rows: <span class="number">978046</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">7.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">table_name: Profile</span><br><span class="line">partition_name: p6</span><br><span class="line">table_rows: <span class="number">990703</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">8.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">table_name: Profile</span><br><span class="line">partition_name: p7</span><br><span class="line">table_rows: <span class="number">978639</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">9.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">table_name: Profile</span><br><span class="line">partition_name: p8</span><br><span class="line">table_rows: <span class="number">1085334</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">10.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">table_name: Profile</span><br><span class="line">partition_name: p9</span><br><span class="line">table_rows: <span class="number">982788</span></span><br><span class="line"><span class="number">10</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.80</span> sec)</span><br></pre></td></tr></table></figure>

<p>注意：即使是根据自增长主键进行的 HASH 分区，也不能保证分区数据的均匀。因为插入的自增长 ID 并非总是连续的，如果该主键值因为某种原因被回滚了，则该值将不会再次被自动使用。</p>
<p>如果进行主键的查询，可以发现分区的确是有意义的：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> EXPLAIN PARTITIONS <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> Profile <span class="keyword">WHERE</span> id<span class="operator">=</span><span class="number">1</span>\G;</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">id: <span class="number">1</span></span><br><span class="line">select_type: SIMPLE</span><br><span class="line"><span class="keyword">table</span>: Profile</span><br><span class="line">partitions: p1</span><br><span class="line">type: const</span><br><span class="line">possible_keys: <span class="keyword">PRIMARY</span></span><br><span class="line"><span class="keyword">key</span>: <span class="keyword">PRIMARY</span></span><br><span class="line">key_len: <span class="number">4</span></span><br><span class="line"><span class="keyword">ref</span>: const</span><br><span class="line"><span class="keyword">rows</span>: <span class="number">1</span></span><br><span class="line">Extra:</span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<p>可以发现只寻找了 p1 分区，但是对于表 Profile 中 nickname 列索引的查询，EXPLAIN PARTITIONS 则会得到如下的结果：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> EXPLAIN PARTITIONS</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> Profile <span class="keyword">WHERE</span> nickname<span class="operator">=</span><span class="string">&#x27;david&#x27;</span>\G;</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">id: <span class="number">1</span></span><br><span class="line">select_type: SIMPLE</span><br><span class="line"><span class="keyword">table</span>: Profile</span><br><span class="line">partitions: p0,p1,p2,p3,p4,p5,p6,p7,p8,p9</span><br><span class="line">type: <span class="keyword">ref</span></span><br><span class="line">possible_keys: nickname</span><br><span class="line">key: nickname</span><br><span class="line">key_len: <span class="number">62</span></span><br><span class="line"><span class="keyword">ref</span>: const</span><br><span class="line"><span class="keyword">rows</span>: <span class="number">10</span></span><br><span class="line">Extra: <span class="keyword">Using</span> <span class="keyword">where</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<p>可以看到，MySQL 数据库会搜索所有分区，因此查询速度上会慢很多。比较上述语句：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> Profile <span class="keyword">WHERE</span> nickname<span class="operator">=</span><span class="string">&#x27;david&#x27;</span>\G;</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">id: <span class="number">5566</span></span><br><span class="line">nickname: david</span><br><span class="line">password: <span class="number">3e35</span>d1025659d07ae28e0069ec51ab92</span><br><span class="line">sex: M</span><br><span class="line">rdate: <span class="number">2003</span><span class="number">-09</span><span class="number">-20</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">1.05</span> sec)</span><br></pre></td></tr></table></figure>

<p>上述简单的索引查找语句竟然需要 1.05 秒，这是因为查询需要遍历所有分区的关系，实际上的 IO 执行了约 20～30 次。而在未分区的同样结构和大小的表上，执行上述同样的 SQL 语句只需要 0.26 秒。</p>
<p>因此对于使用 InnoDB 存储引擎作为 OLTP 应用的表在使用分区时应该十分小心，设计时确认数据的访问模式，否则在 OLTP 应用下分区可能不仅不会带来查询速度的提高，反而可能会使你的应用执行得更慢。</p>
<h3 id="在表和分区间交换数据"><a href="#在表和分区间交换数据" class="headerlink" title="在表和分区间交换数据"></a>在表和分区间交换数据</h3><p>MySQL 5.6 开始支持 <code>ALTER TABLE … EXCHANGE PARTITION</code> 语法。该语句允许分区或子分区中的数据与另一个非分区的表中的数据进行交换。如果非分区中的数据为空，那么相当于将分区中的数据移动到非分区表中；若分区表中的数据为空，则相当于将外部表中的数据导入到分区中。</p>
<p>要使用 <code>ALTER TABLE … EXCHANGE PARTITION</code> 语句，必须满足下面的条件：</p>
<ul>
<li>要交换的表需和分区表有相同的表结构，但表不能包含分区；</li>
<li>在非分区表中的数据必须在交换的分区定义内；</li>
<li>被交换的表中不能有外键，或者其他的表含有对该表的外键引用；</li>
<li>用户除了需要 ALTER、INSERT 和 CREATE 权限外，还需要 DROP 的权限。</li>
</ul>
<p>此外，有两个小细节也需要注意：</p>
<ul>
<li>⚠️ 使用该语句时，不会触发交换表和被交换表上的触发器；</li>
<li>⚠️ <code>AUTO_INCREMENT</code> 列将被重置。</li>
</ul>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>OLTP 索引</title>
    <url>/undefined/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/01/24/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/OLTP%20%E7%B4%A2%E5%BC%95/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h1 id="B-Tree"><a href="#B-Tree" class="headerlink" title="B+Tree"></a>B+Tree</h1><p>B+Tree 通过宽而浅的多路平衡结构，以及对页级 IO、顺序访问、并发保护和崩溃恢复的深度优化，完美契合 OLTP 系统对<strong>低延迟点查找</strong>、<strong>高并发访问</strong>和<strong>安全写入</strong>的严格要求，因此成为主流关系型数据库（MySQL、PostgreSQL、Oracle 等）在 OLTP 场景中最常用的索引实现。</p>
<p><strong>性能特点</strong></p>
<ol>
<li><strong>O(log n) 查找复杂度</strong>：树高 ≈ logₘ N，当 m 很大时，即使 N 达到亿级，树高也通常只有 3～4 层，单次查找只需 3～4 次磁盘／页访问。</li>
<li><strong>磁盘友好</strong>：每个节点对应一个（或多个）磁盘页（页大小常见 4 KB、8 KB），节点内存储大量键／指针，充分利用页读取的预读和缓存特性，减少 IO。</li>
<li><strong>顺序访问高效</strong>：叶子节点通过链表串联，做范围查询（e.g. WHERE key BETWEEN A AND B）时，只要从第一个叶子开始，顺序遍历链表即可，不必回溯到内节点，再次查找。</li>
<li><strong>并发控制</strong>：在多事务并发访问时，对节点（页）加共享或独占的轻量级锁（latch），确保在结构调整（分裂／合并）期间不会破坏其他事务的读取或写入视图。</li>
<li><strong>安全写入</strong>：配合 <strong>WAL</strong> 或 <strong>双写缓冲</strong> 机制，即使在页分裂或更新过程中发生崩溃，也能借助日志或双写页恢复到一致状态，不会丢失或损坏索引结构。</li>
</ol>
<p><strong>各种 Latch 实现方式的比较</strong></p>
<table>
<thead>
<tr>
<th><strong>实现方式</strong></th>
<th><strong>原理与特点</strong></th>
<th><strong>适用场景</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>Test-and-Set Spinlock</strong></td>
<td>原子地执行一条 test and set 操作：读—改—写一个标志位<br />若已被占用，则不断自旋（busy-wait）直到释放<br />实现简单、开销低（无系统调用）</td>
<td>持有时间极短、线程数少、CPU 空闲时可快速获得锁</td>
</tr>
<tr>
<td><strong>Blocking OS Mutex</strong></td>
<td>调用操作系统的互斥锁原语（如 pthread_mutex）<br />若锁被占用，线程进入睡眠（阻塞），由内核调度唤醒</td>
<td>线程可能长时间等待、锁竞争激烈、无法一直自旋时</td>
</tr>
<tr>
<td><strong>Adaptive Spinlock</strong></td>
<td>结合自旋与阻塞：先自旋若干次（避免短期冲突），超时后再阻塞<br />在多核系统上可减少线程睡眠、上下文切换开销</td>
<td>对临界区长度不稳定、短时冲突多长时冲突时都需兼顾</td>
</tr>
<tr>
<td><strong>Queue-based Spinlock</strong></td>
<td>基于队列（如 MCS、CLH）组织申请线程<br />自旋在各自本地节点上，避免全局自旋总线抖动<br />公平性好，防止饥饿</td>
<td>高并发竞争场景，需要严格 FIFO 公平性</td>
</tr>
<tr>
<td><strong>Reader-Writer Locks</strong></td>
<td>区分读锁（shared）与写锁（exclusive）<br />允许多个读者并行、写者独占<br />可基于自旋或阻塞实现</td>
<td>读多写少场景，如 B+Tree 查找（多数是读），偶尔分裂&#x2F;合并（写）</td>
</tr>
</tbody></table>
<p><strong>Test-and-Set Spinlock 的实现</strong></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">std::atomic_flag latch;</span><br><span class="line">…</span><br><span class="line"><span class="keyword">while</span> (latch.<span class="built_in">test_and_set</span>(...)) &#123;</span><br><span class="line">    <span class="comment">// Yield? Abort? Retry?</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>以上代码中，<code>test_and_set</code> 是一个原子指令：读取锁标志，置 1，并返回旧值。如果返回值表明锁已被占用，线程就在 while 循环中不断自旋重试。</p>
<p><strong>优点</strong></p>
<ul>
<li><strong>极低的延迟</strong>：一次原子 CPU 指令即可完成加／解锁，若临界区非常短，开销远小于一次系统调用。</li>
<li><strong>实现简单</strong>：依赖硬件指令，无需操作系统介入。</li>
</ul>
<p><strong>缺点</strong></p>
<ul>
<li><strong>忙等</strong>：自旋期间 CPU 一直在循环，占用周期，却不做实质性工作。</li>
<li><strong>总线抖动</strong>：多核同时自旋会争抢同一缓存行，导致缓存一致性流量剧增。</li>
<li><strong>可扩展性差</strong>：并发度一高就容易产生严重争用，甚至导致某些线程长期拿不到锁（饥饿）。这种情况在多机器／多核环境下更为明显：TaS 自旋锁会导致耗费大量总线带宽，甚至在远程节点上更容易饿死。</li>
</ul>
<h1 id="Latch-Coupling"><a href="#Latch-Coupling" class="headerlink" title="Latch Coupling"></a>Latch Coupling</h1><p>在遍历 B+Tree（从根到叶）过程中，始终维持一条“锁链”：</p>
<ol>
<li>加锁当前节点；</li>
<li>在确定要访问的子节点加锁后，再释放父节点的锁。</li>
</ol>
<p>保证任何时刻，对正在操作路径上的节点都有锁保护，避免结构变化（分裂&#x2F;合并）导致的不一致访问。</p>
<p>思考：</p>
<p>为什么要锁父节点？</p>
<p>避免并发操作导致子节点增删时引发的父节点分裂或合并，从而避免多线程访问到不一致的数据。</p>
<blockquote>
<p>[!NOTE]</p>
<p><strong>何时可以释放父节点锁？</strong></p>
<p>当子节点被判定为“安全”（safe）时，父节点锁可提前释放：</p>
<ul>
<li><strong>插入场景</strong>：子节点没有达到最大容量，插入后不会触发分裂；</li>
<li><strong>删除场景</strong>：子节点删除后依旧保持超过一半的填充度，不会触发合并。</li>
</ul>
</blockquote>
<p><strong>优点</strong></p>
<ul>
<li><strong>锁粒度细化</strong>：仅对正在操作的节点及其立即父节点加锁，其他分支无关节点不受影响</li>
<li><strong>提高并发度</strong>：减少持锁时间，其他事务可以更快地访问不同的子树</li>
</ul>
<p><strong>缺点</strong></p>
<ul>
<li><strong>频繁的锁操作</strong>：每向下一层移动，都要做一次 lock(child) + unlock(parent)，系统调用和内核开销不可忽视</li>
<li><strong>层次深度敏感</strong>：树越深，锁–解锁次数越多；在高并发或极深树结构中，延迟和 CPU 开销上升明显</li>
</ul>
<p>Read Path 中：</p>
<ol>
<li>在根节点加读锁；</li>
<li>定位到要访问的下层子节点；</li>
<li>对该子节点加读锁；</li>
<li>释放其父节点的读锁；</li>
<li>重复 2–4，直到到达叶节点并完成读取。</li>
</ol>
<p>Write Path 中：</p>
<ol>
<li>在根节点加写锁；</li>
<li>定位到要访问的下层子节点；</li>
<li>对子节点加写锁；</li>
<li>检查子节点是否安全：<ul>
<li><strong>插入时</strong>：子节点未满（不会触发分裂）；</li>
<li><strong>删除时</strong>：删除后填充度仍 &gt;&#x3D; 50%（不会触发合并）；</li>
</ul>
</li>
<li>如果安全，释放所有祖先节点的写锁，仅保留子节点锁往下继续；</li>
<li>若不安全，则继续在上层保留必要锁，直至完成分裂&#x2F;合并，再逐级释放。</li>
</ol>
<p>示例 1：搜索数据 23（示例中 B+ 树变化的顺序是从上到下，从左到右）</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_oltp_indexing_lock_coup_search.drawio.png" alt="img"></p>
<p>示例 2：删除数据 44</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_oltp_indexing_lock_coup_delete.drawio.png" alt="img"></p>
<p>示例 3：插入 40</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_oltp_indexing_lock_coup_insert.drawio.png" alt="img"></p>
<h1 id="重要观察"><a href="#重要观察" class="headerlink" title="重要观察"></a>重要观察</h1><p>传统的 B+Tree 是为慢磁盘／页式存储优化的，而在纯内存数据库中，我们可以选用更 CPU 缓存友好、指针开销更小、分支因子更灵活的数据结构。比如：</p>
<p><strong>Adaptive Radix Tree (ART)</strong></p>
<p>一种基于 Radix-Trie（前缀树）的变体，根据子节点数动态压缩节点类型（4／16／48／256 分支），兼顾空间与速度。</p>
<p><strong>优势</strong>：</p>
<ul>
<li>存储密度极高；按 key 前缀快速定位，指针跳转少</li>
<li>支持前缀查询，范围查询也只需一次遍历即可顺序扫描叶子</li>
<li>插入／删除时节点扩张／收缩成本低</li>
</ul>
<p>适用于对内存利用率敏感、需要高吞吐点查和范围查的 OLTP 场景。</p>
<p><strong>Bw-Tree（Latch-Free）</strong></p>
<p>微软提出的无锁 B+Tree，核心是 delta record 日志链 + 原子 CAS 更新，所有结构修改都追加写入 LSN，读者通过多版本链合并视图。</p>
<p><strong>优势</strong>：</p>
<ul>
<li>无全局锁或页级 latch，天然适合超高并发写入；</li>
<li>写热点变为对内存日志的追加，分裂／合并操作也只是更新 delta。</li>
</ul>
<p>适用于写密集型、高并发事务环境。</p>
<p><strong>Masstree</strong></p>
<p>结合了 B+Tree 与 Trie 的优点，对多列复合键可层级拆分，且各层使用紧凑数组存储。</p>
<p><strong>优势</strong>：</p>
<ul>
<li>支持多列复合索引，Trie 能快速跳过公共前缀</li>
<li>使用 per-node lock-coupling + optimistic read 提升并发性能</li>
</ul>
<p>适用于典型 KV 或多字段查找场景。</p>
<p>之后的内容会重点介绍 Bw-Tree。</p>
<h1 id="Bw-Tree"><a href="#Bw-Tree" class="headerlink" title="Bw-Tree"></a>Bw-Tree</h1><p>BW-Tree 是微软 Hekaton 内存数据库中用于 OLTP 场景的无锁索引结构。它通过增量记录（delta record）和映射表（mapping table）两大核心机制，实现了对 B+Tree 操作的完全无锁化。</p>
<p><strong>Delta 机制：无就地更新</strong></p>
<ul>
<li><p><strong>增量链</strong>：每次对某个页的插入、删除、分裂等修改，都不是直接改写页本身，而是在映射表条目后面追加一个小的 delta 节点，记录本次的修改操作。</p>
</li>
<li><p><strong>好处</strong></p>
<ul>
<li><strong>无锁安全</strong>：对页的修改仅是往链尾追加，不会破坏其他读者正在访问的旧版本数据。</li>
<li><strong>减少缓存抖动</strong>：不改写原页，旧页仍然稳定驻留在 CPU 缓存中，新 delta 追加只影响少量缓存行。</li>
</ul>
</li>
<li><p><strong>读取时合并视图</strong></p>
<p>读者先通过映射表定位基础页（base page），然后顺着 delta 链向前合并各个 change record，最终得到当前一致性视图。</p>
</li>
</ul>
<p><strong>Mapping Table：页指针的原子替换</strong></p>
<ul>
<li><strong>映射表结构</strong>：类似于页 ID → 页物理地址（或页链表头节点）的一个数组／哈希表。每个索引页（或叶子页）在映射表中有一条定长条目。</li>
<li><strong>CAS 原子切换</strong><ul>
<li>当需要分裂一个 leaf page 或合并多个 delta 到一个新的 consolidated page 时，只需在映射表中对该页条目执行一次 <strong>Compare-And-Swap</strong> 操作。</li>
<li>线程安全、无锁：所有并发读者只要先读一次映射表，就能看到分裂前或分裂后的整块页内容；中间状态对读者透明。</li>
</ul>
</li>
</ul>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_oltp_indexing_bwtree_structure.drawio.png" alt="img"></p>
<p>上图中，绿色的虚线箭头是逻辑指针，黑色的实线箭头是物理指针。</p>
<p>物理指针的用途：</p>
<ul>
<li>在直接访问数据的场景中使用，提供快速访问能力。</li>
<li>通常用于叶子节点内部或数据页的局部操作。</li>
</ul>
<p>逻辑指针的用途：</p>
<ul>
<li>在节点之间（特别是父子节点之间）的连接中使用，提供动态调整的灵活性。</li>
<li>逻辑指针指向的是映射表中的条目，映射表将逻辑指针解析为实际的物理位置。</li>
<li>节点分裂或合并时，映射表更新物理位置，而逻辑指针保持不变。</li>
</ul>
<p>思考：</p>
<p>为什么节点之间用 logical pointer 连起来？</p>
<p>在 BW-Tree 中，当某个子节点发生分裂或合并等变化时，只需要在映射表中更新该节点的 Page ID 对应的物理地址，一定程度上和父节点进行解耦。</p>
<p>父节点里存的只是 Page ID（逻辑指针），因此父节点无需做物理修改或大范围加锁，这样极大提升了并发能力和更新效率。</p>
<p><strong>更新与搜索（Delta Updates &amp; Search）</strong></p>
<p>每次对页的更新操作都会产生一个新的 delta 节点，该节点通过物理指针指向基页（base page），之后通过 CAS 操作将原来从映射表指向基页的物理指针指向新的 delta 节点。</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_oltp_indexing_update_cas.drawio.png" alt="img"></p>
<p>思考：</p>
<p>为什么 delta 节点使用 physical pointer 指向基页？</p>
<p><strong>物理指针一旦写入即不可变</strong>，读者沿着物理地址可以无歧义地遍历历史记录节点，即便映射表后续对该 Page ID 做了 CAS 更新也不影响已追加的 Delta 链的正确合并和回放。而逻辑指针（Page ID）会随映射表更新而变化，若 Delta 节点也存逻辑指针，就无法区分应访问旧页还是新页；物理指针则始终指向原有的内存位置，确保版本链的完整性和一致性。</p>
<p>并发更新是怎么进行的？</p>
<p>秉持着先来先服务的理念，后到的操作则会被驳回或者重试，从而避免两个 delta 节点指向同一个下层节点。</p>
<p>下图中，我们假设 <code>DELETE K8</code> 先来，那么 <code>INSERT K6</code> 就会被驳回或重试。</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_oltp_indexing_content_update.drawio.png" alt="img"></p>
<blockquote>
<p>[!NOTE]</p>
<p>在并发更新场景下，上图的竞争中通常会加锁。</p>
</blockquote>
<p>之后如果要搜索的话，流程如下：</p>
<ol>
<li>从根到叶，像常规 B+Tree 那样遍历；</li>
<li>定位到叶子页后，检查映射表指向；</li>
<li>如果映射表指向 Delta 链：<ol>
<li>自上而下遍历 Delta 链，对每个 Record（Insert&#x2F;Delete）检查：<ol>
<li>若 Record 的键等于查询键，则：<ol>
<li>如果是 <strong>Delete</strong> 类型，说明该键已被删除，搜索可提前返回不存在；</li>
<li>如果是 <strong>Insert</strong> 类型，说明该键最新就在此处，立即返回对应的值；</li>
</ol>
</li>
</ol>
</li>
<li>如果遍历完整个 Delta 链都没命中，再回退到 Base Page；</li>
</ol>
</li>
<li>否则，或 Delta 链未命中：<ol>
<li><strong>对 Base Page 执行二分查找</strong>（就像普通 B+Tree 的叶页内搜索那样）；</li>
<li>若在 Base Page 中找到该键且未被后续的 Delete 覆盖，即返回对应记录；否则返回不存在。</li>
</ol>
</li>
</ol>
<p><strong>合并与清理（Consolidation&#x2F;Garbage Collection）</strong></p>
<ul>
<li>随着 delta 不断追加，链条会变长，读者合并成本上升。</li>
<li><strong>后台合并线程</strong>会定期：<ol>
<li>扫描映射表，选取 delta 链过长或更新频繁的页；</li>
<li>将所有 delta 应用到一个新建的基础页，生成新的 base page；</li>
<li>用 CAS 原子地在映射表中替换旧页指针；</li>
<li>将旧的 base page + delta 链标记为可回收。</li>
</ol>
</li>
</ul>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_oltp_indexing_consolidation.drawio.png" alt="img"></p>
<p>合并完成后，我们会把 old page 2 放入一个池子中，便于之后的复用。</p>
<p>思考：</p>
<p>在合并的过程中，如果执行了大量的操作，那是怎么处理的？</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_oltp_indexing_consolidate_1.drawio.png" alt="img"></p>
<p>上图中，合并期间加入的 delta 节点会一开始指向 INSERT K5，待合并完成后这些节点会指向 new page 2。</p>
<p><strong>结构变更</strong></p>
<p><strong>Split Delta Record</strong></p>
<p>表示将基页中一部分键范围（key range）移动到了另一个页面，并使用逻辑指针指向新的页面。</p>
<p><strong>Separator Delta Record</strong></p>
<p>提供一种快捷路径，用于告诉父节点：应该在哪个键范围中查找已经被拆分出来的新页面。</p>
<p>以上两个组件会带来如下优势：</p>
<ol>
<li><strong>位置变化无需修改 BW-Tree 索引结构</strong>：一旦某个页面的位置发生变化，只需修改 mapping table 即可，无需更改 BW-Tree 上层结构中的索引节点。这是因为 BW-Tree 的索引项记录的是页面的 page id，而非物理地址。这样避免了传统 B-Tree 中频繁重建索引的开销。</li>
<li><strong>页面大小灵活，提升空间与性能利用率</strong>：mapping table 中的 page 大小不必固定为如 8KB 这类块对齐的大小。可以根据业务需要进行更细粒度的划分或合并，从而减少因空间浪费或合并而产生的额外写放大。</li>
<li><strong>解耦内存与存储结构，便于系统各层独立优化</strong>：BW-Tree 通过逻辑页和 mapping table 的机制，将存储管理与内存结构解耦。这样使得存储层可以专注于持久化效率优化，而内存层则可专注于读写性能与并发控制，彼此互不干扰，从而实现系统整体性能提升。</li>
</ol>
<p>假设 BW-Tree 中的 page 3 发生分裂，具体分裂步骤如下：</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_oltp_indexing_bw_SMO.drawio.png" alt="img"></p>
<p>需要注意，一个 split delta record 就对应要创建一个 separator delta record，多个 separator delta record 也会形成跟之前一样的 delta record 链。</p>
<p>在以上的节点分裂过程中，无需加锁，而且不论何时都可以访问到对应的节点，不会出现空指针异常。</p>
<p>思考：</p>
<p>为什么 split delta 节点指向 page 3 的是物理指针，而不是逻辑指针呢？</p>
<p>跟之前的 delta record 通过物理指针指向基页的原理是一样的。</p>
<blockquote>
<p>[!NOTE]</p>
<p>Split 节点同时使用物理和逻辑指针，既可以保证老的读操作（可能还在访问旧的物理页 3）不受影响，又能让新的读写操作访问到新的页面 5 上去。</p>
</blockquote>
<p><strong>关键观察</strong></p>
<p>在每一层节点上进行查找时，若缓存中没有相应数据，就会发生 <strong>cache miss</strong>，导致额外的内存访问延迟，尤其是当树高较大时，每层都有潜在的 miss。</p>
<p>传统设计中，内部节点和叶节点大多存于随机内存地址，查找时经常会产生多次 cache miss。</p>
<p><strong>如何减少 Cache Miss？</strong></p>
<ol>
<li><p><strong>节点预取</strong></p>
<ul>
<li><p>硬件级预取：CPU 的硬件预取器可以根据访问模式（如 stride 或 stream）提前将相邻缓存行加载到缓存中。</p>
</li>
<li><p>软件或路径预取：在树的搜索路径上提前发起预取，例如先加载 root，再预测加载下层 child 块 。</p>
</li>
</ul>
</li>
<li><p><strong>缓存友好型节点结构</strong></p>
<ul>
<li>调整节点大小至多个缓存行，让一个节点的多个缓存行能并行预取，减少单节点内部的 miss 数量。</li>
</ul>
</li>
<li><p><strong>增加树扇出，降低树高</strong></p>
<ul>
<li>增大节点容量（存更多键&#x2F;指针）可以减少树的高度，也就减少访问叶子需访问的层数，从而降低总体 cache miss 数量 。</li>
</ul>
</li>
<li><p><strong>避免路径中的重复访问</strong></p>
<ul>
<li>可记录较热的路径节点，实现快速访问。</li>
</ul>
</li>
<li><p><strong>批量预加载</strong></p>
<ul>
<li>对于范围扫描或批量插入，可以一次性预加载整颗叶子区域，从 root 之后连续加载所有相关叶子节点，提高顺序访问的 cache 命中率。</li>
</ul>
</li>
</ol>
]]></content>
      <categories>
        <category>高级数据存储</category>
      </categories>
  </entry>
  <entry>
    <title>触发器</title>
    <url>/undefined/MySQL/2024/10/19/MySQL/%E8%A7%A6%E5%8F%91%E5%99%A8/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><p>在 insert &#x2F; update &#x2F; delete 之前或之后，触发并执行触发器中定义的 SQL 语句集合。</p>
<p>确保数据完整性，日志记录，数据校验等操作。</p>
<p>使用别名 OLD 和 NEW 来引用触发器中发生变化的记录内容。</p>
<table>
<thead>
<tr>
<th>触发器类型</th>
<th>NEW 和 OLD</th>
</tr>
</thead>
<tbody><tr>
<td>Insert 型</td>
<td>NEW 表示将要或已经新增的数据</td>
</tr>
<tr>
<td>Update 型</td>
<td>OLD 表示修改之前的数据，NEW 表示将要或已经修改后的数据</td>
</tr>
<tr>
<td>Delete 型</td>
<td>OLD 表示将要或已经删除的数据</td>
</tr>
</tbody></table>
<p>行级触发器：触发次数等于影响的行数。</p>
<p>语句级触发器：不论影响的行数，只触发一次。</p>
<p>MySQL触发器只支持<strong>行级触发</strong>，不支持语句级触发。</p>
<p>创建</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">trigger</span> trigger_name</span><br><span class="line">before <span class="operator">/</span> after <span class="keyword">insert</span> <span class="operator">/</span> <span class="keyword">update</span> <span class="operator">/</span> <span class="keyword">delete</span></span><br><span class="line"><span class="keyword">on</span> table_name <span class="keyword">for</span> <span class="keyword">each</span> <span class="type">row</span></span><br><span class="line"><span class="keyword">begin</span></span><br><span class="line">	<span class="keyword">SQL</span> 语句;</span><br><span class="line"><span class="keyword">end</span>;</span><br></pre></td></tr></table></figure>

<p>查看：<code>show triggers;</code></p>
<p>删除：<code>drop trigger [schema_name]trigger_name;</code></p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>锁</title>
    <url>/undefined/MySQL/2024/11/08/MySQL/%E9%94%81/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><p>如何在高并发访问下，既充分利用数据库的并发能力，又保证每个用户对数据的读写操作保持一致性呢？为此，数据库系统引入了锁（locking）机制，这也是它与文件系统的一个关键区别。</p>
<p>而且这里需要澄清，只有当系统真正需要更高锁粒度时，行级锁才会出现开销，而 InnoDB 本身并不依赖锁升级机制，因为单个锁与多个锁的成本是相当的。也就是说，在不需要非常高并发写冲突控制的情况下，InnoDB 不会主动为每一行都添加行锁；只有当真的有并发冲突需要保护同一行时，才会产生行级锁对应的数据结构开销。</p>
<p>锁是计算机中协调多个进程或线程并发访问某一资源的机制。</p>
<p>在MySQL中，事务中的锁（行锁、表锁等）会一直保留到事务结束（COMMIT 或 ROLLBACK）。</p>
<h2 id="lock-与-latch"><a href="#lock-与-latch" class="headerlink" title="lock 与 latch"></a>lock 与 latch</h2><ol>
<li>Latch（闩锁）<ul>
<li>也称为轻量级锁或临界区锁，主要用于保护数据库内部的临时数据结构与内存资源，确保多个线程在访问或修改同一份临界资源时不会产生并发安全问题。</li>
<li>必须保证其持有时间极短：一旦线程完成对临界资源的访问，必须立即释放 latch，否则会严重影响整个系统的并发性能。</li>
<li>在 InnoDB 存储引擎内部，latch 进一步分为两类：<ul>
<li>Mutex（互斥量）：最简单的二元互斥锁，用于保护对某个共享资源的独占访问。</li>
<li>RWLock（读写锁）：允许多个读线程同时进入临界区，但写线程独占，保证读写操作对同一资源的并发正确性。</li>
</ul>
</li>
<li>无死锁检测：由于 latch 的持有时间极短，InnoDB 不会对其进行死锁检测。一旦某线程在短时间内未能获取到 latch，往往是因为有其他线程暂时占用，系统会进行短暂等待或重试，直到拿到 latch 才继续执行。</li>
</ul>
</li>
<li>Lock（事务锁）<ul>
<li>针对数据库对象（如表、页、行）而设计，由事务进行获取和释放：<ul>
<li>加锁操作（例如加行锁、页锁）只会在事务提交（COMMIT）或回滚（ROLLBACK）时才被释放（不同的隔离级别下，锁的释放时机可能会有所区别）。</li>
<li>Lock 的持有时间较长（往往跨越整个事务执行过程），因此对并发冲突的检测和处理必须更完整。</li>
</ul>
</li>
<li>支持死锁检测与处理：当多个事务彼此等待对方持有的锁而陷入循环等待时，InnoDB 会自动检测死锁并选择性地回滚某个事务以打破循环，从而保证系统不会长期阻塞。</li>
<li>锁级别包括：意向锁（Intention Lock）、行级锁（Record Lock）、间隙锁（Gap Lock）、次序锁（Next-Key Lock）等，它们共同配合以实现更高效、更细粒度的并发控制。</li>
</ul>
</li>
</ol>
<h2 id="锁问题"><a href="#锁问题" class="headerlink" title="锁问题"></a>锁问题</h2><p>通过锁定机制可以实现事务的隔离性要求，使得事务可以并发地工作。锁提高了并发，但是却会带来潜在的问题。不过好在因为事务隔离性的要求，锁只会带来三种问题，如果可以防止这三种情况的发生，那将不会产生并发异常。</p>
<h3 id="脏读"><a href="#脏读" class="headerlink" title="脏读"></a>脏读</h3><p>在理解脏读（Dirty Read）之前，需要理解脏数据的概念。但是脏数据和之前所介绍的脏页完全是两种不同的概念。脏页指的是在缓冲池中已经被修改的页，但是还没有刷新到磁盘中，即数据库实例内存中的页和磁盘中的页的数据是不一致的，当然在刷新到磁盘之前，日志也已经被写入到了重做日志文件中。而所谓脏数据是指事务对缓冲池中行记录的修改，并且还没有被提交（commit）。</p>
<p>对于脏页的读取，是非常正常的。脏页是因为数据库实例内存和磁盘的异步造成的，这并不影响数据的一致性（或者说两者最终会达到一致，即当脏页都刷新到磁盘）。并且因为脏页的刷新是异步的，不影响数据库的可用性，因此可以带来性能的提高。</p>
<p>脏数据却截然不同，脏数据是指未提交的数据，如果读到脏数据，即一个事务可以读取到另外一个事务中未提交的数据，则显然违反了数据库的隔离性。</p>
<p>脏读指的就是在不同的事务下，当前事务可以读到另外事务未提交的数据，简单来说就是可以读到脏数据。</p>
<p>脏读发生的条件是需要事务的隔离级别为 READ UNCOMMITTED，而目前绝大部分的数据库都会至少设置成 READ COMMITTED。InnoDB 存储引擎默认的事务隔离级别为 REPEATABLE READ，Microsoft SQL Server 数据库为 READ COMMITTED，Oracle 数据库同样也是 READ COMMITTED。</p>
<blockquote>
<p>[!NOTE]</p>
<p>关于 InnoDB 默认采用 RR 隔离级别的原因可参考：<a href="/MySQL/2024/10/28/MySQL/%E6%96%87%E4%BB%B6/#why_rr">为什么 InnoDB 默认采用 RR 隔离级别？</a></p>
</blockquote>
<p>脏读隔离看似毫无用处，但在一些比较特殊的情况下还是可以将事务的隔离级别设置为 READ UNCOMMITTED。例如 replication 环境中的 slave 节点，并且在该 slave 上的查询并不需要特别精确的返回值。</p>
<h3 id="不可重复读"><a href="#不可重复读" class="headerlink" title="不可重复读"></a>不可重复读</h3><p>不可重复读指在同一个事务（会话）内多次读取同一数据集时，由于另一个事务对该数据集进行了 DML 修改（插入、更新或删除），导致第一次和第二次读取的结果不一致。换句话说，同一事务中对同一行数据执行两次 SELECT 查询，若中间有其他事务提交了修改，使得这两次查询得到不同的数据，就发生了不可重复读。</p>
<p>大多数数据库（如 Oracle、Microsoft SQL Server、PostgreSQL 等）在默认隔离级别为 READ COMMITTED 时，允许发生不可重复读，因为读取的是已提交数据，一般被认为可接受，不会引起严重一致性问题。</p>
<p>InnoDB 存储引擎默认隔离级别是 REPEATABLE READ，在该级别下使用 Next-Key Locking（锁定索引记录本身以及其前一个 gap 范围）来防止不可重复读和幻读。</p>
<ul>
<li>当事务第一次扫描索引行时，会对这条数据及其相邻的 gap 区间加锁，阻止其他事务在该范围内插入或修改行。</li>
<li>因此，同一事务的后续读取始终只能看到最初加锁时的“快照”数据，不会因他人提交修改而改变读取结果。</li>
</ul>
<p>若将隔离级别设置为 READ COMMITTED，InnoDB 只对具体记录加行锁（Record Lock），不再对 gap 进行加锁，因此允许在两次读取之间对行或 gap 进行插入&#x2F;更新，从而出现不可重复读。</p>
<h3 id="丢失更新"><a href="#丢失更新" class="headerlink" title="丢失更新"></a>丢失更新</h3><p>丢失更新指的是：当两个事务（或两个并发操作）都希望修改同一行数据时，后提交的那个更新“覆盖”了先提交的更新，导致先前的修改最终没有被保存，从而出现数据不一致。例如：</p>
<ol>
<li>事务 T1 将行记录 r 更新为 v1，但是事务 T1 并未提交。</li>
<li>与此同时，事务 T2 将行记录 r 更新为 v2，事务 T2 未提交。</li>
<li>事务 T1 提交。</li>
<li>事务 T2 提交。</li>
</ol>
<p>但是，在当前数据库的任何隔离级别下，都不会导致数据库理论意义上的丢失更新问题。这是因为，即使是 READ UNCOMMITTED 的事务隔离级别，对于行的 DML 操作，需要对行或其他粗粒度级别的对象加锁。因此在上述步骤 2) 中，事务 T2 并不能对行记录 r 进行更新操作，其会被阻塞，直到事务 T1 提交。</p>
<p>虽然数据库能阻止丢失更新问题的产生，但是在生产应用中还有另一个逻辑意义的丢失更新问题，而导致该问题的并不是因为数据库本身的问题。实际上，在所有多用户计算机系统环境下都可能产生这个问题。简单地说来，出现下面的情况时，就会发生丢失更新：</p>
<ol>
<li>事务 T1 查询一行数据，放入本地内存，并显示给一个终端用户 User1。</li>
<li>事务 T2 也查询该行数据，并将取得的数据显示给终端用户 User2。</li>
<li>User1 修改该行记录，更新数据库并提交。</li>
<li>User2 修改该行记录，更新数据库并提交。</li>
</ol>
<p>显然，这个过程中用户 User1 的修改更新操作丢失了，而这可能会导致一个恐怖的结果。设想银行发生丢失更新现象，例如一个用户账号中有 10000 元人民币，他用两个网上银行的客户端分别进行转账操作。第一次转账 9000 人民币，因为网络和数据的关系，这时需要等待。但是这时用户操作另一个网上银行客户端，转账 1 元，如果最终两个转账都成功了，用户的帐号余额是 9999 人民币，第一次转的 9000 人民币并没有得到更新，但是在转账的另一个账户却会收到这 9000 元，这导致的结果就是钱变多，而账不平。</p>
<p>这里需要澄清的是，以上银行问题的发生和数据库无关，而是业务逻辑的问题。</p>
<p>也就是说，如果我们直接写 <code>UPDATE account SET cash = cash - 9000 WHERE user = pUser;</code>，那么 InnoDB 会对满足 <code>user = pUser</code> 的那一行加 X 锁，保证同时不会有别的事务也在修改它。但在很多业务里，我们并不能“直接更新”——往往要先读余额（SELECT），做业务判断（比如余额是否足够、是否与外部系统交互等），然后再走 UPDATE。<strong>在你只使用普通的</strong> <strong>SELECT …</strong> <strong>而没有加锁（FOR UPDATE）时，数据库不会对这条记录加行级排他锁</strong>，这时别的事务就可能同时也读到同一个旧余额，然后各自计算完毕后分别执行 UPDATE，造成后面那笔更新把前面那笔更新覆盖——这才是真正的丢失更新。</p>
<p>要避免丢失更新发生，需要让事务在这种情况下的操作变成串行化，而不是并行的操作。即在上述四个步骤的 1) 中，对用户读取的记录加上一个排他 X 锁。同样，在步骤 2) 的操作过程中，用户同样也需要加一个排他 X 锁。通过这种方式，步骤 2) 就必须等待 1) 和 3) 完成，最后完成步骤 4)。</p>
<h2 id="InnoDB-存储引擎中的锁"><a href="#InnoDB-存储引擎中的锁" class="headerlink" title="InnoDB 存储引擎中的锁"></a>InnoDB 存储引擎中的锁</h2><h3 id="锁的类型"><a href="#锁的类型" class="headerlink" title="锁的类型"></a>锁的类型</h3><p><strong>按照兼容性可分为：</strong></p>
<ul>
<li>共享锁（S Lock），允许事务读一行数据。</li>
<li>排他锁（X Lock），允许事务删除或更新一行数据。</li>
</ul>
<p>如果一个事务 T1 已经获得了 r 行的共享锁，那么另外的事务 T2 可以立即获得 r 行的共享锁，因为读取并没有改变 r 行的数据，称这种情况为锁兼容（Lock Compatible）。但若有其他的事务 T3 想获得 r 行的排他锁，则其必须等待事务 T1、T2 释放 r 行上的共享锁──这种情况称为锁不兼容。</p>
<p>下表显示了共享锁和排他锁的兼容性：</p>
<table>
<thead>
<tr>
<th></th>
<th>S</th>
<th>X</th>
</tr>
</thead>
<tbody><tr>
<td>S</td>
<td>兼容</td>
<td>冲突</td>
</tr>
<tr>
<td>X</td>
<td>冲突</td>
<td>冲突</td>
</tr>
</tbody></table>
<p>此外，InnoDB 存储引擎支持多粒度锁定，这种锁定允许事务在行级上的锁和表级上的锁同时存在。为了支持在不同粒度上进行加锁操作，InnoDB 存储引擎支持一种额外的锁方式，称之为意向锁（Intention Lock）。意向锁是将锁定的对象分为多层次，意向锁意味着事务希望在更细粒度（fine granularity）上进行加锁。</p>
<p>若将上锁的对象看成一棵树，那么对最下层的对象上锁，也就是对最细粒度的对象进行上锁，那么首先需要对粗粒度的对象上锁。如下图，如果需要对页上的记录 r 进行 X 锁，那么首先需要对数据库 A、表、页上意向锁 IX，最后对记录 r 上 X 锁。若其中任何一个部分导致等待，那么该操作需要等待粗粒度锁的完成。比如说，在对记录 r 加 X 锁之前，已经有事务对该表进行了 S 表锁，那么表上已存在 S 锁，之后事务需要对记录 r 在表上加上 IX，由于不兼容，所以该事务需要等待表锁操作的完成。</p>
<p>InnoDB 存储引擎支持意向锁的设计比较简练，其意向锁即为表级别的锁。设计目的主要是为了在一个事务中揭示下一行将被请求的锁类型。其支持两种意向锁：</p>
<ol>
<li>意向共享锁（IS Lock）：事务想要获得一张表中某几行的共享锁；</li>
<li>意向排他锁（IX Lock）：事务想要获得一张表中某几行的排他锁。</li>
</ol>
<p>由于 InnoDB 存储引擎支持的是行级别的锁，因此意向锁其实不会阻塞除全表扫描以外的任何请求。下表展示了表级意向锁与行级锁的兼容性：</p>
<table>
<thead>
<tr>
<th></th>
<th>IS</th>
<th>IX</th>
<th>S</th>
<th>X</th>
</tr>
</thead>
<tbody><tr>
<td><strong>IS</strong></td>
<td>兼容</td>
<td>兼容</td>
<td>兼容</td>
<td>不兼容</td>
</tr>
<tr>
<td><strong>IX</strong></td>
<td>兼容</td>
<td>兼容</td>
<td>不兼容</td>
<td>不兼容</td>
</tr>
<tr>
<td><strong>S</strong></td>
<td>兼容</td>
<td>不兼容</td>
<td>兼容</td>
<td>不兼容</td>
</tr>
<tr>
<td><strong>X</strong></td>
<td>不兼容</td>
<td>不兼容</td>
<td>不兼容</td>
<td>不兼容</td>
</tr>
</tbody></table>
<p>在 InnoDB 1.0 版本之前，用户只能通过命令 <code>SHOW FULL PROCESSLIST</code>、<code>SHOW ENGINE INNODB STATUS</code> 等来查看当前数据库中锁的请求，然后再判断事务锁的情况。</p>
<p>从 InnoDB 1.0 开始，在 <code>INFORMATION_SCHEMA</code> 架构下添加了表 <code>INNODB_TRX</code>、<code>INNODB_LOCKS</code>、<code>INNODB_LOCK_WAITS</code>。通过这三张表，用户可以更简单地监控当前事务并分析可能存在的锁问题。</p>
<p>下表是对于表 INNODB_TRX 的定义：</p>
<table>
<thead>
<tr>
<th>字段名</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>trx_id</code></td>
<td>InnoDB 存储引擎内部唯一的事务 ID</td>
</tr>
<tr>
<td><code>trx_state</code></td>
<td>当前事务的状态</td>
</tr>
<tr>
<td><code>trx_started</code></td>
<td>事务的开始时间</td>
</tr>
<tr>
<td><code>trx_requested_lock_id</code></td>
<td>等待事务的锁 ID。如 <code>trx_state</code> 的状态为 <code>LOCK WAIT</code>，那么该值代表当前的事务等待之前事务占用锁资源的 ID。若 <code>trx_state</code> 不是 <code>LOCK WAIT</code>，则该值为 <code>NULL</code>。</td>
</tr>
<tr>
<td><code>trx_wait_started</code></td>
<td>事务等待开始的时间</td>
</tr>
<tr>
<td><code>trx_weight</code></td>
<td>事务的权重，反映了一个事务修改和锁住的行数。在 InnoDB 存储引擎中，当发生死锁需要回滚时，InnoDB 存储引擎会选择该值最小的进行回滚。</td>
</tr>
<tr>
<td><code>trx_mysql_thread_id</code></td>
<td>MySQL 中的线程 ID，<code>SHOW PROCESSLIST</code> 显示的结果</td>
</tr>
<tr>
<td><code>trx_query</code></td>
<td>事务运行的 SQL 语句</td>
</tr>
</tbody></table>
<p>下表是对于 INNODB_LOCKS 的定义：</p>
<table>
<thead>
<tr>
<th>字段名</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>lock_id</code></td>
<td>锁的 ID</td>
</tr>
<tr>
<td><code>lock_trx_id</code></td>
<td>事务 ID</td>
</tr>
<tr>
<td><code>lock_mode</code></td>
<td>锁的模式</td>
</tr>
<tr>
<td><code>lock_type</code></td>
<td>锁的类型（表锁还是行锁）</td>
</tr>
<tr>
<td><code>lock_table</code></td>
<td>要加锁的表</td>
</tr>
<tr>
<td><code>lock_index</code></td>
<td>锁定的索引</td>
</tr>
<tr>
<td><code>lock_space</code></td>
<td>锁对象所在的 space id</td>
</tr>
<tr>
<td><code>lock_page</code></td>
<td>事务锁定页的数量；若是表锁，则该值为 <code>NULL</code></td>
</tr>
<tr>
<td><code>lock_rec</code></td>
<td>事务锁定行的数量；若是表锁，则该值为 <code>NULL</code></td>
</tr>
<tr>
<td><code>lock_data</code></td>
<td>事务锁定记录的主键值；若是表锁，则该值为 <code>NULL</code></td>
</tr>
</tbody></table>
<p>另外需要特别注意的是，在查看 <code>INNODB_LOCKS</code> 的内容时，<code>lock_data</code> 这个值并非是可信的值。例如当用户运行一个范围查找时， <code>lock_data</code> 可能只返回第一行的主键值。与此同时，如果当前资源被锁住了，若锁住的页因为 InnoDB 存储引擎缓冲池的容量，导致该页从缓冲池中被刷出，则在查看 <code>INNODB_LOCKS</code> 表时，该值同样会显示为 NULL，即 InnoDB 存储引擎不会从磁盘进行再一次的查找。</p>
<p>在通过表 <code>INNODB_LOCKS</code> 查看了每张表上锁的情况后，用户就可以来判断由此引发的等待情况了。当事务较小时，用户就可以人为地、直观地进行判断。但是当事务量非常大，其中锁和等待也时常发生，这个时候就不会这么容易判断。但是通过表 <code>INNODB_LOCK_WAITS</code> ，可以很直观地反映当前事务的等待。表 <code>INNODB_LOCK_WAITS</code> 的结构如下表。</p>
<table>
<thead>
<tr>
<th>字段</th>
<th>说明</th>
<th>字段</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>requesting_trx_id</code></td>
<td>申请锁资源的事务 ID</td>
<td><code>blocking_trx_id</code></td>
<td>阻塞的事务 ID</td>
</tr>
<tr>
<td><code>requesting_lock_id</code></td>
<td>申请的锁的 ID</td>
<td><code>blocking_lock_id</code></td>
<td>阻塞的锁的 ID</td>
</tr>
</tbody></table>
<p>总的来说，用户可以结合 <code>INNODB_TRX</code>、<code>INNODB_LOCKS</code>、<code>INNODB_LOCK_WAITS</code> 三张表进一步查询。比如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">  r.trx_id      <span class="keyword">AS</span> waiting_trx_id,</span><br><span class="line">  r.trx_mysql_thread_id <span class="keyword">AS</span> waiting_thread,</span><br><span class="line">  r.trx_query     <span class="keyword">AS</span> waiting_query,</span><br><span class="line">  b.trx_id      <span class="keyword">AS</span> blocking_trx_id,</span><br><span class="line">  b.trx_mysql_thread_id <span class="keyword">AS</span> blocking_thread,</span><br><span class="line">  b.trx_query     <span class="keyword">AS</span> blocking_query</span><br><span class="line"><span class="keyword">FROM</span> information_schema.innodb_lock_waits w</span><br><span class="line"><span class="keyword">INNER</span> <span class="keyword">JOIN</span> information_schema.innodb_trx b</span><br><span class="line">  <span class="keyword">ON</span> b.trx_id <span class="operator">=</span> w.blocking_trx_id</span><br><span class="line"><span class="keyword">INNER</span> <span class="keyword">JOIN</span> information_schema.innodb_trx r</span><br><span class="line">  <span class="keyword">ON</span> r.trx_id <span class="operator">=</span> w.requesting_trx_id\G</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">waiting_trx_id:    <span class="number">73122</span>F</span><br><span class="line">waiting_thread:    <span class="number">471719</span></span><br><span class="line">waiting_query:    <span class="keyword">NULL</span></span><br><span class="line">blocking_trx_id:   <span class="number">7311</span>FC</span><br><span class="line">blocking_thread:   <span class="number">471718</span></span><br><span class="line">blocking_query:    <span class="keyword">NULL</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<p><strong>按照锁的粒度可分为：</strong></p>
<p><strong>全局锁</strong>：对整个数据库实例加锁，实例处于只读状态。</p>
<p>使用场景：进行整个数据库的逻辑备份，对所有的表进行锁定，从而获取一致性视图，保证数据完整性（DDL，DML 语句被阻塞，DQL 正常运行）。</p>
<p>步骤：</p>
<ol>
<li>加锁：<code>flush tables with read lock;</code></li>
<li>数据备份：<code>mysqldump -h192.168.200.202 -uroot -p1234 db01 &gt; db01.sql</code></li>
<li>解锁：<code>unlock tables;</code></li>
</ol>
<p>产生的问题：</p>
<p>如果在主库上备份，备份期间不能执行插入、更新等操作，<strong>业务基本上停摆</strong>。</p>
<p>如果在从库上备份，备份期间从库不能执行主库同步过来的二进制日志，导致<strong>主从延迟</strong>。</p>
<p>解决方法：</p>
<p>备份时，加上参数 -single-transaction 来完成不加锁的一致性数据备份（快照读取）：<code>mysqldump -single-transaction -h192.168.200.202 -uroot -p1234 db01 &gt; db01.sql</code></p>
<p><strong>表级锁</strong>：开销小，加锁快；锁定力度大，发生锁冲突概率高，并发度最低；不会出现死锁。</p>
<p>表**共享-**读锁：当表被 READ 锁定时，其他会话只能获取该表的 READ 锁，不能获取 WRITE 锁。READ 锁的会话可以进行读取操作（SELECT），但不能进行写入操作（INSERT、UPDATE、DELETE 等）。同时，加了 READ 锁的会话可以与其他 READ 锁并发读取表数据，但不能有写入操作。</p>
<p>表**独占-**写锁：当表被 WRITE 锁定时，其他所有会话都不能对该表进行任何操作（无论是读还是写），只有当前会话可以进行读写操作。写锁是独占锁，一旦被某个会话持有，其他会话都必须等待该锁被释放。</p>
<p>使用语法：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">lock tables table_name1, table_name2 read<span class="operator">/</span>write;</span><br><span class="line">unlock tables <span class="operator">/</span> 客户端断开连接;</span><br></pre></td></tr></table></figure>

<p>当客户端与 MySQL 服务器断开连接时，MySQL 会自动释放当前会话持有的所有表锁。这是为了防止锁永远保持不释放的情况，因为锁定表的会话已经断开，不再能主动解锁。</p>
<p><strong>元数据锁（meta data lock，MDL）</strong></p>
<p>元数据是控制表结构、表逻辑相关的信息。加锁过程由系统自动控制，无需显式使用。</p>
<p>当我们执行诸如 CREATE TABLE、DROP TABLE、ALTER TABLE 等 DDL（数据定义语言）语句时，MySQL 需要对表的元数据进行修改。在这些情况下，MDL 锁可以防止其他事务同时进行操作，确保结构修改的安全性。</p>
<p>当我们执行 SELECT、INSERT、UPDATE、DELETE 等 DML（数据操作语言）语句时，MySQL 也会申请 MDL 锁以保护表结构，防止在读取或写入数据的过程中表结构发生改变。</p>
<p>MDL 锁的类型：</p>
<p>MDL 共享锁（MDL Shared Lock）：</p>
<ul>
<li>当事务对表进行读取（如 SELECT）或普通的数据操作（如 INSERT、UPDATE）时，会申请 MDL 共享锁。</li>
<li>共享锁之间是兼容的，即多个事务可以同时持有 MDL 共享锁，这样可以允许多个事务同时读写表中的数据。</li>
</ul>
<p>MDL 排他锁（MDL Exclusive Lock）：</p>
<ul>
<li>当事务要对表进行结构修改（如 ALTER TABLE）时，会申请 MDL 排他锁。</li>
<li>MDL 排他锁与其他所有类型的锁都不兼容。因此，在表结构被修改期间，其他事务将被阻塞，直到持有排他锁的事务提交或回滚。</li>
</ul>
<p>查看 MDL：<code>select * from performance_schema.metadata_locks;</code></p>
<table>
<thead>
<tr>
<th>SQL 语句</th>
<th>锁类型</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>lock tables xxx read &#x2F; write</td>
<td>shared_read_only &#x2F; shared_no_read_write</td>
<td></td>
</tr>
<tr>
<td>select, select … lock in share mode</td>
<td>shared_read</td>
<td>与 shared_read, shared_write 兼容，与 exclusive 互斥</td>
</tr>
<tr>
<td>insert, update, delete, select … for update</td>
<td>shared_write</td>
<td>与 shared_read, shared_write 兼容，与 exclusive 互斥</td>
</tr>
<tr>
<td>alter table …</td>
<td>exclusive</td>
<td>与其他 MDL 都互斥</td>
</tr>
</tbody></table>
<p><strong>意向锁</strong></p>
<p>意向锁的出现是为了支持 InnoDB 的多粒度锁，它的主要作用是用来<strong>协调表级锁和行级锁之间的关系</strong>，从而提升锁定机制的性能和效率。它的核心用途是为了在表级别加锁时能够快速判断是否存在冲突，防止误加表级锁而导致锁冲突或死锁。</p>
<p><strong>意向锁本质</strong>：只是用于标识即将进行的锁操作。它主要用于快速判断是否可以对表或表中某些行施加其他类型的锁。</p>
<p>我们需要加表锁时，需要判断表中有没有数据行被锁定，以确定是否能加锁成功。</p>
<p>之前没有意向锁，我们就得遍历表中所有数据行来判断有没有行锁；有了意向锁这个表级锁之后，我们直接判断意向锁是否存在便可知表中是否有数据行被锁定。</p>
<p>有了意向锁之后，要执行的事务 A 在申请行锁（写锁）之前，数据库会自动先给事务 A 申请表的<strong>意向排他锁</strong>。当事务 B 去申请表的互斥锁时就会失败，因为表上有意向排他锁之后事务 B 申请表的互斥锁时会被阻塞。</p>
<ol>
<li>意向共享锁（IS）：由语句 <code>select ... lock in share mode;</code> 添加。</li>
</ol>
<ul>
<li>当一个事务打算对表中的某些行加共享锁（S 锁）时，它会在表级别加一个意向共享锁（IS 锁）。</li>
<li>意向共享锁之间是兼容的，可以允许多个事务同时对表中不同的行加共享锁。</li>
</ul>
<ol>
<li>意向排他锁（IX）：由 insert，update，delete，<code>select … for update;</code> 添加。</li>
</ol>
<ul>
<li>当一个事务打算对表中的某些行加排他锁（X 锁）时，它会在表级别加一个意向排他锁（IX 锁）。</li>
<li>意向排他锁之间也是兼容的，允许多个事务同时对表中不同的行加排他锁或共享锁。</li>
</ul>
<p>查看：<code>select * from performace_schema.data_locks;</code></p>
<p>下表中的 S 和 X 指的是表级锁，<strong>意向锁不会与行级的读写锁互斥！！！</strong></p>
<table>
<thead>
<tr>
<th></th>
<th>X 锁</th>
<th>S 锁</th>
</tr>
</thead>
<tbody><tr>
<td><strong>IS 锁</strong></td>
<td>不兼容</td>
<td>兼容</td>
</tr>
<tr>
<td><strong>IX 锁</strong></td>
<td>不兼容</td>
<td>不兼容</td>
</tr>
</tbody></table>
<p>意向锁的使用场景</p>
<ol>
<li>行级锁与表级锁的兼容性检测：<ul>
<li>当一个事务需要对表中的某些行加锁时，它会先在表级别加上相应的意向锁（IS 或 IX）。</li>
<li>这样，当其他事务尝试获取表级锁（例如 <code>LOCK TABLES</code>）时，只需要检查表级别的意向锁状态，就可以知道是否可以安全地进行加锁操作。</li>
</ul>
</li>
<li>防止死锁：<ul>
<li>通过使用意向锁，可以有效防止死锁的发生。例如，如果两个事务同时尝试对表的不同部分加锁，如果没有意向锁的机制，可能会导致相互等待，最终陷入死锁。</li>
<li>意向锁通过明确锁的意图，可以提前检测到潜在的冲突，从而避免死锁情况的出现。</li>
</ul>
</li>
</ol>
<p><strong>行级锁</strong>：开销大，加锁慢；锁定粒度小，发生锁冲突概率低，并发度高；会出现死锁。通过对索引中叶子节点的索引项加锁来实现。</p>
<p>行级锁的具体实现包含：记录锁，间隙锁和邻键锁。</p>
<p>记录锁（record lock）：锁定单个行的锁，防止其它事务对此进行 update 和 delete，在 Read committed、Repeatable read 隔离级别下都支持。</p>
<p><img src="/../../images/MySQL/mysql_locking_rec.drawio.png" alt="img"></p>
<ul>
<li>共享锁（S）：允许一个事务读一行，阻止其它事务获得相同数据集的排他锁。</li>
<li>排他锁（X）：允许获取排他锁的事务更新数据，阻止其它事务获得相同数据集的共享锁和排他锁。</li>
</ul>
<table>
<thead>
<tr>
<th>SQL</th>
<th>行锁类型</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>insert</td>
<td>X</td>
<td>自动加锁</td>
</tr>
<tr>
<td>update</td>
<td>X</td>
<td>自动加锁</td>
</tr>
<tr>
<td>delete</td>
<td>X</td>
<td>自动加锁</td>
</tr>
<tr>
<td>select （正常）</td>
<td>不加任何锁</td>
<td></td>
</tr>
<tr>
<td>select … lock in share mode</td>
<td>S</td>
<td>需要手动在select之后加lock in share mode</td>
</tr>
<tr>
<td>select … for update</td>
<td>X</td>
<td>需要手动在select之后添加for update</td>
</tr>
</tbody></table>
<p>间隙锁（gap lock）：锁定索引记录间隙（不含该记录），确保索引记录间隙不变，防止其它事务在这个间隙进行插入操作以产生幻读，在 Repeatable read 隔离级别下支持。间隙锁可共存，一个事务采用的间隙锁不会阻止另一个事务在同一间隙上采用间隙锁。</p>
<p><img src="/../../images/MySQL/mysql_locking_gap.drawio.png" alt="img"></p>
<p>以 <code>SELECT * FROM employees WHERE age BETWEEN 25 AND 30 FOR UPDATE;</code> 为例：</p>
<p>InnoDB 会对二级索引 age 的叶子节点加锁，包括：</p>
<ul>
<li>范围内存在的所有索引项（记录锁）。</li>
<li>范围内不存在记录的“间隙”部分（间隙锁）。</li>
</ul>
<p>随后，对这些索引项所指向的聚簇索引中的行数据加锁。</p>
<p>也就是说这种情况下，二级索引和聚簇索引的多个节点都会被加锁，以避免幻读和保证一致性。</p>
<p>除了上述例子的一致性锁定读之外，UPDATE 和 DELETE 在查询非唯一索引时也会使用间隙锁。</p>
<p>间隙锁可能带来的问题</p>
<ol>
<li>降低并发性能：间隙锁锁住的是一个范围，而不是具体的行，因此可能导致较多事务被阻塞。例如，一个简单的范围查询可能锁住比预期更多的行或区间。</li>
<li>死锁风险增加：由于间隙锁锁定的范围较广，在高并发场景下，多个事务可能会竞争相邻的间隙，导致死锁。</li>
<li>仅适用于索引字段：间隙锁只能作用于有索引的字段。如果字段没有索引，在 InnoDB 下会退化为表锁，从而进一步降低性能。</li>
</ol>
<p>临键锁（next-key lock）：行锁和间隙锁的组合，同时锁住数据以及数据前面的间隙（左开右闭区间），在 Repeatable read 隔离级别下支持。该锁用于解决幻读问题。</p>
<p><img src="/../../images/MySQL/mysql_locking_nxt_key.drawio.png" alt="img"></p>
<p>当查询的索引是针对唯一属性列时，临键锁会退化为记录锁，因为没必要锁一个区间，所有该字段的值都是唯一值。</p>
<p>此外，对于非唯一索引，如果查询的数据存在，那么 InnoDB 还会对该索引中的下一个区间加间隙锁。</p>
<p>假设我们创建一个表：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> z ( a <span class="type">INT</span>, b <span class="type">INT</span>, <span class="keyword">PRIMARY KEY</span>(a), KEY(b) );</span><br></pre></td></tr></table></figure>

<p>表 z 的列 b 是辅助索引，若在会话 A 中执行下面的 SQL 语句：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT INTO</span> z <span class="keyword">SELECT</span> <span class="number">1</span>,<span class="number">1</span>;</span><br><span class="line"><span class="keyword">INSERT INTO</span> z <span class="keyword">SELECT</span> <span class="number">3</span>,<span class="number">1</span>;</span><br><span class="line"><span class="keyword">INSERT INTO</span> z <span class="keyword">SELECT</span> <span class="number">5</span>,<span class="number">3</span>;</span><br><span class="line"><span class="keyword">INSERT INTO</span> z <span class="keyword">SELECT</span> <span class="number">7</span>,<span class="number">6</span>;</span><br><span class="line"><span class="keyword">INSERT INTO</span> z <span class="keyword">SELECT</span> <span class="number">10</span>,<span class="number">8</span>;</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> z <span class="keyword">WHERE</span> b<span class="operator">=</span><span class="number">3</span> <span class="keyword">FOR</span> <span class="keyword">UPDATE</span>;</span><br></pre></td></tr></table></figure>

<p>很明显，这时 SQL 语句通过索引列 b 进行查询，因此其使用传统的 Next-Key Locking 技术加锁，并且由于有两个索引，其需要分别进行锁定。对于聚集索引，其仅对列 a 等于 5 的索引加上 Record Lock。而对于辅助索引，其加上的是 Next-Key Lock，锁定的范围是 <code>(1, 3)</code>，特别需要注意的是，InnoDB 存储引擎还会对辅助索引下一个键值</p>
<p>加上 gap lock，即还有一个辅助索引范围为 <code>(3, 6)</code> 的锁。因此，若在新会话 B 中执行下面的 SQL 语句，都会被阻塞：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> z <span class="keyword">WHERE</span> a <span class="operator">=</span> <span class="number">5</span> LOCK <span class="keyword">IN</span> SHARE MODE;</span><br><span class="line"><span class="keyword">INSERT INTO</span> z <span class="keyword">SELECT</span> <span class="number">4</span>,<span class="number">2</span>;</span><br><span class="line"><span class="keyword">INSERT INTO</span> z <span class="keyword">SELECT</span> <span class="number">6</span>,<span class="number">5</span>;</span><br></pre></td></tr></table></figure>

<p>第一个 SQL 语句不能执行，因为在会话 A 中执行的 SQL 语句已经对聚集索引中列 a &#x3D; 5 的值加上 X 锁，因此执行会被阻塞。第二个 SQL 语句，主键插入 4，没有问题，但是插入的辅助索引值 2 在锁定的范围 <code>(1, 3)</code> 中，因此执行同样会被阻塞。第三个 SQL 语句，插入的主键 6 没有被锁定，5 也不在范围 <code>(1, 3)</code> 之间。但插入的值 5 在另一个锁定的范围 <code>(3, 6)</code> 中，故同样需要等待。而下面的 SQL 语句，不会被阻塞，可以立即执行：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT INTO</span> z <span class="keyword">SELECT</span> <span class="number">8</span>,<span class="number">6</span>;</span><br><span class="line"><span class="keyword">INSERT INTO</span> z <span class="keyword">SELECT</span> <span class="number">2</span>,<span class="number">0</span>;</span><br><span class="line"><span class="keyword">INSERT INTO</span> z <span class="keyword">SELECT</span> <span class="number">6</span>,<span class="number">7</span>;</span><br></pre></td></tr></table></figure>

<p>从上面的例子中可以看到，Gap Lock 的作用是为了阻止多个事务将记录插入到同一范围内，而这会导致 Phantom Problem 问题的产生。例如在上面的例子中，会话 A 中用户已经锁定了 b &#x3D; 3 的记录。若此时没有 Gap Lock 锁定 <code>(3, 6)</code>，那么用户可以插入索引 b 列为 3 的记录，这会导致会话 A 中的用户再次执行同样查询时会返回不同的记录，即导致 Phantom Problem 问题的产生。</p>
<p>用户可以通过以下两种方式来显式地关闭 Gap Lock：</p>
<ul>
<li>将事务的隔离级别设置为 READ COMMITTED</li>
<li>将参数 <code>innodb_locks_unsafe_for_binlog</code> 设置为 1</li>
</ul>
<p>在上述的配置下，除了外键约束和唯一性检查依然需要的 Gap Lock，其余情况仅使用 Record Lock 进行锁定。但需要牢记的是，上述设置破坏了事务的隔离性，并且对于 replication，可能会导致主从数据的不一致。此外，从性能上来看，READ COMMITTED 也不会优于默认的事务隔离级别 READ REPEATABLE。</p>
<p>在 InnoDB 存储引擎中，对于 INSERT 的操作，其会检查插入记录的下一条记录是否被锁定，若已经被锁定，则不允许查询。对于上面的例子，会话 A 已经锁定了表 z 中 b &#x3D; 3 的记录，即已经锁定了 <code>(1, 3)</code> 的范围，这时若在其他会话中进行如下的插入同样会导致阻塞：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT INTO</span> z <span class="keyword">SELECT</span> <span class="number">2</span>,<span class="number">2</span>;</span><br></pre></td></tr></table></figure>

<p>因为在辅助索引列 b 上插入值为 2 的记录时，会监测到下一个记录 3 已经被索引。而将插入修改为如下的值，可以立即执行：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT INTO</span> z <span class="keyword">SELECT</span> <span class="number">2</span>,<span class="number">0</span>;</span><br></pre></td></tr></table></figure>

<p>需要注意的是，对于唯一键值的锁定，Next-Key Lock 降级为 Record Lock 仅存在于查询所有的唯一索引列。若唯一索引由多个列组成，而查询仅是查找多个唯一索引列中的其中一个，那么查询其实是 range 类型查询，而不是 point 类型查询，故 InnoDB 存储引擎依然使用 Next-Key Lock 进行锁定。</p>
<p>InnoDB 存储引擎默认的事务隔离级别是 REPEATABLE READ，在该隔离级别下，其采用 Next-Key Locking 的方式来加锁。而在事务隔离级别 READ COMMITTED 下，其仅采用 Record Lock。</p>
<p>此外，用户可以通过 InnoDB 存储引擎的 Next-Key Locking 机制在应用层面实现唯一性的检查。例如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">WHERE</span> col <span class="operator">=</span> xxx LOCK <span class="keyword">IN</span> SHARE MODE;</span><br><span class="line"></span><br><span class="line">If <span class="keyword">not</span> found <span class="keyword">any</span> <span class="type">row</span>:</span><br><span class="line">  # <span class="keyword">unique</span> <span class="keyword">for</span> <span class="keyword">insert</span> <span class="keyword">value</span></span><br><span class="line">  <span class="keyword">INSERT INTO</span> <span class="keyword">table</span> <span class="keyword">VALUES</span> (...);</span><br></pre></td></tr></table></figure>

<p>如果用户通过索引查询一个值，并对该值加上一个 SLock，那么即使查询的值不存在，其锁定的也是一个范围。因此若没有返回任何行，那么新插入的值一定是唯一的。或许有读者会疑问：如果在进行第一步 <code>SELECT … LOCK IN SHARE MODE</code> 操作时，有多个事务并发操作，那么这种唯一性检查机制是否存在问题？其实并不会，因为这时会导致死锁，只有一个事务的插入操作会成功，而其余的事务会抛出死锁错误。如下表所示：</p>
<table>
<thead>
<tr>
<th><strong>时间</strong></th>
<th><strong>会话 A</strong></th>
<th><strong>会话 B</strong></th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>BEGIN</td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>SELECT * FROM z WHERE b&#x3D;4 LOCK IN SHARE MODE;</td>
<td></td>
</tr>
<tr>
<td>3</td>
<td></td>
<td>SELECT * FROM z WHERE b&#x3D;4 LOCK IN SHARE MODE;</td>
</tr>
<tr>
<td>4</td>
<td>INSERT INTO z SELECT 4,4; # 阻塞</td>
<td></td>
</tr>
<tr>
<td>5</td>
<td></td>
<td>INSERT INTO z SELECT 4,4; ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction # 抛出死锁异常，并打破死锁</td>
</tr>
<tr>
<td>6</td>
<td># INSERT 插入成功</td>
<td></td>
</tr>
</tbody></table>
<p><strong>插入意向锁</strong></p>
<p>插入意向锁是间隙粒度的锁，精细到单个索引页里某两个值之间的区间，用于标识事务计划在某个索引间隙内插入数据而加设的锁。它并不锁定具体已存在的行，而是将要插入的位置所在的间隙临时锁定为计划插入，从而允许多个事务在同一间隙内并发插入不同的记录。也就是说，插入意向锁仅表示意向，不直接阻塞其他事务对同一间隙的插入，只要插入位置互不冲突即可并发执行。 </p>
<p>它介于行级（Record Lock，锁已存在行）和页&#x2F;表级（锁整页或整表）之间，用来协调多个事务同时往同一个区间插入新行，而不去阻塞彼此。该锁的设计初衷是<strong>提高并发插入能力</strong>，减少因行锁或表级锁而产生的阻塞。</p>
<p>当执行 INSERT 语句时，InnoDB 会先定位插入值在聚集索引（或唯一索引）中的正确位置。在真正写入新行之前，InnoDB 会对该插入间隙加上插入意向锁，以表明本事务计划在此间隙插入数据。只有当此时该间隙已经被其他事务以 Gap Lock 形式范围锁定（如执行范围扫描加锁）时，才能导致当前插入意向锁请求被阻塞。否则，插入意向锁之间互不冲突。</p>
<p>获得插入意向锁后，InnoDB 会继续在实际要插入的新行位置加行级写锁，确保后续写操作的原子性与一致性。在插入完成并提交后，这条新插入行上的行锁保持至事务结束，然后随着事务提交释放；插入意向锁在加行锁后也会被释放，不会持续阻塞。</p>
<p>任何普通的 INSERT 操作（包括单行插入和多行插入），在执行前都会对目标插入点所在的索引空隙加一个插入意向锁，表明当前事务打算在此处插入新行，但不会阻塞同一区间的其他插入操作。</p>
<p>InnoDB 在 REPEATABLE READ 隔离级别下，针对不同类型的索引检索与扫描操作采取了不同的锁策略：</p>
<ul>
<li>执行的范围扫描（如 <code>SELECT … FOR UPDATE</code>、UPDATE、DELETE 等）会使用 Next-Key 锁，它相当于给索引记录加上行锁（Record Lock），同时对该记录之前的空隙加上间隙锁，从而禁止并发事务在此间隙插入幻行。</li>
<li>当对唯一索引进行等值查询（unique index + … WHERE key &#x3D; value）时，如果能精确匹配到某条已存在记录，InnoDB 会直接对该记录加行级锁（Record Lock），而不再对前置间隙加锁（即不使用 Gap Lock）。这种唯一索引 + 等值匹配的情况被 InnoDB 自动优化为仅行锁，以减少锁级别和冲突。</li>
<li>InnoDB 的行锁是加在索引记录上的，如果某条查询完全不经过索引（例如全表扫描、非索引列条件），InnoDB 会退化为给整张表加表级锁。</li>
<li>当在 唯一索引上执行等值查询，但该值在表中不存在（即要锁定某个不存在的记录）时，InnoDB 会对对应索引位置的空隙加上间隙锁，防止其他事务在该位置插入新行。</li>
<li>在非唯一索引上执行等值查询（ordinary index + WHERE key &#x3D; value）时，InnoDB 会先沿索引向右遍历查找匹配行；若查到的最后一个值仍不满足等值条件，Next-Key 锁会退化为仅加间隙锁，而不是继续对某条不存在的记录加行锁。</li>
<li>在唯一索引上执行范围查询（<code>WHERE key BETWEEN a AND b</code> 或 <code>WHERE key &gt; a</code> 等），InnoDB 访问到第一个不满足条件的值后就停止，这也保证了越界位置的间隙锁效果——只锁定真正满足条件的记录之前的空隙，避免后续出现新的幻行。</li>
</ul>
<p>按照加锁机制可分为：</p>
<p><strong>乐观锁</strong></p>
<p>乐观锁假设冲突在系统中出现的频率较低，因此在数据库事务执行过程中，不会频繁地去锁定资源。相反，它在提交更新的时候才检查是否有其他事务已经修改了数据。</p>
<p>可以通过在数据表中使用版本号或时间戳来实现，每次读取记录时，同时获取版本号或时间戳，更新时检查版本号或时间戳是否发生变化。</p>
<p>如果没有变化，则执行更新并增加版本号或更新时间戳；如果检测到冲突（即版本号或时间戳与之前读取的不同），则拒绝更新。</p>
<p><strong>悲观锁</strong></p>
<p>悲观锁假设冲突是常见的，因此在数据处理过程中，它会主动锁定数据，防止其他事务进行修改。</p>
<p>可以直接使用数据库的锁机制，如行锁或表锁，来锁定被访问的数据。常见的实现是 <code>SELECT FOR UPDATE</code> 语句，它在读取数据时就加上了锁，直到当前事务提交或回滚后才释放。</p>
<p><strong>解决库存超买问题</strong></p>
<p>乐观锁</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> inventory <span class="keyword">SET</span> count <span class="operator">=</span> count <span class="operator">-</span> <span class="number">1</span>, version <span class="operator">=</span> version <span class="operator">+</span> <span class="number">1</span> <span class="keyword">WHERE</span> product_id <span class="operator">=</span> <span class="number">1</span> <span class="keyword">AND</span> version <span class="operator">=</span> current_version;</span><br></pre></td></tr></table></figure>

<p>因此乐观锁通过不断递增的版本号来控制并发事务。</p>
<p>悲观锁</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">START</span> TRANSACTION;</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> inventory <span class="keyword">WHERE</span> product_id <span class="operator">=</span> <span class="number">1</span> <span class="keyword">FOR</span> <span class="keyword">UPDATE</span>;</span><br><span class="line"><span class="keyword">UPDATE</span> inventory <span class="keyword">SET</span> count <span class="operator">=</span> count <span class="operator">-</span> <span class="number">1</span> <span class="keyword">WHERE</span> product_id <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line"><span class="keyword">COMMIT</span>;</span><br></pre></td></tr></table></figure>

<p>由此可见，悲观锁会在事务开始时直接锁定库存记录，直到事务结束。</p>
<h3 id="一致性非锁定读"><a href="#一致性非锁定读" class="headerlink" title="一致性非锁定读"></a>一致性非锁定读</h3><p>一致性非锁定读是一种利用多版本并发控制（MVCC）的读取方式。当事务执行普通的 SELECT 语句时，即使另一事务正在对同一行进行 UPDATE 或 DELETE，读取操作也不会被阻塞。</p>
<p>InnoDB 会为每条记录在 undo 段中保存历史版本。当读取请求到来时，若目标行正被加锁或已被修改，InnoDB 会取用该行的快照数据（历史版本）而非等待当前锁的释放，从而实现非锁定地读取一致性数据。</p>
<p>每次对行执行更新或删除时，InnoDB 会将修改前的行数据写入 undo 段，形成一个快照版本。一个行记录可能拥有多个历史版本，每个版本对应不同时间点的值。通过在事务启动时或者读取时确定一个合适的版本，InnoDB 能保证读取到符合隔离级别要求的“旧数据”或“最新已提交数据”，而不去抢占当前正在被写锁定的行。</p>
<p>由于读取操作无需等待行级锁释放，InnoDB 的并发性能大幅提升。读操作不会阻塞写操作，写操作也不会过度影响其它读事务。</p>
<p>在大多数情况下，事务仅需访问行快照，即可保证数据一致性，无须引入额外锁，从而避免死锁与锁等待带来的性能开销。</p>
<p>**READ COMMITTED：**每次读取都会取当前最新的“已提交”快照。若在同一事务中连续执行两次相同查询，第二次查询可能看到其他事务已提交的更新。</p>
<p>**REPEATABLE READ（InnoDB 默认）：**事务启动后即确定一个读取视图（snapshot），所有后续读取都基于该视图中的版本。无论其他事务如何提交，当前事务看到的行数据都是事务开始时的一致快照。</p>
<h3 id="一致性锁定读"><a href="#一致性锁定读" class="headerlink" title="一致性锁定读"></a>一致性锁定读</h3><p>在 InnoDB 默认的 REPEATABLE READ 隔离级别下，普通的 SELECT 都是非锁定的一致性读，通过 MVCC 机制读取快照而不会阻塞或等待行锁。但在某些业务场景中，用户需要显式地对读取到的数据加锁，以强制保证数据逻辑上的一致性，此时就需要使用“一致性锁定读”。</p>
<p>InnoDB 支持对 SELECT 语句加锁的两种方式：</p>
<ul>
<li><code>SELECT … FOR UPDATE</code></li>
<li><code>SELECT … LOCK IN SHARE MODE</code></li>
</ul>
<p>其中：</p>
<ul>
<li><code>SELECT … FOR UPDATE</code><ul>
<li>会对检索到的每一行记录加上排他锁。</li>
<li>一旦某行被 X 锁锁定，其他事务既不能对该行加 X 锁，也不能加 S 锁，必须等该事务提交或回滚后才可访问。</li>
</ul>
</li>
<li><code>SELECT … LOCK IN SHARE MODE</code><ul>
<li>会对检索到的每一行记录加上共享锁。</li>
<li>其他事务可以对该行继续加共享锁（并发读取），但若尝试加排他锁就会被阻塞，直到 S 锁释放。</li>
</ul>
</li>
</ul>
<p><code>SELECT … FOR UPDATE</code>&#x2F;<code>LOCK IN SHARE MODE</code> 必须在显式事务内执行，也就是在执行之前要先执行：</p>
<ul>
<li><code>BEGIN</code> 或 <code>START TRANSACTION</code></li>
<li>或者将会话设置为 <code>SET AUTOCOMMIT=0</code>，然后执行 <code>SELECT … FOR UPDATE</code>／<code>SELECT … LOCK IN SHARE MODE</code>。</li>
</ul>
<p>只有在事务结束后（提交或回滚），这些行锁才会被释放，其他事务才能继续操作这些行。</p>
<p>对于一致性非锁定读，就算目标行正在被 X 锁锁定，InnoDB 依然能通过读取行的历史快照来返回结果，不会阻塞。</p>
<h3 id="自增长与锁"><a href="#自增长与锁" class="headerlink" title="自增长与锁"></a>自增长与锁</h3><p>自增长在数据库中是非常常见的一种属性。在 InnoDB 存储引擎的内存结构中，每个含有自增长值的表都有一个自增长计数器（auto-increment counter）。当对含有自增长计数器的表进行插入操作时，这个计数器会被初始化，执行如下语句来得到计数器的值：</p>
<p>插入操作会依据这个自增长计数器的值加 1 赋予自增列。这个实现方式称做 AUTO-INC Locking。这种锁其实是采用一种特殊的表锁机制，为了提高插入的性能，锁不是在一个事务完成后才释放，而是在完成对自增长值插入的 SQL 语句后立即释放。</p>
<p>虽然 AUTO-INC Locking 从一定程度上提高了并发插入的效率，但还是存在一些性能上的问题。首先，对于有自增长值的列的并发插入性能较差，事务必须等待前一个插入的完成（虽然不用等待整个事务的结束）。其次，对于 <code>INSERT … SELECT</code> 的大数据量插入，会影响插入的性能，因为此时另一个事务中的插入会被阻塞。</p>
<p>从 MySQL 5.1.22 版本开始，InnoDB 存储引擎中提供了一种轻量级互斥量的自增长实现机制，这种机制大大提高了自增长值插入的性能。并且从该版本开始，InnoDB 存储引擎提供了一个参数 <code>innodb_autoinc_lock_mode</code> 来控制自增长的模式，该参数的默认值为 1。</p>
<p>下表对插入操作进行分类：</p>
<table>
<thead>
<tr>
<th>插入类型</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>insert-like</code></td>
<td>insert-like 指所有的插入语句，如 <code>INSERT</code>、<code>REPLACE</code>、<code>INSERT … SELECT</code>、<code>REPLACE … SELECT</code>、<code>LOAD DATA</code> 等</td>
</tr>
<tr>
<td><code>simple inserts</code></td>
<td>simple inserts 指能在插入前就确定插入行数的语句。这些语句包括 <code>INSERT</code>、<code>REPLACE</code> 等。需要注意的是：simple inserts 不包含 <code>INSERT … ON DUPLICATE KEY UPDATE</code> 这类 SQL 语句</td>
</tr>
<tr>
<td><code>bulk inserts</code></td>
<td>bulk inserts 指在插入前不能确定插入行数的语句，如 <code>INSERT … SELECT</code>、<code>REPLACE … SELECT</code>、<code>LOAD DATA</code></td>
</tr>
<tr>
<td><code>mixed-mode inserts</code></td>
<td>mixed-mode inserts 指插入中有一部分的值是自增的，有一部分是确定的。如：<br><code>INSERT INTO t1 (c1,c2) VALUES (1,&#39;a&#39;), (NULL,&#39;b&#39;), (5,&#39;c&#39;), (NULL,&#39;d&#39;);</code><br>也可以指 <code>INSERT … ON DUPLICATE KEY UPDATE</code> 这类 SQL 语句</td>
</tr>
</tbody></table>
<p><code>innodb_autoinc_lock_mode</code> 有三个有效值可供设定，具体如下：</p>
<table>
<thead>
<tr>
<th>innodb_autoinc_lock_mode</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>这是 MySQL 5.1.22 版本之前自增长的实现方式，即通过表锁的 AUTO-INC Locking 方式。因为有了新的自增长实现方式，0 这个选项不应该是新版用户的首选项。</td>
</tr>
<tr>
<td>1</td>
<td>这是该参数的默认值。• 对于 “simple inserts” （简单插入），该值会用互斥量（mutex）去对内存中的计数器进行累加操作。• 对于 “bulk inserts” （批量插入），还是使用传统锁的 AUTO-INC Locking 方式。在这种配置下，如果不考虑回滚操作，对于自增值的增长还是连续的。并且在这种方式下，statement-based 方式的 replication 还是能很好地工作。• 需要注意的是，如果已经使用 AUTO-INC Locking 方式产生自增长值，而这时需要再进行 “simple inserts” 的操作时，还是需要等待 AUTO-INC Locking 的释放。</td>
</tr>
<tr>
<td>2</td>
<td>在这个模式下，对于所有 “insert-like” 自增长值的产生都是通过互斥量，而不是 AUTO-INC Locking 的方式。显然，这会带来一定的问题，因为并发插入的存在，在每次插入时，自增值的值不保证是连续的。此外，最重要的是，基于 Statement-Based Replication 会出现问题。因此，使用该模式，任何时候都应该使用 row-based replication。这样才能保证最大的并发性能及 replication 主从数据的一致。</td>
</tr>
</tbody></table>
<p>此外，还需要特别注意的是，在 InnoDB 存储引擎中自增长的实现和 MyISAM 不同。MyISAM 存储引擎是表锁设计，自增长不考虑并发插入的问题。因此在 master 上用 InnoDB 存储引擎，在 slave 上用 MyISAM 存储引擎的 replication 架构下，用户必须考虑这种情况。</p>
<p>上表中，并发插入问题指的是在高并发场景下，用互斥量（mutex）保护自增计数器时会出现的两类问题：</p>
<ol>
<li>ID 分配成为串行瓶颈<ul>
<li>互斥量会让每个插入请求都要轮流抢一次锁，才能执行 <code>counter++</code> 并分配一个自增值。这在并发插入很高时，会频繁争抢同一个互斥量，造成吞吐下降。</li>
</ul>
</li>
<li>自增 ID 不连续或乱序<ul>
<li>互斥量模式下，插入时就分配 ID。如果某个事务分配到 ID 后回滚，这个号就空了，导致跳号更明显。</li>
<li>并发事务各自抢到互斥量分配 ID，但可能是后抢到的人先真正写入、先提交，最终物理插入顺序与 ID 逻辑顺序并不一致。</li>
</ul>
</li>
</ol>
<p>在 InnoDB 存储引擎中，如果要让某个列使用 <code>AUTO_INCREMENT</code> 功能，必须满足两个条件：</p>
<ol>
<li>该列要有索引；</li>
<li>在对应索引中，它必须是最左边（第一列）。</li>
</ol>
<p>如果把自增列放在联合索引但不是第一个字段，或者根本没给它建立索引，InnoDB 会报错并拒绝插入；而 MyISAM 在相同情况下则不会报异常。</p>
<h3 id="外键和锁"><a href="#外键和锁" class="headerlink" title="外键和锁"></a>外键和锁</h3><p>InnoDB 在创建外键时，如果外键列上没有显式索引，会自动为该列创建一个索引，以避免全表扫描带来的锁争用。<br>当对子表执行插入或更新外键列（即要引用父表某条记录）时，InnoDB 必须先查询父表确保对应的主键（或唯一键）存在。</p>
<p>但简单的 一致性非锁定读（普通 SELECT）并不能保证在事务并发环境中数据的一致性——可能会出现脏写或幻读情形。</p>
<p>因此，InnoDB 在查询父表时会使用 <code>SELECT … LOCK IN SHARE MODE</code>，对父表所查的行加一个 S 锁（共享锁）。这样做有两个作用：</p>
<ol>
<li>防止父表被并发事务删除或更新：如果父表对应行已被其他事务加了 X 锁（排他锁），子事务在 <code>LOCK IN SHARE MODE</code> 时就会阻塞，直到父锁释放为止。</li>
<li>保证外键引用时数据不会不一致：只有拿到父表的 S 锁，才能证明此父键在本事务内是稳固存在的、不被其他事务删除或修改。</li>
</ol>
<p>如果此时父表相应行已经被别的事务用 <code>SELECT … FOR UPDATE</code> 或 UPDATE&#x2F;DELETE 加上了 X 锁，子表的外键检查就必须等这一 X 锁释放后才能继续。</p>
<p>也就是说，外键引用操作会被刻意设计成主动等待父表可读且稳固的状态，从而避免插入不存在的父记录或引用已改&#x2F;已删的数据。</p>
<h2 id="阻塞"><a href="#阻塞" class="headerlink" title="阻塞"></a>阻塞</h2><p>因为不同锁之间的兼容性关系，在有些时刻一个事务中的锁需要等待另一个事务中的锁释放它所占用的资源，这就是阻塞。阻塞并不是一件坏事，其是为了确保事务可以并发且正常地运行。</p>
<p>在 InnoDB 存储引擎中，参数 <code>innodb_lock_wait_timeout</code> 用来控制等待的时间（默认是 50 秒），<code>innodb_rollback_on_timeout</code> 用来设定是否在等待超时时对进行中的事务进行回滚操作（默认为 OFF，代表不回滚）。参数 <code>innodb_lock_wait_timeout</code> 是动态的，可以在 MySQL 数据库运行时进行调整：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SET</span> @<span class="variable">@innodb_lock_wait_timeout</span><span class="operator">=</span><span class="number">60</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<p>而 <code>innodb_rollback_on_timeout</code> 是静态的，不可在启动时进行修改，如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SET</span> @<span class="variable">@innodb_rollback_on_timeout</span><span class="operator">=</span><span class="keyword">on</span>;</span><br><span class="line">ERROR <span class="number">1238</span> (HY000): Variable <span class="string">&#x27;innodb_rollback_on_timeout&#x27;</span> <span class="keyword">is</span> a read <span class="keyword">only</span> variable</span><br></pre></td></tr></table></figure>

<p>当发生超时，MySQL 数据库会抛出一个 1205 的错误，如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">BEGIN</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> t <span class="keyword">WHERE</span> a <span class="operator">=</span> <span class="number">1</span> <span class="keyword">FOR</span> <span class="keyword">UPDATE</span>;</span><br><span class="line">ERROR <span class="number">1205</span> (HY000): Lock wait timeout exceeded; try restarting transaction</span><br></pre></td></tr></table></figure>

<p>需要注意的是，在默认情况下 InnoDB 不会回滚超时引发的错误异常，其实 InnoDB 在大部分情况下都不会对异常进行回滚。</p>
<h2 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h2><h3 id="死锁的概念"><a href="#死锁的概念" class="headerlink" title="死锁的概念"></a>死锁的概念</h3><p>死锁是指两个或两个以上的事务在执行过程中，因争夺锁资源而造成的一种互相等待的现象。若无外力作用，事务都将无法推进下去。解决死锁问题最简单的方式是不 要有等待，将任何的等待都转化为回滚，并且事务重新开始。毫无疑问，这的确可以避免死锁问题的产生。然而在线上环境中，这可能导致并发性能的下降，甚至任何一个事务都不能进行。而这所带来的问题远比死锁问题更为严重，因为这很难被发现并且浪费资源。</p>
<p>解决死锁问题最简单的一种方法是超时，即当两个事务互相等待时，当一个等待时间超过设置的某一阈值时，其中一个事务进行回滚，另一个等待的事务就能继续进行。在 InnoDB 存储引擎中，参数 <code>innodb_lock_wait_timeout</code> 用来设置超时时间。</p>
<p>超时机制虽然简单，但是其仅通过超时后对事务进行回滚的方式来处理，或者说其是根据 FIFO 的顺序选择回滚对象。但被超时的事务所占权重比较大，如事务操作更新了很多行，占用了较多的 undo log，这时采用 FIFO 的方式，就显得不合适了，因为回滚这个事务的时间相对另一个事务所占用的时间可能会很多。</p>
<p>因此，除了超时机制，目前数据库还普遍采用 wait-for graph（等待图）的方式来进行死锁检测。较之超时的解决方案，这是一种更为主动的死锁检测方式。InnoDB 存储引擎也采用的这种方式。wait-for graph 要求数据库保存以下两种信息：</p>
<ul>
<li>锁的信息链表 </li>
<li>事务等待链表</li>
</ul>
<p>通过上述链表可以构造出一张图，而在这个图中若存在回路，就代表存在死锁，因此资源间相互发生等待。在 wait-for graph 中，事务为图中的节点。而在图中，事务 T1 指向 T2 边的定义为：事务 T1 等待事务 T2 所占用的资源，也就是事务之间在等待相同的资源，而事务 T1 发生在事务 T2 的后面。</p>
<p>假设当前事务和锁的状态如下图：</p>
<p><img src="/../../images/MySQL/mysql_locking_trx_lock.drawio.png" alt="img"></p>
<p>在 Transaction Wait Lists 中可以看到共有 4 个事务 t1、t2、t3、t4，故在 wait-for graph 中应有 4 个节点。而事务 t2 对 row1 占用 X 锁，事务 t1 对 row2 占用 S 锁。事务 t1 需要等待事务 t2 对 row1 的资源，因此在 wait-for graph 中有条边从节点 t1 指向节点 t2。事务 t2 需要等待事务 t1、t4 所占用的 row2 对象，故而存在节点 t2 到节点 t1、t4 的边。同样，存在节点 t3 到节点 t1、t2、t4 的边，因此最终的 wait-for graph 如下图：</p>
<p><img src="/../../images/MySQL/mysql_locking_wait_graph.drawio.png" alt="img"></p>
<p>可以发现存在回路 <code>(t1, t2)</code>，因此存在死锁。通过上述的介绍，可以发现 wait-for graph 是一种较为主动的死锁检测机制，在每个事务请求锁并发生等待时都会判断是否存在回路，若存在则有死锁。通常来说，InnoDB 存储引擎选择回滚 undo 量最小的事务。</p>
<p>wait-for graph 的死锁检测通常采用深度优先的算法实现，在 InnoDB 1.2 版本之前，都是采用递归方式实现。而从 1.2 版本开始，对 wait-for graph 的死锁检测进行了优化，将递归用非递归的方式实现，从而进一步提高了 InnoDB 存储引擎的性能。</p>
<p><strong>死锁示例</strong></p>
<p>如果程序是串行的，那么不可能发生死锁。死锁只存在于并发的情况，而数据库本身就是一个并发运行的程序，因此可能会发生死锁。下表的操作演示了死锁的一种经典的情况，即 A 等待 B， B 在等待 A，这种死锁问题被称为 AB-BA 死锁。</p>
<table>
<thead>
<tr>
<th>时间</th>
<th>会话 A</th>
<th>会话 B</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>BEGIN;</td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>mysql&gt; SELECT * FROM t WHERE a &#x3D; 1 FOR UPDATE;<br />******** 1 row ******** a: 1 1 row in set (0.00 sec)</td>
<td>BEGIN</td>
</tr>
<tr>
<td>3</td>
<td></td>
<td>mysql&gt; SELECT * FROM t WHERE a &#x3D; 2 FOR UPDATE;<br /> ******** 1 row ******** a: 2 1 row in set (0.00 sec)</td>
</tr>
<tr>
<td>4</td>
<td>mysql&gt; SELECT * FROM t WHERE a &#x3D; 2 FOR UPDATE; # 等待</td>
<td></td>
</tr>
<tr>
<td>5</td>
<td></td>
<td>mysql&gt; SELECT * FROM t WHERE a &#x3D; 1 FOR UPDATE;<br /> ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction</td>
</tr>
</tbody></table>
<p>在上述操作中，会话 B 中的事务抛出了 1213 这个错误提示，即表示事务发生了死锁。死锁的原因是会话 A 和 B 的资源在互相等待。大多数的死锁 InnoDB 存储引擎本身可以侦测到，不需要人为干预。但是在上面的例子中，在会话 B 中的事务抛出死锁异常后，会话 A 中马上得到了记录 2 的这个资源，这其实是因为会话 B 中的事务发生了回滚，否则会话 A 中的事务是不可能得到该资源的。之前说过 InnoDB 存储引擎并不会回滚大部分的异常，但死锁除外。发现死锁后，InnoDB 存储引擎会马上回滚一个事务，这一点需要注意。因此如果在应用程序中捕获了 1213 这个错误，其实并不需要对其进行额外回滚。</p>
<p>此外还有另一种死锁，即当前事务持有了待插入记录的下一个记录的 X 锁，但是在等待队列中存在一个 S 锁的请求，则可能会发生死锁。来看一个例子，首先根据如下代码创建测试表 t，并导入一些数据：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> t (</span><br><span class="line">  a <span class="type">INT</span> <span class="keyword">PRIMARY KEY</span></span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB;</span><br><span class="line"><span class="keyword">INSERT INTO</span> t <span class="keyword">VALUES</span> (<span class="number">1</span>), (<span class="number">2</span>), (<span class="number">4</span>), (<span class="number">5</span>);</span><br></pre></td></tr></table></figure>

<p>下面演示两会话（会话 A 和会话 B）并发执行时发生死锁的过程：</p>
<table>
<thead>
<tr>
<th>时间</th>
<th>会话 A</th>
<th>会话 B</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td><code>BEGIN;</code></td>
<td></td>
</tr>
<tr>
<td>2</td>
<td></td>
<td><code>BEGIN;</code></td>
</tr>
<tr>
<td>3</td>
<td><code>SELECT * FROM t WHERE a = 4 FOR UPDATE;</code></td>
<td></td>
</tr>
<tr>
<td>4</td>
<td></td>
<td><code>SELECT * FROM t WHERE a &lt;= 4 LOCK IN SHARE MODE;</code><br>– 等待</td>
</tr>
<tr>
<td>5</td>
<td><code>INSERT INTO t VALUES (3);</code><br><code>ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction</code></td>
<td></td>
</tr>
<tr>
<td>6</td>
<td></td>
<td>– 事务获得锁，正常运行</td>
</tr>
</tbody></table>
<p>事务 A 在时间点 3：</p>
<p>执行 <code>SELECT * FROM t WHERE a = 4 FOR UPDATE;</code></p>
<p>这条语句会对主键值 a&#x3D;4 的记录加 X 锁。到此时刻，事务 A 持有对记录 (a&#x3D;4) 的 X 锁，且锁保持不释放（事务尚未提交或回滚）。</p>
<p>事务 B 在时间点 4：</p>
<p>执行 <code>SELECT * FROM t WHERE a &lt;= 4 LOCK IN SHARE MODE;</code></p>
<p>由于条件 a &lt;&#x3D; 4 会匹配到主键值 1, 2, 4 三条记录，因此事务 B 需要对这些记录的索引范围（Range）加 S 锁。其中，对 (a&#x3D;4) 那条记录上的 S 锁请求会因为事务 A 已经持有该行的 X 锁而被阻塞，导致事务 B 进入等待队列。</p>
<p>事务 A 在时间点 5：</p>
<p>执行 <code>INSERT INTO t VALUES (3);</code></p>
<p>插入新行 a&#x3D;3 时，InnoDB 需要在索引（聚簇索引）上为记录 3 所在位置加上插入意向锁（Gap Lock &#x2F; Next-key Lock）。由于 InnoDB 的聚簇索引按主键值顺序存储，此时 a&#x3D;3 属于介于 a&#x3D;2 与 a&#x3D;4 之间的间隙。</p>
<p>然而，事务 B 已在索引范围上对 (a &lt;&#x3D; 4) 加了 S 锁，并且正等待获取 (a&#x3D;4) 上的 S 锁。换句话说，此时索引上存在：</p>
<ul>
<li>事务 A：已对 a&#x3D;4 加了 X 锁，还需要对间隙 <code>(2, 4)</code> 加插入意向 X 锁，才能插入 a&#x3D;3。</li>
<li>事务 B：已对间隙 <code>(2, 4)</code>（更准确地说是对 a &lt;&#x3D; 4 范围）请求 S 锁，其中包括 (a&#x3D;2)、(a&#x3D;4) 以及它们之间的间隙。</li>
</ul>
<p><strong>为何形成死锁？</strong></p>
<ul>
<li>事务 B 正在等待 (a &#x3D; 4) 上的 S 锁，而当事务 A 在时间点 5 尝试插入 a&#x3D;3 时，InnoDB 会先对 (a &#x3D; 3) 的插入位置加 X 锁（Gap Lock 或 Next-key Lock）。由于事务 B 已对 (a &lt;&#x3D; 4) 这个范围中的间隙（包括 (2, 4)）持有 S 锁请求（还未获得，但已在等待队列中），所以此时：<ul>
<li>事务 A 需要等到 Gap Lock 获得，而 Gap Lock 又受限于事务 B 已在其上排队的 S 锁；</li>
<li>同时，事务 B 需要等到 (a &#x3D; 4) 上的 S 锁释放，而 (a &#x3D; 4) 由事务 A 持有 X 锁；</li>
</ul>
</li>
<li>这样就形成循环等待：<ul>
<li>事务 A 等待事务 B 在间隙 <code>(2, 4)</code> 上的 S 锁释放（因为事务 B 在关键范围上排队），</li>
<li>事务 B 等待事务 A 释放 (a &#x3D; 4) 上的 X 锁。</li>
</ul>
</li>
</ul>
<p>由于两者互相等待、谁都无法前进一步，InnoDB 判定为死锁。</p>
<p><strong>InnoDB 如何选择回滚？</strong></p>
<p>在常见的 AB-BA 死锁（即会话 A 等待会话 B 持有的资源，同时会话 B 等待会话 A 持有的资源）场景中，InnoDB 会回滚产生的事务中undo log 使用量最小的那个，以尽量减少回滚开销。</p>
<p>然而本例中的死锁类型不同：它属于插入意向锁与共享锁（Gap Lock&#x2F;S 锁）之间的循环等待。此时应回滚哪一个事务呢？</p>
<ul>
<li>事务 A：已持有 (a&#x3D;4) 的 X 锁，而正在尝试插入 a&#x3D;3（需要对间隙 <code>(2, 4)</code> 加 X 锁），此时这一步才触发死锁检测；</li>
<li>事务 B：已在时间点 4 提出对 a &lt;&#x3D; 4 范围的 S 锁请求，但尚未获得该锁，处于等待状态。</li>
</ul>
<p>InnoDB 在检测到此时的死锁后，会回滚 undo log 记录量最大的事务。对比：</p>
<ul>
<li>事务 A：已读取并锁定了整行 a&#x3D;4，其 undo log 可能包含对索引与行锁记录的修改；</li>
<li>事务 B：尚未真正获取任何锁（仅在等待）；其 undo log 体积更小。</li>
</ul>
<p><strong>排查死锁的简单流程</strong></p>
<ol>
<li>查看死锁日志 <code>show engine innodb status;</code></li>
<li>找出死锁对应的 SQL</li>
<li>分析这些 SQL 的加锁情况</li>
<li>模拟死锁的发生过程</li>
<li>分析死锁日志</li>
<li>分析死锁结果</li>
</ol>
<h2 id="锁升级"><a href="#锁升级" class="headerlink" title="锁升级"></a>锁升级</h2><p>锁升级（Lock Escalation）是指将当前锁的粒度降低。举例来说，数据库可以把一个表的 1000 个行锁升级为一个页锁，或者将页锁升级为表锁。如果在数据库的设计中认为锁是一种稀有资源，而且想避免锁的开销，那么数据库中会频繁出现锁升级现象。</p>
<p>Microsoft SQL Server 数据库的设计认为锁是一种稀有的资源，在适合的时候会自动地将行、键或分项锁升级为更粗粒度的表级锁。这种升级保护了系统资源，防止系统使用太多的内存来维护锁，在一定程度上提高了效率。</p>
<p>在 Microsoft SQL Server 数据库中，由于锁是一种稀有的资源，因此锁升级会带来一定的效率提高。但是锁升级带来的一个问题却是因为锁粒度的降低而导致并发性能的降低。</p>
<p>InnoDB 存储引擎不存在锁升级的问题。因为其不是根据每个记录来产生行锁，相反，其根据每个事务访问的每个页对锁进行管理的，采用的是位图的方式。因此不管一个事务锁住页中一个记录还是多个记录，其开销通常都是一致的。</p>
<p>也就是说，在 InnoDB 中，每当一个事务要对某个页内的若干行加锁时，会在该页对应的 lock 对象（<code>lock_rec_t</code>）后面附加一个<strong>位图（bitmap）</strong>，用来表示该页内哪些行被锁住了。每条记录在页内有一个唯一的 <code>heap_no</code> 编号，对应到位图中的一个比特位。当事务锁定某行时，就将该行对应 <code>heap_no</code> 的位图位置置为 1。多个行的锁请求会共用同一个 lock 对象，通过设置不同的 bit 来记录多个行锁。该方式极大地减少了内存开销，避免了行级锁的逐个对象管理及锁升级问题。</p>
<p>假设一张表有 3,000,000 个数据页，每个页大约有 100 条记录，那么总共有 300,000,000 条记录。若有一个事务执行全表更新的 SQL 语句，则需要对所有记录加 X 锁。若根据每行记录产生锁对象进行加锁，并且每个锁占用 10 字节，则仅对锁管理就需要差不多 3 GB 的内存。而 InnoDB 存储引擎根据页进行加锁，并采用位图方式，假设每个页存储的锁信息占用 30 个字节，则锁对象仅需 90 MB 的内存。由此可见两者对于锁资源开销的差距之大。</p>
<h2 id="B-树索引中的锁"><a href="#B-树索引中的锁" class="headerlink" title="B+ 树索引中的锁"></a>B+ 树索引中的锁</h2><p>在 InnoDB 源码层面，B+ 树锁通常包含两种基本类型：</p>
<ul>
<li><strong>索引锁（Index Lock）</strong>：对应代码中的 <code>dict_index-&gt;lock</code>，用于保护整个 B+ 树索引结构，主要在结构修改（SMO）时使用。</li>
<li><strong>页锁（Page Lock）</strong>：对应 B+ 树中各数据页的锁变量，用于并发访问控制。非叶子节点页与叶子节点页都可以加锁。</li>
</ul>
<p>在 MySQL 5.6 版本中：</p>
<ol>
<li><strong>查询（SELECT）请求</strong><ul>
<li>首先对 B+ 树索引加一个共享锁（S LOCK），随后仅在找到目标叶子节点后，对该叶子页再次加 S LOCK，然后释放索引锁。</li>
</ul>
</li>
<li><strong>修改（UPDATE&#x2F;DELETE&#x2F;INSERT）请求</strong><ul>
<li>若仅修改叶子页数据：先对索引加 S LOCK，再在找到叶子页后对该叶子页加排它锁（X LOCK），然后释放索引锁。</li>
<li>若修改触发了结构变化（SMO）：<ol>
<li>对整个 B+ 树索引升级为 X LOCK；</li>
<li>执行 <code>btr_cur_search_to_nth_level</code> 定位页面；</li>
<li>在必要时对父节点直到根节点都施加 X LOCK，防止并发干扰。</li>
</ol>
</li>
<li><strong>非叶子节点并不显式加锁</strong>，这导致在 SMO 过程中，查询操作可能被阻塞，产生性能抖动。</li>
</ul>
</li>
</ol>
<p>从 MySQL 8.0 开始，引入了更细化的锁机制：</p>
<ol>
<li><strong>SX 锁（Shared eXclusive Intent Lock）</strong><ul>
<li>在可能发生结构修改时，用于表示预期会写入该分支但尚未真正改动，不会与 S LOCK 冲突，但会与 X LOCK 和其它 SX LOCK 冲突。</li>
</ul>
</li>
<li><strong>非叶子节点页锁</strong><ul>
<li>不再只锁叶子页，而对查找路径上所有非叶子节点页先后加锁（先父后子），实现所谓的锁耦合（Latch Coupling），从而缩小锁范围。</li>
</ul>
</li>
</ol>
<p><strong>B+ 树遍历锁机制：从根到叶</strong></p>
<p>下面以 MySQL 8.0+ 的机制为例，详细描述锁如何从根节点一路向下传递到叶子节点。</p>
<p>这里提前说明，索引锁和根节点的页锁不是一个东西。</p>
<p><strong>读操作</strong></p>
<ol>
<li>申请索引级共享锁（S LOCK on dict_index）<ul>
<li>客户端提交 <code>SELECT … FROM table WHERE key = … FOR UPDATE</code>&#x2F;<code>LOCK IN SHARE MODE</code> 时，InnoDB 会先对目标表的聚簇索引（<code>dict_index</code> 对象）加一个共享锁（S LOCK），用来保证当前索引结构不会被并发的结构修改操作破坏。</li>
</ul>
</li>
<li>从根节点开始逐级查找<ul>
<li>根节点会被先加页级 S LOCK。一旦对根页加锁成功，InnoDB 才继续往下访问子节点。</li>
<li>InnoDB 根据查询条件计算散列，然后通过 <code>btr_cur_search_to_nth_level()</code> 在根节点页中查找下一级页面指针。</li>
</ul>
</li>
<li>加锁子节点并逐步下降<ul>
<li>当从根节点读取到下一层节点的页号后，会释放根节点的 S LOCK，然后对该子节点页加 S LOCK，确保在当前事务继续寻找下一级时，不会遭到并发页分裂或合并等结构修改。</li>
<li>重复上述过程：在子节点加锁成功后，再释放父节点的锁，然后对孙子节点加 S LOCK……如此递归，直到叶子节点。</li>
<li>这种先子后父的锁耦合方式，保证了在任何时刻只有当前路径上的一部分节点被锁住，避免一次性锁定整棵树，提升并发性能。</li>
</ul>
</li>
<li>在叶子节点加锁并释放索引锁<ul>
<li>当定位到叶子节点后，对叶子页加上 S LOCK，并同时在页内搜索目标记录。若是 <code>FOR UPDATE</code>，则将对该记录使用 X LOCK（通过行锁实现）；若是 <code>LOCK IN SHARE MODE</code>，则使用 S LOCK。</li>
<li>此时可以释放最初的索引级共享锁（<code>dict_index-&gt;lock</code>），因为页锁已足以保证后续读取过程中不被结构修改破坏。</li>
</ul>
</li>
</ol>
<p><strong>写操作</strong></p>
<ol>
<li>申请索引级共享锁（S LOCK on <code>dict_index</code>）<ul>
<li>当执行 <code>UPDATE t SET col=… WHERE key=…</code> 时，InnoDB 依旧首先加索引级 S LOCK，防止在查找路径上结构变化。</li>
</ul>
</li>
<li>递归锁定路径上的非叶子节点<ul>
<li>执行与读场景相同的路径查找，但依次对每个非叶子节点页加 S LOCK（并在获得子节点锁后立即释放父节点锁），保证当前页不被分裂或重组删除。</li>
</ul>
</li>
<li>在叶子页加 X LOCK<ul>
<li>定位到叶子页后，加上一个排它锁（X LOCK），并在页内根据 <code>heap_no</code> 对应到位图将该行锁定。此时可释放索引级共享锁（<code>dict_index-&gt;lock</code>）。</li>
</ul>
</li>
<li>执行更新<ul>
<li>对目标记录进行写操作，如更新列值。若更新值导致插入新记录或页内空间不足，就会触发叶子页分裂，此时需要对分裂路径重新加锁。</li>
<li>如果触发了页分裂，则会将当前路径上涉及分裂的非叶子节点也升级为 SX LOCK 或 X LOCK，并相应地执行分裂操作。</li>
</ul>
</li>
<li>完成后释放锁<ul>
<li>事务结束时，InnoDB 会遍历该事务的 <code>trx_locks</code> 链表，逐个释放所有页锁和行锁。</li>
</ul>
</li>
</ol>
<p>这部分的具体内容可参考：<a href="/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/01/25/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/OLTP%20%E7%B4%A2%E5%BC%95/">OLTP 索引</a></p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title>OLAP 索引</title>
    <url>/undefined/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/01/19/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/OLAP%20%E7%B4%A2%E5%BC%95/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h1 id="Data-Skipping"><a href="#Data-Skipping" class="headerlink" title="Data Skipping"></a>Data Skipping</h1><p>我们可以利用辅助数据结构标识表中哪些部分可以跳过扫描，避免对每一行（tuple）都做判断。</p>
<p><strong>OLAP 场景下为什么要用 Data Skipping？</strong></p>
<p>在 OLAP 场景中，查询往往是扫描大量历史数据，筛选满足某种复杂条件的子集，典型例子如数据仓库的多维分析、报表查询等。此时：</p>
<ol>
<li><strong>表非常大</strong>：可能有数十亿、上百亿行，逐行检查每个行是否满足条件，代价非常高。</li>
<li><strong>查询通常按若干列做过滤</strong>：比如 <code>WHERE 年份 = 2024 AND 地区 = &#39;北京&#39;</code>，而且常常只要少量数据就够了（高选择性场景）。</li>
<li><strong>批量扫描 vs. 随机读取</strong>：读整个表，会触发大量 I&#x2F;O；如果能一眼就知道哪些数据页根本不用读，就能省下大量 I&#x2F;O 时间。</li>
</ol>
<p>因此，Data Skipping 的核心思路，就是通过在数据块或分区级别维护一些<strong>辅助信息</strong>，让查询在执行过滤时能够判断“某个数据块（比如一个文件区块、一个数据页、一个段&#x2F;partition）肯定不包含满足过滤条件的行，就直接跳过，不去读取和解析该块中的每一行”，从而大幅减少 I&#x2F;O，以及后续的行级计算。</p>
<p>常见的 Data Skipping 技术主要有以下几类：</p>
<ol>
<li><strong>Zone Map &#x2F; Min-Max 索引</strong><ul>
<li>每个数据块（block 或 segment）存一对最小值和最大值，例如按时间分块后，记录该块中时间列的 [min_timestamp, max_timestamp]。</li>
<li>查询时，如果查询条件为 <code>timestamp BETWEEN &#39;2024-01-01&#39; AND &#39;2024-03-01&#39;</code>，当某个块的最大时间都早于 ‘2024-01-01’，或者最小时间都晚于 ‘2024-03-01’，就可以完全跳过该块。</li>
<li>优点：实现简单、维护开销低；适用于列值分布相对平缓的场景。</li>
<li>缺点：如果一个块里 min–max 范围很宽（分布倾斜或块太大），就容易出现“区间重叠”，跳不过去，效率下降。</li>
</ul>
</li>
<li><strong>位图索引（Bitmap Index）</strong><ul>
<li>针对低基数的列（如性别、地区、状态等），为每个可能的离散取值维护一个位图（bitset）。</li>
<li>每个数据块也可以维护该位图的摘要（比如每 N 行分一个小位图），查询时快速根据位图判断该数据段中是否存在某个值，若不存在就跳过。</li>
<li>优点：在基数较低、数据倾斜度不高时，效果很好；位图操作位运算开销低。</li>
<li>缺点：对于高基数列，位图会很大，且维护成本高。</li>
</ul>
</li>
<li><strong>布隆过滤器（Bloom Filter）</strong><ul>
<li>保存每个数据页中的列值集合的 Bloom Filter，当查询时先检查 Bloom Filter 是否可能包含该值，若 Bloom Filter 结果为不可能存在，则跳过整个页。</li>
<li>优点：Bloom Filter 占用空间小，查询时布尔判断开销低。</li>
<li>缺点：存在误报率（false-positive），即有时候 Bloom Filter 误判可能存在，需要再回退到读页；但绝不会误判真正存在而跳过，保证正确性。</li>
</ul>
</li>
<li><strong>Skip List／Skip Table 结构</strong><ul>
<li>某些列可以对数据块按值范围做多级跳跃索引，比如最外层根据范围将整个表划分为若干区域，里层再分页索引。</li>
<li>OLAP 引擎（如 Apache Parquet、ORC）通常在文件格式层面（列存格式）会同时维护多层次的自底向上的统计信息（Statistics）。</li>
<li>Query Planner 就会根据统计信息决定哪些 Row Group（行组）或 Stride（步长）可以跳过。</li>
</ul>
</li>
<li><strong>分区表（Partitioning）</strong><ul>
<li>将大表水平拆分成多个分区（按时间、地区、业务线等），在查询时如果过滤条件里包含分区键（如 date），可以直接分区剪裁，跳过不相关分区。</li>
<li>其实分区本质也是一种粗粒度的 Data Skipping，跳过整个分区文件。</li>
</ul>
</li>
</ol>
<p><strong>设计 Data Skipping 时的关键考虑点</strong></p>
<p><strong>1. 谓词选择性</strong></p>
<ul>
<li><p><strong>低选择性场景</strong></p>
<p>比如查询 <code>WHERE gender = &#39;M&#39;</code>，如果全表大约一半行都是 <code>gender=&#39;M&#39;</code>，则满足谓词的行很多，跳过就算跳掉了另一半行，也意味着还要扫描一半行，节省有限。</p>
</li>
<li><p><strong>高选择性场景</strong></p>
<p>比如查询 <code>WHERE customer_id = 123456789</code>，或 <code>WHERE event_date = &#39;2025-06-01&#39; AND region = &#39;北京&#39;</code>，只会有极少量行符合条件。此时如果辅助结构能识别掉绝大多数数据块，就能极大节省 I&#x2F;O。</p>
</li>
</ul>
<p><strong>2. 列值分布</strong></p>
<ul>
<li>如果某列的值高度偏斜，例如某个列绝大多数行都是同一个值，其余值极少，Zone Map 或基于统计的跳过就不太准。<ul>
<li>举例：某列几乎全是 ‘A’，只有很少行是 ‘B’，若文件切分并不按照该列聚簇，那么即便大多数块里都是 ‘A’，但每块的最小值&#x2F;最大值同样会显示为 ‘A’，所有块看起来都可能包含 ‘B’，无法跳过。</li>
</ul>
</li>
<li>因此，一般会结合<strong>物理排序（clustering）或分桶（bucketing）</strong>：<ul>
<li>在生成文件时先按该列做排序&#x2F;分桶，这样相同值会被写到同一数据块里；</li>
<li>有了同一数据块里只有一个值的特性，块级统计就变得非常有效。</li>
</ul>
</li>
</ul>
<h1 id="Bitmap-Indexes"><a href="#Bitmap-Indexes" class="headerlink" title="Bitmap Indexes"></a>Bitmap Indexes</h1><p><strong>位图索引</strong>为某个属性（列）的每个不同取值，都存储一份单独的位图，位图中的第 <em>i</em> 位对应了表中第 <em>i</em> 条记录。</p>
<p>对于下表的原始数据：</p>
<table>
<thead>
<tr>
<th>order_id</th>
<th>paid</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>Y</td>
</tr>
<tr>
<td>2</td>
<td>Y</td>
</tr>
<tr>
<td>3</td>
<td>Y</td>
</tr>
<tr>
<td>4</td>
<td>N</td>
</tr>
</tbody></table>
<p>压缩后的数据如下：</p>
<table>
  <thead>
    <tr>
      <th>order_id</th>
      <th colspan="2">paid</th>
    </tr>
    <tr>
      <td></td>
      <td>Y</td>
      <td>N</td>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>

<p>对于多列多值的组合过滤，Bitmap 索引支持高效的按位与（AND）、或（OR）、非（NOT）等位运算。</p>
<p>如果把整个表的行数记为 <em>N</em>，那么一个属性值对应的位图长度就是 <em>N</em> 位。当表非常大（数千万、上亿行），单张位图也会变得很大。为避免一次性分配庞大、连续的内存块，常见做法是分段（segment&#x2F;chunk）：把总行数 <em>N</em> 划分成若干个固定大小的块（例如每块 1 百万行），那么位图也相应地分成若干个子段，每个子段只需要维护该区间内的位。查询时只需要扫描与目标区间重叠的位段。</p>
<p>思考：</p>
<p>为什么使用 Bitmap？</p>
<ol>
<li><p><strong>空间利用率较高</strong></p>
<p>位图本质上是一个位数组，对于低基数或中等基数的列，位图能精确记录行与属性值的映射，且只需 1 位&#x2F;行。</p>
</li>
<li><p><strong>位运算速度快，适合多条件混合过滤</strong></p>
<p>多列过滤条件时，只要获取每个条件对应的位图，对它们做位与&#x2F;或&#x2F;非等操作，就能快速算出满足所有条件的行集合。</p>
</li>
</ol>
<p>为什么位图索引适合压缩？</p>
<ul>
<li>如果某个取值非常稀疏地分布在整个表中，那么位图中绝大多数位都是 0，只有少数位置是 1。或者，若有些连续行都满足该取值，又会出现连续的 1 序列。利用这种长串 0 或长串 1 可用<strong>压缩算法</strong>（如 Run-Length Encoding、WAH、Roaring Bitmap 等）进一步缩小存储空间。</li>
<li>现代 OLAP 引擎（例如 Apache Druid、ClickHouse、Presto 等）在底层都会选择一些成熟的压缩位图实现，这些实现不仅压缩率高，而且能够在压缩态下做位运算，避免了每次查询都需要先把整个位图解压到内存。</li>
</ul>
<h1 id="常见的四种编码技术"><a href="#常见的四种编码技术" class="headerlink" title="常见的四种编码技术"></a>常见的四种编码技术</h1><p>位图索引常见的四种编码技术：等值编码（Equality Encoding）、区间编码（Range Encoding）、分层编码（Hierarchical Encoding）和位切片编码（Bit-sliced Encoding）。</p>
<ol>
<li><p><strong>等值编码</strong></p>
<p>为某一列（属性）中的每个<strong>唯一取值</strong>都维护一份独立的位图。也就是说，如果该列有 m 个不同取值，则总共有 m 个位图，每份位图长度为表的总行数 N。这种编码形式上类似 One-Hot 独热编码。具体示例可参考之前的两张表。</p>
<p>优点：直观简单并且等值查询高效。</p>
<p>缺点：占用大量空间。</p>
</li>
<li><p><strong>区间编码</strong></p>
<p>与等值编码不同，不为每个<strong>单一取值</strong>都建一份位图，而是按照若干有意义的区间（interval）来划分，每个区间对应一份位图。</p>
<p>举例：以一个数值列 age 为例，表中 age 范围在 0–100 岁之间，可以把区间划分为 [0–17]、[18–30]、[31–50]、[51–70]、[71–100]。</p>
<p>为每个区间建一份位图：</p>
<ul>
<li>Bitmap_0_17：标记哪些行的 age 落在 0–17 之间；</li>
<li>Bitmap_18_30：标记哪些行的 age 落在 18–30 之间；</li>
<li>以此类推。</li>
</ul>
<p>优点：适合范围查询并且比等值编码更节省空间。</p>
<p>缺点：区间的粒度需要权衡。划分的区间越细，能更精准地匹配查询，但要维护的位图份数越多；划分区间越粗，则位图份数越少，但位图对应的行集合范围更大，查询时跳过的效率会下降。</p>
</li>
<li><p><strong>分层编码</strong></p>
<p>通过构建<strong>树形层次结构</strong>（hierarchy），在不同层级对值或值范围做<strong>分段统计&#x2F;位图标识</strong>，用于快速识别那些整个子树&#x2F;子范围内没有数据的情况。</p>
<p>通常从较粗的范围到较细的范围构建多层位图：</p>
<ol>
<li>第一层（根层）：记录整个列的全部可能值范围，并标注哪些子范围是非空（或者空）。</li>
<li>第二层：把根层范围继续细分为若干更小区间，分别维护各自的标识。</li>
<li>依次向下，直到最底层是单个取值或某个可接受的最小分区。</li>
</ol>
<p>以一列 zipcode（邮政编码）为例，取值范围是 00000–99999，总计 100,000 个可能值。如果直接对每个具体的 5 位数字都建一份位图，太耗空间。改用分层编码：</p>
<ol>
<li><strong>第一层</strong>：只看邮编的第一位，共 10 种可能（0、1、2、…、9），<ul>
<li>构建 10 个顶层位图，分别标记表中哪些行的 zipcode 第一位是 0、哪些行的第一位是 1，以此类推。</li>
</ul>
</li>
<li><strong>第二层</strong>：假设在第一层为前缀 &#x3D; 3（假设查询潜在目标值的前缀为 3）的情况下，第二层把 zipcode 的前两位 30 ～ 39 这 10 个前缀，各自再建位图；</li>
<li><strong>第三层</strong>：再细分为 300 ～ 309 等前缀，递归向下，直到精确到具体 5 位。</li>
</ol>
<p>优点：快速剪裁空范围且适用于高基数&#x2F;稀疏分布的列。</p>
<p>缺点：存储与维护复杂度更高。需要为每层维护对应的位图，并保持各层之间的一致性。</p>
</li>
<li><p><strong>位切片编码</strong></p>
<p>不是将每个取值或每个区间映射到一份位图，而是针对某个<strong>数值列的二进制表示</strong>，维护<strong>按位的位置拆分的一组位图</strong>。</p>
<p>假设有一个 8 位的整数列，如下：</p>
<table>
<thead>
<tr>
<th><strong>行号</strong></th>
<th>value（原始值）</th>
<th><strong>value（二进制）</strong></th>
<th><strong>Bit_0</strong></th>
<th><strong>Bit_1</strong></th>
<th><strong>Bit_2</strong></th>
<th><strong>Bit_3</strong></th>
<th><strong>Bit_4</strong></th>
<th><strong>Bit_5</strong></th>
<th><strong>Bit_6</strong></th>
<th><strong>Bit_7</strong></th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>5</td>
<td>00000101</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>2</td>
<td>18</td>
<td>00010010</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>3</td>
<td>7</td>
<td>00000111</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>4</td>
<td>25</td>
<td>00011001</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
</tbody></table>
<p>上表中，Bit_0 代表的是最低位，Bit_7 代表最高位。</p>
<p>位切片编码中，如果要基于上表中的数据进行如下条件过滤：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> tbl <span class="keyword">WHERE</span> <span class="keyword">value</span> <span class="operator">&gt;</span> <span class="number">17</span>;</span><br></pre></td></tr></table></figure>

<p>我们先将 17 转换成二进制：10001，并在位切片编码过的位图索引中搜索并过滤：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">10100000</span><br><span class="line">01001000</span><br><span class="line">11100000</span><br><span class="line">10011000</span><br><span class="line">--------</span><br><span class="line">10001000 # 17</span><br></pre></td></tr></table></figure>

<p>我们先找出 17 的最高位是 Bit_4，并得出表中 4 行的这一位以及更高位中只有第 2 和第 4 行是和 17 至少一样大，因此可以快速过滤掉第 1 和第 3 行。</p>
<p>优点：</p>
<ol>
<li><strong>支持任意数值比较</strong>：当需要执行 WHERE value &gt; K 或 WHERE value BETWEEN L AND R 之类的数值比较时，只需根据 K、L、R 的二进制表现，结合多份 Bit_j 位图做<strong>布尔代数运算</strong>（AND、OR、NOT），就能快速构造出满足条件的行号位图。</li>
<li><strong>对高基数数值列尤为合适</strong>：与等值编码相比，高基数字段如果直接为每个取值建位图会产生海量位图；而位切片只需按二进制位宽度建 B 份位图，无论具体取值基数多大，都只需 B 份（例如 32 或 64）位图。</li>
</ol>
<p>缺点：</p>
<ol>
<li><strong>查询时位运算代价较大</strong>：与简单的等值位图（只要读取并返回一份位图）、区间位图（只要读取一份或几份位图）相比，位切片编码在做数值比较或范围查询时，需要对多份位图做组合运算（AND&#x2F;OR&#x2F;NOT），逻辑比较稍复杂，CPU 开销更高。但<strong>总体仍比全表扫描或传统 B+ 树索引的多次随机 I&#x2F;O 要高效得多</strong>，尤其在 OLAP 大规模并行计算场景下，位运算的吞吐量很大。</li>
</ol>
</li>
</ol>
<h1 id="BitWeaving"><a href="#BitWeaving" class="headerlink" title="BitWeaving"></a>BitWeaving</h1><p>BitWeaving 项目由威斯康星大学 Quickstep 团队提出和实现，旨在在主内存分析型 DBMS 中以“裸机”速度运行全表扫描操作  。</p>
<p>它利用处理器的位级并行性，将来自多个元组和列的位在单个时钟周期内同时处理，从而将每列的扫描周期降低到低于 1 个周期的级别 。</p>
<p>为支持复杂谓词评估，BitWeaving 提出了算术框架，将列值编码转换为适合位操作的格式，并生成结果位向量，用于后续布尔组合运算 。</p>
<p><strong>与传统列式存储的比较</strong></p>
<ul>
<li><strong>传统列式存储</strong>：将压缩后或原始列值按值连续存储，为了适配 SIMD 指令集，通常需要将每个值填充到固定边界（如 32 位、64 位），这会造成大量空间浪费，并增加对齐开销 。</li>
<li><strong>SIMD 扫描</strong>：将多个字典编码值打包到 SIMD 寄存器槽中，利用向量指令并行比较，但依然存在填充浪费和对齐处理两个瓶颈 。</li>
<li><strong>BitWeaving&#x2F;V</strong>：将每个列值的同一比特位聚集存储，实现完整利用字宽，且通过“早期剪枝”可在满足或不满足条件时跳过后续比特的处理，极大减少处理位数和内存带宽 。</li>
<li><strong>BitWeaving&#x2F;H</strong>：将编码后的整值按交错方式存储，并在每个值中预留一位结果标记，既可支持快速位级扫描，也可在需要完整重构列值时一次性提取，兼顾扫描和输出需求 。</li>
</ul>
<p>BitWeaving 包括两种主要存储布局：</p>
<ul>
<li><strong>BitWeaving&#x2F;Vertical</strong>：按位平面（bit-plane）垂直存储，每个比特位平面连续排列，天然支持按位剪枝；</li>
<li><strong>BitWeaving&#x2F;Horizontal</strong>：按元组水平交错存储，附加一位用于记录谓词结果，便于整值提取和多阶段谓词级联</li>
</ul>
<p>以下详细说明 Horizontal 和 Vertical Storage。</p>
<h2 id="Horizontal-storage"><a href="#Horizontal-storage" class="headerlink" title="Horizontal storage"></a>Horizontal storage</h2><p>把每条记录的全部 k 位 code 串成一块，按记录依次存放。</p>
<p>在内存中，一个 SIMD 寄存器会同时装入多条记录的全部位，对这些记录做并行比较。</p>
<p>我们以某个整数类型的字段为例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Segment#1:</span><br><span class="line">t0: bits=[0, 0, 1] -&gt; 1</span><br><span class="line">t1: bits=[1, 0, 1] -&gt; 5</span><br><span class="line">t2: bits=[1, 1, 0] -&gt; 6</span><br><span class="line">t3: bits=[0, 0, 1] -&gt; 1</span><br><span class="line">t4: bits=[1, 1, 0] -&gt; 6</span><br><span class="line">t5: bits=[1, 0, 0] -&gt; 4</span><br><span class="line">t6: bits=[0, 0, 0] -&gt; 0</span><br><span class="line">t7: bits=[1, 1, 1] -&gt; 7</span><br><span class="line"></span><br><span class="line">Segment#2:</span><br><span class="line">t8: bits=[1, 0, 0] -&gt; 4</span><br><span class="line">t9: bits=[0, 1, 1] -&gt; 3</span><br></pre></td></tr></table></figure>

<p>以上内容中，t0 到 t9 为行号，bits 为该字段的二进制表示，箭头右边的是原始数据。全部的数据被分成了多个段。</p>
<p>假设一个处理器 word 只能容纳 8 个 bit 用于并行处理，那么以上代码块中的内容会被表示为如下结构：</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_bitweaving_h.drawio.png" alt="img"></p>
<blockquote>
<p>[!NOTE]</p>
<p><strong>Word</strong> 是处理器一次能够自然处理的固定长度数据单元，其长度称为<strong>字长</strong>（word length 或 word size），通常是处理器数据总线宽度的整数倍或分数。字长决定了CPU在单次操作中能读取、写入或传输的数据量，同时影响指令长度、寄存器宽度、寻址能力等关键特性。</p>
</blockquote>
<p>如果要处理如下 SQL 指令：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> tbl <span class="keyword">WHERE</span> val <span class="operator">&lt;</span> <span class="number">5</span>;</span><br></pre></td></tr></table></figure>

<p>那么会进行如下 SIMD 计算（以 t0 和 t4 为例）：</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_bitweaving_h_cal.drawio.png" alt="img"></p>
<p>最终，分割符为 1 的就是符合条件的数据。</p>
<p>但是之后我们需要如何汇总所有的过滤结果来确定要获取哪些数据呢？</p>
<p>我们可以通过 shift 操作输出所有的过滤结果到一个 bitmap 中，这个 bitmap 的每一位对应表中数据的行号。我们以 Segment#1 为例给出汇总过程：</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_bitweaving_h_bitmap.drawio.png" alt="img"></p>
<p>上图中的位图也被称为 selection vector。</p>
<p>现在我们汇总得到了哪些数据符合条件以及哪些不符合，那要如何转成实际的下标或者是偏移量呢？</p>
<p>有两种常见的方法：</p>
<ol>
<li><p>迭代扫描</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;Integer&gt; sel = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; N; i++) &#123;</span><br><span class="line">  <span class="keyword">if</span> (selectionVector[i] == <span class="number">1</span>) &#123;</span><br><span class="line">    sel.add(i);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>优点</strong>：实现简单，不需要预处理。</p>
<p><strong>缺点</strong>：每次都要检查 N 位，分支预测失效会有开销；对于高选择率或低选择率都要遍历全阵列。</p>
</li>
<li><p>预计算位置表</p>
<p>把 selection vector（这里是 8 位）转换成十进制数据作为表的 key，而下标数组作为 payload。</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_bitweaving_h_pre_tbl.drawio.png" alt="img"></p>
<p><strong>优点</strong>：避免了每个位的分支判断，大大提高吞吐；字节级批量处理，利用了查表的连续读缓存。</p>
<p><strong>缺点</strong>：需要额外的 256 条查表开销，及存储这些小列表。</p>
</li>
</ol>
<h2 id="Vertical-storage"><a href="#Vertical-storage" class="headerlink" title="Vertical storage"></a>Vertical storage</h2><p>把所有记录在同一位位置 i 上的 bit 聚到一起，形成一条长长的位向量，然后依次存放各个位向量（从最低位到最高位）。</p>
<p>在内存中，一个 SIMD 寄存器会拿到同一位向量的一大段数据，一次性对所有记录的该位进行逻辑运算。</p>
<p>还是用之前的例子，数据如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Segment#1:</span><br><span class="line">t0: bits=[0, 0, 1] -&gt; 1</span><br><span class="line">t1: bits=[1, 0, 1] -&gt; 5</span><br><span class="line">t2: bits=[1, 1, 0] -&gt; 6</span><br><span class="line">t3: bits=[0, 0, 1] -&gt; 1</span><br><span class="line">t4: bits=[1, 1, 0] -&gt; 6</span><br><span class="line">t5: bits=[1, 0, 0] -&gt; 4</span><br><span class="line">t6: bits=[0, 0, 0] -&gt; 0</span><br><span class="line">t7: bits=[1, 1, 1] -&gt; 7</span><br><span class="line"></span><br><span class="line">Segment#2:</span><br><span class="line">t8: bits=[1, 0, 0] -&gt; 4</span><br><span class="line">t9: bits=[0, 1, 1] -&gt; 3</span><br></pre></td></tr></table></figure>

<p>在 Vertical Storage 中，以上数据会被表示为以下结构：</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_bitweaving_v.drawio.png" alt="img"></p>
<p>也就是说，同一 segment 的 bits 数组中的同一下标的数据会被放到一个 word 中处理。</p>
<p>如果我们要处理如下命令：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> tbl <span class="keyword">WHERE</span> val <span class="operator">=</span> <span class="number">2</span>;</span><br></pre></td></tr></table></figure>

<p>会进行如下计算：</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_bitweaving_v_cal.drawio.png" alt="img"></p>
<p>这里在处理完 col1 之后，我们观察到结果已经全是 0（即没有任何记录同时满足前两位匹配），就可以 <strong>跳过</strong> 第三轮比较（早剪枝），直接得出最终结果全 0。</p>
<p>优点：</p>
<ul>
<li>极高的查询性能：在 OLAP 场景下，Bit Weaving 能在压缩数据上直接进行位运算（如 AND、OR、XOR 等），极大提升聚合、过滤、排序等操作的速度。</li>
<li>空间效率高：采用位存储和压缩技术，极大节省磁盘和内存空间，同时也减少了 I&#x2F;O 成本。</li>
<li>良好的向量化和 SIMD 支持：在现代 CPU（如 AVX、SSE）下可充分利用 SIMD 指令集，实现高并发、高吞吐量的位级操作。</li>
</ul>
<p>缺点：</p>
<ul>
<li>对点查询不友好：相较于 B+ 树等结构，Bit Weaving 在单点查找或小范围查找时效率较低，主要优势在大范围数据扫描和聚合分析中。</li>
</ul>
<h1 id="近似位图索引"><a href="#近似位图索引" class="headerlink" title="近似位图索引"></a>近似位图索引</h1><p>传统的位图索引对每一个值都精确地维护一个 bitmap，而近似位图索引只保留粗略信息，牺牲部分准确性（即可能出现 false positives，假阳性），以便在常见查询场景下更快速地过滤大部分不匹配的元组。</p>
<p>当位图判断某条记录可能匹配时，还需要回到原始数据进行最后一次精确检查，从而消除 false positives。</p>
<p><strong>两种主流技术</strong></p>
<ul>
<li><p><strong>Column Imprints（列印迹）</strong></p>
<p>将列值按块（如每 64 或 128 个值）划分，对每个块维护一个小位图，位图的每一位对应一个值范围（bucket）。</p>
<p>查询时只需查块级位图，快速过滤掉整个块都不可能包含目标值的部分；再对剩余块逐条扫描。</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_approx_bitmap_col.drawio.png" alt="img"></p>
<p>或者更通用的方式是：</p>
<p>在 Column Imprint 中，每个 0 或 1 表示的是缓存行中的信息。具体来说，每一位表示某个直方图区间是否在对应的缓存行中有数据值：</p>
<ul>
<li><p>如果缓存行中的某些值落入某个区间，则该区间对应的位被设置为 1；</p>
</li>
<li><p>如果缓存行中的数据都不在该区间中，则该区间对应的位为 0。</p>
</li>
</ul>
<p>一个缓存行可以包含多个数据值（例如 64 字节的数据）。Column Imprint 并不记录每个数据值的精确位置，而是粗粒度地表示这些值的分布范围。</p>
<p>同样用之前的例子，假设缓存行中有三个值：1，8，4。</p>
<p>这些值会被映射到直方图的不同区间，例如：值 1 属于区间 [1, 2)；值 8 属于区间 [8, 9)；值 4 属于区间 [4, 5)。</p>
<p>最终的位向量可能是 10010001，其中：第 1 位表示缓存行中有值落入区间 [1, 2)；第 4 位表示缓存行中有值落入区间 [4, 5)；第 8 位表示缓存行中有值落入区间 [8, 9)。</p>
<p>如果之后要查询如 <code>val BETWEEN 4 AND 8</code> → 对应要检查的 bins 为 B₃…B₇ → mask &#x3D; 00011111：</p>
<ul>
<li>位向量 <code>AND mask</code> ≠ 0 → 说明该缓存行<strong>可能</strong>包含符合条件的值 → 需要回表做精确过滤；</li>
<li>位向量 <code>AND mask</code> &#x3D; 0 → 直接跳过整个缓存行。</li>
</ul>
</li>
<li><p><strong>Column Sketches（列摘要&#x2F;草图）</strong></p>
<p>用固定长度码（通常只有几位）替代完整位图。每个记录只存一个小码，表示它属于哪几个预定义区间。</p>
<p>整体流程如下：</p>
<p>首先根据列的值分布，在直方图中将整个值域划分成若干区间。之后为每个区间分配一个固定长度的二进制码，每条记录的 sketch，就是它所属区间的那个短码。</p>
<p>假设原数据为 [13, 191, 56, 92, 81, 140, 231, 172]，那么分布直方图和用于映射区间和 compression map 如下：</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_approx_bitmap_skch_hist.drawio.png" alt="img"></p>
<p>map 中的对应关系代表：小于 60 的数据映射到 00 代码，小于 132 大于 60 的数据映射到 01 代码，以此类推。</p>
<p>因此原数据对应的 sketched column 为：[‘00’, ‘11’, ‘00’, ‘01’, ‘01’, ‘10’, ‘11’, ‘11’]。</p>
<p>此时，如果我们要执行如下命令：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> tbl <span class="keyword">WHERE</span> val <span class="operator">&lt;</span> <span class="number">90</span>;</span><br></pre></td></tr></table></figure>

<p>首先会确定要在区间 [0, 60] 和 (60, 132] 中找数据，接着对于代码为 00 的数据可直接确定为符合条件，对于代码为 01 的数据则要回表查看实际数据是否小于 90。</p>
<p>也就是，对于 [‘00’, ‘11’, ‘00’, ‘01’, ‘01’, ‘10’, ‘11’, ‘11’] 中的 01，我们要查看原数据，分别是 92 和 81，92 &gt; 90，因此排除掉 92，保留 81。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>高级数据存储</category>
      </categories>
  </entry>
  <entry>
    <title>编译查询的自适应执行</title>
    <url>/undefined/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/03/01/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Review%20Report%20-%20Adaptive%20Execution%20of%20Compiled%20Queries/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>该论文解决了三个问题：</p>
<ol>
<li>如何减少复杂但快速查询的编译时间？</li>
<li>如何减少极大查询的编译时间？</li>
<li>如何减少首次传入查询的编译时间？</li>
</ol>
<p>论文提出了两个新颖的想法，并详细阐述了每个想法的实现方法：</p>
<ol>
<li><strong>自适应执行 (Adaptive execution)：</strong> 对于特定的查询流水线（pipeline），该方案跟踪工作线程的进度，基于流水线中所有线程的整体状态预测三种执行模式下剩余工作负载的持续时间，最终选择持续时间最短的模式应用于所有线程。</li>
<li><strong>快速字节码解释 (Fast bytecode interpretation)：</strong> 基于寄存器机器，该方案通过按区间（intervals）处理基本块（basic block）并利用并查集（disjoint set）和路径压缩（path compression）等算法，实现了线性时间的活性计算（liveness computation），从而进一步优化了寄存器分配。此外，字节码解释器的行为与生成的机器码等效，确保了在解释执行和机器码执行之间可以无缝切换。</li>
</ol>
<p>分析与实验结果：对于不同的比例因子（scale factors），自适应执行能够切换到具有最优性能的模式，确保相比其他静态模式选择具有最低的执行时间。在行动方面，自适应执行能够立即在所有可用工作线程上开始处理流水线分片（pipeline morsels），并对工作负载繁重的流水线进行动态模式切换，使其完成查询的速度比竞争对手快10%、40%和80%。虽然解释执行的代码比编译后的代码慢，但它比PostgreSQL快，并且在使用多核时能像编译代码一样扩展。此外，字节码解释器具有完美的扩展性，能够在短时间内处理大型查询。</p>
<h1 id="论文优势"><a href="#论文优势" class="headerlink" title="论文优势"></a>论文优势</h1><ul>
<li>论文清晰详尽地描述了待解决的问题。在第二节中，通过流程图展示了SQL查询在HyPer中的多步骤处理过程，并强调LLVM编译任务占据了总执行时间的大部分。通过比较在比例因子1的TPC-H Query 1上不同执行模式的编译和执行时间，论文引入了解释器和编译器之间的权衡，论证了可以对同一查询的不同部分应用不同的执行模式。此外，论文分析了最大的TPC-H和TPC-DS查询，得出结论：编译时间随查询规模呈超线性增长。</li>
<li>论文提供了全面的文献综述。在第六节中，引用了其他关于编译时间的研究论文中的实验结果，得出结论：编译到LLVM中间表示（IR）比编译到C语言更快。基于实践经验，论文强调查询编译延迟在生产环境中成为一个主要问题，这使得自适应执行成为使查询编译真正实用化的关键组件。随后探讨了将自适应执行集成到MemSQL、LegoBase和Microsoft Hekaton等数据库系统中的可行性。此外，论文展示了自适应执行相对于自动计划缓存（automatic plan caching）的优势，即能够在每次执行时重新优化查询。最后，讨论了自适应执行与编程语言中执行引擎（如JVM、V8和CLR）的异同。</li>
<li>论文取得了显著的改进，即线性时间的活性计算。传统逐个基本块计算活性的解决方案通常需要$O(n^2)$的运行时间。然而，论文提出了一种线性时间算法。该算法以逆后序（reverse postorder）标记所有基本块并将其组织成支配树（dominator tree），这使得解释器能够在$O(1)$时间内确定基本块之间的关系，并为识别循环铺平了道路。它通过使用带路径压缩的并查集（disjoint set with path compression）来识别每个基本块的最内层封闭循环（innermost enclosing loop），并基于与某个值的定义和使用相关的基本块分布来确定该值的生命周期。该计算的低成本主要归功于采用了适当的数据结构。</li>
</ul>
<h1 id="论文不足"><a href="#论文不足" class="headerlink" title="论文不足"></a>论文不足</h1><ul>
<li>论文未清晰解释基本概念。在第二节中，没有解释延迟和吞吐量在HyPer上下文中的具体含义，以及两者之间的关系，因此读者可能无法认识到权衡的重要性，也可能不理解后续实验结果中性能提升是如何实现的。例如，读者可能无法理解为什么解释器能通过牺牲吞吐量来实现非常低的延迟。因此，论文应解释这些概念。</li>
<li>论文的实验不够全面。作为数据处理和存储的核心组件，自适应执行框架仅被证明在执行时间上具有优势，而缺乏展示其物理设备利用率、稳定性和故障恢复性能的实验。这些指标对于评估框架的整体性能同样至关重要。例如，对于同一组查询，如果执行时间短但CPU和内存使用率极高，或者抛出异常的概率高且需要大量时间进行故障恢复，那么该框架仍有改进空间。因此，论文应包含这些指标的实验结果。</li>
<li>论文未详细解释如何翻译成虚拟机代码。在第四节B小节中，论文提到被归约（subsumed）的指令不会被翻译，但未具体说明哪些类型的指令会被归约，或者以何种方式被归约。这些遗漏会使读者感到困惑，阻碍他们对翻译伪代码的理解。因此，论文应解释归约指令背后的原理。</li>
</ul>
<p>参考文献: <a href="https://db.in.tum.de/~leis/papers/adaptiveexecution.pdf">https://db.in.tum.de/~leis/papers/adaptiveexecution.pdf</a></p>
]]></content>
      <categories>
        <category>高级数据存储</category>
      </categories>
  </entry>
  <entry>
    <title>AnalyticDB - 阿里云的实时 OLAP 数据库系统</title>
    <url>/undefined/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/01/24/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Review%20Report%20-%20AnalyticDB%20Real-time%20OLAP%20Database%20System%20at%20Alibaba%20Cloud/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>该论文解决了三个问题：</p>
<ol>
<li>如何以低延迟处理用户更复杂多样的查询；</li>
<li>如何设计一种友好且统一的数据布局，使其兼容列式存储和行式存储，能够处理复杂数据类型，并保持低延迟；</li>
<li>如何以低延迟处理每秒海量请求。</li>
</ol>
<p>该论文提出了 5 个创新性想法，并详细阐述了每个想法的实现方法：</p>
<ol>
<li><strong>读写分离：</strong> 工作节点专用于处理读操作或写操作，确保读操作不会干扰写操作。在实时读模式下，引入版本验证机制（<code>最新版本 = max(V₁, V₂)</code>）以保证每次查询都能检索到最新数据。此外，每次写操作完成后，写节点会主动将最新版本拉取到相应的读节点，以避免后续读操作出现高延迟。</li>
<li><strong>混合行列存储：</strong> 用于存储复杂类型数据。一个明细文件 (detail file) 由 <code>n</code> 个行组 (row group) 组成；一个行组由 <code>k</code> 个数据块组成；一个数据块由 <code>p</code> 个 FBlock 组成；一个 FBlock 存储一个或多个行的部分行中某一列的 <code>x</code> 个值。</li>
<li><strong>高效索引管理：</strong> 包括对基线数据和增量数据的索引构建与维护。对于基线数据，AnalyticDB 构建倒排索引并引入过滤比 (filter ratio) 来优化读操作。对于增量数据，AnalyticDB 在读节点上构建轻量级的排序索引，以加速在完成该类型数据的倒排索引异步构建之前的读操作。</li>
<li><strong>优化器：</strong> AnalyticDB 引入了 STARs 框架来同时评估存储能力和关系代数能力，并采用动态规划技术，以实现高效的谓词下推 (predicate push-down)。该数据库最小化了联接下推 (join push-down) 所需的表重排 (shuffling) 成本。对于基于索引的联接和聚合，它采用左深树 (LeftDeepTree) 来高效利用全列索引 (index-on-all-columns)，同时下推谓词和聚合操作。此外，优化器和执行引擎采用基于采样的基数估计 (cardinality estimation)，辅以缓存先前采样结果、优化的采样算法和改进的派生基数 (derived cardinality)。</li>
<li><strong>执行引擎：</strong> 能够直接在序列化的二进制数据上操作，而非 Java 对象，从而消除了在大数据重排过程中序列化和反序列化的高昂开销。</li>
</ol>
<p><strong>分析与实验结果：</strong> 在 1TB 数据集上，AnalyticDB 的性能优于 PrestoDB、Druid、Spark SQL 和 Greenplum，并且在扩展到 10TB 数据集时，其性能未受到显著影响。随着写节点数量的增加，AnalyticDB 的写入吞吐量呈现稳定增长。在 TPC-H 基准测试中，AnalyticDB 在 22 个查询中的 20 个上，其完成时间仅为次快数据库所需时间的一半。然而，对于查询 2，由于选择了不同的联接顺序，AnalyticDB 的速度慢于 PrestoDB 和 Greenplum。</p>
<h1 id="论文优势"><a href="#论文优势" class="headerlink" title="论文优势"></a>论文优势</h1><ul>
<li>论文中概述的 3 项挑战精准地指向了 OLAP 系统在实现实时高效响应时所面临的关键障碍。解决这些挑战不仅能显著提升数据库对多样化查询和复杂数据类型的兼容性，还能改善其在生产环境中的响应能力，突显了其高度的研究价值。读写分离与版本验证的结合确保了读写操作的隔离性，同时始终为读查询提供最新数据。混合数据布局和索引的设计融入了对 JSON、全文和向量数据等复杂数据类型的支持，为多样化的数据操作提供了统一的访问接口。这极大地拓宽了 AnalyticDB 在更广泛用例中的适用性。此外，执行引擎将基于采样的基数估计与缓存、优化的采样算法等技术相结合，以低开销和最小延迟实现了高精度的估计。总而言之，AnalyticDB 引入的改进和优化方案代表了在增强 OLAP 系统数据多样性和实时响应能力方面迈出的重要一步，其综合性解决方案将在高并发电商场景中充分展现其能力。</li>
<li>论文提供了全面的文献综述。第 2 节 Related Work 讨论了不同数据库的不足。例如，OLTP 数据库中昂贵的索引更新会降低吞吐量并增加延迟；而 OLAP 数据库（如 TeradataDB 和 Greenplum）中的列式存储会导致点查 (point-lookup) 查询产生高昂的随机 I&#x2F;O 成本。上述问题在 AnalyticDB 中得到了有效解决。此外，论文还概述了 AnalyticDB 相较于 Amazon Redshift 的改进，以及与 Google BigQuery 在查询和聚合方面的差异。</li>
<li>论文详细描述了 AnalyticDB 中各项功能的过程，包括：<ol>
<li>从读和写两个角度对读写分离过程进行了透彻的解释，并附有流程图专门说明更复杂的读操作。</li>
<li>查询执行 (Query Execution) 涉及的 3 个算法的关键指令的伪代码和注释。</li>
<li>将基线数据与增量数据合并过程分解为 3 个阶段的示意图。</li>
</ol>
</li>
</ul>
<h1 id="论文不足"><a href="#论文不足" class="headerlink" title="论文不足"></a>论文不足</h1><ul>
<li>论文中对某些功能的描述不够完整。在论文第 3.4 节 Read&#x2F;Write Decoupling 中，仅提到了实时读 (real-time read)，而遗漏了有限延迟读 (bounded-staleness read)。对于 OLAP 而言，读取过时数据是可以接受的，有限延迟读允许读节点在写操作完成后的特定延迟之后才访问写节点上的最新数据，因此它在一定程度上确保了 AnalyticDB 的快速响应。然而，论文中并未解释这种读取模式。</li>
<li>论文对某些新引入概念的描述不够清晰。在第 5.1.1 节中，关于谓词下推的讨论仅对 STARs 框架做了简要概述，没有解释它如何应用关系代数、如何进行成本计算，以及优化器如何使用动态规划来封装关系代数运算符。这些遗漏可能会让读者感到困惑。</li>
<li>论文中的性能评估实验相对简单。首先，仅测试了 3 条 SQL 语句，覆盖的查询类型范围狭窄，且仅针对特定的表分区策略、特定的表和字段以及特定的数据类型。测试并未涉及如 JSON 等复杂数据类型。其次，实验仅测试了 1TB 和 10TB 的数据集。然而，在生产环境中，每日新增数据量可达数十甚至数百 PB。在双 11 或 618 等高峰促销日，每日数据处理量可达数百甚至数千 PB。例如，在 2022 年双 11 期间，淘宝和天猫的订单支付峰值达到每秒 583,000 笔。因此，实验所用的数据集远远不足以反映真实场景的规模。第三，基于 TPC-H 基准的测试仅评估了 22 个查询，不足以全面反映这 5 个数据库的真实性能。因此，建议纳入生产环境中涉及的所有数据和查询，例如 MySQL binlog、ElasticSearch 索引日志和 Kafka 日志等，并在这 5 个数据库上开展为期一周或更长时间的稳定性测试，以提供更真实的评估。</li>
</ul>
<p>参考文献：<a href="https://www.vldb.org/pvldb/vol12/p2059-zhan.pdf">https://www.vldb.org/pvldb/vol12/p2059-zhan.pdf</a></p>
]]></content>
      <categories>
        <category>高级数据存储</category>
      </categories>
  </entry>
  <entry>
    <title>内存优化数据库中的冷数据管理</title>
    <url>/undefined/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/04/05/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Review%20Report%20-%20Managing%20Cold%20Data%20in%20a%20Memory-Optimized%20Database/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>该论文解决了两个问题：</p>
<ol>
<li>如何将记录迁移到冷存储以及从冷存储迁出。</li>
<li>如何以事务一致的方式读取和更新冷存储中的记录。</li>
</ol>
<p>论文提出了三个新颖的想法，并详细阐述了每个想法的实现方法：</p>
<ol>
<li><strong>统一的接口，向高层隐藏记录的物理位置</strong>：通过冷存储、访问过滤器、私有缓存和更新备忘录之间的协作实现。</li>
<li><strong>最小化访问二级存储带来的开销</strong>：每个事务拥有自己的私有缓存。</li>
<li><strong>热存储与冷存储之间的无缝迁移</strong>：系统在事务中使用插入和删除操作执行迁移。</li>
</ol>
<p>分析与实验结果：论文在 YCSB 基准测试和多步骤读&#x2F;更新工作负载上评估了 Siberia 的性能，得出以下结论。在现实的客户端延迟下，吞吐量损失仅为 3%。即使在极高的冷数据访问率下，内存中的 Siberia 机制也仅带来较低的性能损失。当实时迁移激活时，系统性能保持稳定。访问备忘录的开销较大，这意味着备忘录清理对于提高性能很重要。在冷数据访问率为 5% 和 10% 的现实场景下，只读事务的性能损失分别为 7% 和 14%，这是可接受的。对于纯更新事务，5% 的冷数据更新导致 8% 的吞吐量损失，10% 的冷数据更新率导致 13% 的吞吐量损失，同样可接受。在 YCSB 工作负载下，随着访问偏斜度降低以及内存与数据库大小比例增加，性能会下降；与写密集型工作负载相比，读密集型工作负载在更高的偏斜率下表现出更低的事务中止率。</p>
<h1 id="论文优势"><a href="#论文优势" class="headerlink" title="论文优势"></a>论文优势</h1><ul>
<li><strong>论文提供了全面的文献综述</strong>。在 HEKATON 存储与索引 部分，论文简要概述了 HEKATON 的索引和数据存储结构及其基于 MVCC（多版本并发控制）的读写操作。在 RELATED WORK 部分，论文分析了现有数据库系统如何处理冷数据，解释了 Hyper 使用虚拟页管理冷数据，Stoica 等人提出将热冷数据分离到不同的内存位置。最后，论文描述了反缓存（anti-caching）的工作原理，并指出了其两个缺点：节省空间有限和重复执行。</li>
<li><strong>论文详细描述了将 SIBERIA 集成到 HEKATON 后的工作原理</strong>。它展示了数据迁移到冷存储期间使用的两种事务的工作流程。插入和更新操作确保数据被放入热存储，以避免检查冷存储的开销。删除和读取操作利用更新备忘录中的通知执行并发控制和冲突检测。冷存储清理也由更新备忘录驱动，这使得可以及时从冷存储中移除对任何活跃事务都不可见的记录。此外，验证阶段也利用更新备忘录中的通知，并计算 <code>TsBoundSer</code> 以确保可串行化事务的正确性，从而增强了幻读检测。</li>
<li><strong>论文呈现了相对全面的实验</strong>。实验基于 YCSB 基准测试和多步骤读&#x2F;更新工作负载，这可以测试 Siberia 在不同工作负载下的性能。此外，论文评估了 Siberia 的纯内存开销、运行实时迁移的开销以及访问冷记录路径上更新备忘录的开销。并且，在 YCSB 工作负载下，展示了工作负载偏斜度、内存与数据库大小比率与工作负载性能之间的关系。</li>
</ul>
<h1 id="论文不足"><a href="#论文不足" class="headerlink" title="论文不足"></a>论文不足</h1><ul>
<li><strong>论文未在代码层面描述 Siberia 集成到 HEKATON 的过程</strong>，仅提到了在数据处理和存储机制层面进行集成。它详细描述了冷数据迁移过程，并解释了插入、删除、读取和更新操作中的更新备忘录通知如何与 HEKATON 的版本控制和并发控制协作。然而，论文未涉及 Siberia 如何在代码层面（如识别核心函数、代码段及相应修改）集成到 HEKATON。这一缺失使得读者难以轻松复现 Siberia。因此，论文至少应提供代码修改的概要说明。</li>
<li><strong>在 Synthetic End-to-End Workload 部分，论文未讨论中等至高冷数据访问率下的吞吐量损失</strong>。论文仅展示了在 5% 和 10% 冷数据访问率下的吞吐量损失，并声称这些是现实的冷数据访问率。首先，在 Read-Only Transactions 部分，论文未能说明是哪个报告或文献支持 5% 和 10% 是“真实的冷数据访问率”。其次，即使假设上述数据是准确的，论文也未描述当冷数据访问率超过 10% 时，吞吐量损失如何变化。这一缺失使读者无法全面了解 Siberia 处理工作负载的性能。因此，论文应解释“现实的冷数据访问率”是如何确定的，并描述在中等至高冷数据访问率下吞吐量损失的变化情况。</li>
<li><strong>论文未讨论 Siberia 的性能限制或其性能可能下降的条件</strong>，尽管实验部分展示了令人印象深刻的性能。这种优异的性能可能是以高硬件利用率（如高 CPU 使用率）为代价获得的。或者，将 Siberia 集成到 HEKATON 中虽然增强了热冷数据处理能力，但可能损害了 HEKATON 原有的某些特性。因此，论文应阐明 Siberia 性能可能下降的情形。</li>
</ul>
<p>参考文献: <a href="https://www.vldb.org/pvldb/vol7/p931-eldawy.pdf">https://www.vldb.org/pvldb/vol7/p931-eldawy.pdf</a></p>
]]></content>
      <categories>
        <category>高级数据存储</category>
      </categories>
  </entry>
  <entry>
    <title>Orca - 面向大数据的模块化查询优化器架构</title>
    <url>/undefined/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/02/10/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Review%20Report%20-%20Orca/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>本文解决了两个问题：</p>
<ol>
<li>如何设计一个能够处理大数据和复杂分析查询，同时确保生成高效查询计划的查询优化器。</li>
<li>探索高级查询优化理论在生产环境中的应用。</li>
</ol>
<p>本文提出了4个新颖的想法，并详细阐述了每个想法的实现方法：</p>
<ol>
<li><strong>通过DXL将优化器与数据库系统解耦</strong>：不同的数据库系统需要实现3个转换器（Query2DXL、MD Provider 和 DXL2Plan）来支持Orca。</li>
<li><strong>使用Memo和组哈希表进行优化</strong>：Memo中的每个组存储给定操作的所有逻辑等价表达式（包括强制执行运算符）。组哈希表记录每个优化请求的最优实现（即最佳组表达式）。在查询优化期间，通过检索每个组及其子组对应于给定优化请求的最佳组表达式（best GExprs），将这些最佳GExprs链接在一起形成最佳执行计划。</li>
<li><strong>利用作业依赖图和作业队列实现并行查询优化</strong>：如果一个组当前正在处理一个优化作业，其他作业将被放入队列等待。一旦作业完成，其结果可供后续作业利用。</li>
<li><strong>开发高效的测试工具</strong>：AMPERe用于捕获错误并生成转储文件以供后续重放调试。TAQO基于优化请求的链接结构均匀采样计划，并通过计算基于估计成本的采样计划排序与基于实际成本的排序之间的相关性得分，来评估优化器的准确性。</li>
</ol>
<p>分析与实验结果：基于TPC-DS基准测试，使用有限的查询集测试了GPDB传统查询优化器（111个查询，MPP）和Orca，以及Impala（31个查询，Hadoop）、Stinger（19个查询，Hadoop）、Presto（12个查询，Hadoop）和HAWQ。结果表明，在80%的查询执行中，Orca的性能匹配或优于GPDB优化器。对于14个查询，Orca相比GPDB优化器实现了至少1000倍的加速比。Presto在所有测试条件下均未能处理任何TPC-DS查询，而HAWQ上的查询执行性能普遍优于Impala和Stinger。</p>
<h1 id="论文优势"><a href="#论文优势" class="headerlink" title="论文优势"></a>论文优势</h1><ul>
<li><strong>论文提供了全面的文献综述</strong>，并涵盖了理解Orca所需的预备知识。在 PRELIMINARIES 部分，论文简要分析了GPDB，解释了其3个核心组件：主节点（master）、段节点（segments）和互联层（interconnect layer）；阐述了SQL和查询优化器如何集成到Hadoop等大数据处理组件中；并分析了由Orca优化的HAWQ架构相比Impala和Presto的优势。在 RELATED WORK 部分，论文介绍了Volcano和Cascades框架，强调Cascades比Volcano提供了更大的灵活性；随后讨论了MPP数据库中各种面向大数据的查询优化器实现，如PDW和SCOPE；最后回顾了将SQL与Hadoop集成的现有努力，例如将查询转换为MapReduce作业（Hive）以及数据库管理系统与Hadoop技术的共置（Hadapt）。</li>
<li><strong>论文提出了针对大数据查询优化的极具价值的解决方案：DXL和并行查询优化</strong>。不同的数据库只需实现各自的Query2DXL和DXL2Plan转换器即可实现与Orca的兼容，这赋予了Orca适配任何现有数据库系统的潜力。为满足大数据的核心需求——并发处理，Orca构建了优化作业依赖图来确定作业间的依赖关系。父作业必须在其子作业完成后才能执行，而独立的作业可以并行运行。为处理资源争用，Orca将传入的作业放入作业队列中等待，直到正在运行的作业完成。这些等待的作业随后可以利用已完成作业生成的结果。</li>
<li><strong>论文在 QUERY OPTIMIZATION 部分详细阐述了Orca优化的步骤</strong>。在探索（Exploration）阶段，Orca创建逻辑等价表达式并使用Memo进行去重。在统计推导（Statistics Derivation）阶段，Orca估算Memo组的基数和数据倾斜。在实现（Implementation）阶段，Orca生成逻辑表达式的物理实现。在优化（Optimization）阶段，生成多个执行计划（必要时包含强制执行运算符），然后使用成本模型选择成本最低的执行计划。这些细节有效地帮助读者对Orca的工作原理建立起高层次的理解。</li>
</ul>
<h1 id="论文不足"><a href="#论文不足" class="headerlink" title="论文不足"></a>论文不足</h1><ul>
<li><strong>论文缺乏对优化阶段如何计算执行计划成本的描述</strong>。具体而言，完全未讨论成本模型，而这应是Orca的核心功能。这一点在处理大数据和无共享架构（shared-nothing architecture）时尤为重要，此处的成本模型可能不同于Selinger成本模型，需要纳入跨多个工作节点的协调和通信成本，并考虑网络带宽。建议论文包含对成本模型的详细描述，并讨论其在单体式和分布式数据库系统中的行为。</li>
<li><strong>论文针对MPP数据库的实验评估基于有限的数据集</strong>。Orca仅与GPDB传统查询优化器使用119个查询进行了比较。无论是查询数量还是被比较的MPP数据库优化器的数量都不足以令人信服地证明Orca相对于其他MPP数据库优化器的优势。因此，实验应进行更广泛的MPP数据库比较，例如与Amazon Redshift和Teradata Aster进行比较，以提供更全面的评估。</li>
<li><strong>论文的实验未反映Orca的硬件利用率</strong>，如CPU使用率、内存消耗等。Orca很可能会在无共享架构中运行，它将跨多个服务器运行。然而，在生产环境中，这些服务器不太可能专用于Orca，包括Orca将要优化的数据库在内的其他进程很可能与Orca运行在同一台服务器上。如果Orca的CPU或内存使用率过高，可能会对这些数据库的查询执行以及其他应用程序的性能产生负面影响。这种影响可能在多台服务器上累积，导致显著的性能下降。因此，论文还应包含对Orca硬件资源消耗的评估。</li>
</ul>
<p>参考文献: <a href="https://dl.acm.org/doi/10.1145/2588555.2595637">https://dl.acm.org/doi/10.1145/2588555.2595637</a></p>
]]></content>
      <categories>
        <category>高级数据存储</category>
      </categories>
  </entry>
  <entry>
    <title>TicToc</title>
    <url>/undefined/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/03/17/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Review%20Report%20-%20TicToc/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>本文解决了一个核心问题：</p>
<ol>
<li>如何设计一种高效的并发控制算法，以提升 OLTP 数据库管理系统在多核环境下的可扩展性？</li>
</ol>
<p>本文提出了 4 个新颖的想法，并详细阐述了每个想法的实现方案：</p>
<ol>
<li><strong>TicToc 算法：</strong> 在乐观并发控制 (OCC) 基础上实现。其核心在于事务的时间戳将延迟到提交时刻，根据该事务处理的所有元组进行计算。这种方式也提高了并行性。</li>
<li><strong>验证阶段的无等待锁定 (No-wait locking in validation phase)：</strong> 如果事务无法为其写集 (write set) 中的某个元组获取锁，验证阶段将立即中止。TicToc 会在等待一段时间后重启该阶段。</li>
<li><strong>抢占式中止 (Preemptive aborts)：</strong> 基于一个近似的提交时间戳以及元组的本地读时间戳 (rts) 和写时间戳 (wts)，可以在锁定写集中的元组之前就判断是否应中止该事务。</li>
<li><strong>时间戳历史记录 (Timestamp history)：</strong> 当读取的元组的本地读时间戳 (rts) 低于事务的 <code>commit_ts</code>，且其写时间戳 (wts) 与最新 wts 不同时，会进一步检查该元组的历史缓冲区 (history buffer)，以决定是否启动验证阶段。</li>
</ol>
<p>分析与实验结果： 本文比较了五种算法：TicToc, Silo, HEKATON, DL_DETECT 和 NO_WAIT。</p>
<ul>
<li><strong>TPC-C 结果：</strong> 在 4 仓规模下，TicToc 实现了最高的吞吐量，且中止率低于 Silo。随着仓数增加，TicToc 的吞吐量最终在约 80 仓时被 Silo 超越，但其中止率仍低于 Silo。</li>
<li><strong>YCSB 结果：</strong><ul>
<li>处理只读事务时，TicToc 的吞吐量与 Silo 接近，并高于其他算法。</li>
<li>在中等竞争条件下处理读写事务时，TicToc 的吞吐量与 Silo 相当，但其中止率显著低于 Silo、HEKATON 和 NO_WAIT。</li>
<li>在高竞争条件下，TicToc 的吞吐量远超 Silo，尽管其中止率变得与 Silo 更为接近。</li>
</ul>
</li>
<li><strong>优化测试：</strong> 表明大部分性能提升来源于无等待锁定和抢占式中止。此外，TicToc 的时间戳增长速度远低于 TS_ALLOC。</li>
<li><strong>隔离级别影响：</strong> 当隔离级别降低时，TicToc 显示出吞吐量的提升和中止率的下降，但这些变化的程度与其他算法相比并不显著。</li>
</ul>
<h1 id="论文优势"><a href="#论文优势" class="headerlink" title="论文优势"></a>论文优势</h1><ul>
<li><strong>背景与问题阐述清晰：</strong> 论文清晰地描述了背景知识和待解决的问题。它详细阐述了二阶段锁 (2PL) 策略的弱点，并指出基于时间戳排序 (T&#x2F;O) 的策略（如 MVCC 和 OCC）已逐渐成为主流。接着指出传统 T&#x2F;O 算法中集中式时间戳分配器 (centralized timestamp allocator) 和 CPU 的缓存一致性协议 (cache coherence protocol) 导致了时间戳分配瓶颈。此外，文中提到的所有硬件解决方案均未能完美契合大多数现代 CPU 的架构，即使实现其性能也欠佳。论文还简要描述了 OCC 的执行阶段，并介绍了两种基于 OCC 的优化方法（即 DTA 和 Silo），同时指出这两种方案仍存在可扩展性瓶颈。为解决这些问题，论文提出了 TicToc 算法。</li>
<li><strong>核心流程描述详实：</strong> 论文为 TicToc 算法的核心流程提供了代码、图表和示例，使读者能快速理解实现细节和工作流程。<ul>
<li>在 3.2 节，论文展示了读取阶段 (Read Phase)、验证阶段 (Validation Phase) 和写入阶段 (Write Phase) 的伪代码，清晰地说明了其设计如何应对并发和并行场景下的冲突，以及分布式时间戳分配。</li>
<li>在 3.6 节，论文展示了用于存储读&#x2F;写时间戳的结构，并通过伪代码有效地呈现了解决 delta 属性潜在溢出问题的方案。</li>
<li>在 3.3 节，论文提供了一个交错执行事务的示例，并辅以条形图，清晰地展示了 TicToc 在处理并发和并行挑战时的高灵活性和性能。</li>
</ul>
</li>
<li><strong>实验评估全面：</strong> 论文在 DBx1000 上对 TicToc 进行了全面的实验评估。<ul>
<li>在 TPC-C 和 YCSB 场景下评估了 TicToc 的性能。</li>
<li>比较了在不同竞争级别和不同仓数下，TicToc 与 Silo、HEKATON、DL_DETECT、NO_WAIT 的吞吐量和中止率。</li>
<li>评估了 TicToc 各项优化的效果，强调了无等待锁定和抢占式中止对性能提升的贡献。</li>
<li>比较了 TicToc 的时间戳增长速率与线性时间戳增长速率。</li>
<li>比较了在不同隔离级别下，TicToc 与其他 4 种算法在吞吐量和中止率上的差异。</li>
</ul>
</li>
</ul>
<h1 id="论文不足"><a href="#论文不足" class="headerlink" title="论文不足"></a>论文不足</h1><ul>
<li><strong>集成过程缺失：</strong> 论文未展示将 TicToc 集成到 DBx1000 的过程。作为一个并发控制算法，TicToc 必须与其他关键组件（如事务、索引、日志）交互，这涉及大量工作。然而，论文未涉及此方面，使读者难以复现该算法。因此，论文至少应简要概述必要的集成步骤，以帮助读者实现此功能。</li>
<li><strong>普适性验证不足：</strong> 论文的实验未能证明 TicToc 在多种数据库上的通用性。评估仅在 DBx1000 环境中进行，因此仅证实了 TicToc 在 DBx1000 内的高性能。但许多商用数据库（如 SQL Server、MySQL 等）在不同工作负载下表现出不同的特性，这可能导致使用 TicToc 时性能表现各异。然而，论文对此方面完全未提及。因此，论文还应包含 TicToc 在这些主流数据库上的集成和测试工作。</li>
<li><strong>关键优化细节缺失：</strong> 论文在关键的 OPTIMIZATIONS 章节中，未能为某些关键概念提供代码或详细解释。根据实验结果，无等待锁定和抢占式中止带来了显著的性能提升。然而，优化部分并未呈现任何相关代码。<ul>
<li>例如，在 No-Wait Locking in Validation Phase 小节，论文既未阐明给定上下文中抖动问题 (thrashing problems) 的具体含义，也未展示无等待锁定的代码，或指出其相对于原始 TicToc 实现的修改之处。</li>
<li>因此，论文应包含优化代码以及对相关概念的解释。</li>
</ul>
</li>
</ul>
<p>参考文献: <a href="https://people.csail.mit.edu/sanchez/papers/2016.tictoc.sigmod.pdf">https://people.csail.mit.edu/sanchez/papers/2016.tictoc.sigmod.pdf</a></p>
]]></content>
      <categories>
        <category>高级数据存储</category>
      </categories>
  </entry>
  <entry>
    <title>查询规划</title>
    <url>/undefined/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/02/08/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%9F%A5%E8%AF%A2%E8%A7%84%E5%88%92/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css">]]></content>
      <categories>
        <category>高级数据存储</category>
      </categories>
  </entry>
  <entry>
    <title>数据存储布局</title>
    <url>/undefined/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/01/12/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E5%B8%83%E5%B1%80/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><p>数据存储格式决定了数据如何在物理介质上组织与编码，这直接影响了系统的读写性能与资源使用效率。在大数据环境下，不同的格式会带来显著的 I&#x2F;O 差异，从而影响查询响应时间和吞吐量  。此外，恰当的存储格式有助于提高压缩比，实现更高的数据密度，降低存储成本，并减少网络传输开销 。对于需要长期保留的数据，选择稳定且可持续的格式至关重要，否则会面临文件格式过时与不可读的风险。最后，不同应用场景（如 OLTP 与 OLAP）对读写模式有不同要求，合适的存储格式既能满足高并发事务访问，也能兼顾批量分析查询，实现系统的整体优化。</p>
<p>当前常用的数据存储格式有以下三种：</p>
<ol>
<li><strong>行式存储（Row-oriented Layout）</strong></li>
<li><strong>列式存储（Column-oriented Layout）</strong></li>
<li><strong>混合式存储（Hybrid Layout）</strong></li>
</ol>
<h1 id="行式存储"><a href="#行式存储" class="headerlink" title="行式存储"></a>行式存储</h1><p>行式存储将同一行的所有字段值连续存储在物理介质上，因而非常适合事务型（OLTP）操作，能够快速插入、更新和检索整行数据，同时在点查询时性能较优，因为一次查询往往需要访问同一行数据的多个字段值。</p>
<p>行式存储下，数据库通常需要小页面。因为：</p>
<ol>
<li>磁盘是按照页来读取数据的，无论实际需要一页中的多少数据（哪怕只需要一行数据），都会加载整个页面。这种情况下如果页面较大，数据库就会反复加载无关数据，从而浪费磁盘和内存带宽。</li>
<li>数据库在执行事务的时候会锁住索引中被操作的叶子节点（数据页）来保持一致性，因此如果页面越大，那么被锁住的无关数据也就会越多，从而加剧了锁竞争。</li>
</ol>
<p>比如，我们有一个表 <code>user</code>，内容如下：</p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Age</th>
<th>Address</th>
</tr>
</thead>
<tbody><tr>
<td>Sam</td>
<td>18</td>
<td>Los Angeles</td>
</tr>
<tr>
<td>John</td>
<td>16</td>
<td>London</td>
</tr>
<tr>
<td>Alice</td>
<td>16</td>
<td>New York</td>
</tr>
</tbody></table>
<p>那么行式存储格式如下：</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_row_layout.drawio.png" alt="img"></p>
<p>因此在上图中，我们可以通过页号 + slot 号来确定一个页的位置。</p>
<p>思考：</p>
<ol>
<li><p>上图中为什么 Slots Array 和具体的数据要放在一个页的两端并且从两端向中间增加数据，而不是放在一起呢？</p>
<p>因为系统在插入时并不知道一页能容纳多少条可变长度的记录。把真实数据区从页面尾部往中间分配，就能在新增槽条目（在页面头部扩展）和写数据（在页面尾部收缩）之间形成一个松紧自适应的自由空间。如果数据紧跟在槽数组后面，那么插入时槽数组增长会挤占数据区，就必须把数据整体往后搬移，造成大量的内存（或磁盘页）移动开销。将数据放到页尾之后，每次插入都只在两端各做一小步，不会触及中间已存数据，从而极大降低了插入时的成本。</p>
<p>此外，系统只需要比较槽数组末尾指针和数据区末尾指针是否交错，即可判断该页是否还有足够余量插入新行。</p>
</li>
<li><p>频繁的指针访问（Pointer Access）在这里会引发什么问题？</p>
<ol>
<li><p>Cache Misses（缓存未命中）</p>
<p>指针场景下的实际数据往往在内存中彼此不连续放置，CPU 需要不断跳转到新的地址才能访问下一个数据，这种非顺序的内存访问会导致缓存行频繁未命中。</p>
</li>
<li><p>Memory Indirection（内存间接访问）</p>
<p>当程序想读取一个字段值时，通常先要读取槽数组里保存的偏移量（offset），然后去跳转到真正的物理地址。对于可变长度属性，元组头里还可能保存了再一层次的 pointer（比如 varchars 可能存放在页外溢出页），导致额外一跳。这会触发二次甚至多次的内存访问。</p>
<p>如果该偏移地址对应的缓存行当前不在 L1&#x2F;L2&#x2F;L3 缓存中，就必须从主存加载数据，导致高昂的内存访问延迟（几十到上百纳秒），远高于高速缓存访问延迟（几纳秒）。</p>
</li>
<li><p>Branch Prediction and Speculation Issues（分支预测与推测执行）</p>
<p>如果访问逻辑里要做大量的指针非空检查或可变长度判断，会引入很多条件分支。当 CPU 的分支预测器频繁猜错，就会导致流水线冲刷和重新预测，进一步影响性能。</p>
</li>
<li><p>TLB Misses（TLB 未命中）</p>
<p>大页、小页切换、可变长度数据放在页外时，程序要根据虚拟地址到物理地址多次查表。如果 TLB 不命中，CPU 就要走更慢的页表遍历，也会严重拖慢访问速度。</p>
</li>
</ol>
</li>
</ol>
<p><strong>优点</strong>：</p>
<ul>
<li><p>适合需要访问整条记录（整个元组）的查询。</p>
</li>
<li><p>适合插入、更新和删除操作（OLTP 工作负载）。</p>
</li>
</ul>
<p><strong>缺点</strong>：</p>
<ul>
<li><p>不适合需要访问整列数据（整个列）的查询。</p>
<p>例如，在行式布局下，如果执行</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">SELECT <span class="title function_">SUM</span><span class="params">(colA)</span>, AVG(colC)</span><br><span class="line">  FROM xxx</span><br><span class="line">  WHERE colA &gt; <span class="number">1000</span>;</span><br></pre></td></tr></table></figure>

<p>每一行会被遍历两遍，也就是说要为每条记录分别读取 colA 和 colC，重复读取同一条数据，无法做到顺序访问。</p>
</li>
<li><p>不适合大规模扫描和读取（OLAP 工作负载）。</p>
<p>因为数据是散落在每行里的，无法连续读取（非 sequential access），会产生大量指针跳转，开销很高。</p>
</li>
<li><p>不利于压缩节省。</p>
<p>不同列的数据往往混杂在一起，数据类型不一致，压缩效率会下降。</p>
</li>
</ul>
<h1 id="列式存储"><a href="#列式存储" class="headerlink" title="列式存储"></a>列式存储</h1><p>列式存储则将同一列的所有数值放在一起，便于对单列或少量列进行聚合及分析查询，尤其在数据仓库和在线分析处理（OLAP）场景下能够显著减少 I&#x2F;O 开销和提升查询效率。</p>
<p>该布局使得聚合操作变成了顺序读，因此 CPU 会进行预取操作，降低了缓存未命中的情况。并且列式存储布局更适合大页面，因为 OLAP 查询通常会一次性处理整个列的数据，大页面可以将更多的列数据存储在一个连续区域中，从而减少磁盘 I&#x2F;O 次数。同时，列式存储中的数据类型通常是同质化的（比如 Name 列都是 Char 类型的），这使得压缩算法在列式存储中的效果更好。</p>
<p><code>user</code> 表在列式存储下的结构为：</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_col_layout.drawio.png" alt="img"></p>
<p>在列式布局中，不再需要页号 + 槽号来唯一标识一条记录。相应地，我们只要给每列分配一个简单的偏移索引（即行号，从 0 开始到 N−1），就能唯一定位到该列对应行的值。</p>
<p>实际业务中往往会有可变长度字段（如 VARCHAR、TEXT、BLOB）。这时常见的做法是：往往会把这一列中的每一行真正的值存放在一个连续的数据区，而在该列文件中同时保留一个偏移量数组。偏移量数组里的第 i 项记录了第 i 行的数据在数据区里的起始位置和长度。</p>
<p>上图中，紧接在 Header 后面，会放一个 Null Bitmap，并且假设当前列有 M 行（行号从 0 到 M−1），则 Bitmap 通常是 M 位（二进制位），第 i 位为 1 表示第 i 行对应列值为 NULL，为 0 表示不为 NULL。</p>
<p>思考：</p>
<p>这里采用 Null Bitmap 的好处是什么？</p>
<ol>
<li>空值稀疏时，可以节省存储空间，不必给每个空值都分配实际存储字节。</li>
<li>在做向量化扫描时，可以直接跳过 NULL 行，提升 CPU 缓存命中率。</li>
</ol>
<blockquote>
<p>[!NOTE]</p>
<p>对于变长数据，我们还能怎么处理？</p>
<ol>
<li>在实际内容后面追加特殊字符，让每条记录占用的存储空间都达到一个统一的固定大小。但是当全表有成千上万行，其中大部分都比最大长度要短得多时，累积起来的无用填充就会非常庞大，导致磁盘空间和内存的浪费，还会降低 I&#x2F;O 和缓存利用率。</li>
<li>把本来可变字段都映射到某个定长标识上，那么存储时就无需再让每条记录都占用不同的字节数。比如有一个国家名称列，实际内容只有中国&#x2F;美国&#x2F;英国&#x2F;法国&#x2F;德国……这几十个明确的枚举值，那么我们可以先构建一个字典，给每个国家分配一个固定长度的编码（比如 2 字节、4 字节的整数）。在真实数据页里，只存整数编码（定长字段），而把对应的国家名称及其编码关系放在一个独立的字典里（通常在内存或元数据结构中）。如此一来，表里的国家列就变成了一个定长的整数列，检索时再通过字典查回实际名称。</li>
</ol>
</blockquote>
<p><strong>优点</strong>：</p>
<ul>
<li>适合需要访问整列数据的查询（例如聚合查询）。</li>
<li>适合大规模扫描与读取（OLAP 工作负载）。</li>
<li>能实现更紧凑的存储：与各种数据压缩技术天然契合，可显著减少磁盘与内存占用。</li>
<li>更好的局部性与缓存重用：单列数据连续存放，CPU 预取与缓存命中率更高，加快查询处理速度。</li>
</ul>
<p><strong>缺点</strong>：</p>
<ul>
<li>不适合需要访问整条记录的查询：若一次要读回多列，就必须在多个列文件之间来回跳转并重组整个元组，开销较大。</li>
<li>不适合插入、更新和删除操作（OLTP 工作负载）：单条写入会涉及多个列文件的维护与重组，随机 I&#x2F;O 开销较高。</li>
</ul>
<h1 id="混合式存储"><a href="#混合式存储" class="headerlink" title="混合式存储"></a>混合式存储</h1><blockquote>
<p>理论上，纯列式布局对“只扫描一两列”非常高效；但实际 OLAP 查询往往不仅仅要过滤某列，还需要把过滤后的结果组装为“完整行”，甚至会用到其他列或多列联合过滤。</p>
<p>如果直接把所有列彻底拆开，各列之间又没有任何物理地域上的联系，就会让行重建的开销变得十分巨大。</p>
<p><strong>因此，需要一种折中布局：既要保证列连续以获得压缩和大规模顺序扫描的优势，又要让同一行的各列值彼此在磁盘&#x2F;内存中相对接近，好在需要时快速组装回完整元组。</strong></p>
</blockquote>
<p>混合式存储（PAX）融合了行式与列式两者的优点，通过在写入时同时维护行与列两种视图来兼顾高并发点查和批量分析，但会带来额外的存储开销与维护成本，需要根据业务场景权衡选择。</p>
<p>混合存储的核心思想是：水平分区 + 垂直分区。</p>
<p>首先，将整个表的所有行（Row #0、Row #1、…、Row #5）按照一定的行数分成多个行组（Row Group）。在每个行组内部，再进一步将行组里的各列分开存放。也就是说，组内的所有行先把同一列的值放一起，然后再放下一列的值。</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_hybrid_layout.drawio.png" alt="img"></p>
<p>因此混合存储通过这种方式，就在一个页或一个文件片段（segment）内部，既保留了局部行按顺序聚集的信息，也保留了同一列值连续存放的好处。</p>
<h1 id="水平分区"><a href="#水平分区" class="headerlink" title="水平分区"></a>水平分区</h1><p>将原本集中存储在单一服务器或单个存储介质上的数据，按照某种策略拆分成多份，分别放到不同的物理节点或不同的磁盘上。</p>
<p><strong>为什么要这样做？</strong></p>
<ol>
<li><strong>扩展性能</strong>：当数据量或并发请求量超过单台机器的承载能力时，把数据拆分到多台机器能够并行处理，提升吞吐量。</li>
<li><strong>扩展存储容量</strong>：单个磁盘或服务器空间有限，把数据分散到多台机器才能存下更多数据。</li>
<li><strong>可用性&#x2F;容错</strong>：如果某台机器或某个磁盘出现故障，只会影响部分分片的数据，整体系统仍可继续对其它分片提供服务（可结合副本机制进一步提高容灾）。</li>
</ol>
<p>两种分区模式：</p>
<ol>
<li><p>逻辑分区（Logically, Shared Storage）</p>
<p>多个分区虽然在逻辑上被看作是分散的，但底层共用同一个存储介质。换句话说，数据切分为多个逻辑分区，但这些分区的数据仍然落在同一套磁盘或存储系统上。</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_shared_storage.drawio.png" alt="img"></p>
<p>优点：部署相对简单，无需管理多台物理机器；数据仍然集中在一起，备份和维护方便。</p>
<p>缺点：底层物理存储是共享的 I&#x2F;O 总线，如果并发量很大，仍然会遇到单个存储后端的带宽瓶颈；并不能真正摆脱单点故障。</p>
</li>
<li><p>物理分区（Physically, Shared Nothing）</p>
<p>每个分区都完全独占自己的计算与存储资源，真正做到各自为政、不共享存储，也就是典型的 Shared‐Nothing 架构。</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_shared_nothing.drawio.png" alt="img"></p>
<p>优点：可线性扩展，新增机器即可增加吞吐和存储；不同分区之间互不干扰，故障隔离更好，一个节点挂掉只影响该分区，其他节点仍可正常提供服务。</p>
<p>缺点：架构更复杂，需要维护多台机器，多副本同步、路由与协调也更困难；跨分区的事务和 JOIN 查询会额外复杂且性能成本更高。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>高级数据存储</category>
      </categories>
  </entry>
  <entry>
    <title>查询优化</title>
    <url>/undefined/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/01/29/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><p>查询优化是构建高性能数据库管理系统时最困难的部分之一，它需要在大量等价的查询执行方案中找到资源消耗最小的那个方案。其核心目标是以某种成本函数衡量每个候选计划，并选择估算成本最低的计划。</p>
<p>查询优化的首要目标就是在可行的计划中选出“最低成本”的一个，通常采用成本模型对 I&#x2F;O、CPU、网络等资源进行加权求和，得出一个标量成本值，不同系统也可能纳入缓冲区命中率、并行度等额外因素。</p>
<h2 id="成本评估"><a href="#成本评估" class="headerlink" title="成本评估"></a>成本评估</h2><p>在关系型数据库的**代价优化器（Cost-Based Optimizer）**中，会将一个查询计划的总代价定义为其所有算子（Operator）估算代价的累加：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi><mi>o</mi><mi>s</mi><mi>t</mi><mspace width="0.22222em"></mspace><mi>o</mi><mi>f</mi><mspace width="0.22222em"></mspace><mi>P</mi><mi>l</mi><mi>a</mi><mi>n</mi><mo>=</mo><mo>∑</mo><mo>(</mo><mi>C</mi><mi>o</mi><mi>s</mi><mi>t</mi><mspace width="0.22222em"></mspace><mi>o</mi><mi>f</mi><mspace width="0.22222em"></mspace><mi>e</mi><mi>a</mi><mi>c</mi><mi>h</mi><mspace width="0.22222em"></mspace><mi>P</mi><mi>l</mi><mi>a</mi><mi>n</mi><mspace width="0.22222em"></mspace><mi>O</mi><mi>p</mi><mi>e</mi><mi>r</mi><mi>a</mi><mi>t</mi><mi>o</mi><mi>r</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">
Cost\:of\:Plan = \sum (Cost\:of\:each\:Plan\:Operator)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.05em;"></span><span class="strut bottom" style="height:1.6000100000000002em;vertical-align:-0.55001em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.07153em;">C</span><span class="mord mathit">o</span><span class="mord mathit">s</span><span class="mord mathit">t</span><span class="mord mspace mediumspace"></span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right:0.10764em;">f</span><span class="mord mspace mediumspace"></span><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">a</span><span class="mord mathit">n</span><span class="mrel">=</span><span class="op-symbol large-op mop" style="top:-0.000004999999999977245em;">∑</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.07153em;">C</span><span class="mord mathit">o</span><span class="mord mathit">s</span><span class="mord mathit">t</span><span class="mord mspace mediumspace"></span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right:0.10764em;">f</span><span class="mord mspace mediumspace"></span><span class="mord mathit">e</span><span class="mord mathit">a</span><span class="mord mathit">c</span><span class="mord mathit">h</span><span class="mord mspace mediumspace"></span><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">a</span><span class="mord mathit">n</span><span class="mord mspace mediumspace"></span><span class="mord mathit" style="margin-right:0.02778em;">O</span><span class="mord mathit">p</span><span class="mord mathit">e</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit">a</span><span class="mord mathit">t</span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mclose">)</span></span></span></span></span>

<p>而每个算子的估算代价又通常与该算子所处理的输入规模成正比：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi><mi>o</mi><mi>s</mi><mi>t</mi><mo>(</mo><mi>O</mi><mi>p</mi><mi>e</mi><mi>r</mi><mi>a</mi><mi>t</mi><mi>o</mi><mi>r</mi><mo>)</mo><mo>∝</mo><mi>S</mi><mi>i</mi><mi>z</mi><mi>e</mi><mspace width="0.22222em"></mspace><mi>o</mi><mi>f</mi><mspace width="0.22222em"></mspace><mi>O</mi><mi>p</mi><mi>e</mi><mi>r</mi><mi>a</mi><mi>t</mi><mi>o</mi><mi>r</mi><mspace width="0.22222em"></mspace><mi>I</mi><mi>n</mi><mi>p</mi><mi>u</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">
Cost(Operator) \propto Size\:of\:Operator\:Input
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.07153em;">C</span><span class="mord mathit">o</span><span class="mord mathit">s</span><span class="mord mathit">t</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.02778em;">O</span><span class="mord mathit">p</span><span class="mord mathit">e</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit">a</span><span class="mord mathit">t</span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mclose">)</span><span class="mrel">∝</span><span class="mord mathit" style="margin-right:0.05764em;">S</span><span class="mord mathit">i</span><span class="mord mathit" style="margin-right:0.04398em;">z</span><span class="mord mathit">e</span><span class="mord mspace mediumspace"></span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right:0.10764em;">f</span><span class="mord mspace mediumspace"></span><span class="mord mathit" style="margin-right:0.02778em;">O</span><span class="mord mathit">p</span><span class="mord mathit">e</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit">a</span><span class="mord mathit">t</span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mspace mediumspace"></span><span class="mord mathit" style="margin-right:0.07847em;">I</span><span class="mord mathit">n</span><span class="mord mathit">p</span><span class="mord mathit">u</span><span class="mord mathit">t</span></span></span></span></span>

<p>以上两条公式构成了代价估算的基础：先通过输入规模得出算子代价，然后累加得到整个执行计划的成本。接下来，需要详细说明如何确定算子输入规模，以及如何基于选取性（Selectivity）估算非基表算子的输出规模。</p>
<p>对于基表扫描（Table Scan）或索引扫描（Index Scan），输入规模通常等于表或索引在磁盘上的物理存储量（页数或行数）。</p>
<blockquote>
<p>[!NOTE]</p>
<p>对于此类扫描操作，我们可以在有索引的情况下，可将过滤条件下推至索引层，只读取满足谓词的行或页，以减少输入规模和 I&#x2F;O 操作，也就是进行索引下推。</p>
</blockquote>
<p>对于投影（Project）、选择（Filter）等算子，优化器首先根据输入规模和选取性估算输出规模；连接（Join）算子则需基于两侧子计划的输出规模与连接选取性共同计算其输出规模，也就是：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>O</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi><mspace width="0.22222em"></mspace><mi>S</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo>=</mo><mi>S</mi><mi>e</mi><mi>l</mi><mi>e</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>i</mi><mi>t</mi><mi>y</mi><mo>×</mo><mo>(</mo><mi mathvariant="normal">∣</mi><mi>L</mi><mi>e</mi><mi>f</mi><mi>t</mi><mi mathvariant="normal">∣</mi><mo>×</mo><mi mathvariant="normal">∣</mi><mi>R</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>t</mi><mi mathvariant="normal">∣</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">
Output\:Size = Selectivity \times (|Left| \times |Right|)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">O</span><span class="mord mathit">u</span><span class="mord mathit">t</span><span class="mord mathit">p</span><span class="mord mathit">u</span><span class="mord mathit">t</span><span class="mord mspace mediumspace"></span><span class="mord mathit" style="margin-right:0.05764em;">S</span><span class="mord mathit">i</span><span class="mord mathit" style="margin-right:0.04398em;">z</span><span class="mord mathit">e</span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.05764em;">S</span><span class="mord mathit">e</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">e</span><span class="mord mathit">c</span><span class="mord mathit">t</span><span class="mord mathit">i</span><span class="mord mathit" style="margin-right:0.03588em;">v</span><span class="mord mathit">i</span><span class="mord mathit">t</span><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mbin">×</span><span class="mopen">(</span><span class="mord mathrm">∣</span><span class="mord mathit">L</span><span class="mord mathit">e</span><span class="mord mathit" style="margin-right:0.10764em;">f</span><span class="mord mathit">t</span><span class="mord mathrm">∣</span><span class="mbin">×</span><span class="mord mathrm">∣</span><span class="mord mathit" style="margin-right:0.00773em;">R</span><span class="mord mathit">i</span><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="mord mathit">h</span><span class="mord mathit">t</span><span class="mord mathrm">∣</span><span class="mclose">)</span></span></span></span></span>

<p>选取性（Selectivity）是算子发出数据量与接收数据量之比，取值范围 0–1，表示谓词或连接条件对数据的过滤强度。</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>O</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi><mspace width="0.22222em"></mspace><mi>S</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo>=</mo><mi>S</mi><mi>e</mi><mi>l</mi><mi>e</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>i</mi><mi>t</mi><mi>y</mi><mo>×</mo><mi>I</mi><mi>n</mi><mi>p</mi><mi>u</mi><mi>t</mi><mspace width="0.22222em"></mspace><mi>S</mi><mi>i</mi><mi>z</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">
Output\:Size = Selectivity \times Input\:Size
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">O</span><span class="mord mathit">u</span><span class="mord mathit">t</span><span class="mord mathit">p</span><span class="mord mathit">u</span><span class="mord mathit">t</span><span class="mord mspace mediumspace"></span><span class="mord mathit" style="margin-right:0.05764em;">S</span><span class="mord mathit">i</span><span class="mord mathit" style="margin-right:0.04398em;">z</span><span class="mord mathit">e</span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.05764em;">S</span><span class="mord mathit">e</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">e</span><span class="mord mathit">c</span><span class="mord mathit">t</span><span class="mord mathit">i</span><span class="mord mathit" style="margin-right:0.03588em;">v</span><span class="mord mathit">i</span><span class="mord mathit">t</span><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mbin">×</span><span class="mord mathit" style="margin-right:0.07847em;">I</span><span class="mord mathit">n</span><span class="mord mathit">p</span><span class="mord mathit">u</span><span class="mord mathit">t</span><span class="mord mspace mediumspace"></span><span class="mord mathit" style="margin-right:0.05764em;">S</span><span class="mord mathit">i</span><span class="mord mathit" style="margin-right:0.04398em;">z</span><span class="mord mathit">e</span></span></span></span></span>

<p>假设我们针对有 100 条记录的部门表 dept，10000 条记录的职员表 emp，30000 条记录的儿童表 kids，执行如下 SQL 语句：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> </span><br><span class="line"><span class="keyword">FROM</span> emp, dept, kids</span><br><span class="line"><span class="keyword">WHERE</span> sal <span class="operator">&gt;</span> <span class="number">10000</span> </span><br><span class="line">  <span class="keyword">AND</span> emp.dno <span class="operator">=</span> dept.dno </span><br><span class="line">  <span class="keyword">AND</span> emp.eid <span class="operator">=</span> kids.eid;</span><br></pre></td></tr></table></figure>

<p>其中，每 100 条记录是一个页面，10 KB 是一个页面的大小，内存大小是 10 个页面。</p>
<p>对于每种执行计划，我们可以进行如下步骤：</p>
<p>第一步，评估表（关系）的大小：</p>
<ul>
<li>dept 只有 100 条记录，占用 1 页（10 KB&#x2F;页）；</li>
<li>emp 有 10000 条记录，占用 100 页（10 KB&#x2F;页）；</li>
<li>kids 有 30000 条记录，占用 300 页（10 KB&#x2F;页）。</li>
</ul>
<p>第二步，评估选择性：</p>
<ul>
<li><code>WHERE sal &gt; 10k</code> 的选择性为 0.1；</li>
<li>dept 和 emp 的 JOIN 操作的选择性为 0.01，产生结果集 A；</li>
<li>A 和 kids 的 JOIN 操作的选择性为 0.0001，产生结果 B。</li>
</ul>
<p>第三步，计算中间结果的大小，如下执行计划树所示，其中冒号右边的数据为此次操作得到的结果集的大小：</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/db_adv_query_optimize_eg1.drawio.png" alt="img"></p>
<p>需要注意的是，整棵树的阅读顺序推荐从叶子到根。</p>
<p>第四步，评估各个执行计划的成本并选出最低的。</p>
<p>以上只是一个简单的流程，下面基于 Selinger 等人提出的 System R 成本优化器框架给出每个步骤的详细解释，该框架迄今仍被主流关系型数据库（如 DB2、PostgreSQL、MySQL 等）沿用。</p>
<p>第一步，评估关系的大小，其中的统计量如下：</p>
<ul>
<li><strong>NCARD(T)</strong>：关系 T 的基数，即元组总数；</li>
<li><strong>TCARD(T)</strong>：关系 T 所占用的数据页数；</li>
<li><strong>ICARD(I)</strong>：索引 I 中不同键值的数量；</li>
<li><strong>NINDX(I)</strong>：索引 I 在磁盘上占用的页数。</li>
</ul>
<blockquote>
<p>[!NOTE]</p>
<p>现代数据库在 System R 的统计量基础上引入多种增强策略：</p>
<ol>
<li><p><strong>直方图（Histograms）</strong></p>
<ul>
<li><strong>等宽直方图（Equi-width）</strong>：将值域划分为固定宽度的 k 个区间，区间内数据不均匀时易失真 。</li>
<li><strong>等深直方图（Equi-depth）</strong>：保证每个桶内的元组数近似相同，可更准确估算范围谓词 。</li>
</ul>
</li>
<li><p><strong>最常见值列表（Frequency List）</strong>：维护出现频率最高的 m 个键值及其频率分布，对高频值谓词（如 <code>col IN (…)</code>）提供精确估算。</p>
</li>
<li><p><strong>聚簇因子（Clustering Factor）</strong>：描述索引键值在数据块中的物理聚集度，值越低表示更紧密的簇集，有助于优化随机 vs 顺序 I&#x2F;O 的成本估算。</p>
</li>
<li><p><strong>分区增量统计</strong>：对于分区表，会为每个分区单独收集统计信息，并维护全局统计，通过分区修剪（Partition Pruning）显著降低查询开销。</p>
</li>
<li><p><strong>分层采样</strong>：在全表采样成本过高时，数据库可基于分区或分层样本抽样（如 1% 分区样本），动态更新统计，同时避免全表扫描统计带来的停机与高 I&#x2F;O 负载。</p>
</li>
</ol>
</blockquote>
<p>第二步，评估选择性：</p>
<p>我们这里先定义 F 或者 F(pred) &#x3D; 谓词的选择性 &#x3D; 没有被过滤掉的记录的占比。</p>
<p>那么，对于<strong>等值谓词</strong> <code>col == val</code>：若有索引，则假设均匀分布，选取性</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>F</mi><mo>=</mo><mn>1</mn><mi mathvariant="normal">/</mi><mi>I</mi><mi>C</mi><mi>A</mi><mi>R</mi><mi>D</mi></mrow><annotation encoding="application/x-tex">
F = 1 / ICARD
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">F</span><span class="mrel">=</span><span class="mord mathrm">1</span><span class="mord mathrm">/</span><span class="mord mathit" style="margin-right:0.07847em;">I</span><span class="mord mathit" style="margin-right:0.07153em;">C</span><span class="mord mathit">A</span><span class="mord mathit" style="margin-right:0.00773em;">R</span><span class="mord mathit" style="margin-right:0.02778em;">D</span></span></span></span></span>

<p>；否则粗略取 1&#x2F;10。</p>
<p>对于<strong>范围谓词</strong> <code>col &gt; val</code> 或类似开区间比较：若有索引，则线性插值计算</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>F</mi><mo>=</mo><mo>(</mo><mi>h</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi mathvariant="normal">_</mi><mi>k</mi><mi>e</mi><mi>y</mi><mspace width="0.22222em"></mspace><mo>−</mo><mspace width="0.22222em"></mspace><mi>v</mi><mi>a</mi><mi>l</mi><mo>)</mo><mi mathvariant="normal">/</mi><mo>(</mo><mi>h</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi mathvariant="normal">_</mi><mi>k</mi><mi>e</mi><mi>y</mi><mspace width="0.22222em"></mspace><mo>−</mo><mspace width="0.22222em"></mspace><mi>l</mi><mi>o</mi><mi>w</mi><mi mathvariant="normal">_</mi><mi>k</mi><mi>e</mi><mi>y</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">
F = (high\_key\:-\:val) / (high\_key\:-\:low\_key)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1.06em;vertical-align:-0.31em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">F</span><span class="mrel">=</span><span class="mopen">(</span><span class="mord mathit">h</span><span class="mord mathit">i</span><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="mord mathit">h</span><span class="mord mathrm" style="margin-right:0.02778em;">_</span><span class="mord mathit" style="margin-right:0.03148em;">k</span><span class="mord mathit">e</span><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mord mspace mediumspace"></span><span class="mbin">−</span><span class="mord mspace mediumspace"></span><span class="mord mathit" style="margin-right:0.03588em;">v</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mclose">)</span><span class="mord mathrm">/</span><span class="mopen">(</span><span class="mord mathit">h</span><span class="mord mathit">i</span><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="mord mathit">h</span><span class="mord mathrm" style="margin-right:0.02778em;">_</span><span class="mord mathit" style="margin-right:0.03148em;">k</span><span class="mord mathit">e</span><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mord mspace mediumspace"></span><span class="mbin">−</span><span class="mord mspace mediumspace"></span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mord mathrm" style="margin-right:0.02778em;">_</span><span class="mord mathit" style="margin-right:0.03148em;">k</span><span class="mord mathit">e</span><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span></span>

<p>；否则取 1&#x2F;3。</p>
<p>对于<strong>列间相等谓词</strong> <code>col1 = col2</code>：</p>
<p>若两列均有索引，取两索引基数（ICARD）较大值的倒数：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>F</mi><mo>=</mo><mfrac><mrow><mn>1</mn></mrow><mrow><mi>max</mi><mo fence="true">(</mo><mtext><mi mathvariant="normal">I</mi><mi mathvariant="normal">C</mi><mi mathvariant="normal">A</mi><mi mathvariant="normal">R</mi><mi mathvariant="normal">D</mi></mtext><mo>(</mo><mi>c</mi><mi>o</mi><msub><mi>l</mi><mn>1</mn></msub><mo>)</mo><mo separator="true">,</mo><mspace width="0.16667em"></mspace><mtext><mi mathvariant="normal">I</mi><mi mathvariant="normal">C</mi><mi mathvariant="normal">A</mi><mi mathvariant="normal">R</mi><mi mathvariant="normal">D</mi></mtext><mo>(</mo><mi>c</mi><mi>o</mi><msub><mi>l</mi><mn>2</mn></msub><mo>)</mo><mo fence="true">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">
F = \frac{1}{\max\bigl(\text{ICARD}(col_1),\,\text{ICARD}(col_2)\bigr)}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.32144em;"></span><span class="strut bottom" style="height:2.41145em;vertical-align:-1.09001em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">F</span><span class="mrel">=</span><span class="mord reset-textstyle displaystyle textstyle uncramped"><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.74em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle textstyle cramped"><span class="mord textstyle cramped"><span class="mop">max</span><span class="mopen"><span class="style-wrap reset-textstyle textstyle uncramped"><span class="delimsizing size1">(</span></span></span><span class="text mord textstyle cramped"><span class="mord mathrm">I</span><span class="mord mathrm">C</span><span class="mord mathrm">A</span><span class="mord mathrm">R</span><span class="mord mathrm">D</span></span><span class="mopen">(</span><span class="mord mathit">c</span><span class="mord mathit">o</span><span class="mord"><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.01968em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mord mspace thinspace"></span><span class="text mord textstyle cramped"><span class="mord mathrm">I</span><span class="mord mathrm">C</span><span class="mord mathrm">A</span><span class="mord mathrm">R</span><span class="mord mathrm">D</span></span><span class="mopen">(</span><span class="mord mathit">c</span><span class="mord mathit">o</span><span class="mord"><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.01968em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span><span class="mclose"><span class="style-wrap reset-textstyle textstyle uncramped"><span class="delimsizing size1">)</span></span></span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.677em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle textstyle uncramped"><span class="mord textstyle uncramped"><span class="mord mathrm">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span>​</span></span></span><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span></span></span></span></span>

<p>；</p>
<p>若只有单列有索引，则</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>F</mi><mo>=</mo><mn>1</mn><mi mathvariant="normal">/</mi><mi>I</mi><mi>C</mi><mi>A</mi><mi>R</mi><mi>D</mi></mrow><annotation encoding="application/x-tex">
F = 1/ICARD
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">F</span><span class="mrel">=</span><span class="mord mathrm">1</span><span class="mord mathrm">/</span><span class="mord mathit" style="margin-right:0.07847em;">I</span><span class="mord mathit" style="margin-right:0.07153em;">C</span><span class="mord mathit">A</span><span class="mord mathit" style="margin-right:0.00773em;">R</span><span class="mord mathit" style="margin-right:0.02778em;">D</span></span></span></span></span>

<p>；否则取 1&#x2F;10。</p>
<p>此外，在查询中常有多重谓词组合，Selinger 优化器使用以下规则在<strong>逻辑优化</strong>和<strong>成本估算</strong>阶段快速合成最终选取性 F：</p>
<p><strong>逻辑与（AND）</strong>：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>F</mi><mrow><mtext><mi mathvariant="normal">a</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">d</mi></mtext></mrow></msub><mo>=</mo><mi>F</mi><mo>(</mo><msub><mi>p</mi><mn>1</mn></msub><mo>)</mo><mspace width="0.16667em"></mspace><mo>×</mo><mspace width="0.16667em"></mspace><mi>F</mi><mo>(</mo><msub><mi>p</mi><mn>2</mn></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">
F_{\text{and}} = F(p_1)\,\times\,F(p_2)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.13889em;">F</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.13889em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="text mord scriptstyle cramped"><span class="mord mathrm">a</span><span class="mord mathrm">n</span><span class="mord mathrm">d</span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.13889em;">F</span><span class="mopen">(</span><span class="mord"><span class="mord mathit">p</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span><span class="mord mspace thinspace"></span><span class="mbin">×</span><span class="mord mspace thinspace"></span><span class="mord mathit" style="margin-right:0.13889em;">F</span><span class="mopen">(</span><span class="mord"><span class="mord mathit">p</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span></span></span></span></span>

<p><strong>逻辑或（OR）</strong>：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>F</mi><mrow><mtext><mi mathvariant="normal">o</mi><mi mathvariant="normal">r</mi></mtext></mrow></msub><mo>=</mo><mn>1</mn><mo>−</mo><msub><mi>F</mi><mrow><mtext><mi mathvariant="normal">a</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">d</mi></mtext></mrow></msub><mo>=</mo><mi>F</mi><mo>(</mo><msub><mi>p</mi><mn>1</mn></msub><mo>)</mo><mo>+</mo><mi>F</mi><mo>(</mo><msub><mi>p</mi><mn>2</mn></msub><mo>)</mo><mo>−</mo><mi>F</mi><mo>(</mo><msub><mi>p</mi><mn>1</mn></msub><mo>)</mo><mspace width="0.16667em"></mspace><mi>F</mi><mo>(</mo><msub><mi>p</mi><mn>2</mn></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">
F_{\text{or}} = 1 - F_{\text{and}} = F(p_1) + F(p_2) - F(p_1)\,F(p_2)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.13889em;">F</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.13889em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="text mord scriptstyle cramped"><span class="mord mathrm">o</span><span class="mord mathrm">r</span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathrm">1</span><span class="mbin">−</span><span class="mord"><span class="mord mathit" style="margin-right:0.13889em;">F</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.13889em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="text mord scriptstyle cramped"><span class="mord mathrm">a</span><span class="mord mathrm">n</span><span class="mord mathrm">d</span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.13889em;">F</span><span class="mopen">(</span><span class="mord"><span class="mord mathit">p</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span><span class="mbin">+</span><span class="mord mathit" style="margin-right:0.13889em;">F</span><span class="mopen">(</span><span class="mord"><span class="mord mathit">p</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span><span class="mbin">−</span><span class="mord mathit" style="margin-right:0.13889em;">F</span><span class="mopen">(</span><span class="mord"><span class="mord mathit">p</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span><span class="mord mspace thinspace"></span><span class="mord mathit" style="margin-right:0.13889em;">F</span><span class="mopen">(</span><span class="mord"><span class="mord mathit">p</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span></span></span></span></span>

<p><strong>逻辑非（NOT）</strong>：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>F</mi><mrow><mtext><mi mathvariant="normal">n</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">t</mi></mtext></mrow></msub><mo>=</mo><mn>1</mn><mo>−</mo><mi>F</mi><mo>(</mo><mi>p</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">
F_{\text{not}} = 1 - F(p)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.13889em;">F</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.13889em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="text mord scriptstyle cramped"><span class="mord mathrm">n</span><span class="mord mathrm">o</span><span class="mord mathrm">t</span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathrm">1</span><span class="mbin">−</span><span class="mord mathit" style="margin-right:0.13889em;">F</span><span class="mopen">(</span><span class="mord mathit">p</span><span class="mclose">)</span></span></span></span></span>

<p>思考：</p>
<p>为什么等值谓词在没有索引的时候要取 1&#x2F;10？</p>
<p>在缺乏精确统计时，优化器宁可假设谓词对数据的过滤效果<strong>较弱</strong>（即选取性估算偏大），也不轻易假设它过滤得非常彻底。</p>
<p>如果低估谓词效果（认为它能过滤掉更多行），某些访问路径（如索引扫描）看起来成本极低，以至于优化器可能跳过对其他方案的评估；而高估则保证几乎所有可行方案都被保留用于比较，从而不至于因估算过于乐观而错过实测可能更优的计划。</p>
<p>假设有两种访问 emp 表的方案：</p>
<ol>
<li><strong>索引扫描+连接</strong>：若低估谓词效果（认为只过滤 1%），算出极低的中间行数，导致优化器只评估此方案并剪掉全表扫描方案。</li>
<li><strong>高估策略</strong>（假设过滤 10%）：使得索引扫描方案看起来代价更高，全表扫描的成本也被评估，优化器才会真正比较两者。</li>
</ol>
<p>最终在实际运行中，全表扫描+哈希连接可能因顺序 I&#x2F;O 更快而胜出，但若一开始就剪掉它，就永远不会被考虑。</p>
<p>第三步，计算中间结果的大小，该步骤的内容之前已经叙述过。</p>
<p>第四步，评估每个执行计划的成本：</p>
<p>在基于成本的优化器中，每个物理算子的总代价通常由以下两部分构成：</p>
<ul>
<li><strong>I&#x2F;O 代价</strong>：以读取页面的次数为单位，乘以相应的 I&#x2F;O 权重（如顺序读取 <code>seq_page_cost</code> 或随机读取 <code>random_page_cost</code>） 。</li>
<li><strong>CPU 代价</strong>：以处理记录或执行谓词的次数为单位，乘以对应的 CPU 权重（如 <code>cpu_tuple_cost</code>、<code>cpu_operator_cost</code>） 。</li>
</ul>
<p>最终，优化器对算子代价取页读次数与记录处理次数的线性组合来估算：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext><mi mathvariant="normal">C</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">t</mi></mtext><mo>=</mo><mo>(</mo><mtext><mi mathvariant="normal">p</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">g</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">s</mi><mtext> </mtext><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">d</mi></mtext><mo>)</mo><mo>+</mo><mi>W</mi><mo>×</mo><mo>(</mo><mtext><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">d</mi><mi mathvariant="normal">s</mi><mtext> </mtext><mi mathvariant="normal">e</mi><mi mathvariant="normal">v</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">d</mi></mtext><mo>)</mo></mrow><annotation encoding="application/x-tex">
\text{Cost} = (\text{pages read}) + W \times (\text{records evaluated})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">C</span><span class="mord mathrm">o</span><span class="mord mathrm">s</span><span class="mord mathrm">t</span></span><span class="mrel">=</span><span class="mopen">(</span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">p</span><span class="mord mathrm">a</span><span class="mord mathrm" style="margin-right:0.01389em;">g</span><span class="mord mathrm">e</span><span class="mord mathrm">s</span><span class="mord mspace"> </span><span class="mord mathrm">r</span><span class="mord mathrm">e</span><span class="mord mathrm">a</span><span class="mord mathrm">d</span></span><span class="mclose">)</span><span class="mbin">+</span><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="mbin">×</span><span class="mopen">(</span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">r</span><span class="mord mathrm">e</span><span class="mord mathrm">c</span><span class="mord mathrm">o</span><span class="mord mathrm">r</span><span class="mord mathrm">d</span><span class="mord mathrm">s</span><span class="mord mspace"> </span><span class="mord mathrm">e</span><span class="mord mathrm" style="margin-right:0.01389em;">v</span><span class="mord mathrm">a</span><span class="mord mathrm">l</span><span class="mord mathrm">u</span><span class="mord mathrm">a</span><span class="mord mathrm">t</span><span class="mord mathrm">e</span><span class="mord mathrm">d</span></span><span class="mclose">)</span></span></span></span></span>

<p>，其中 W 表示单位记录的 CPU 权重 。</p>
<p>对于<strong>带唯一索引的等值谓词</strong>，访问路径通常为：</p>
<ol>
<li><strong>B-Tree 索引查找</strong>：读取根到叶的路径上若干索引页（假设固定深度），通常记为 “1 页 I&#x2F;O” 来表示一次查找操作的近似代价。</li>
<li><strong>堆表行定位</strong>（Heap File lookup）：利用索引返回的行定位信息，再读取对应数据页，平均也是一次 I&#x2F;O 操作。</li>
</ol>
<p>综合起来，此算子的总代价可表示为：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mtext> </mtext><mo>(</mo><mtext><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">d</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">x</mi><mtext> </mtext><mi mathvariant="normal">p</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">g</mi><mi mathvariant="normal">e</mi><mtext> </mtext><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">d</mi></mtext><mo>)</mo><mspace width="0.277778em"></mspace><mo>+</mo><mspace width="0.277778em"></mspace><mn>1</mn><mtext> </mtext><mo>(</mo><mtext><mi mathvariant="normal">d</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">a</mi><mtext> </mtext><mi mathvariant="normal">p</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">g</mi><mi mathvariant="normal">e</mi><mtext> </mtext><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">d</mi></mtext><mo>)</mo><mspace width="0.277778em"></mspace><mo>+</mo><mspace width="0.277778em"></mspace><mi>W</mi><mtext> </mtext><mo>(</mo><mtext><mi mathvariant="normal">C</mi><mi mathvariant="normal">P</mi><mi mathvariant="normal">U</mi></mtext><mo>)</mo></mrow><annotation encoding="application/x-tex">
1\ (\text{index page read}) \;+\; 1\ (\text{data page read}) \;+\; W\ (\text{CPU})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathrm">1</span><span class="mord mspace"> </span><span class="mopen">(</span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">i</span><span class="mord mathrm">n</span><span class="mord mathrm">d</span><span class="mord mathrm">e</span><span class="mord mathrm">x</span><span class="mord mspace"> </span><span class="mord mathrm">p</span><span class="mord mathrm">a</span><span class="mord mathrm" style="margin-right:0.01389em;">g</span><span class="mord mathrm">e</span><span class="mord mspace"> </span><span class="mord mathrm">r</span><span class="mord mathrm">e</span><span class="mord mathrm">a</span><span class="mord mathrm">d</span></span><span class="mclose">)</span><span class="mord mspace thickspace"></span><span class="mbin">+</span><span class="mord mspace thickspace"></span><span class="mord mathrm">1</span><span class="mord mspace"> </span><span class="mopen">(</span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">d</span><span class="mord mathrm">a</span><span class="mord mathrm">t</span><span class="mord mathrm">a</span><span class="mord mspace"> </span><span class="mord mathrm">p</span><span class="mord mathrm">a</span><span class="mord mathrm" style="margin-right:0.01389em;">g</span><span class="mord mathrm">e</span><span class="mord mspace"> </span><span class="mord mathrm">r</span><span class="mord mathrm">e</span><span class="mord mathrm">a</span><span class="mord mathrm">d</span></span><span class="mclose">)</span><span class="mord mspace thickspace"></span><span class="mbin">+</span><span class="mord mspace thickspace"></span><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="mord mspace"> </span><span class="mopen">(</span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">C</span><span class="mord mathrm">P</span><span class="mord mathrm">U</span></span><span class="mclose">)</span></span></span></span></span>

<p>。</p>
<p>该模型假设索引组织为聚簇或近似聚簇结构，因此每次索引查找可定位到唯一一条记录。</p>
<p>对于<strong>聚簇索引的范围扫描</strong>，算子需扫描多个索引条目并可能访问多条数据行，<strong>I&#x2F;O 代价</strong>为</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>F</mi><mo>×</mo><mo>(</mo><mtext><mi mathvariant="normal">N</mi><mi mathvariant="normal">I</mi><mi mathvariant="normal">N</mi><mi mathvariant="normal">D</mi><mi mathvariant="normal">X</mi></mtext><mo>+</mo><mtext><mi mathvariant="normal">T</mi><mi mathvariant="normal">C</mi><mi mathvariant="normal">A</mi><mi mathvariant="normal">R</mi><mi mathvariant="normal">D</mi></mtext><mo>)</mo></mrow><annotation encoding="application/x-tex">
F \times (\text{NINDX} + \text{TCARD})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">F</span><span class="mbin">×</span><span class="mopen">(</span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">N</span><span class="mord mathrm">I</span><span class="mord mathrm">N</span><span class="mord mathrm">D</span><span class="mord mathrm">X</span></span><span class="mbin">+</span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">T</span><span class="mord mathrm">C</span><span class="mord mathrm">A</span><span class="mord mathrm">R</span><span class="mord mathrm">D</span></span><span class="mclose">)</span></span></span></span></span>

<p>，<strong>CPU 代价</strong>为</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>W</mi><mo>×</mo><mo>(</mo><mtext><mi mathvariant="normal">t</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">s</mi><mtext> </mtext><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">d</mi></mtext><mo>)</mo></mrow><annotation encoding="application/x-tex">
W \times (\text{tuples read})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="mbin">×</span><span class="mopen">(</span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">t</span><span class="mord mathrm">u</span><span class="mord mathrm">p</span><span class="mord mathrm">l</span><span class="mord mathrm">e</span><span class="mord mathrm">s</span><span class="mord mspace"> </span><span class="mord mathrm">r</span><span class="mord mathrm">e</span><span class="mord mathrm">a</span><span class="mord mathrm">d</span></span><span class="mclose">)</span></span></span></span></span>

<p>，因此整体成本为：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>F</mi><mo>×</mo><mo>(</mo><mtext><mi mathvariant="normal">N</mi><mi mathvariant="normal">I</mi><mi mathvariant="normal">N</mi><mi mathvariant="normal">D</mi><mi mathvariant="normal">X</mi></mtext><mo>+</mo><mtext><mi mathvariant="normal">T</mi><mi mathvariant="normal">C</mi><mi mathvariant="normal">A</mi><mi mathvariant="normal">R</mi><mi mathvariant="normal">D</mi></mtext><mo>)</mo><mo>+</mo><mi>W</mi><mo>×</mo><mo>(</mo><mtext><mi mathvariant="normal">t</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">s</mi><mtext> </mtext><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">d</mi></mtext><mo>)</mo></mrow><annotation encoding="application/x-tex">
F \times (\text{NINDX} + \text{TCARD}) + W \times (\text{tuples read})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">F</span><span class="mbin">×</span><span class="mopen">(</span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">N</span><span class="mord mathrm">I</span><span class="mord mathrm">N</span><span class="mord mathrm">D</span><span class="mord mathrm">X</span></span><span class="mbin">+</span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">T</span><span class="mord mathrm">C</span><span class="mord mathrm">A</span><span class="mord mathrm">R</span><span class="mord mathrm">D</span></span><span class="mclose">)</span><span class="mbin">+</span><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="mbin">×</span><span class="mopen">(</span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">t</span><span class="mord mathrm">u</span><span class="mord mathrm">p</span><span class="mord mathrm">l</span><span class="mord mathrm">e</span><span class="mord mathrm">s</span><span class="mord mspace"> </span><span class="mord mathrm">r</span><span class="mord mathrm">e</span><span class="mord mathrm">a</span><span class="mord mathrm">d</span></span><span class="mclose">)</span></span></span></span></span>

<p>，其中 NINDX 为索引页数，TCARD 为表的总页数，F 为谓词选取性；每个匹配索引条目对应一次数据页顺序 I&#x2F;O。</p>
<p>对于<strong>非聚簇索引的范围扫描</strong>，CPU 成本和聚簇索引的一致，但是 I&#x2F;O 成本为</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>F</mi><mo>×</mo><mo>(</mo><mtext><mi mathvariant="normal">N</mi><mi mathvariant="normal">I</mi><mi mathvariant="normal">N</mi><mi mathvariant="normal">D</mi><mi mathvariant="normal">X</mi></mtext><mo>+</mo><mtext><mi mathvariant="normal">N</mi><mi mathvariant="normal">C</mi><mi mathvariant="normal">A</mi><mi mathvariant="normal">R</mi><mi mathvariant="normal">D</mi></mtext><mo>)</mo></mrow><annotation encoding="application/x-tex">
F \times (\text{NINDX} + \text{NCARD})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">F</span><span class="mbin">×</span><span class="mopen">(</span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">N</span><span class="mord mathrm">I</span><span class="mord mathrm">N</span><span class="mord mathrm">D</span><span class="mord mathrm">X</span></span><span class="mbin">+</span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">N</span><span class="mord mathrm">C</span><span class="mord mathrm">A</span><span class="mord mathrm">R</span><span class="mord mathrm">D</span></span><span class="mclose">)</span></span></span></span></span>

<p>，因此整体成本为：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>F</mi><mo>×</mo><mo>(</mo><mtext><mi mathvariant="normal">N</mi><mi mathvariant="normal">I</mi><mi mathvariant="normal">N</mi><mi mathvariant="normal">D</mi><mi mathvariant="normal">X</mi></mtext><mo>+</mo><mtext><mi mathvariant="normal">N</mi><mi mathvariant="normal">C</mi><mi mathvariant="normal">A</mi><mi mathvariant="normal">R</mi><mi mathvariant="normal">D</mi></mtext><mo>)</mo><mo>+</mo><mi>W</mi><mo>×</mo><mo>(</mo><mtext><mi mathvariant="normal">t</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">s</mi><mtext> </mtext><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">d</mi></mtext><mo>)</mo></mrow><annotation encoding="application/x-tex">
F \times (\text{NINDX} + \text{NCARD}) + W \times (\text{tuples read})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">F</span><span class="mbin">×</span><span class="mopen">(</span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">N</span><span class="mord mathrm">I</span><span class="mord mathrm">N</span><span class="mord mathrm">D</span><span class="mord mathrm">X</span></span><span class="mbin">+</span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">N</span><span class="mord mathrm">C</span><span class="mord mathrm">A</span><span class="mord mathrm">R</span><span class="mord mathrm">D</span></span><span class="mclose">)</span><span class="mbin">+</span><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="mbin">×</span><span class="mopen">(</span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">t</span><span class="mord mathrm">u</span><span class="mord mathrm">p</span><span class="mord mathrm">l</span><span class="mord mathrm">e</span><span class="mord mathrm">s</span><span class="mord mspace"> </span><span class="mord mathrm">r</span><span class="mord mathrm">e</span><span class="mord mathrm">a</span><span class="mord mathrm">d</span></span><span class="mclose">)</span></span></span></span></span>

<p>，此时每个匹配条目都可能落在不同的数据页上，平均需一次随机 I&#x2F;O，因此用 NCARD（行数）来近似页数。</p>
<p>对于<strong>分段顺序扫描</strong>，不利用索引，需读取表的所有页并评估所有行：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext><mi mathvariant="normal">C</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">t</mi></mtext><mo>=</mo><mtext><mi mathvariant="normal">T</mi><mi mathvariant="normal">C</mi><mi mathvariant="normal">A</mi><mi mathvariant="normal">R</mi><mi mathvariant="normal">D</mi></mtext><mo>+</mo><mi>W</mi><mo>×</mo><mtext><mi mathvariant="normal">N</mi><mi mathvariant="normal">C</mi><mi mathvariant="normal">A</mi><mi mathvariant="normal">R</mi><mi mathvariant="normal">D</mi></mtext></mrow><annotation encoding="application/x-tex">
\text{Cost} = \text{TCARD} + W \times \text{NCARD}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="base displaystyle textstyle uncramped"><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">C</span><span class="mord mathrm">o</span><span class="mord mathrm">s</span><span class="mord mathrm">t</span></span><span class="mrel">=</span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">T</span><span class="mord mathrm">C</span><span class="mord mathrm">A</span><span class="mord mathrm">R</span><span class="mord mathrm">D</span></span><span class="mbin">+</span><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="mbin">×</span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">N</span><span class="mord mathrm">C</span><span class="mord mathrm">A</span><span class="mord mathrm">R</span><span class="mord mathrm">D</span></span></span></span></span></span>

<p>，其中 TCARD 为全表页数，NCARD 为元组总数；顺序扫描的 I&#x2F;O 可享有预取（prefetch）与缓冲优势，故只计算页面读取的总数。</p>
<p>接着，我们来看 JOIN 的成本计算，以<strong>嵌套循环连接</strong>（Nested-Loop Join）为例。</p>
<p>它的<strong>总代价公式</strong>：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mrow><mi mathvariant="normal">C</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">t</mi></mrow><mrow><mtext><mi mathvariant="normal">N</mi><mi mathvariant="normal">L</mi><mi mathvariant="normal">J</mi></mtext></mrow></msub><mo>(</mo><mi>A</mi><mo separator="true">,</mo><mi>B</mi><mo>)</mo><mo>=</mo><mrow><mi mathvariant="normal">C</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">t</mi></mrow><mo>(</mo><mi>A</mi><mo>)</mo><mspace width="0.277778em"></mspace><mo>+</mo><mspace width="0.277778em"></mspace><mrow><mi mathvariant="normal">N</mi><mi mathvariant="normal">C</mi><mi mathvariant="normal">A</mi><mi mathvariant="normal">R</mi><mi mathvariant="normal">D</mi></mrow><mo>(</mo><mi>A</mi><mo>)</mo><mo>×</mo><mrow><mi mathvariant="normal">C</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">t</mi></mrow><mo>(</mo><mi>B</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">
\mathrm{Cost}_{\text{NLJ}}(A,B) = \mathrm{Cost}(A) \;+\;\mathrm{NCARD}(A)\times \mathrm{Cost}(B)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class=""><span class="mord displaystyle textstyle uncramped"><span class="mord mathrm">C</span><span class="mord mathrm">o</span><span class="mord mathrm">s</span><span class="mord mathrm">t</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="text mord scriptstyle cramped"><span class="mord mathrm">N</span><span class="mord mathrm">L</span><span class="mord mathrm">J</span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord mathit">A</span><span class="mpunct">,</span><span class="mord mathit" style="margin-right:0.05017em;">B</span><span class="mclose">)</span><span class="mrel">=</span><span class="mord displaystyle textstyle uncramped"><span class="mord mathrm">C</span><span class="mord mathrm">o</span><span class="mord mathrm">s</span><span class="mord mathrm">t</span></span><span class="mopen">(</span><span class="mord mathit">A</span><span class="mclose">)</span><span class="mord mspace thickspace"></span><span class="mbin">+</span><span class="mord mspace thickspace"></span><span class="mord displaystyle textstyle uncramped"><span class="mord mathrm">N</span><span class="mord mathrm">C</span><span class="mord mathrm">A</span><span class="mord mathrm">R</span><span class="mord mathrm">D</span></span><span class="mopen">(</span><span class="mord mathit">A</span><span class="mclose">)</span><span class="mbin">×</span><span class="mord displaystyle textstyle uncramped"><span class="mord mathrm">C</span><span class="mord mathrm">o</span><span class="mord mathrm">s</span><span class="mord mathrm">t</span></span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.05017em;">B</span><span class="mclose">)</span></span></span></span></span>

<p>，其中 A 为外层计划，B 为内层基表，NCARD(A) 为外层输出元组数。</p>
<p>为了控制连接顺序的枚举复杂度，System R 优化器仅考虑<strong>左深树</strong>：</p>
<ul>
<li>每一步连接的右子树 B 必须为尚未使用的基表，而非先前连接出的中间子树。</li>
<li>这样能保证枚举过程中只需维护基表之间的累积连接，而无需考虑更复杂的树形拓扑，大幅减少计划数量（从 $O(N!)$ 降到约 $O(2^N)$)。</li>
</ul>
<blockquote>
<p>[!NOTE]</p>
<p>之前例子中的图就是一棵左深树。</p>
</blockquote>
<p>对于谓词形如 <code>B.key = A.key</code>，且在 B 的 key 列上存在<strong>唯一或聚簇索引</strong>，优化器近似认为：</p>
<ol>
<li>一次 B+Tree 索引查找需 “1 页” I&#x2F;O（从根到叶路径平均代价）。</li>
<li>根据索引返回的行定位信息，再一次 Heap File lookup 也需 “1 页” I&#x2F;O。</li>
<li>最后对该行执行谓词或投影等操作，产生 W 单位的 CPU 代价。</li>
</ol>
<p>综合得到：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mrow><mi mathvariant="normal">C</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">t</mi></mrow><mo>(</mo><mi>B</mi><mo>)</mo><mo>=</mo><mn>1</mn><mspace width="0.277778em"></mspace><mo>+</mo><mspace width="0.277778em"></mspace><mn>1</mn><mspace width="0.277778em"></mspace><mo>+</mo><mspace width="0.277778em"></mspace><mi>W</mi></mrow><annotation encoding="application/x-tex">
\mathrm{Cost}(B) = 1 \;+\; 1 \;+\; W
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord displaystyle textstyle uncramped"><span class="mord mathrm">C</span><span class="mord mathrm">o</span><span class="mord mathrm">s</span><span class="mord mathrm">t</span></span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.05017em;">B</span><span class="mclose">)</span><span class="mrel">=</span><span class="mord mathrm">1</span><span class="mord mspace thickspace"></span><span class="mbin">+</span><span class="mord mspace thickspace"></span><span class="mord mathrm">1</span><span class="mord mspace thickspace"></span><span class="mbin">+</span><span class="mord mspace thickspace"></span><span class="mord mathit" style="margin-right:0.13889em;">W</span></span></span></span></span>

<p>，该模型忽略了缓存预取及并行扫描等复杂因素，但其简洁性足以支撑海量计划的快速比较。</p>
<p>若内层无可用索引，则只能顺序扫描整个表：</p>
<ul>
<li><p><strong>I&#x2F;O 代价</strong>：需读取 TCARD(B) 页（表在磁盘上的总页数）；</p>
</li>
<li><p><strong>CPU 代价</strong>：对 NCARD(B) 条元组逐一评估谓词和产生输出，共</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>W</mi><mo>×</mo><mrow><mi mathvariant="normal">N</mi><mi mathvariant="normal">C</mi><mi mathvariant="normal">A</mi><mi mathvariant="normal">R</mi><mi mathvariant="normal">D</mi></mrow><mo>(</mo><mi>B</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">
W\times \mathrm{NCARD}(B)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="mbin">×</span><span class="mord displaystyle textstyle uncramped"><span class="mord mathrm">N</span><span class="mord mathrm">C</span><span class="mord mathrm">A</span><span class="mord mathrm">R</span><span class="mord mathrm">D</span></span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.05017em;">B</span><span class="mclose">)</span></span></span></span></span>

<p>。</p>
</li>
</ul>
<p>因此：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mrow><mi mathvariant="normal">C</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">t</mi></mrow><mo>(</mo><mi>B</mi><mo>)</mo><mo>=</mo><mrow><mi mathvariant="normal">T</mi><mi mathvariant="normal">C</mi><mi mathvariant="normal">A</mi><mi mathvariant="normal">R</mi><mi mathvariant="normal">D</mi></mrow><mo>(</mo><mi>B</mi><mo>)</mo><mspace width="0.277778em"></mspace><mo>+</mo><mspace width="0.277778em"></mspace><mi>W</mi><mspace width="0.16667em"></mspace><mo>×</mo><mrow><mi mathvariant="normal">N</mi><mi mathvariant="normal">C</mi><mi mathvariant="normal">A</mi><mi mathvariant="normal">R</mi><mi mathvariant="normal">D</mi></mrow><mo>(</mo><mi>B</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">
\mathrm{Cost}(B) = \mathrm{TCARD}(B)\;+\;W\,\times \mathrm{NCARD}(B)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord displaystyle textstyle uncramped"><span class="mord mathrm">C</span><span class="mord mathrm">o</span><span class="mord mathrm">s</span><span class="mord mathrm">t</span></span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.05017em;">B</span><span class="mclose">)</span><span class="mrel">=</span><span class="mord displaystyle textstyle uncramped"><span class="mord mathrm">T</span><span class="mord mathrm">C</span><span class="mord mathrm">A</span><span class="mord mathrm">R</span><span class="mord mathrm">D</span></span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.05017em;">B</span><span class="mclose">)</span><span class="mord mspace thickspace"></span><span class="mbin">+</span><span class="mord mspace thickspace"></span><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="mord mspace thinspace"></span><span class="mbin">×</span><span class="mord displaystyle textstyle uncramped"><span class="mord mathrm">N</span><span class="mord mathrm">C</span><span class="mord mathrm">A</span><span class="mord mathrm">R</span><span class="mord mathrm">D</span></span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.05017em;">B</span><span class="mclose">)</span></span></span></span></span>

<p>，该模型同样简化了缓冲与批量读写等优化手段，但体现了顺序扫描的典型开销。</p>
<p>如果是 Sort-Merge Join 的话，代价模型：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi><mi>o</mi><mi>s</mi><mi>t</mi><mo>=</mo><mi>C</mi><mi>o</mi><mi>s</mi><mi>t</mi><mo>(</mo><mi>A</mi><mo>)</mo><mo>+</mo><mi>C</mi><mi>o</mi><mi>s</mi><mi>t</mi><mo>(</mo><mi>B</mi><mo>)</mo><mo>+</mo><mi>s</mi><mi>o</mi><mi>r</mi><mi>t</mi><mspace width="0.22222em"></mspace><mi>c</mi><mi>o</mi><mi>s</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">
Cost = Cost(A) + Cost(B) + sort\:cost
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.07153em;">C</span><span class="mord mathit">o</span><span class="mord mathit">s</span><span class="mord mathit">t</span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.07153em;">C</span><span class="mord mathit">o</span><span class="mord mathit">s</span><span class="mord mathit">t</span><span class="mopen">(</span><span class="mord mathit">A</span><span class="mclose">)</span><span class="mbin">+</span><span class="mord mathit" style="margin-right:0.07153em;">C</span><span class="mord mathit">o</span><span class="mord mathit">s</span><span class="mord mathit">t</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.05017em;">B</span><span class="mclose">)</span><span class="mbin">+</span><span class="mord mathit">s</span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit">t</span><span class="mord mspace mediumspace"></span><span class="mord mathit">c</span><span class="mord mathit">o</span><span class="mord mathit">s</span><span class="mord mathit">t</span></span></span></span></span>

<ol>
<li><strong>Cost(A)</strong>：外层子计划（子树）A 的总代价；</li>
<li><strong>Cost(B)</strong>：内层子计划 B（可以是基表或中间结果）的总代价；</li>
<li><strong>sort cost</strong>：对 A 和 B 各自执行排序的代价之和。</li>
</ol>
<blockquote>
<p>排序—归并连接是一种基于将两输入关系各自按连接键排序，随后线性归并扫描输出匹配对的算法。</p>
<ul>
<li><strong>阶段一：排序（Sort）</strong><ul>
<li>对输入关系 A、B 按连接属性（pred 中指定的字段）各自进行排序。</li>
<li>如果输入已经部分或完全有序，则可跳过或简化排序步骤。</li>
</ul>
</li>
<li><strong>阶段二：归并（Merge）</strong><ul>
<li>维护两个游标，分别指向 A、B 的当前最小键值记录。</li>
<li>比较当前 A、B 键值：<ul>
<li>若 A.key &lt; B.key，则将 A 游标前移；</li>
<li>若 A.key &gt; B.key，则将 B 游标前移；</li>
<li>若相等，则输出所有相同键值的配对（可能需要在一个输入保留缓冲区中暂存重复键值），并前移游标。</li>
</ul>
</li>
<li>该归并过程只需一次顺序扫描，两边各推进，故 I&#x2F;O 和 CPU 都相对高效。</li>
</ul>
</li>
<li><strong>适用场景</strong><ul>
<li>两输入均可顺序访问或已排序，且连接键上无合适哈希索引时最优；</li>
<li>特别适合大批量数据输出且需要顺序结果的场景。</li>
</ul>
</li>
</ul>
</blockquote>
<p>如果后续操作涉及选取最大最小值，那么最好使用 Sort-Merge Join 先得出排序后的 JOIN 结果。</p>
<p>第五步，选出成本最低的执行计划：</p>
<p>若对所有可能的联接树与交叉产品一一枚举，计划数目将呈阶乘级增长，无法承受 。System R（Selinger 优化器）的核心思想是，通过<strong>启发式剪枝</strong>大幅减少搜索空间，同时用<strong>自底向上动态规划</strong>保证在受限空间内选出最优左深计划。</p>
<ul>
<li><strong>全空间规模</strong>：对 n 个基表，所有可能的联接树数约为 n!（叶深树）。例如 6 表联接时有 6! &#x3D; 720 种联接顺序；10 表时增至 3 628 800 种。</li>
<li><strong>启发式目标</strong>：在保证生成足够优质计划的前提下，剪掉绝大多数计划，避免枚举交叉组合、子查询作为内层的树形连接等无效情况。</li>
</ul>
<p>这里展示<strong>三大启发式规则</strong>：</p>
<ol>
<li><p><strong>谓词下推</strong></p>
<p>越早执行过滤谓词，可最大程度减少后续算子的输入规模与 I&#x2F;O 或 CPU 代价。</p>
<p>在构建执行计划时，把每个谓词 $\sigma$ 尽可能下推到最接近基表扫描或索引扫描的层面，不把过滤延迟到后面再算。</p>
</li>
<li><p><strong>避免笛卡尔积</strong></p>
<p>对无关联谓词的表进行笛卡尔积会产生极大中间结果，通常不可接受。</p>
<p>仅在<strong>所有过滤条件均已消耗殆尽</strong>（即查询本质需要交叉连接）时，才枚举产生交叉产品的计划；否则只枚举带有有效联接谓词的表对。</p>
</li>
<li><p><strong>仅枚举左深树</strong></p>
<p>在左深树中，每次联接的右子树必须是一个<strong>基表</strong>，而不能是先前联接所得的中间子树。</p>
<p>这样可以使得<strong>搜索空间大幅缩减</strong>：从全空间的 O(n!) 降至约 O(2ⁿ) 或更小；以及<strong>流水线执行</strong>：左深树可实现完全流水线（pipelining），中间结果无需写入磁盘临时表；对大多数算子（NLJ、Hash Join、Merge Join）均适用。</p>
</li>
</ol>
<p><strong>自底向上的动态规划</strong></p>
<p>以上的三种启发式规则带来的提升有限，所以 System R 还引入了动态规划。</p>
<p>动态规划算法利用了<strong>最优子结构</strong>的性质：如果在所有包含关系集 {A,B,C} 的计划中，连接 A、B、C 最优的顺序是  (A ⋈ B) ⋈ C，那么无论这个三表子集在更大计划中如何出现，(A ⋈ B) 必然是 {A,B} 的最优子计划之一，不需要再次枚举.</p>
<p>由于子计划不依赖于外部上下文，其最优性是全局性的，只需计算一次，即可复用到所有包含该子集的更大计划中。这一思想即 “不要在更大的计划中重新考虑子计划”。</p>
<p>System R 优化器按照子计划包含的基表数目，从小到大分层枚举：</p>
<ol>
<li><strong>第 1 轮</strong>（1-表计划）：分别为每个基表 $R_i$ 选择成本最低的访问路径（全表扫描或索引扫描）并记录其成本与输出行数。</li>
<li><strong>第 2 轮</strong>（2-表计划）：对第 1 轮中的每个单表计划 P（作为外层），将尚未使用的每个基表 $R_j$ 作为内层，计算连接成本，并在所有方案中保留最优者。</li>
<li><strong>…</strong></li>
<li><strong>第 k 轮</strong>（k-表计划）：对所有包含 k-1 表的最优子计划 S，尝试将每个剩余基表 R 连接进来，更新并保留每个大小为 k 的子集的最优左深计划，直至包含所有 n 张表。</li>
</ol>
<p>如此，算法以 n 轮完成枚举，每轮仅对上一轮的最优子计划进行扩展，不必遍历所有 O(n!) 种联接树，空间和时间复杂度可控制在指数级但远低于阶乘级别。</p>
<p>用伪代码来表示就是：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">R ← <span class="built_in">set</span> of relations to join</span><br><span class="line"><span class="keyword">for</span> i in &#123;<span class="number">1</span>…|R|&#125;:                              <span class="comment">// 按子集大小自底向上</span></span><br><span class="line">  <span class="keyword">for</span> S in &#123;all subsets of R of size i&#125;:</span><br><span class="line">    optcost_S = ∞</span><br><span class="line">    optjoin_S = ∅</span><br><span class="line">    <span class="keyword">for</span> a in S:                              <span class="comment">// 枚举将 a 作为最后连接的基表</span></span><br><span class="line">      c_sa = optcost_&#123;S–&#123;a&#125;&#125;</span><br><span class="line">             + min_cost_to_join((S–&#123;a&#125;), a)</span><br><span class="line">             + min_access_cost(a)</span><br><span class="line">      <span class="keyword">if</span> c_sa &lt; optcost_S:</span><br><span class="line">        optcost_S = c_sa</span><br><span class="line">        optjoin_S  = optjoin_&#123;S–&#123;a&#125;&#125; ⨝ a</span><br><span class="line">    <span class="comment">// 计算并缓存 S 的最优子计划，包括 optcost_* 和 optjoin_*</span></span><br></pre></td></tr></table></figure>

<p>该算法默认只搜索左深树，因为可以在子集拆分的时候采用 S - a + a 的方式来选取已有的子树和要 JOIN 的基表，并大幅减小搜索空间。</p>
<p>以 PostgreSQL 中的最优子计划复用为例：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 第一次：emp ⋈ kids 的最低成本执行计划</span></span><br><span class="line">Hash <span class="keyword">Join</span>  (cost<span class="operator">=</span><span class="number">347292.59</span>.<span class="number">.498019</span><span class="number">.60</span> <span class="keyword">rows</span><span class="operator">=</span><span class="number">3000001</span> width<span class="operator">=</span><span class="number">36</span>)</span><br><span class="line"> Hash Cond: (kids.eno <span class="operator">=</span> emp.eno)</span><br><span class="line">   <span class="operator">-</span><span class="operator">&gt;</span> Seq Scan <span class="keyword">on</span> kids         (cost<span class="operator">=</span><span class="number">0.00</span>.<span class="number">.49099</span><span class="number">.01</span> <span class="keyword">rows</span><span class="operator">=</span><span class="number">3000001</span> width<span class="operator">=</span><span class="number">18</span>)</span><br><span class="line">   <span class="operator">-</span><span class="operator">&gt;</span> Hash                   (cost<span class="operator">=</span><span class="number">163696.15</span>.<span class="number">.163696</span><span class="number">.15</span> <span class="keyword">rows</span><span class="operator">=</span><span class="number">10000115</span> width<span class="operator">=</span><span class="number">22</span>)</span><br><span class="line">        <span class="operator">-</span><span class="operator">&gt;</span> Seq Scan <span class="keyword">on</span> emp    (cost<span class="operator">=</span><span class="number">0.00</span>.<span class="number">.163696</span><span class="number">.15</span> <span class="keyword">rows</span><span class="operator">=</span><span class="number">10000115</span> width<span class="operator">=</span><span class="number">22</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 第二次：dept ⋈ (emp ⋈ kids) 的最低成本执行计划</span></span><br><span class="line">Hash <span class="keyword">Join</span>  (cost<span class="operator">=</span><span class="number">350376.61</span>.<span class="number">.556245</span><span class="number">.96</span> <span class="keyword">rows</span><span class="operator">=</span><span class="number">3000001</span> width<span class="operator">=</span><span class="number">40</span>)</span><br><span class="line"> Hash <span class="keyword">Join</span>  (cost<span class="operator">=</span><span class="number">347292.59</span>.<span class="number">.498019</span><span class="number">.60</span> <span class="keyword">rows</span><span class="operator">=</span><span class="number">3000001</span> width<span class="operator">=</span><span class="number">36</span>) <span class="comment">-- 最优子结构复用</span></span><br><span class="line">  Hash Cond: (kids.eno <span class="operator">=</span> emp.eno)</span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> Seq Scan <span class="keyword">on</span> kids </span><br><span class="line">    <span class="operator">-</span><span class="operator">&gt;</span> Hash </span><br><span class="line">         <span class="operator">-</span><span class="operator">&gt;</span> Seq Scan <span class="keyword">on</span> emp <span class="comment">-- 最优子结构复用结束</span></span><br><span class="line">   <span class="operator">-</span><span class="operator">&gt;</span> Hash  (cost<span class="operator">=</span><span class="number">1443.01</span>.<span class="number">.1443</span><span class="number">.01</span> <span class="keyword">rows</span><span class="operator">=</span><span class="number">100001</span> width<span class="operator">=</span><span class="number">8</span>)</span><br><span class="line">        <span class="operator">-</span><span class="operator">&gt;</span> Seq Scan <span class="keyword">on</span> dept</span><br></pre></td></tr></table></figure>

<p>假设有四个表 A、B、C、D，它们通过动态规划选出最优执行计划的步骤如下：</p>
<p>当前计算出 A 的最优执行计划是索引扫描，B 是顺序扫描（C 和 D 这里不展示），那么 {A, B} &#x3D; AB or BA，{A, C} &#x3D; AC or CA，{B, C} &#x3D; BC or CB。</p>
<p>经过一系列计算，我们可以在动态规划中得出如下的备忘录：</p>
<table>
<thead>
<tr>
<th>Relations</th>
<th>Best Plan</th>
<th>Cost</th>
</tr>
</thead>
<tbody><tr>
<td>A</td>
<td>Index Scan</td>
<td>5</td>
</tr>
<tr>
<td>B</td>
<td>Seq Scan</td>
<td>15</td>
</tr>
<tr>
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
<tr>
<td>{A, B}</td>
<td>B ⨝ A</td>
<td>75</td>
</tr>
<tr>
<td>{A, C}</td>
<td>A ⨝ C</td>
<td>12</td>
</tr>
<tr>
<td>{B, C}</td>
<td>C ⨝ B</td>
<td>22</td>
</tr>
<tr>
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
</tbody></table>
<p>之后，我们要计算 {A, B, C}，那么就是要计算：</p>
<ol>
<li>不包含 A 的：比较 A({B, C}) 和 ({B, C})A；</li>
<li>不包含 B 的：比较 ({A, C})B 和 B({A, C})；</li>
<li>不包含 C 的：比较 C({A, B}) 和 ({A, B})C。</li>
</ol>
<p>这个时候我们发现 {A, B}、{A, C}、{B, C} 的最优执行计划已经被缓存起来了，可以直接复用。perfecto！</p>
<p>最终，我们可以得出如下的备忘录表：</p>
<table>
<thead>
<tr>
<th>Relations</th>
<th>Best Plan</th>
<th>Cost</th>
</tr>
</thead>
<tbody><tr>
<td>A</td>
<td>Index Scan</td>
<td>5</td>
</tr>
<tr>
<td>B</td>
<td>Seq Scan</td>
<td>15</td>
</tr>
<tr>
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
<tr>
<td>{A, B}</td>
<td>B ⨝ A</td>
<td>75</td>
</tr>
<tr>
<td>{A, C}</td>
<td>A ⨝ C</td>
<td>12</td>
</tr>
<tr>
<td>{B, C}</td>
<td>C ⨝ B</td>
<td>22</td>
</tr>
<tr>
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
<tr>
<td>{A, B, C}</td>
<td>(CB) ⨝ A</td>
<td>35</td>
</tr>
<tr>
<td>{B, C, D}</td>
<td>(CB) ⨝ D</td>
<td>42</td>
</tr>
<tr>
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
<tr>
<td>{A, B, C, D}</td>
<td>((CB) ⨝ D) ⨝ A</td>
<td>57</td>
</tr>
</tbody></table>
<p>因此，我们可以知道 JOIN ABCD 这四个表的最低成本和最优执行计划了。</p>
<p>并且该算法在最差情况下需要枚举所有表子集并对每个子集尝试所有可能的最后加入表，因此具有指数级时间复杂度：O(n · 2ⁿ)。</p>
<p>我们可以将该问题等价成类似 01 子集问题，也就是 n 张表对应一串长度为 n 的二进制串，第 i 位为 1 代表关系 i 已经被 JOIN 了，因此有 2ⁿ - 1 个子集。而且每个子集要进行 n 次状态转移计算，也就是尝试去除集合中的某一个表来构建连接计划。最终两者相乘可得出如上的时间复杂度。</p>
<p><strong>有趣排序（interesting order）</strong></p>
<p>查询优化器在枚举左深执行计划时，除了比较不同访问路径和连接算法的代价外，还要考虑输出结果的排序属性——若某计划天然生成了对后续算子（如 Merge Join、ORDER BY、GROUP BY、去重等）有用的顺序，则称该排序为有趣排序。优化器会为每个子集在<strong>每种</strong>有趣排序下各自缓存最优子计划，从而保证后续算子能够直接利用已有排序，避免额外排序或物化开销，但这也会使枚举空间按有趣排序数量 k 成倍增长，总体复杂度增加 k + 1 倍。</p>
<p>尽管枚举空间增加，优化器借此能提前利用排序属性，减少后续全局排序及临时物化，往往在整体查询时间上取得收益，尤其在多级排序或多次归并连接链中更为明显。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> each subset S of relations:</span><br><span class="line">  <span class="keyword">for</span> each interesting order o in &#123;unordered&#125; ∪ Orders(S):</span><br><span class="line">    compute min-cost plan producing S with order o</span><br><span class="line">    keep plan <span class="keyword">if</span> cost smaller than previous best <span class="title function_">for</span> <span class="params">(S,o)</span></span><br></pre></td></tr></table></figure>

<h2 id="基数估算"><a href="#基数估算" class="headerlink" title="基数估算"></a>基数估算</h2><p>基数估算（Cardinality Estimation）是成本模型的核心环节，优化器需要对每一种可能的关联操作都进行行数估算；当查询涉及 8–16 张表关联时，由于关联顺序的组合数呈指数级增长，可能需要上百到上千次估算；为了避免优化阶段延迟过大，估算器通常要在毫秒级完成一次估算；因此，各数据库系统普遍采用各种快速而简化的假设或采样策略，在估算精度与执行开销之间做权衡。</p>
<p>PostgreSQL 在 pg_statistic 系统目录中，为表的每一列收集的两大核心统计：</p>
<ol>
<li><strong>直方图边界（histogram_bounds）</strong>：按等频原则划分的区间边界，用于估算范围查询的选择性。</li>
<li><strong>最常见值列表（most_common_vals）</strong>：出现频率最高的一组值及其对应频率，用于快速处理等值查询。查询优化器在生成执行计划时，会结合这两类统计信息来估算谓词的行数（selectivity），进而比较不同执行策略的成本。</li>
</ol>
<p>下面将介绍这两种方案。</p>
<p>直方图又分为等宽和等深两种类型：</p>
<ol>
<li><p>等宽直方图（Equal-Width Histogram）是最简单的直方图类型，它将数据值范围等分成若干个固定宽度的桶（bins），并统计每个桶内数据所占的比例（selectivity）。下图将总共 7854 条记录分入等宽的若干个区间（比如 0–5K、5K–10K 等），并在每个桶上方标注该区间内记录占总量的比例（如 0–5K 桶占 61%）。查询优化器可以利用这些比例估算范围查询或不在最常见值列表中的等值查询的行数，从而评估不同执行计划的成本。</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_histo_equi_width.png" alt="img"></p>
<p>根据上图，如果我们要选取小于 5000 的数据，那么操作的范围只局限于第一个桶中，因此估算的基数为 0.61 * 7854 &#x3D; 4796。</p>
<p>但这里会有个问题：如果范围查找的数值不是某个同的边界呢？也就是比如我们想查找小于 7500 的数据，而这个值刚好在第二个桶的正中间。这个时候我们只能假设数据为均匀分布，但是实际情况并不总是如此：可能大部分数据都集中在第二个桶的 5-6K 这一部分，也可能集中在 9-10K 这一部分，因此会存在较大误差。同时为了减少误差，我们又不可能无限制地缩小每个桶的宽度，因为最终会导致大量的桶，反而会加剧查询和存储的开销。因此我们需要等深直方图。</p>
</li>
<li><p>等深直方图（Equal-Depth Histogram）通过保证每个桶内的<strong>行数（频数）大致相同</strong>来划分数据范围。下图仍然是针对 7854 条记录使用 100 个桶来划分，每个桶含有相似数量的值，因此即使值域跨度不均，桶高（selectivity）也差不多（≈0.008），更能反映底层数据分布的真实密度。</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_histo_equi_depth.png" alt="img"></p>
<p>在上图中，如果我们要选取小于 195.5K 的数据，那么操作范围在最后两个桶中，因此估算的基数为 (0.008 + 0.008) * 7854 &#x3D;126。</p>
<p>通常来说，等深直方图由于等宽直方图，因为它保证了每个桶的选取性的一致，从而导致数据分布更密集的桶更窄，数据分布更稀疏的桶更宽，这更好地反映出了数据分布。但是这样的维护成本也会更高，尤其是某些 DML 操作导致一个桶的高度变化时，它之后的桶需要不断地移动一些数据到这个桶直到选取性达到 0.008，之后的每个桶需要不断往前一个桶移动数据来保证每个桶的高度达到 0.008，每个桶的在 X 轴上的范围也可能会因此变化，甚至某些情况下的工作量不亚于从头构建。此外，每个桶中的数据倾斜仍然无法被避免。</p>
<p>也就是，如果我们要选取小于 347866 的数据，那么仍然需要假设为均匀分布，这个时候遇到的问题和等宽直方图的是一样的。</p>
</li>
</ol>
<p>通常情况下导致数据倾斜的大概率是一些极端离群值（outliers），我们可以通过下面这个方案来处理它。</p>
<p><strong>等深直方图 + 最常见值（Most Common Values）</strong></p>
<p>这个方案中，对于出现极高频率或明显偏斜的值，等深直方图会将它们剔除到最常见值列表，以免扭曲桶的划分边界和高度。</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_histo_equi_depth.png" alt="img"></p>
<table>
<thead>
<tr>
<th>Value</th>
<th align="right">Selectivity</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td align="right">0.07</td>
</tr>
<tr>
<td>1</td>
<td align="right">0.0048</td>
</tr>
<tr>
<td>2</td>
<td align="right">0.00407</td>
</tr>
<tr>
<td>…</td>
<td align="right">…</td>
</tr>
<tr>
<td>94</td>
<td align="right">0.0002</td>
</tr>
<tr>
<td>850</td>
<td align="right">0.0007</td>
</tr>
<tr>
<td><strong>Total</strong></td>
<td align="right"><strong>0.14</strong></td>
</tr>
</tbody></table>
<p>上面这个表格就是最常见值列表。</p>
<p>如果我们要选取等于 0 的数据，那么直接从最常见值的表里获取 0.07，然后 0.07 * 7854 &#x3D; 550 就是预估的基数。</p>
<p>如果我们要选取大于 812 且小于 860 的数据，那么估算的基数为 (0.008 + 0.0007) * 7854 &#x3D; 68.45。</p>
<p>但是这个方案仍然存在问题：当我们对多字段（列）的谓词过滤进行基数预估的时候，往往会低估基数，也就是预估的基数往往会比真实操作的元组的基数要低。这是因为不同列的过滤谓词被假设彼此独立，即联合选择性等于各单列选择性的乘积。这种做法在实际数据分布中往往并不成立：当列之间存在相关性时，单列乘积往往远小于真实的联合选择性，导致估算行数被严重低估，从而可能选择次优的执行计划。</p>
<p>为了克服完全独立性假设在多谓词估算中严重低估结果的问题，SQL Server 引入了三种谓词相关性假设：</p>
<ol>
<li><strong>完全独立</strong>：各谓词假设互不相关，联合选择性直接相乘。</li>
<li><strong>完全相关</strong>：各谓词假设完全相关，联合选择性取最小者。</li>
<li><strong>部分相关</strong>：折中假设，既不完全独立也不完全相关，通过对较低的选择性取根号后再相乘，减缓低估程度。</li>
</ol>
<p>而多列 MCV 是将单列 MCV 的思路扩展到多列组合上：在统计收集阶段，为常一起出现在 WHERE 条件中的列组建立一个联合 MCV 列表，记录这些组合值及其联合频率；查询时，若谓词中出现该组合值，优化器即可直接使用其真实联合选择性，而无需依赖独立性假设或柱状图估算，从而显著提升多谓词过滤的准确性。</p>
<table>
<thead>
<tr>
<th>balance</th>
<th>age</th>
<th>selectivity</th>
</tr>
</thead>
<tbody><tr>
<td>4776</td>
<td>34</td>
<td>0.009</td>
</tr>
<tr>
<td>76325</td>
<td>41</td>
<td>0.0005</td>
</tr>
<tr>
<td>…</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>但是这种方案的构建成本会随着查询涉及的列数的增长而增长。</p>
<p>同样，多列直方图也面临多个列的组合的爆炸式增长问题。</p>
<p>最后一种方案是 BayesCard：传统查询优化器常用<strong>独立直方图</strong>，对每列单独建模并将联合选择性取乘积 P(A)P(B)P(C)，这种方法速度极快但在列高度相关时严重低估真实结果；若对多列直接建立<strong>三维直方图</strong>，空间开销将成指数级 </p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mrow><mi mathvariant="script">O</mi></mrow><mo>(</mo><mi mathvariant="normal">∣</mi><mi>N</mi><msup><mi mathvariant="normal">∣</mi><mn>3</mn></msup><mo>)</mo></mrow><annotation encoding="application/x-tex">
\mathcal{O}(|N|^3)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8641079999999999em;"></span><span class="strut bottom" style="height:1.1141079999999999em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord displaystyle textstyle uncramped"><span class="mord mathcal" style="margin-right:0.02778em;">O</span></span><span class="mopen">(</span><span class="mord mathrm">∣</span><span class="mord mathit" style="margin-right:0.10903em;">N</span><span class="mord"><span class="mord mathrm">∣</span><span class="vlist"><span style="top:-0.413em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathrm">3</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span></span></span></span></span>

<p>，也无法在生产环境中普及。<strong>图形模型</strong>（如 Bayesian 网络）通过学习列间条件依赖，并将联合分布因子化为若干局部条件概率：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>A</mi><mo>)</mo><mspace width="0.16667em"></mspace><mi>P</mi><mo>(</mo><mi>B</mi><mo>∣</mo><mi>A</mi><mo>)</mo><mspace width="0.16667em"></mspace><mi>P</mi><mo>(</mo><mi>C</mi><mo>∣</mo><mi>A</mi><mo separator="true">,</mo><mi>B</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">
P(A)\,P(B\mid A)\,P(C\mid A,B)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathit">A</span><span class="mclose">)</span><span class="mord mspace thinspace"></span><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.05017em;">B</span><span class="mrel">∣</span><span class="mord mathit">A</span><span class="mclose">)</span><span class="mord mspace thinspace"></span><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.07153em;">C</span><span class="mrel">∣</span><span class="mord mathit">A</span><span class="mpunct">,</span><span class="mord mathit" style="margin-right:0.05017em;">B</span><span class="mclose">)</span></span></span></span></span>

<p>，在保留关联性的前提下，将参数规模控制到 </p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mrow><mi mathvariant="script">O</mi></mrow><mo>(</mo><mn>2</mn><mi mathvariant="normal">∣</mi><mi>N</mi><msup><mi mathvariant="normal">∣</mi><mn>2</mn></msup><mo>)</mo></mrow><annotation encoding="application/x-tex">
\mathcal{O}(2|N|^2)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8641079999999999em;"></span><span class="strut bottom" style="height:1.1141079999999999em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord displaystyle textstyle uncramped"><span class="mord mathcal" style="margin-right:0.02778em;">O</span></span><span class="mopen">(</span><span class="mord mathrm">2</span><span class="mord mathrm">∣</span><span class="mord mathit" style="margin-right:0.10903em;">N</span><span class="mord"><span class="mord mathrm">∣</span><span class="vlist"><span style="top:-0.413em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span></span></span></span></span>

<p>，从而在毫秒级完成联合 Selectivity 推断，并在多项基准测试中显著降低估算误差，实现了精度与性能的平衡。</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/db_adv_query_optimize_bayes_card.drawio.png" alt="img"></p>
<p>关于 BayesCard 的具体内容可参考：<a href="https://arxiv.org/pdf/2012.14743">https://arxiv.org/pdf/2012.14743</a></p>
<p>传统关系型数据库对等值和范围谓词均有成熟的统计信息（如直方图、最常见值列表）支持，但对于 LIKE 和 UDF 这两类黑箱谓词，数据库优化器往往难以利用现有统计直接估算、只能退而求其次使用启发式规则或假定常数选择性，导致估算误差大、执行计划次优。近年来，研究界针对 LIKE 查询提出了<strong>模式&#x2F;序列模型</strong>（pattern-based 或 positional histograms）来改善精度，而 UDF 则几乎无法通过统计建模，只能依赖<strong>运行时采样</strong>或<strong>成本抑制</strong>策略。</p>
<p><strong>模式&#x2F;序列直方图方法</strong></p>
<p><strong>SPH（Sequential Pattern-based Histogram）</strong>：通过挖掘字符串的频繁子序列，将常见的子串模式构建成模式直方图，在优化时根据查询模式匹配度快速估算 selectivity，从而显著优于传统直方图和常数假定。</p>
<p><strong>Positional Sequence Patterns</strong>：针对 SPH 偶尔会高估的问题，引入位置序列模式区分相邻匹配与可插入匹配，通过信息熵剔除冗余模式，再结合分区匹配策略，使 LIKE 查询的平均误差率降低约 20%。</p>
<p><strong>深度学习方法</strong>：近期有工作利用神经网络对 LIKE 模式进行表征和回归预测，能够学习复杂通配符下的非线性分布，但目前仍处于研究阶段，工业界应用有限。</p>
<p><strong>样本采样（Sampling）</strong></p>
<p>样本采样是一种简单直接的基数估算方法：在数据库中为每张表维护一个小规模的随机样本（例如，1% 的行）并常驻内存；在优化阶段，针对查询谓词仅在样本上执行过滤，计算样本命中率，然后将其外推到全表数据，得到整体选择性和估算行数。</p>
<p>该方案的优点是：</p>
<p><strong>支持任意谓词</strong>：由于直接在样本上运行过滤运算，不依赖预先计算的直方图或分布假设，对<strong>任何</strong>运算符或 UDF 都有效。</p>
<p><strong>摆脱独立性等假设</strong>：无需假设列间相互独立，也无需假设值在桶内均匀分布；样本大致反映真实分布，即可获取估算。</p>
<p><strong>易于集成</strong>：只要在优化器中加入样本访问路径，就能在编译阶段快速完成过滤并计算比例，无需维护复杂的统计结构。</p>
<p>缺点是：</p>
<p><strong>可能遗漏极端值</strong>：如果查询谓词对应的行在样本中未出现（例如极端离群值或低频组合），会导致估算为零或极小，严重低估真实行数。</p>
<p><strong>编译时开销</strong>：需要在优化阶段执行过滤运算，若样本量或谓词复杂度较高，编译时间可能显著增加；采样比例若过低，则准确度下降，否则延迟上升。</p>
<p><strong>不适用于多表连接</strong>：在多表连接查询中，需要对多个表的样本进行笛卡尔组合或联动抽样，开销与实现复杂度呈指数级增长，因此通常<strong>不对连接</strong>使用样本采样估算，只针对单表谓词有效。</p>
<p>下面展示 PostgreSQL 中是如何进行基数估算的：</p>
<p>PostgreSQL（沿用 System R 的经典做法）对单列等值联结 R₁ ⋈ R₂ ON R₁.a &#x3D; R₂.a 估算行数时，先分别估算表过滤后行数 |R₁|、|R₂| 及各自该列的基数 (d₁、d₂)，然后假定联结属性在两表中同构分布并采用最保守的分母：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo fence="true">∣</mo><msub><mi>R</mi><mn>1</mn></msub><mo>⋈</mo><msub><mi>R</mi><mn>2</mn></msub><mo fence="true">∣</mo><mspace width="0.277778em"></mspace><mo>≈</mo><mspace width="0.277778em"></mspace><mfrac><mrow><mi mathvariant="normal">∥</mi><msub><mi>R</mi><mn>1</mn></msub><mi mathvariant="normal">∥</mi><mspace width="0.277778em"></mspace><mo>×</mo><mspace width="0.277778em"></mspace><mi mathvariant="normal">∥</mi><msub><mi>R</mi><mn>2</mn></msub><mi mathvariant="normal">∥</mi></mrow><mrow><mi>max</mi><mo>(</mo><msub><mi>d</mi><mn>1</mn></msub><mo separator="true">,</mo><mspace width="0.16667em"></mspace><msub><mi>d</mi><mn>2</mn></msub><mo>)</mo></mrow></mfrac><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">
\bigl|R_1 \Join R_2\bigr| \;\approx\; \frac{\|R_1\|\;\times\;\|R_2\|}{\max(d_1,\,d_2)}.
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.427em;"></span><span class="strut bottom" style="height:2.363em;vertical-align:-0.936em;"></span><span class="base displaystyle textstyle uncramped"><span class="mopen"><span class="style-wrap reset-textstyle textstyle uncramped"><span class="delimsizing mult"><span class="vlist"><span style="top:0.35000999999999993em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-0.25599000000000005em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span><span class="mord"><span class="mord mathit" style="margin-right:0.00773em;">R</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.00773em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">⋈</span><span class="mord"><span class="mord mathit" style="margin-right:0.00773em;">R</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.00773em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose"><span class="style-wrap reset-textstyle textstyle uncramped"><span class="delimsizing mult"><span class="vlist"><span style="top:0.35000999999999993em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-0.25599000000000005em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span><span class="mord mspace thickspace"></span><span class="mrel">≈</span><span class="mord mspace thickspace"></span><span class="mord reset-textstyle displaystyle textstyle uncramped"><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.686em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle cramped"><span class="mord textstyle cramped"><span class="mop">max</span><span class="mopen">(</span><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="mord mspace thinspace"></span><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span></span></span></span><span style="top:-0.2300000000000001em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.677em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped"><span class="mord textstyle uncramped"><span class="mord mathrm">∥</span><span class="mord"><span class="mord mathit" style="margin-right:0.00773em;">R</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.00773em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord mathrm">∥</span><span class="mord mspace thickspace"></span><span class="mbin">×</span><span class="mord mspace thickspace"></span><span class="mord mathrm">∥</span><span class="mord"><span class="mord mathit" style="margin-right:0.00773em;">R</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.00773em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord mathrm">∥</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mord mathrm">.</span></span></span></span></span>

<p>，其中 <code>max(d₁,d₂)</code> 是两表中该列唯一值数量的较大者，用作平均每个值匹配行数的分母，以避免乘积模型在高度偏斜场景下的严重低估。</p>
<p>假设有三个表 emp，dept，kids：</p>
<p>emp：</p>
<table>
<thead>
<tr>
<th>eid</th>
<th>employee</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>Lee</td>
</tr>
<tr>
<td>2</td>
<td>Kim</td>
</tr>
<tr>
<td>3</td>
<td>Sam</td>
</tr>
</tbody></table>
<p>dept：</p>
<table>
<thead>
<tr>
<th>eid</th>
<th>department</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>财务部</td>
</tr>
<tr>
<td>2</td>
<td>财务部</td>
</tr>
<tr>
<td>3</td>
<td>行政部</td>
</tr>
</tbody></table>
<p>kids：</p>
<table>
<thead>
<tr>
<th>eid</th>
<th>name</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>Neil</td>
</tr>
<tr>
<td>1</td>
<td>Lebron</td>
</tr>
<tr>
<td>2</td>
<td>Justin</td>
</tr>
<tr>
<td>3</td>
<td>Tom</td>
</tr>
</tbody></table>
<p>如果执行 <code>SELECT * FROM emp, dept, kids WHERE eid = eid AND emp.eid = kids.eid;</code>，也就是没有过滤条件的情况，那么 </p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>∣</mo><mi>e</mi><mi>m</mi><mi>p</mi><mo>∣</mo><mo>=</mo><mn>3</mn><mspace width="1em"></mspace><mo>∣</mo><mi>d</mi><mi>e</mi><mi>p</mi><mi>t</mi><mo>∣</mo><mo>=</mo><mn>3</mn><mspace width="1em"></mspace><mo>∣</mo><mi>k</mi><mi>i</mi><mi>d</mi><mi>s</mi><mo>∣</mo><mo>=</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">
\lvert emp\rvert = 3 \quad \lvert dept\rvert = 3 \quad \lvert kids\rvert = 4
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mopen">∣</span><span class="mord mathit">e</span><span class="mord mathit">m</span><span class="mord mathit">p</span><span class="mclose">∣</span><span class="mrel">=</span><span class="mord mathrm">3</span><span class="mord mspace quad"></span><span class="mopen">∣</span><span class="mord mathit">d</span><span class="mord mathit">e</span><span class="mord mathit">p</span><span class="mord mathit">t</span><span class="mclose">∣</span><span class="mrel">=</span><span class="mord mathrm">3</span><span class="mord mspace quad"></span><span class="mopen">∣</span><span class="mord mathit" style="margin-right:0.03148em;">k</span><span class="mord mathit">i</span><span class="mord mathit">d</span><span class="mord mathit">s</span><span class="mclose">∣</span><span class="mrel">=</span><span class="mord mathrm">4</span></span></span></span></span>

<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mrow><mi>e</mi><mo separator="true">,</mo><mrow><mi mathvariant="normal">e</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">d</mi></mrow></mrow></msub><mo>=</mo><mn>3</mn><mspace width="1em"></mspace><msub><mi>d</mi><mrow><mi>d</mi><mo separator="true">,</mo><mrow><mi mathvariant="normal">e</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">d</mi></mrow></mrow></msub><mo>=</mo><mn>3</mn><mspace width="1em"></mspace><msub><mi>d</mi><mrow><mi>k</mi><mo separator="true">,</mo><mrow><mi mathvariant="normal">e</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">d</mi></mrow></mrow></msub><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">
d_{e,\mathrm{eid}} = 3 \quad d_{d,\mathrm{eid}} = 3 \quad d_{k,\mathrm{eid}} = 3
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">e</span><span class="mpunct">,</span><span class="mord scriptstyle cramped"><span class="mord mathrm">e</span><span class="mord mathrm">i</span><span class="mord mathrm">d</span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathrm">3</span><span class="mord mspace quad"></span><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">d</span><span class="mpunct">,</span><span class="mord scriptstyle cramped"><span class="mord mathrm">e</span><span class="mord mathrm">i</span><span class="mord mathrm">d</span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathrm">3</span><span class="mord mspace quad"></span><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit" style="margin-right:0.03148em;">k</span><span class="mpunct">,</span><span class="mord scriptstyle cramped"><span class="mord mathrm">e</span><span class="mord mathrm">i</span><span class="mord mathrm">d</span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathrm">3</span></span></span></span></span>

<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo fence="true">∣</mo><mtext><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">p</mi></mtext><mo>⋈</mo><mtext><mi mathvariant="normal">d</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">t</mi></mtext><mo fence="true">∣</mo><mo>≈</mo><mfrac><mrow><mn>3</mn><mo>×</mo><mn>3</mn></mrow><mrow><mi>max</mi><mo>(</mo><mn>3</mn><mo separator="true">,</mo><mn>3</mn><mo>)</mo></mrow></mfrac><mo>=</mo><mfrac><mrow><mn>3</mn><mo>×</mo><mn>3</mn></mrow><mrow><mn>3</mn></mrow></mfrac><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">
\bigl|\text{emp}\Join\text{dept}\bigr| \approx \frac{3\times3}{\max(3,3)} = \frac{3\times3}{3} = 3
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.32144em;"></span><span class="strut bottom" style="height:2.25744em;vertical-align:-0.936em;"></span><span class="base displaystyle textstyle uncramped"><span class="mopen"><span class="style-wrap reset-textstyle textstyle uncramped"><span class="delimsizing mult"><span class="vlist"><span style="top:0.35000999999999993em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-0.25599000000000005em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">e</span><span class="mord mathrm">m</span><span class="mord mathrm">p</span></span><span class="mrel">⋈</span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">d</span><span class="mord mathrm">e</span><span class="mord mathrm">p</span><span class="mord mathrm">t</span></span><span class="mclose"><span class="style-wrap reset-textstyle textstyle uncramped"><span class="delimsizing mult"><span class="vlist"><span style="top:0.35000999999999993em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-0.25599000000000005em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span><span class="mrel">≈</span><span class="mord reset-textstyle displaystyle textstyle uncramped"><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.686em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle cramped"><span class="mord textstyle cramped"><span class="mop">max</span><span class="mopen">(</span><span class="mord mathrm">3</span><span class="mpunct">,</span><span class="mord mathrm">3</span><span class="mclose">)</span></span></span></span><span style="top:-0.2300000000000001em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.677em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped"><span class="mord textstyle uncramped"><span class="mord mathrm">3</span><span class="mbin">×</span><span class="mord mathrm">3</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mrel">=</span><span class="mord reset-textstyle displaystyle textstyle uncramped"><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.686em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle cramped"><span class="mord textstyle cramped"><span class="mord mathrm">3</span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.677em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped"><span class="mord textstyle uncramped"><span class="mord mathrm">3</span><span class="mbin">×</span><span class="mord mathrm">3</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mrel">=</span><span class="mord mathrm">3</span></span></span></span></span>

<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo fence="true">∣</mo><mtext><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">p</mi></mtext><mo>⋈</mo><mtext><mi mathvariant="normal">k</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">d</mi><mi mathvariant="normal">s</mi></mtext><mo fence="true">∣</mo><mo>≈</mo><mfrac><mrow><mn>3</mn><mo>×</mo><mn>4</mn></mrow><mrow><mi>max</mi><mo>(</mo><mn>3</mn><mo separator="true">,</mo><mn>3</mn><mo>)</mo></mrow></mfrac><mo>=</mo><mfrac><mrow><mn>3</mn><mo>×</mo><mn>4</mn></mrow><mrow><mn>3</mn></mrow></mfrac><mo>=</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">
\bigl|\text{emp}\Join\text{kids}\bigr| \approx \frac{3\times4}{\max(3,3)} = \frac{3\times4}{3} = 4
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.32144em;"></span><span class="strut bottom" style="height:2.25744em;vertical-align:-0.936em;"></span><span class="base displaystyle textstyle uncramped"><span class="mopen"><span class="style-wrap reset-textstyle textstyle uncramped"><span class="delimsizing mult"><span class="vlist"><span style="top:0.35000999999999993em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-0.25599000000000005em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">e</span><span class="mord mathrm">m</span><span class="mord mathrm">p</span></span><span class="mrel">⋈</span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">k</span><span class="mord mathrm">i</span><span class="mord mathrm">d</span><span class="mord mathrm">s</span></span><span class="mclose"><span class="style-wrap reset-textstyle textstyle uncramped"><span class="delimsizing mult"><span class="vlist"><span style="top:0.35000999999999993em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-0.25599000000000005em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span><span class="mrel">≈</span><span class="mord reset-textstyle displaystyle textstyle uncramped"><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.686em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle cramped"><span class="mord textstyle cramped"><span class="mop">max</span><span class="mopen">(</span><span class="mord mathrm">3</span><span class="mpunct">,</span><span class="mord mathrm">3</span><span class="mclose">)</span></span></span></span><span style="top:-0.2300000000000001em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.677em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped"><span class="mord textstyle uncramped"><span class="mord mathrm">3</span><span class="mbin">×</span><span class="mord mathrm">4</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mrel">=</span><span class="mord reset-textstyle displaystyle textstyle uncramped"><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.686em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle cramped"><span class="mord textstyle cramped"><span class="mord mathrm">3</span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.677em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped"><span class="mord textstyle uncramped"><span class="mord mathrm">3</span><span class="mbin">×</span><span class="mord mathrm">4</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mrel">=</span><span class="mord mathrm">4</span></span></span></span></span>

<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo fence="true">∣</mo><mo>(</mo><mtext><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">p</mi></mtext><mo>⋈</mo><mtext><mi mathvariant="normal">d</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">t</mi></mtext><mo>)</mo><mo>⋈</mo><mtext><mi mathvariant="normal">k</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">d</mi><mi mathvariant="normal">s</mi></mtext><mo fence="true">∣</mo><mo>≈</mo><mfrac><mrow><mn>3</mn><mo>×</mo><mn>4</mn></mrow><mrow><mi>max</mi><mo>(</mo><mn>3</mn><mo separator="true">,</mo><mn>3</mn><mo>)</mo></mrow></mfrac><mo>=</mo><mfrac><mrow><mn>3</mn><mo>×</mo><mn>4</mn></mrow><mrow><mn>3</mn></mrow></mfrac><mo>=</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">
\bigl|(\text{emp}\Join\text{dept})\Join\text{kids}\bigr| \approx \frac{3\times4}{\max(3,3)} = \frac{3\times4}{3} = 4
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.32144em;"></span><span class="strut bottom" style="height:2.25744em;vertical-align:-0.936em;"></span><span class="base displaystyle textstyle uncramped"><span class="mopen"><span class="style-wrap reset-textstyle textstyle uncramped"><span class="delimsizing mult"><span class="vlist"><span style="top:0.35000999999999993em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-0.25599000000000005em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span><span class="mopen">(</span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">e</span><span class="mord mathrm">m</span><span class="mord mathrm">p</span></span><span class="mrel">⋈</span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">d</span><span class="mord mathrm">e</span><span class="mord mathrm">p</span><span class="mord mathrm">t</span></span><span class="mclose">)</span><span class="mrel">⋈</span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">k</span><span class="mord mathrm">i</span><span class="mord mathrm">d</span><span class="mord mathrm">s</span></span><span class="mclose"><span class="style-wrap reset-textstyle textstyle uncramped"><span class="delimsizing mult"><span class="vlist"><span style="top:0.35000999999999993em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-0.25599000000000005em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span><span class="mrel">≈</span><span class="mord reset-textstyle displaystyle textstyle uncramped"><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.686em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle cramped"><span class="mord textstyle cramped"><span class="mop">max</span><span class="mopen">(</span><span class="mord mathrm">3</span><span class="mpunct">,</span><span class="mord mathrm">3</span><span class="mclose">)</span></span></span></span><span style="top:-0.2300000000000001em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.677em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped"><span class="mord textstyle uncramped"><span class="mord mathrm">3</span><span class="mbin">×</span><span class="mord mathrm">4</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mrel">=</span><span class="mord reset-textstyle displaystyle textstyle uncramped"><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.686em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle cramped"><span class="mord textstyle cramped"><span class="mord mathrm">3</span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.677em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped"><span class="mord textstyle uncramped"><span class="mord mathrm">3</span><span class="mbin">×</span><span class="mord mathrm">4</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mrel">=</span><span class="mord mathrm">4</span></span></span></span></span>

<p>，</p>
<p>如果执行 <code>SELECT * FROM emp, dept, kids WHERE dept.department = &#39;财务部&#39; AND emp.eid = dept.eid AND emp.eid = kids.eid;</code>，那么 </p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>∣</mo><mi>e</mi><mi>m</mi><mi>p</mi><mo>∣</mo><mo>=</mo><mn>3</mn><mspace width="1em"></mspace><mo>∣</mo><mi>d</mi><mi>e</mi><mi>p</mi><mi>t</mi><mo>∣</mo><mo>=</mo><mn>1</mn><mspace width="1em"></mspace><mo>∣</mo><mi>k</mi><mi>i</mi><mi>d</mi><mi>s</mi><mo>∣</mo><mo>=</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">
\lvert emp\rvert = 3 \quad \lvert dept\rvert = 1 \quad \lvert kids\rvert = 4
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mopen">∣</span><span class="mord mathit">e</span><span class="mord mathit">m</span><span class="mord mathit">p</span><span class="mclose">∣</span><span class="mrel">=</span><span class="mord mathrm">3</span><span class="mord mspace quad"></span><span class="mopen">∣</span><span class="mord mathit">d</span><span class="mord mathit">e</span><span class="mord mathit">p</span><span class="mord mathit">t</span><span class="mclose">∣</span><span class="mrel">=</span><span class="mord mathrm">1</span><span class="mord mspace quad"></span><span class="mopen">∣</span><span class="mord mathit" style="margin-right:0.03148em;">k</span><span class="mord mathit">i</span><span class="mord mathit">d</span><span class="mord mathit">s</span><span class="mclose">∣</span><span class="mrel">=</span><span class="mord mathrm">4</span></span></span></span></span>

<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mrow><mi>e</mi><mo separator="true">,</mo><mrow><mi mathvariant="normal">e</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">d</mi></mrow></mrow></msub><mo>=</mo><mn>3</mn><mspace width="1em"></mspace><msub><mi>d</mi><mrow><mi>d</mi><mo separator="true">,</mo><mrow><mi mathvariant="normal">e</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">d</mi></mrow></mrow></msub><mo>=</mo><mn>1</mn><mspace width="1em"></mspace><msub><mi>d</mi><mrow><mi>k</mi><mo separator="true">,</mo><mrow><mi mathvariant="normal">e</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">d</mi></mrow></mrow></msub><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">
d_{e,\mathrm{eid}} = 3 \quad d_{d,\mathrm{eid}} = 1 \quad d_{k,\mathrm{eid}} = 3
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">e</span><span class="mpunct">,</span><span class="mord scriptstyle cramped"><span class="mord mathrm">e</span><span class="mord mathrm">i</span><span class="mord mathrm">d</span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathrm">3</span><span class="mord mspace quad"></span><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">d</span><span class="mpunct">,</span><span class="mord scriptstyle cramped"><span class="mord mathrm">e</span><span class="mord mathrm">i</span><span class="mord mathrm">d</span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathrm">1</span><span class="mord mspace quad"></span><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit" style="margin-right:0.03148em;">k</span><span class="mpunct">,</span><span class="mord scriptstyle cramped"><span class="mord mathrm">e</span><span class="mord mathrm">i</span><span class="mord mathrm">d</span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathrm">3</span></span></span></span></span>

<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo fence="true">∣</mo><mtext><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">p</mi></mtext><mo>⋈</mo><mtext><mi mathvariant="normal">d</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">t</mi></mtext><mo fence="true">∣</mo><mo>≈</mo><mfrac><mrow><mn>3</mn><mo>×</mo><mn>1</mn></mrow><mrow><mi>max</mi><mo>(</mo><mn>3</mn><mo separator="true">,</mo><mn>1</mn><mo>)</mo></mrow></mfrac><mo>=</mo><mfrac><mrow><mn>3</mn><mo>×</mo><mn>1</mn></mrow><mrow><mn>3</mn></mrow></mfrac><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">
\bigl|\text{emp}\Join\text{dept}\bigr| \approx \frac{3\times1}{\max(3,1)} = \frac{3\times1}{3} = 3
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.32144em;"></span><span class="strut bottom" style="height:2.25744em;vertical-align:-0.936em;"></span><span class="base displaystyle textstyle uncramped"><span class="mopen"><span class="style-wrap reset-textstyle textstyle uncramped"><span class="delimsizing mult"><span class="vlist"><span style="top:0.35000999999999993em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-0.25599000000000005em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">e</span><span class="mord mathrm">m</span><span class="mord mathrm">p</span></span><span class="mrel">⋈</span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">d</span><span class="mord mathrm">e</span><span class="mord mathrm">p</span><span class="mord mathrm">t</span></span><span class="mclose"><span class="style-wrap reset-textstyle textstyle uncramped"><span class="delimsizing mult"><span class="vlist"><span style="top:0.35000999999999993em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-0.25599000000000005em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span><span class="mrel">≈</span><span class="mord reset-textstyle displaystyle textstyle uncramped"><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.686em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle cramped"><span class="mord textstyle cramped"><span class="mop">max</span><span class="mopen">(</span><span class="mord mathrm">3</span><span class="mpunct">,</span><span class="mord mathrm">1</span><span class="mclose">)</span></span></span></span><span style="top:-0.2300000000000001em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.677em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped"><span class="mord textstyle uncramped"><span class="mord mathrm">3</span><span class="mbin">×</span><span class="mord mathrm">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mrel">=</span><span class="mord reset-textstyle displaystyle textstyle uncramped"><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.686em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle cramped"><span class="mord textstyle cramped"><span class="mord mathrm">3</span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.677em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped"><span class="mord textstyle uncramped"><span class="mord mathrm">3</span><span class="mbin">×</span><span class="mord mathrm">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mrel">=</span><span class="mord mathrm">3</span></span></span></span></span>

<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo fence="true">∣</mo><mtext><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">p</mi></mtext><mo>⋈</mo><mtext><mi mathvariant="normal">k</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">d</mi><mi mathvariant="normal">s</mi></mtext><mo fence="true">∣</mo><mo>≈</mo><mfrac><mrow><mn>3</mn><mo>×</mo><mn>4</mn></mrow><mrow><mi>max</mi><mo>(</mo><mn>3</mn><mo separator="true">,</mo><mn>3</mn><mo>)</mo></mrow></mfrac><mo>=</mo><mfrac><mrow><mn>3</mn><mo>×</mo><mn>4</mn></mrow><mrow><mn>3</mn></mrow></mfrac><mo>=</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">
\bigl|\text{emp}\Join\text{kids}\bigr| \approx \frac{3\times4}{\max(3,3)} = \frac{3\times4}{3} = 4
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.32144em;"></span><span class="strut bottom" style="height:2.25744em;vertical-align:-0.936em;"></span><span class="base displaystyle textstyle uncramped"><span class="mopen"><span class="style-wrap reset-textstyle textstyle uncramped"><span class="delimsizing mult"><span class="vlist"><span style="top:0.35000999999999993em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-0.25599000000000005em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">e</span><span class="mord mathrm">m</span><span class="mord mathrm">p</span></span><span class="mrel">⋈</span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">k</span><span class="mord mathrm">i</span><span class="mord mathrm">d</span><span class="mord mathrm">s</span></span><span class="mclose"><span class="style-wrap reset-textstyle textstyle uncramped"><span class="delimsizing mult"><span class="vlist"><span style="top:0.35000999999999993em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-0.25599000000000005em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span><span class="mrel">≈</span><span class="mord reset-textstyle displaystyle textstyle uncramped"><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.686em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle cramped"><span class="mord textstyle cramped"><span class="mop">max</span><span class="mopen">(</span><span class="mord mathrm">3</span><span class="mpunct">,</span><span class="mord mathrm">3</span><span class="mclose">)</span></span></span></span><span style="top:-0.2300000000000001em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.677em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped"><span class="mord textstyle uncramped"><span class="mord mathrm">3</span><span class="mbin">×</span><span class="mord mathrm">4</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mrel">=</span><span class="mord reset-textstyle displaystyle textstyle uncramped"><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.686em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle cramped"><span class="mord textstyle cramped"><span class="mord mathrm">3</span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.677em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped"><span class="mord textstyle uncramped"><span class="mord mathrm">3</span><span class="mbin">×</span><span class="mord mathrm">4</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mrel">=</span><span class="mord mathrm">4</span></span></span></span></span>

<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo fence="true">∣</mo><mo>(</mo><mtext><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">p</mi></mtext><mo>⋈</mo><mtext><mi mathvariant="normal">d</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">t</mi></mtext><mo>)</mo><mo>⋈</mo><mtext><mi mathvariant="normal">k</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">d</mi><mi mathvariant="normal">s</mi></mtext><mo fence="true">∣</mo><mo>≈</mo><mfrac><mrow><mn>1</mn><mo>×</mo><mn>4</mn></mrow><mrow><mi>max</mi><mo>(</mo><mn>1</mn><mo separator="true">,</mo><mn>3</mn><mo>)</mo></mrow></mfrac><mo>=</mo><mfrac><mrow><mn>1</mn><mo>×</mo><mn>4</mn></mrow><mrow><mn>3</mn></mrow></mfrac><mo>=</mo><mn>1</mn><mi mathvariant="normal">.</mi><mn>3</mn></mrow><annotation encoding="application/x-tex">
\bigl|(\text{emp}\Join\text{dept})\Join\text{kids}\bigr| \approx \frac{1\times4}{\max(1,3)} = \frac{1\times4}{3} = 1.3
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.32144em;"></span><span class="strut bottom" style="height:2.25744em;vertical-align:-0.936em;"></span><span class="base displaystyle textstyle uncramped"><span class="mopen"><span class="style-wrap reset-textstyle textstyle uncramped"><span class="delimsizing mult"><span class="vlist"><span style="top:0.35000999999999993em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-0.25599000000000005em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span><span class="mopen">(</span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">e</span><span class="mord mathrm">m</span><span class="mord mathrm">p</span></span><span class="mrel">⋈</span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">d</span><span class="mord mathrm">e</span><span class="mord mathrm">p</span><span class="mord mathrm">t</span></span><span class="mclose">)</span><span class="mrel">⋈</span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">k</span><span class="mord mathrm">i</span><span class="mord mathrm">d</span><span class="mord mathrm">s</span></span><span class="mclose"><span class="style-wrap reset-textstyle textstyle uncramped"><span class="delimsizing mult"><span class="vlist"><span style="top:0.35000999999999993em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-0.25599000000000005em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span><span class="mrel">≈</span><span class="mord reset-textstyle displaystyle textstyle uncramped"><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.686em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle cramped"><span class="mord textstyle cramped"><span class="mop">max</span><span class="mopen">(</span><span class="mord mathrm">1</span><span class="mpunct">,</span><span class="mord mathrm">3</span><span class="mclose">)</span></span></span></span><span style="top:-0.2300000000000001em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.677em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped"><span class="mord textstyle uncramped"><span class="mord mathrm">1</span><span class="mbin">×</span><span class="mord mathrm">4</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mrel">=</span><span class="mord reset-textstyle displaystyle textstyle uncramped"><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.686em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle cramped"><span class="mord textstyle cramped"><span class="mord mathrm">3</span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.677em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped"><span class="mord textstyle uncramped"><span class="mord mathrm">1</span><span class="mbin">×</span><span class="mord mathrm">4</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mrel">=</span><span class="mord mathrm">1</span><span class="mord mathrm">.</span><span class="mord mathrm">3</span></span></span></span></span>

<p>。</p>
<p>思考：</p>
<p>这里出现小数点有影响么？</p>
<p>实际上是没有影响的，这个指标只用于基数评估并最终用于确定执行计划，实际的操作执行和这个无关。</p>
<p><strong>基数的低估和高估问题</strong></p>
<p>基数估算问题可分为<strong>低估（Under-Estimates）和高估（Over-Estimates）两类。两者均会导致选错执行计划，但低估往往更具破坏性</strong>：当优化器低估中间结果行数时，可能选择内存嵌套循环而不是外部哈希连接，导致大量磁盘溢写和 I&#x2F;O 阻塞，从而极度拖慢查询。独立性假设是导致低估的主要根源之一，因为真实数据中列间高度相关时，简单的乘积模型会大幅低估联合选择性。</p>
]]></content>
      <categories>
        <category>高级数据存储</category>
      </categories>
  </entry>
  <entry>
    <title>查询管道和物化</title>
    <url>/undefined/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/02/02/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%9F%A5%E8%AF%A2%E7%AE%A1%E9%81%93%E5%92%8C%E7%89%A9%E5%8C%96/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h2 id="查询执行"><a href="#查询执行" class="headerlink" title="查询执行"></a>查询执行</h2><p>在数据库查询执行中，查询管道（pipelining）和物化（materialization）是两种核心的执行模型。查询管道通过让元组在操作符之间持续流动，实现了流水线式的处理，从而减少了中间结果的写入和读取开销；而物化模型则在每个操作之后将中间结果保存为临时表，再由下一个操作读取，便于管理和重用，但会引入额外的 I&#x2F;O 和存储成本。</p>
<p>在数据库查询执行中，要在既定的查询计划不变的前提下进一步提升性能，常见的三大技术杠杆正好对应经典的 <strong>CPU 性能方程</strong>：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext><mi mathvariant="normal">C</mi><mi mathvariant="normal">P</mi><mi mathvariant="normal">U</mi><mtext> </mtext><mi mathvariant="normal">T</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">e</mi></mtext><mo>=</mo><mtext><mi mathvariant="normal">I</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">n</mi><mtext> </mtext><mi mathvariant="normal">C</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">t</mi></mtext><mo>×</mo><mtext><mi mathvariant="normal">C</mi><mi mathvariant="normal">y</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">s</mi><mtext> </mtext><mi mathvariant="normal">P</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi><mtext> </mtext><mi mathvariant="normal">I</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">n</mi></mtext><mo>×</mo><mtext><mi mathvariant="normal">C</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">k</mi><mtext> </mtext><mi mathvariant="normal">C</mi><mi mathvariant="normal">y</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">e</mi><mtext> </mtext><mi mathvariant="normal">T</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">e</mi></mtext></mrow><annotation encoding="application/x-tex">
\text{CPU Time} = \text{Instruction Count} \times \text{Cycles Per Instruction} \times \text{Clock Cycle Time}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="base displaystyle textstyle uncramped"><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">C</span><span class="mord mathrm">P</span><span class="mord mathrm">U</span><span class="mord mspace"> </span><span class="mord mathrm">T</span><span class="mord mathrm">i</span><span class="mord mathrm">m</span><span class="mord mathrm">e</span></span><span class="mrel">=</span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">I</span><span class="mord mathrm">n</span><span class="mord mathrm">s</span><span class="mord mathrm">t</span><span class="mord mathrm">r</span><span class="mord mathrm">u</span><span class="mord mathrm">c</span><span class="mord mathrm">t</span><span class="mord mathrm">i</span><span class="mord mathrm">o</span><span class="mord mathrm">n</span><span class="mord mspace"> </span><span class="mord mathrm">C</span><span class="mord mathrm">o</span><span class="mord mathrm">u</span><span class="mord mathrm">n</span><span class="mord mathrm">t</span></span><span class="mbin">×</span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">C</span><span class="mord mathrm" style="margin-right:0.01389em;">y</span><span class="mord mathrm">c</span><span class="mord mathrm">l</span><span class="mord mathrm">e</span><span class="mord mathrm">s</span><span class="mord mspace"> </span><span class="mord mathrm">P</span><span class="mord mathrm">e</span><span class="mord mathrm">r</span><span class="mord mspace"> </span><span class="mord mathrm">I</span><span class="mord mathrm">n</span><span class="mord mathrm">s</span><span class="mord mathrm">t</span><span class="mord mathrm">r</span><span class="mord mathrm">u</span><span class="mord mathrm">c</span><span class="mord mathrm">t</span><span class="mord mathrm">i</span><span class="mord mathrm">o</span><span class="mord mathrm">n</span></span><span class="mbin">×</span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">C</span><span class="mord mathrm">l</span><span class="mord mathrm">o</span><span class="mord mathrm">c</span><span class="mord mathrm">k</span><span class="mord mspace"> </span><span class="mord mathrm">C</span><span class="mord mathrm" style="margin-right:0.01389em;">y</span><span class="mord mathrm">c</span><span class="mord mathrm">l</span><span class="mord mathrm">e</span><span class="mord mspace"> </span><span class="mord mathrm">T</span><span class="mord mathrm">i</span><span class="mord mathrm">m</span><span class="mord mathrm">e</span></span></span></span></span></span>

<p>。</p>
<p>基于这一方程，我们可以通过以下三种途径分别作用于各项，从而整体降低查询的执行时间。</p>
<ol>
<li><p><strong>减少指令数</strong>：通过让同样的计算工作消耗更少的指令，直接降低方程中的 <strong>Instruction Count</strong>。</p>
<p>解决方案：</p>
<ul>
<li><strong>算法与逻辑优化</strong>：在查询执行层面，合并相邻的过滤或算子，避免产生冗余的中间操作，如将多重过滤合并成单次扫描中的复合条件。</li>
<li><strong>编译器与JIT优化</strong>：利用现代数据库的即时编译（JIT）技术，将高频 SQL 模板编译成高效机器码，去除不必要的抽象层次。</li>
<li><strong>简化控制流</strong>：减少分支与函数调用，利用内联（inlining）与分支预测友好的代码组织，降低分支错判带来的指令重执行。</li>
</ul>
</li>
<li><p><strong>降低每条指令的平均周期数</strong>：在保证指令数大致不变的情况下，通过加速每条指令的执行来降低平均周期数，使得每个周期内能执行更多的指令。</p>
<p>解决方案：</p>
<ul>
<li><strong>向量化执行</strong>：一次处理多个数据元素（SIMD），使单条指令能够并行作用于多份数据，显著减少每元素的平均周期开销。</li>
<li><strong>缓存友好布局</strong>：优化内存访问模式、减少缓存未命中、利用预取（prefetch）技术，降低内存访问延迟对 CPI 的影响。</li>
<li><strong>流水线与乱序执行</strong>：让 CPU 同时处理多条指令的不同阶段，掩盖指令间的依赖与等待，提高指令吞吐能力。</li>
</ul>
</li>
<li><p><strong>并行化执行</strong>：利用多线程／多进程将查询拆分为若干可并行处理的子任务，以共享整个系统的计算资源。</p>
<p>解决方案：</p>
<ul>
<li><strong>并行扫描 (Parallel Scan)</strong>：将表或分区划分为多个数据块，每个 worker 进程或线程独立扫描其负责的数据块。</li>
<li><strong>并行聚合 (Parallel Aggregation)</strong>：类似 MapReduce，在每个节点本地先做部分聚合，再在汇总阶段合并结果，降低网络与锁竞争开销。</li>
<li><strong>动态分区与调度</strong>：根据实时负载与数据分布，自动调整任务划分与调度策略，避免因数据倾斜或节点瓶颈造成性能倒挂。</li>
</ul>
</li>
</ol>
<p>在现代关系型数据库中，**查询执行（Query Execution）**依赖于三个核心概念：查询计划、操作符实例和任务&#x2F;流水线。查询计划被表示成一个操作符的有向无环图（DAG），它定义了不同运算节点及数据流依赖；操作符实例则是将某一操作符应用到数据的具体调用；任务（也称流水线）由一个或多个操作符实例顺序组成，在同一执行上下文中连续运行，从而实现元组的流式处理和高效并行执行。</p>
<p>假设我们要执行如下 SQL 命令：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> A.id, B.val</span><br><span class="line"><span class="keyword">FROM</span> A <span class="keyword">JOIN</span> B</span><br><span class="line"><span class="keyword">ON</span> A.id <span class="operator">=</span> B.id</span><br><span class="line"><span class="keyword">WHERE</span> A.val <span class="operator">&lt;</span> <span class="number">88</span> <span class="keyword">AND</span> B.val <span class="operator">&gt;</span> <span class="number">214</span>;</span><br></pre></td></tr></table></figure>

<p>此时的查询执行的示意图如下：</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_query_exec_1.drawio.png" alt="img"></p>
<p>但是在以上的查询执行中，会出现两种普遍发生的性能瓶颈：</p>
<ol>
<li><p><strong>指令依赖</strong>：当一条指令的操作数依赖于前一条指令的输出时，就会出现数据依赖，导致后续指令必须等待前一指令完成写回，才能安全地执行。这会导致流水线停顿（Pipeline Stall），也就是依赖链未解除之前，流水线必须插入空周期，暂停取指与执行，直到数据可用。每出现一次停顿，均减少了可用的执行周期，尤其在长依赖链或深度流水线中，性能损失更为显著。</p>
<p>解决方案：</p>
<ol>
<li><strong>前递（Forwarding&#x2F;Bypassing）</strong>：处理器在执行阶段即可将尚未写回的结果转发给下游指令，减少等待时间。</li>
<li><strong>指令重新排序（Out-of-Order Execution）</strong>：乱序发射允许非依赖指令先行执行，填补停顿周期，提高资源利用率。</li>
<li><strong>软件优化</strong>：编译器或 JIT 在生成代码时，通过指令调度将依赖指令错开，或插入无关指令填充空档，降低数据冒险带来的停顿。</li>
</ol>
</li>
<li><p><strong>分支预测</strong>：处理器在遇到分支指令时，会猜测分支是否成立，并预取／预执行分支路径上的指令，以保持流水线连续。这会导致<strong>流水线冲刷（Pipeline Flush）</strong>：若预测错误，必须将已加载但未提交的指令全部作废，并重新从正确目标地址逐级取指，造成数十至上百个周期的空闲；以及<strong>分支惩罚随流水线深度增加而增大</strong>：深度更高的流水线需要冲刷更多级的指令，带来更高的性能损失。</p>
<p>缓解方案：</p>
<ol>
<li><strong>动态分支预测</strong>：利用分支历史表（Branch History Table）等硬件结构根据过去执行情况进行预测，大幅提高准确率。</li>
<li><strong>无分支代码</strong>：使用位运算和逻辑运算消除显式的 <code>if</code> 判断语句，从而让 CPU 不依赖分支预测。</li>
<li><strong>索引下推</strong>：将分支条件判断尽量前移到索引扫描阶段，减少进入后续流水线的无效数据。</li>
<li><strong>向量化执行</strong>：批量处理多条记录，将过滤逻辑应用于整个向量数组，在单条循环中执行多次条件判断并记录掩码，减少分支次数。</li>
</ol>
<blockquote>
<p>[!NOTE]</p>
<p><strong>数据库中的分支失误：过滤操作</strong></p>
<p>在顺序扫描过程中，每访问一行记录，都要执行对该行是否满足过滤条件的判断（<code>if</code> 语句），这构成了 DBMS 中<strong>最频繁</strong>的分支指令序列。由于行数据的分布通常不可预测，过滤条件的真&#x2F;假结果几乎是随机的，硬件分支预测器难以积累稳定的历史。</p>
<p>对于这种情况，我们可以采用无分支代码来解决。假设我们要执行如下命令：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">user</span> <span class="keyword">WHERE</span> age <span class="operator">&gt;</span> $(low) <span class="keyword">AND</span> age <span class="operator">&lt;</span> $(high);</span><br></pre></td></tr></table></figure>

<p>那么这个 SQL 命令对应的有分支的代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">i = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (t <span class="keyword">in</span> table) &#123;</span><br><span class="line">  key = t.key;</span><br><span class="line">  <span class="keyword">if</span> ((key &gt; low) &amp;&amp; (key &lt; high)) &#123;</span><br><span class="line">    copy(t, output[i]);</span><br><span class="line">    i = i + <span class="number">1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在以上代码中，每次 if 检查都生成一条或多条分支，过滤条件结果依赖于数据值分布，通常呈随机模式，硬件分支预测器难以积累有效历史，同时预测错误时需刷新流水线，放弃已取但未执行完的指令，造成 10–20 个周期的空洞。</p>
<p>因此我们可以将其改成无分支的代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">i = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (t <span class="keyword">in</span> table) &#123;</span><br><span class="line">  copy(t, output[i]);</span><br><span class="line">  key = t.key;</span><br><span class="line">  delta = (key &gt; low ? <span class="number">1</span> : <span class="number">0</span>) &amp; (key &lt; high ? <span class="number">1</span> : <span class="number">0</span>);</span><br><span class="line">  i = i + delta;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这段代码使用三目运算符和按位与（&amp;）生成布尔掩码（0 或 1），避免 if 分支，消除了流水线刷新风险，可保持稳定的指令流，而且无分支的循环更符合 SIMD 自动向量化特性，编译器和 JIT 能将单条循环转换为批量处理指令，并利用 AVX&#x2F;SSE 等向量指令集。</p>
</blockquote>
</li>
</ol>
<h2 id="处理模型"><a href="#处理模型" class="headerlink" title="处理模型"></a>处理模型</h2><p>在关系型数据库中，**处理模型（Processing Model）**决定了执行器如何遍历并执行优化器生成的查询计划树。不同处理模型在函数调用开销、中间结果管理、内存与 I&#x2F;O 使用等方面各有取舍，因而对 OLTP（短事务、小结果集）与 OLAP（大批量分析查询）场景会产生截然不同的性能影响。</p>
<h3 id="迭代器模型（Iterator-Volcano-Model）"><a href="#迭代器模型（Iterator-Volcano-Model）" class="headerlink" title="迭代器模型（Iterator &#x2F; Volcano Model）"></a>迭代器模型（Iterator &#x2F; Volcano Model）</h3><p>每个查询计划算子实现一个 <code>next()</code> 方法：调用时返回一个元组或标记结束（<code>null</code>），而且 <code>next()</code> 内部通常是一个循环：对子算子连续调用 <code>next()</code> 以获取下一个元组并进行处理，实现<strong>拉取式（pull-based）流水线</strong>。</p>
<p>在该模型中，<code>JOIN</code>、<code>ORDER BY</code> 和子查询等算子却会一直被阻塞直到子算子发送完了所有的元祖。</p>
<p>下图展示了迭代器模型的执行流程，其中绿色箭头大小控制流，红色箭头代表数据流，之后的图都是如此：</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_query_exec_iterator.drawio.png" alt="img"></p>
<p>上图中，在系统层面，这两个流水线各自由不同的执行线程或调度实体运行，可以在硬件资源（CPU 核、线程）许可下同时活跃。但<strong>哈希连接的建表阶段</strong>是一个<strong>管道断裂点（pipeline breaker）</strong>：建表阶段只依赖 R 表，与 Pipeline #2 无关，因此当建表线程在后台扫描 R 时，Pipeline #2 可以同时并发进行 S 表的过滤。一旦建表完成，Pipeline #2 的探测阶段才会真正开始消费 Filter 的输出；如果 Filter 还没产出下一个符合条件的行，探测就会等待。反之，如果过滤很快，探测也会快速拉取并处理。</p>
<blockquote>
<p>[!NOTE]</p>
<p>拉取式流水线中，调用者（上层算子或执行引擎）通过自顶向下的递归调用不断拉取数据，直到叶子算子从底层存储读取到元组并逐层返回。这种设计将控制流和数据流分离，上层算子负责驱动执行进程，下层算子被动提供数据，适合行级的管道处理。</p>
</blockquote>
<p>优点：</p>
<ol>
<li><strong>内存占用小</strong>：元组生成后可立即沿计划树上下游传递，无需完整物化中间结果。</li>
<li><strong>早期返回</strong>：可以在部分数据处理完后就立即返回这部分的结果。</li>
</ol>
<p>缺点：</p>
<ol>
<li><strong>函数调用开销</strong>：深度计划树和高频 <code>next()</code> 调用在高并行度或大结果集场景下带来显著开销。</li>
<li><strong>难以并行化</strong>：对多核或批处理的支持不够友好。</li>
</ol>
<p>因此，该模型在 OLTP 场景中表现优异。</p>
<h3 id="物化模型（Materialization-Model）"><a href="#物化模型（Materialization-Model）" class="headerlink" title="物化模型（Materialization Model）"></a><strong>物化模型（Materialization Model）</strong></h3><p>Materialization 模型是数据库管理系统中常见的查询执行模型之一，其中每个操作符一次性处理所有输入并一次性输出所有结果，称为物化操作 。该模型适用于 OLTP 场景，因其函数调用较少、协调开销低，能够快速返回少量元组；但对于中间结果集庞大的 OLAP 查询，则可能因临时结果需要写入磁盘而导致性能下降 。DBMS 可通过下推诸如 LIMIT 的执行提示（hints）来避免扫描过多元组，并支持行式存储或列式存储的物化输出方式。</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_query_exec_materialization.drawio.png" alt="img"></p>
<p><strong>向量化模型（Vectorization Model）</strong></p>
<p>Vectorization 模型是一种批量处理的查询执行策略，其中每个操作符在内部循环中一次性读取并处理一批（batch）的元组，然后一次性向外输出该批结果。这种方式通过利用现代 CPU 的 SIMD 指令加速批量数据处理，显著降低函数调用次数并提升缓存命中率，因而特别适合 OLAP 查询；但对于需要低延迟、逐一元组处理的 OLTP 工作负载，则并不理想。该模型的批大小可根据硬件能力（如 AVX 寄存器宽度）和查询属性动态调整，以实现最优性能。 </p>
<p>每个查询操作符实现一个 <code>next()</code> 函数，但不是返回单个元组，而是返回一批元组。操作符的内部循环一次性在向量或批量数据上执行相同的操作，而非逐个元组调用。</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_query_exec_vectorization.drawio.png" alt="img"></p>
<p>需要强调的是，以上的三种处理模型都是属于 pull-based 的。</p>
<p>Pull 模型从根节点发起，通过连续调用 next() 向下拉取数据，适合传统行式、阻塞操作较多的场景；Push 模型则从叶子节点开始，将处理结果推送给父节点，并可在单一循环内融合多个算子，减少中间结果存储，更适合 OLAP 工作负载。</p>
<p>Push-based 模型的示意图如下：</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_query_exec_push.drawio.png" alt="img"></p>
<p><strong>Pull-based 和 Push-based 模型的对比</strong>：</p>
<table>
<thead>
<tr>
<th><strong>特性／模型</strong></th>
<th><strong>Pull（Top-to-Bottom）</strong></th>
<th><strong>Push（Bottom-to-Top）</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>输出控制</strong></td>
<td>易于对 LIMIT、TOP-N 等操作进行控制，父算子可随时停止拉取</td>
<td>不易实现 LIMIT，消费者难以及时通知生产者停止推送</td>
</tr>
<tr>
<td><strong>管道阻塞支持</strong></td>
<td>原生支持排序、聚合等阻塞算子</td>
<td>复杂算子需额外物化或流水线断点才能正确执行</td>
</tr>
<tr>
<td><strong>函数调用开销</strong></td>
<td>每条元组多次调用 <code>next()</code>，虚拟函数和分支跳转较多</td>
<td>同一循环内推送，函数和分支开销更低</td>
</tr>
<tr>
<td><strong>缓存 &amp; SIMD 利用</strong></td>
<td>难以批量处理，SIMD 和缓存局部性利用有限</td>
<td>算子融合后易于批量处理，充分利用缓存和 SIMD</td>
</tr>
<tr>
<td><strong>实现复杂度</strong></td>
<td>基于 Volcano 模型，逻辑清晰、易于实现与维护</td>
<td>需算子融合、回调机制和调度框架，开发调试成本高</td>
</tr>
<tr>
<td><strong>适用场景</strong></td>
<td>OLTP、交互式小批量查询，带 LIMIT 的场景</td>
<td>OLAP、大规模扫描与聚合，列式存储与 MPP 系统</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>高级数据存储</category>
      </categories>
  </entry>
</search>
