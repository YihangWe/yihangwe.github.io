<!DOCTYPE html>
<html lang="zh-CN,en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yihangwe.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Amazon DynamoDB 将 Dynamo 的增量扩展能力和可预测的高性能与 SimpleDB 的易用表模型和强一致性相结合，既避免了自建大型数据库系统所带来的运维复杂性，又突破了 SimpleDB 在存储容量、请求吞吐和查询／写入延迟方面的局限；同时，DynamoDB 作为一款无服务器、全托管的 NoSQL 服务，内置自动扩缩容、安全加固和多区域复制，让开发者能够专注于业务逻辑，而无需管理">
<meta property="og:type" content="article">
<meta property="og:title" content="DynamoDB">
<meta property="og:url" content="https://yihangwe.github.io/undefined/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2024/10/03/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/DynamoDB/index.html">
<meta property="og:site_name" content="EthanWeee 的个人日志">
<meta property="og:description" content="Amazon DynamoDB 将 Dynamo 的增量扩展能力和可预测的高性能与 SimpleDB 的易用表模型和强一致性相结合，既避免了自建大型数据库系统所带来的运维复杂性，又突破了 SimpleDB 在存储容量、请求吞吐和查询／写入延迟方面的局限；同时，DynamoDB 作为一款无服务器、全托管的 NoSQL 服务，内置自动扩缩容、安全加固和多区域复制，让开发者能够专注于业务逻辑，而无需管理">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://yihangwe.github.io/images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/DynamoDB_KV_struct.drawio.png">
<meta property="og:image" content="https://yihangwe.github.io/images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/DynamoDB_opers.png">
<meta property="og:image" content="https://yihangwe.github.io/images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/DynamoDB_s_replica.png">
<meta property="og:image" content="https://yihangwe.github.io/images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/DynamoDB_l_replica.png">
<meta property="og:image" content="https://yihangwe.github.io/images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/dynamodb_arch.png">
<meta property="og:image" content="https://yihangwe.github.io/Users/yihangwei/blog/source/images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/DynamoDB_unbalanced_requests.drawio.png">
<meta property="og:image" content="https://yihangwe.github.io/Users/yihangwei/blog/source/images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/DynamoDB_throttling.drawio.png">
<meta property="og:image" content="https://yihangwe.github.io/Users/yihangwei/blog/source/images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/DynamoDB_token_bucket.drawio.png">
<meta property="og:image" content="https://yihangwe.github.io/images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/dynamodb_txn.png">
<meta property="article:published_time" content="2024-10-03T16:00:00.000Z">
<meta property="article:modified_time" content="2025-06-28T23:22:18.309Z">
<meta property="article:author" content="Yihang Wei">
<meta property="article:tag" content="数据库, 分布式, OLTP, OLAP">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://yihangwe.github.io/images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/DynamoDB_KV_struct.drawio.png">

<link rel="canonical" href="https://yihangwe.github.io/undefined/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2024/10/03/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/DynamoDB/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>DynamoDB | EthanWeee 的个人日志</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start --><script>(function() {function calculateHeight(element) {let height = 0;const items = element.children;for (let i = 0; i < items.length; i++) {height += items[i].offsetHeight || 25;const child = items[i].querySelector(".nav-child");if (child && child.style.display !== "none") {height += calculateHeight(child);}}return height;}function generateToc(lang, container) {const content = document.getElementById(lang + "-content");if (!content) return;const headers = Array.from(content.querySelectorAll("h1, h2, h3, h4, h5, h6"));if (headers.length === 0) return;const ol = document.createElement("ol");ol.className = "nav";let currentLevel = 1;let currentOl = ol;let stack = [ol];let counters = [0, 0, 0, 0, 0, 0];headers.forEach((header, index) => {const level = parseInt(header.tagName[1]);counters[level - 1]++;for (let i = level; i < 6; i++) counters[i] = 0;const li = document.createElement("li");li.className = "nav-item nav-level-" + level;if (level === 1 && index === 0) {li.classList.add("active", "active-current");}const link = document.createElement("a");link.className = "nav-link";if (level === 1 && index === 0) link.classList.add("active");link.href = "#" + header.id;const numSpan = document.createElement("span");numSpan.className = "nav-number";numSpan.textContent = counters.slice(0, level).filter(n => n > 0).join(".");const textSpan = document.createElement("span");textSpan.className = "nav-text";textSpan.textContent = header.textContent;link.appendChild(numSpan);link.appendChild(document.createTextNode(" "));link.appendChild(textSpan);li.appendChild(link);if (level > currentLevel) {const newOl = document.createElement("ol");newOl.className = "nav-child";if (currentLevel === 1) {newOl.style.display = "block";stack[currentLevel - 1].lastElementChild.classList.add("active");}stack[currentLevel - 1].lastElementChild.appendChild(newOl);stack[level - 1] = newOl;currentOl = newOl;} else if (level < currentLevel) {currentOl = stack[level - 1];}currentOl.appendChild(li);currentLevel = level;});container.appendChild(ol);setTimeout(() => {const navHeight = calculateHeight(ol);ol.style.setProperty("--height", navHeight + "px");const navChilds = ol.getElementsByClassName("nav-child");Array.from(navChilds).forEach(child => {if (child.style.display === "block") {const childHeight = calculateHeight(child);child.style.setProperty("--height", childHeight + "px");}});}, 0);return ol;}function updateActiveHeading() {const activeLang = document.getElementById("en-content").style.display === "block" ? "en" : "zh";const content = document.getElementById(activeLang + "-content");const toc = document.getElementById(activeLang + "-toc");if (!content || !toc) return;const headers = Array.from(content.querySelectorAll("h1, h2, h3, h4, h5, h6"));const scrollPos = window.scrollY + window.innerHeight / 3;let activeHeader = null;for (let i = headers.length - 1; i >= 0; i--) {const header = headers[i];const headerTop = header.getBoundingClientRect().top + window.scrollY;if (headerTop <= scrollPos) {activeHeader = header;break;}}const links = toc.getElementsByClassName("nav-link");Array.from(links).forEach(link => {link.classList.remove("active");const parentLi = link.parentElement;if (parentLi) {parentLi.classList.remove("active", "active-current");}});if (activeHeader) {const activeLink = toc.querySelector(`a[href="#${activeHeader.id}"]`);if (activeLink) {activeLink.classList.add("active");let parent = activeLink.parentElement;while (parent && parent.classList) {if (parent.classList.contains("nav-item")) {parent.classList.add("active");if (parent.classList.contains("nav-level-1")) {parent.classList.add("active-current");}}parent = parent.parentElement;}}}}function initTippy() {document.querySelectorAll(".refplus-num").forEach((ref) => {if (ref._tippy) {ref._tippy.destroy();}let refid = ref.firstChild.href.replace(location.origin+location.pathname,"");let refel = document.querySelector(refid);if (!refel) return;let refnum = refel.dataset.num;let ref_content = refel.innerText.replace(`[${refnum}]`,"");tippy(ref, {content: ref_content,});});}function initToc() {const originalToc = document.querySelector(".post-toc-wrap");if (!originalToc || !document.getElementById("langToggle")) return;const tocContainer = document.createElement("div");tocContainer.className = "post-toc-wrap sidebar-panel sidebar-panel-active";const enToc = document.createElement("div");enToc.id = "en-toc";enToc.className = "post-toc motion-element";enToc.style.display = "block";const zhToc = document.createElement("div");zhToc.id = "zh-toc";zhToc.className = "post-toc motion-element";zhToc.style.display = "none";generateToc("en", enToc);generateToc("zh", zhToc);tocContainer.appendChild(enToc);tocContainer.appendChild(zhToc);originalToc.parentNode.replaceChild(tocContainer, originalToc);window.addEventListener("scroll", updateActiveHeading);setTimeout(updateActiveHeading, 0);}window.toggleLanguage = function() {const enContent = document.getElementById("en-content");const zhContent = document.getElementById("zh-content");const enToc = document.getElementById("en-toc");const zhToc = document.getElementById("zh-toc");const button = document.getElementById("langToggle");if (!enContent || !zhContent || !enToc || !zhToc || !button) return;const isEnglish = enContent.style.display === "block";enContent.style.display = isEnglish ? "none" : "block";zhContent.style.display = isEnglish ? "block" : "none";enToc.style.display = isEnglish ? "none" : "block";zhToc.style.display = isEnglish ? "block" : "none";button.querySelector(".button-text").textContent = isEnglish ? "Switch to English" : "切换中文";setTimeout(updateActiveHeading, 0);setTimeout(initTippy, 100);};document.addEventListener("DOMContentLoaded", function() {initToc();setTimeout(initTippy, 3000);});})();</script><style>.post-toc { transition: all 0.2s ease-in-out; }.post-toc .nav { padding-left: 0; }.post-toc .nav-child { padding-left: 1em; }.post-toc .nav-item { line-height: 1.8; }.post-toc .nav-link { color: #555; }.post-toc .nav-link:hover { color: #222; }.post-toc .nav-link.active { color: #fc6423; }.post-toc .active > .nav-link { color: #fc6423; }.post-toc .active-current > .nav-link { color: #fc6423; }</style><!-- hexo injector head_end end --><style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">EthanWeee 的个人日志</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://yihangwe.github.io/undefined/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2024/10/03/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/DynamoDB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yihang Wei">
      <meta itemprop="description" content="聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EthanWeee 的个人日志">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          DynamoDB
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-10-04 00:00:00" itemprop="dateCreated datePublished" datetime="2024-10-04T00:00:00+08:00">2024-10-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-06-29 07:22:18" itemprop="dateModified" datetime="2025-06-29T07:22:18+08:00">2025-06-29</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/" itemprop="url" rel="index"><span itemprop="name">数据库系统</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/" itemprop="url" rel="index"><span itemprop="name">分布式系统</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><p>Amazon DynamoDB 将 Dynamo 的增量扩展能力和可预测的高性能与 SimpleDB 的易用表模型和强一致性相结合，既避免了自建大型数据库系统所带来的运维复杂性，又突破了 SimpleDB 在存储容量、请求吞吐和查询／写入延迟方面的局限；同时，DynamoDB 作为一款无服务器、全托管的 NoSQL 服务，内置自动扩缩容、安全加固和多区域复制，让开发者能够专注于业务逻辑，而无需管理底层基础设施。</p>
<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>一个 DynamoDB 表是多个条目的集合，或者具体来说是 KV 存储，每个条目由多个属性组成并且通过主键唯一标识。主键的模式在创建表时指定，主键模式包含分区键，或者分区键和排序键一起（也就是复合主键）。分区键的值总是作为内部哈希函数的输入，该哈希函数的输出和排序键的值（如果存在）共同决定该条目的存储位置（分区）。在具有复合主键的表中，多个条目可以具有相同的分区键值，但这些项目必须具有不同的排序键值。</p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/DynamoDB_KV_struct.drawio.png" alt="img"></p>
<p>DynamoDB 支持二级索引，一个表可以拥有一个或多个二级索引。二级索引允许使用除主键之外的备用键来查询表中的数据，这个备用键说白了就是二级索引键。</p>
<p>假设我们有一个游戏得分表 <code>GameScores</code>，记录玩家在不同游戏中的最高得分，表结构定义如下：</p>
<p>主表的表名是 <code>GameScores</code>，主键的设置如下：</p>
<ul>
<li>分区键：<code>UserId</code> (String)；</li>
<li>排序键：<code>GameId</code> (String)。</li>
</ul>
<p>在这种设计下，针对单个用户查询他们在某个游戏里的得分非常高效，但如果我们想要按 <strong>游戏名称</strong>（<code>GameTitle</code>）或 <strong>得分排名</strong>（<code>TopScore</code>）来查询所有玩家的成绩，就无法直接使用主键查询。</p>
<p>为满足上述查询需求，我们可以在表中添加一个全局二级索引 <code>GameTitleIndex</code>，其备用键（索引键）定义如下：</p>
<ul>
<li>索引名：<code>GameTitleIndex</code>；</li>
<li>分区键：<code>GameTitle</code> (String)；</li>
<li>排序键：<code>TopScore</code> (Number)。</li>
</ul>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/DynamoDB_opers.png" alt="img"></p>
<p>上表列出了客户端在 DynamoDB 表中读取和写入项目时可用的主要操作。任何插入、更新或删除项目的操作都可以带有一个条件，只有在该条件满足时操作才会成功。该条件判断在高并发场景中可避免多个客户端对同一项条目进行冲突性写入，例如只在某属性值符合预期时才更新。</p>
<p>此外，DynamoDB 支持 ACID 事务，使应用程序能够在更新多个项目时保证原子性、一致性、隔离性和持久性（ACID），而不会影响 DynamoDB 表的可扩展性、可用性和性能特性。</p>
<p>之前提到过，DynamoDB 表被拆分为多个分区，以满足表的吞吐量和存储需求。每个分区承载表键值范围中不重叠的一个连续区段，并在不同可用区分布多个副本，以实现高可用性和持久性。这些副本组成一个复制组，采用 Multi-Paxos 协议进行领导者选举与一致性达成。任一副本都可以发起选举，成为领导者后需定期续租，唯有领导者副本可处理写请求和强一致性读取。领导者在接收到写请求时，会生成预写日志并分发给其他副本，当多数副本将日志持久化后，才向客户端确认写入成功。DynamoDB 支持强一致性和最终一致性读取，其中任何副本都能提供最终一致性读取。若领导者被检测为失败或下线，其它副本可再次发起选举，新领导者在前领导者租约到期前不会处理写入或强一致性读取。复制组包含预写日志和以 B 树形式存储键值数据的存储副本。同时为了进一步提升可用性与持久性，复制组中还可包含仅持久化最近预写日志的日志副本，它们类似 Paxos 中的接受者，但不存储键值数据。也就是说，DynamoDB 的复制组中包含多个数据副本和多个日志副本。</p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/DynamoDB_s_replica.png" alt="img"></p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/DynamoDB_l_replica.png" alt="img"></p>
<p>DynamoDB 是由数十个微服务组成的，其中一些核心服务包括元数据服务、请求路由器服务、存储节点和自动管理服务。元数据服务存储有关表、索引以及给定表或索引的分区复制组的路由信息。请求路由器服务负责对每个请求进行授权、身份验证，并将其路由到相应的服务器。</p>
<p>所有的读取和更新请求都会被路由到承载客户数据的存储节点。请求路由器会从元数据服务中查询路由信息。所有资源创建、更新和数据定义请求则会被路由到自动管理服务。存储服务负责在一组存储节点上保存客户数据，每个存储节点会承载多个不同分区的副本。</p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/dynamodb_arch.png" alt="img"></p>
<p>在上图中，请求首先通过网络到达请求路由器（Request Router）服务，该服务依次调用认证系统进行 IAM 权限校验、查询分区元数据系统获取路由信息，并与全局准入控制（GAC）系统协作对表级吞吐进行限流，最后将请求转发至目标存储节点（Storage Node）进行数据读写操作。存储节点分布在多个可用区（AZ），采用 SSD 存储并在三个副本间使用 Paxos 算法选举主节点以提供写入一致性和读扩展能力，同时依靠副本复制实现高可用与耐久。认证系统通过 AWS IAM 服务简化身份验证与授权管理，分区元数据系统维护分区与存储节点的映射关系，而 GAC 则作为分布式令牌桶机制确保吞吐的可预测性与表级隔离。</p>
<p>这里需要强调的是，自动管理服务被构建为 DynamoDB 的中枢神经系统，它负责集群健康、分区健康、表的弹性扩缩以及所有控制平面请求的执行。该服务会持续监控所有分区的状态，并替换任何被判定为不健康（响应缓慢、无响应或运行在故障硬件上）的副本。它还会对 DynamoDB 的所有核心组件进行健康检查，并替换任何正在出现故障或已故障的硬件。例如，如果自动管理服务检测到某个存储节点不健康，它会启动恢复流程，把此前托管在该节点上的数据副本迁移或重建到其他健康的节点，以确保整个系统的复制组能够再次达到预期的副本数和健康状态。</p>
<blockquote>
<p>[!NOTE]</p>
<p>普遍意义上，控制平面是系统或网络中的大脑或指挥中心，负责管理、配置和决策，决定资源如何被创建、更新、删除以及如何路由请求；而实际的数据转发、存储和处理则由数据平面执行。控制平面通过一系列管理 API 与底层组件通信，实现对系统状态的监控、调度和恢复，从而保证整体的可用性、一致性和可扩展性。</p>
<p>因此，在 DynamoDB 中，控制平面并不仅仅指自动管理服务，而是由多种后台管理组件和它们所提供的管理 API 共同构成的一套系统。</p>
</blockquote>
<h2 id="从预配置到弹性伸缩"><a href="#从预配置到弹性伸缩" class="headerlink" title="从预配置到弹性伸缩"></a>从预配置到弹性伸缩</h2><p>在最初的 DynamoDB 版本中，开发者引入了分区的概念，以便能够动态地扩展表的容量和性能。系统最开始会将一张表切分为多个分区，使其内容能够分布到多台存储节点上，并且与这些节点的可用空间和性能相映射。当表的规模增大或访问负载上升时，系统可以进一步拆分分区并将其迁移，以实现弹性扩展。分区这一抽象证明了其极高的价值，并一直是 DynamoDB 设计的核心。</p>
<p>用户需要以读取吞吐量单位（RCU）和写入吞吐量单位（WCU）的形式，显式地指定一个表所需的吞吐量（预配置吞吐量）。对于不超过 4 KB 的条目，1 个 RCU 可每秒执行 1 次强一致性读取请求；对于不超过 1 KB 的条目，1 个 WCU 可每秒执行 1 次标准写入请求。</p>
<p>显然，早期版本将容量与性能的分配紧密耦合到各个分区，导致了若干挑战。DynamoDB 使用准入控制来确保存储节点不会过载，避免同机房中不同表的分区相互干扰，并强制执行客户所请求的吞吐量限制。</p>
<p>最初，一个表的所有存储节点共同承担准入控制的责任。每个存储节点会根据其本地所存放的分区的分配情况，独立地执行准入控制。由于一个节点通常会承载多个表的分区，系统便利用各分区的分配吞吐量来隔离不同表的工作负载。DynamoDB 会对单个分区可分配的最大吞吐量进行上限限制，同时确保某节点上所有分区的总吞吐量不超过由其存储介质物理特性所决定的该节点最大允许吞吐量。当表的整体吞吐量发生变化或分区被拆分时，系统会相应地调整各分区的分配吞吐量。若因表容量增长而拆分分区，子分区会从父分区继承并平均分配吞吐量；若因吞吐量需求增长而拆分分区，则新分区会按照表的预配置吞吐量进行分配。例如，假设某分区最大可承载 1000 WCU。创建一个具有 3200 WCU 的表时，DynamoDB 会生成 4 个分区，每个分区分配到 800 WCU；若将表的吞吐量提升至 3600 WCU，则每个分区可用吞吐量自动增至 900 WCU；若进一步提升至 6000 WCU，系统会拆分出 8 个子分区，每个分区分配到 750 WCU；若将吞吐量下调至 5000 WCU，则每个分区的吞吐量相应降至 675 WCU。</p>
<p>以上这种对各分区进行均匀吞吐量分配的做法基于如下假设：应用会均匀地访问表中各个键，且按容量拆分分区也会等比地拆分性能。但开发者发现，应用在不同时间和键范围上的访问模式常常并不均匀。当表内请求速率分布不均匀时，将分区拆分并按比例分配吞吐量，往往会导致热点区域拆分后可用性能反而低于拆分前的水平。由于吞吐量在分区层面上被静态分配和强制执行，这类非均匀工作负载偶尔会引发应用的读写请求被拒绝（即“限流”），即使整表的预配置吞吐量充足，也无法满足集中在少数键的高并发访问。</p>
<p><img src="/Users/yihangwei/blog/source/images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/DynamoDB_unbalanced_requests.drawio.png" alt="img"></p>
<p><img src="/Users/yihangwei/blog/source/images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/DynamoDB_throttling.drawio.png" alt="img"></p>
<p>在这种配置下，最常遇到的两个挑战是：<strong>热点分区</strong>（hot partitions）和<strong>吞吐量稀释</strong>（throughput dilution）。热点分区指的是访问始终集中在某些表项上的场景，这些热点可能稳定地落在某几个分区内，也可能随着时间在不同分区间跳动。吞吐量稀释则常出现在因扩容而按大小拆分分区的场景：拆分后，父分区的吞吐量被平均分配到新分区，使得每个分区的可用吞吐量降低。</p>
<p>从用户角度看，这两种情况都会导致资源被限流，使其应用在某些时段出现不可用。遭遇限流的用户往往会通过人为过度提升表的预配置吞吐量来规避问题，但这导致资源浪费、成本上升，并且难以准确估算所需性能。</p>
<p>因此，DynamoDB 在发布后不久就推出了两项改进，即突发容量和自适应容量，以解决这些问题。</p>
<h3 id="突发容量"><a href="#突发容量" class="headerlink" title="突发容量"></a>突发容量</h3><p>当开发者注意到各分区的访问模式并不均匀后，又发现并非所有分区在同一时刻都会耗尽为其分配的吞吐量。因此，为了在分区层面应对短时的工作负载高峰，DynamoDB 引入了突发（bursting）机制，其核心思想是在分区级别让应用可以按尽最大努力使用未被实时消耗的容量，以吸收短暂的访问激增。DynamoDB 会保留每个分区多达 300 秒的未使用容量，用于后续的突发性吞吐需求，这部分未用容量即称为突发容量（burst capacity）。</p>
<p><img src="/Users/yihangwei/blog/source/images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/DynamoDB_token_bucket.drawio.png" alt="img"></p>
<p>此外，为了仍然保证工作负载的隔离性，DynamoDB 要求分区只有在所在节点整体存在未用吞吐量时才能突发。系统在存储节点层面通过多组令牌桶来管理容量：每个分区对应两组桶（一个分配桶 allocated、一个突发桶 burst），整个节点还有一组节点桶 node。它们共同构成了准入控制的机制。</p>
<p>每当读或写请求到达存储节点时，系统首先检查对应分区的“分配桶”是否有剩余令牌。若有，则请求被接纳，并同时从该分区与节点级令牌桶中各扣减相应令牌。当分区分配桶中的令牌耗尽后，系统仅在<strong>分区突发桶</strong>和<strong>节点级桶</strong>均有可用令牌时，才允许继续处理（突发）请求。</p>
<p>而且，完全依据本地（本节点）令牌桶完成校验，无需跨副本通信。写请求除了检查本地突发桶和节点桶外，还需额外验证该分区其他副本所在节点的节点级令牌桶是否有余量，以保证跨副本一致性与可用性。为支持写请求的额外校验，分区的主副本会定期从各成员副本节点收集节点级令牌余量信息，并据此决定是否允许写请求突发。</p>
<h3 id="自适应容量"><a href="#自适应容量" class="headerlink" title="自适应容量"></a>自适应容量</h3><p>DynamoDB 推出了自适应容量（Adaptive Capacity）机制，专门用来应对那些持续时间比较长、突发容量救急不了的高峰期。自适应容量会持续监控所有表的预配置吞吐量和实际消耗情况；当表级别发生节流但整张表的吞吐量仍在预配置范围内时，系统会自动按比例控制算法动态提升该表中热点分区的分配吞吐量。如果表的总消耗超过预配置容量，则会相应地降低刚刚那些已接受提升的分区容量，以避免资源过度使用。自动管理服务等控制平面确保获得加速的分区被迁移到具备足够剩余能力的合适节点上，以保证性能提升能够得到支撑。与突发机制一样，自适应容量也是尽力而为的，但它能消除因访问倾斜导致的 99.99% 以上因为某几个热键访问量太高而被限流的尴尬，从而让应用跑得更稳，也更省钱。</p>
<h3 id="全局准入控制"><a href="#全局准入控制" class="headerlink" title="全局准入控制"></a>全局准入控制</h3><p>虽然 DynamoDB 通过突发和自适应容量在很大程度上缓解了非均匀访问带来的吞吐量问题，但这两种方案各有局限。突发机制仅能应对短时的流量峰值，并且依赖于节点本身还有剩余容量；自适应容量则属于被动响应，仅在检测到限流发生后才会启动，这意味着应用在此之前已经经历了短暂的不可用。两者的关键问题是：我们将分区级的容量管理紧密地和准入控制耦合起来了，而准入控制是分散在各个分区中执行的。换句话说，当用户往某个分区发请求时，这个分区自己就决定放行还是拒绝该请求。这种分区粒度的准入控制无法处理非均匀访问模式导致的热点，往往在整体容量闲置的情况下依然出现局部节流，因为每个分区的准入控制只能感知自身的吞吐量和资源使用情况。因此如果能够将准入控制从分区中剥离出来，让分区始终保持可 burst，同时又能保证不同工作负载之间的隔离，将更为高效。</p>
<p>为此，DynamoDB 用全局准入控制（Global Admission Control，GAC）取代了原有的自适应容量。GAC 依然基于令牌桶思想运行：一个中央服务持续监控全表范围内的令牌消耗情况，每个请求路由器在本地维护一个令牌桶；当应用请求到达时，先尝试从本地令牌桶中扣除令牌；当本地令牌不足时，再向 GAC 请求新的令牌。GAC 根据各路由器提交的消耗信息，动态计算并分发下一时间窗口内可用的全局令牌份额，确保即便流量集中在表中某些键上，也不会超过单个分区的最大处理能力。</p>
<p>与此同时，为了多层防护，DynamoDB 保留了分区级的令牌桶，并对其容量进行了上限限制，以防某个应用独占节点资源或过度消耗其存储节点上的吞吐量。这样，GAC 实现了跨分区的全局流量调度，而分区级令牌桶则继续在最底层保障多租户隔离。</p>
<h3 id="平衡消耗的容量"><a href="#平衡消耗的容量" class="headerlink" title="平衡消耗的容量"></a>平衡消耗的容量</h3><p>让分区始终保持突发（bursting）能力，就需要 DynamoDB 对突发容量进行有效管理。DynamoDB 在多种硬件实例类型上运行，这些实例在吞吐量和存储能力上各不相同。最新一代的存储节点上往往承载着数千个分区副本，这些分区可能完全无关联，属于不同表，甚至不同客户，而各表的访问模式也千差万别。要将这些副本安全地部署在同一节点上，又能保证可用性、稳定的性能、安全性和弹性，就必须设计出合理的分配方案。</p>
<p>如果只用预配置吞吐量，那很好办：分区数固定，按容量找机器，根本不用担心某个分区会多吃流量。但有了突发和自适应后，分区可能随时超出预设容量使用突发资源，这就意味着某些节点在短时内可能会超载，导致把多个数据分区放到同一台机器上变得棘手。</p>
<p>因此，为了在不牺牲可用性的前提下，提高节点利用率，DynamoDB 实现了一套主动均衡系统：每个存储节点独立监控其上所有分区副本的吞吐量和数据大小，一旦发现总吞吐量超过节点最大容量的阈值，就会向自动管理服务报告一批候选迁移分区。自动管理服务再为这些分区寻找新的存储节点（可在同可用区或跨可用区），确保新节点上尚未存在该分区的副本，从而将它们安全地搬迁出去，降低过度紧凑部署带来的可用性风险。</p>
<h3 id="拆分消费"><a href="#拆分消费" class="headerlink" title="拆分消费"></a>拆分消费</h3><p>DynamoDB 在引入全局准入控制和始终可突发能力后，发现当流量高度集中在某些键上时，仍可能出现节流。为此，它会根据分区的实际吞吐量自动扩展：当某个分区的消耗超过阈值时，系统会根据该分区的访问分布（而不是简单地把键范围对半拆分）选择最佳拆分点，将其分成两个子分区。这样可以更精准地将热点区域隔离出来，不过对于只针对单个键或按顺序访问整个键范围的场景，此方法并无优势；对此，DynamoDB 会自动识别并避免执行拆分操作。</p>
<h3 id="按需配置"><a href="#按需配置" class="headerlink" title="按需配置"></a>按需配置</h3><p>DynamoDB 还推出了按需表（On-Demand Tables）模式，帮助之前在本地或自建数据库上运行、需要手动配置服务器的应用解放运维负担，是一种无需用户预先规划吞吐量即可弹性扩缩的无服务器模式。按需表通过读写容量单位（RCU&#x2F;WCU）来自动弹性扩缩，系统会实时监控实际的读写请求量，并能瞬间承载到达表上的流量峰值的两倍。如果后续流量超过此前最大峰值的两倍，DynamoDB 会不断新增分区并按流量情况拆分，以保证应用不会因超出配额而被限流。全局准入控制则负责从整体上监控并保护系统，防止单个应用抢占所有资源；加上基于消耗量的智能分区调度，按需表能够高效利用节点资源，避免触及节点级别的容量上限，让应用在任何突发流量下都能平稳运行。</p>
<h1 id="Durability-and-correctness"><a href="#Durability-and-correctness" class="headerlink" title="Durability and correctness"></a>Durability and correctness</h1><h2 id="Hardware-failures"><a href="#Hardware-failures" class="headerlink" title="Hardware failures"></a>Hardware failures</h2><p>The write-ahead logs in DynamoDB are crucial for ensuring data durability and crash recovery. Each partition has three replicas that store the write-ahead logs. To enhance durability, the logs are periodically archived to Amazon S3. The unarchived logs typically amount to a few hundred megabytes.</p>
<p>In large-scale systems, hardware failures such as memory or disk failures are common. When a node fails, all replication groups hosted on that node are reduced to two copies. The process of repairing a storage replica can take several minutes, as it involves copying both the B-tree and the write-ahead logs.</p>
<p>When the system detects an unhealthy replica, the leader of the replication group adds a log replica to ensure data durability is not compromised. Since only the recent write-ahead logs need to be copied without the B-tree, adding the log replica takes just a few seconds. This quick addition helps restore the affected replication group, ensuring that the most recent writes remain highly durable.</p>
<h2 id="Silent-data-errors"><a href="#Silent-data-errors" class="headerlink" title="Silent data errors"></a>Silent data errors</h2><p>Hardware failures can cause incorrect data storage: In DynamoDB, errors may occur due to issues with storage media, CPU, or memory, and these errors are often difficult to detect.</p>
<p>Extensive use of checksums: DynamoDB maintains checksums for every log entry, message, and log file to detect silent errors and ensure data integrity during each data transfer. When messages are transmitted between nodes, checksums verify whether errors occurred during transmission.</p>
<p>Log archiving and validation: Each log file archived to S3 has a manifest that records details such as the table, partition, and data markers. Before uploading, the archiving agent performs various checks, including checksum validation, verifying that the log belongs to the correct table and partition, and ensuring that there are no gaps in the sequence numbers.</p>
<p>Multiple replica log archiving: Log archiving agents run on all three replicas. If one agent finds that a log file has already been archived, it downloads the file and compares it with the local write-ahead log to verify data integrity.</p>
<p>Checksum validation during S3 upload: Every log file and manifest file is uploaded to S3 with a content checksum. S3 verifies this checksum during the upload process to catch any errors in data transmission.</p>
<h2 id="Continuous-verification"><a href="#Continuous-verification" class="headerlink" title="Continuous verification"></a>Continuous verification</h2><p>Continuous Data Integrity Verification: DynamoDB continuously verifies data at rest to detect silent data errors and bit rot, which can occur due to hardware failures or data corruption. This is a critical defense mechanism for maintaining data reliability.</p>
<p>Scrub Process: The scrub process is central to detecting unforeseen errors. It checks two main aspects:</p>
<ul>
<li><strong>Replica Consistency</strong>: Ensures that all three replicas in a replication group have identical data.</li>
<li><strong>Archived Log Reconstruction</strong>: Rebuilds an offline replica using archived write-ahead logs from S3 and verifies that it matches the live replica.</li>
</ul>
<p>Verification Mechanism: Scrub computes checksums for the live replicas and compares them with those generated from replicas built using archived logs.</p>
<p>Defense in Depth: This mechanism ensures that live storage replicas and those rebuilt from historical logs remain consistent, providing confidence in the system’s integrity and reliability.</p>
<h2 id="Backups-and-restores"><a href="#Backups-and-restores" class="headerlink" title="Backups and restores"></a>Backups and restores</h2><p>Backup and Restore Mechanism: DynamoDB supports backup and restore to protect against logical corruption caused by bugs in customer applications. Backups and restores are built using write-ahead logs stored in S3 and do not affect table performance or availability.</p>
<p>Backup Consistency: Backups are full copies of DynamoDB tables, consistent across multiple partitions to the nearest second, and stored in Amazon S3. Data can be restored to a new DynamoDB table at any time.</p>
<p>Point-in-Time Restore: DynamoDB supports point-in-time restore, allowing customers to restore a table to any point within the last 35 days. This feature creates periodic snapshots of table partitions and stores them in S3.</p>
<p>Snapshots and Write-Ahead Logs: For point-in-time restore, DynamoDB identifies the closest snapshots to the requested time, applies the corresponding write-ahead logs, and restores the table to the desired state.</p>
<h1 id="Availability"><a href="#Availability" class="headerlink" title="Availability"></a>Availability</h1><h2 id="Write-and-consistent-read-availability"><a href="#Write-and-consistent-read-availability" class="headerlink" title="Write and consistent read availability"></a>Write and consistent read availability</h2><p>Write Availability: DynamoDB partition write availability depends on having a healthy leader and a healthy write quorum. A write quorum in DynamoDB requires two out of three replicas across different Availability Zones (AZs) to be healthy.</p>
<p>Handling Write Quorum Failures: <strong>If one replica becomes unresponsive, the leader adds a log replica, which is the fastest way to meet the quorum requirement and minimize write disruptions caused by an unhealthy quorum.</strong></p>
<p>Consistent Reads: Consistent reads are served by the leader replica. <strong>If the leader fails, other replicas detect the failure and elect a new leader to minimize disruptions to consistent read availability.</strong></p>
<p>Impact of Log Replicas: The introduction of log replicas was a significant system change. The use of the formally proven Paxos protocol provided confidence to safely implement this change, increasing system availability. DynamoDB can run millions of Paxos groups with log replicas in a single region.</p>
<p>Eventually Consistent Reads: Eventually consistent reads can be served by any of the replicas.</p>
<h2 id="Failure-detection"><a href="#Failure-detection" class="headerlink" title="Failure detection"></a>Failure detection</h2><p>New Leader Waits for Lease Expiry: A newly elected leader must wait for the old leader’s lease to expire before handling traffic, causing a few seconds of disruption where no new writes or consistent reads can be processed.</p>
<p>Importance of Leader Failure Detection: Quick and robust leader failure detection is crucial for minimizing disruptions. False positives in failure detection can lead to unnecessary leader elections, further disrupting availability.</p>
<p>Impact of Gray Network Failures: Gray network failures, such as communication issues between nodes or routers, can result in false or missed failure detections. These failures can trigger unnecessary leader elections, causing availability interruptions.</p>
<p>Improved Failure Detection Algorithm: To address the availability issues caused by gray failures, DynamoDB’s failure detection algorithm was improved. <strong>When a follower attempts to trigger a failover, it first checks with other replicas to see if they can still communicate with the leader. If they report the leader is healthy, the follower cancels the failover attempt.</strong> This change significantly reduced false leader elections and minimized availability disruptions.</p>
<h2 id="Metadata-availability"><a href="#Metadata-availability" class="headerlink" title="Metadata availability"></a>Metadata availability</h2><p>Metadata Needs for Request Routers: DynamoDB’s request routers require metadata mapping between table primary keys and storage nodes. Initially, this metadata was stored in DynamoDB, and the routers cached it locally. Although the cache hit rate was high, cache misses or cold starts caused metadata lookup traffic spikes, potentially destabilizing the system.</p>
<p>Caching Challenges: When caches failed or during cold starts, request routers frequently queried the metadata service, putting immense pressure on it and leading to cascading failures in other parts of the system.</p>
<p>Introduction of MemDS: <strong>To reduce reliance on local caches, DynamoDB introduced MemDS, a distributed in-memory data store for storing and replicating metadata.</strong> MemDS scales horizontally to handle all incoming requests and stores data in a compressed format. It uses a Perkle tree structure, combining Patricia and Merkle tree features for efficient key lookups and range queries.</p>
<p>Perkle Tree Operations: MemDS supports efficient key lookups, range queries, and special operations like floor (find the largest key ≤ given key) and ceiling (find the smallest key ≥ given key) for metadata retrieval.</p>
<p>New Partition Map Cache: DynamoDB implemented a new cache on request routers, addressing the issues of bimodal behavior. Even when a cache hit occurs, an asynchronous call is made to MemDS to refresh the cache. This ensures that MemDS consistently handles a steady volume of traffic, preventing reliance on cache hit ratios and avoiding cascading failures when caches become ineffective.</p>
<p>Partition Membership Updates: DynamoDB storage nodes, the authoritative source of partition membership data, push updates to MemDS. If a request router queries an incorrect storage node due to outdated information, the node provides updated membership data or triggers a new MemDS lookup.</p>
<h1 id="Programming-Interface"><a href="#Programming-Interface" class="headerlink" title="Programming Interface"></a>Programming Interface</h1><ol>
<li><p><strong>Key-Value Store</strong></p>
<p>DynamoDB allows users to create tables that can grow almost indefinitely. Each table is a collection of items, and each item is a collection of attributes. Each item is uniquely identified by a primary key, ensuring uniqueness within the table. DynamoDB provides a simple interface to store or retrieve items from a table or an index.</p>
</li>
<li><p><strong>Read and Write Operations</strong></p>
<p>DynamoDB operates as a key-value store, and the most common operations used by applications involve reading and writing data. These operations include:</p>
<ul>
<li><p><strong>GetItem</strong>: Retrieves an item with a given primary key.</p>
</li>
<li><p><strong>PutItem</strong>: Inserts a new item or replaces an existing one.</p>
</li>
<li><p><strong>UpdateItem</strong>: Updates an existing item, or adds it if it doesn’t exist.</p>
</li>
<li><p><strong>DeleteItem</strong>: Deletes an item from the table based on the primary key.</p>
</li>
</ul>
<p>These last three operations (PutItem, UpdateItem, and DeleteItem) are collectively referred to as writes. A write operation can optionally include conditions that must be satisfied for the operation to be executed successfully. For instance, you could specify that a PutItem operation should only succeed if the item doesn’t already exist.</p>
</li>
<li><p><strong>Transactional Operations</strong></p>
<p>DynamoDB supports transactions through two key operations:</p>
<ul>
<li><p><strong>TransactGetItems</strong>: Used for reading multiple items atomically. It retrieves the latest versions of items from one or more tables at a single point in time, ensuring consistency. If any conflicting operation is modifying an item that’s being read, the transaction will be rejected.</p>
</li>
<li><p><strong>TransactWriteItems</strong>: This is used for performing atomic writes across multiple items and tables. It allows you to create, update, or delete multiple items in one or more tables within a single atomic transaction. This ensures that either all changes happen, or none do. The operation is synchronous and idempotent (meaning it can be retried without causing duplicate effects). TransactWriteItems can include conditions on the current values of the items, and the operation is rejected if these conditions aren’t met.</p>
</li>
</ul>
</li>
</ol>
<h1 id="Transactions"><a href="#Transactions" class="headerlink" title="Transactions"></a>Transactions</h1><p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/dynamodb_txn.png" alt="img"></p>
<p><strong>Request Router (RR)</strong>:</p>
<ul>
<li>The <strong>Request Router</strong> is the first major component that handles incoming requests after they pass through the network.</li>
<li><strong>Authentication and Authorization</strong>: RR typically interacts with an <strong>Authentication System</strong> to ensure that the request is valid and the user has the proper permissions to access or modify the data.</li>
<li><strong>Routing Requests</strong>: Once a request is authenticated, the RR determines which <strong>Storage Nodes</strong> the request should be forwarded to. It uses the <strong>Metadata System</strong> to map the key(s) involved in the request to the correct storage nodes, as the data is distributed across many nodes.</li>
<li><strong>Forwarding Requests</strong>: Depending on whether the operation is a simple read&#x2F;write or part of a larger transaction, the RR may route the request directly to storage nodes or to the Transaction Coordinator.</li>
</ul>
<p><strong>Transaction Coordinator (TC)</strong>:</p>
<ul>
<li>The <strong>Transaction Coordinator</strong> plays a central role in handling transactions that span multiple items or storage nodes.</li>
<li><strong>Transaction Management</strong>: For requests that involve multiple storage nodes or require consistency (e.g., multi-item writes in a transaction), the RR forwards the request to the TC. The TC is responsible for breaking down the transaction into individual operations and coordinating these operations across the necessary storage nodes.</li>
<li><strong>Distributed Transaction Execution</strong>: The TC ensures that the operations follow the appropriate protocol (e.g., two-phase commit) to guarantee atomicity and consistency, ensuring that all parts of the transaction are either completed successfully or rolled back.</li>
<li><strong>Timestamp Assignment and Conflict Resolution</strong>: In a timestamp-based system like DynamoDB, the TC may assign timestamps to ensure the correct ordering of operations and manage any potential conflicts between concurrent transactions.</li>
</ul>
<p>In summary:</p>
<ul>
<li><strong>Request Router (RR)</strong> handles initial authentication and routing of requests to the appropriate storage nodes or transaction coordinator.</li>
<li><strong>Transaction Coordinator (TC)</strong> manages distributed transactions, ensuring data consistency and handling multi-node operations.</li>
</ul>
<h1 id="Transaction-execution"><a href="#Transaction-execution" class="headerlink" title="Transaction execution"></a>Transaction execution</h1><ol>
<li><p><strong>Transaction Routing</strong></p>
<p>All operation requests first reach a set of frontend hosts known as request routers. These routers are responsible for authenticating the requests and routing them to the appropriate storage nodes. Storage nodes are mapped based on key ranges. For transaction management, the routers forward transaction operations to transaction coordinators.</p>
<p>Transaction coordinators break down the transaction into multiple operations targeting different items and coordinate the execution of these operations across the storage nodes using a distributed protocol.</p>
</li>
<li><p><strong>Timestamp Ordering</strong></p>
<p>Each transaction is assigned a timestamp that defines its logical execution order. Multiple transaction coordinators operate in parallel, and different coordinators assign timestamps to different transactions. As long as transactions execute in the assigned order, serializability is maintained.</p>
<p>The storage nodes are responsible for ensuring that the operations on the items they manage are executed in the correct order and rejecting transactions that cannot be properly ordered.</p>
</li>
<li><p><strong>Write Transaction Protocol</strong></p>
<p>DynamoDB uses a two-phase commit protocol to ensure that the write operations within a transaction are atomic and executed in the correct order. In the prepare phase, the coordinator prepares all the write operations. If all storage nodes accept the operations, the transaction is committed; otherwise, it is canceled.</p>
<p>The storage nodes record the timestamp and metadata of each item involved in the transaction to ensure the transaction is handled correctly.</p>
</li>
<li><p><strong>Read Transaction Protocol</strong></p>
<p>Read transactions also use a two-phase protocol, but it differs from the write transaction protocol. DynamoDB designed a two-phase read protocol without write operations to avoid adding latency and costs to reads.</p>
<p>In the first phase, the coordinator reads all the items involved in the transaction, along with their Log Sequence Numbers (LSN). In the second phase, if the LSN has not changed, the read is successful; otherwise, the read is rejected.</p>
</li>
<li><p><strong>Recovery and Fault Tolerance</strong></p>
<p>If a storage node fails, the leadership role transfers to another storage node within the same replication group, with transaction metadata persistently stored and replicated across the nodes.</p>
<p>Transaction coordinator failures are more complex. Coordinators maintain a persistent record of each transaction to ensure atomicity and completeness. Recovery managers periodically scan these transaction records, looking for incomplete transactions, and reassign them to new coordinators to resume execution.</p>
</li>
</ol>
<h1 id="Two-phase-commit-2PC"><a href="#Two-phase-commit-2PC" class="headerlink" title="Two-phase commit (2PC)"></a>Two-phase commit (2PC)</h1><ol>
<li><p><strong>Prepare Phase</strong></p>
<p>In the prepare phase, the transaction coordinator (TC) is responsible for sending the transaction’s write operations to all the participating storage nodes. The coordinator breaks down the transaction into individual operations targeting specific data items and sends a prepare message to each storage node involved. This message includes:</p>
<ul>
<li><p>The transaction’s timestamp.</p>
</li>
<li><p>The transaction’s unique identifier (ID).</p>
</li>
<li><p>The specific operation to be performed on the data item (such as insert, update, or delete).</p>
</li>
</ul>
<p>Upon receiving the prepare message, each storage node evaluates whether it can accept the transaction. The storage node will accept the transaction’s write operation if all of the following conditions are met:</p>
<ul>
<li><p><strong>Preconditions</strong> are satisfied (e.g., a condition might be that the item must exist, or that it has a certain value).</p>
</li>
<li><p>The write operation does not violate any <strong>system restrictions</strong> (e.g., exceeding the maximum item size).</p>
</li>
<li><p>The transaction’s timestamp is <strong>greater than</strong> the item’s last write timestamp, indicating that this operation is the most recent.</p>
</li>
<li><p>There are no <strong>ongoing transactions</strong> attempting to write to the same item.</p>
</li>
</ul>
<p>If all participating storage nodes accept the transaction during the prepare phase, the coordinator moves to the commit phase. If any node rejects the transaction (e.g., due to a failed precondition or timestamp conflict), the transaction is canceled.</p>
</li>
<li><p><strong>Commit Phase</strong></p>
<p>Once the transaction has been accepted by all storage nodes during the prepare phase, the coordinator enters the commit phase. During this phase, the coordinator sends a commit message to all the storage nodes, instructing them to apply the write operations. Each storage node then:</p>
<ul>
<li><p>Applies the prepared write operations to the local items.</p>
</li>
<li><p>Updates the <strong>timestamp</strong> of the item to reflect the transaction’s timestamp.</p>
</li>
<li><p>Updates the timestamps of any items where preconditions were checked, even if no write operation was performed.</p>
</li>
</ul>
<p>If any node rejects the transaction during the prepare phase, the coordinator sends a cancel message to all storage nodes, instructing them to discard any prepared changes. No writes are applied, ensuring atomicity.</p>
</li>
</ol>
<h1 id="Adapting-timestamp-ordering-for-key-value-operations"><a href="#Adapting-timestamp-ordering-for-key-value-operations" class="headerlink" title="Adapting timestamp ordering for key-value operations"></a>Adapting timestamp ordering for key-value operations</h1><ol>
<li><p><strong>Individual Item Read Operations</strong></p>
<p>In DynamoDB, even if there is a prepared transaction attempting to read to a particular data item, the system still allows read operations on that item. Specifically:</p>
<ul>
<li><p><strong>Bypassing the transaction coordinator</strong>: Non-transactional <code>GetItem</code> operations are routed directly to the storage node responsible for the item, bypassing the transaction coordinator. This avoids potential transaction locks or delays.</p>
</li>
<li><p><strong>Returning the latest data immediately</strong>: The storage node immediately returns the latest committed value of the item, regardless of whether a prepared transaction may later update it.</p>
</li>
<li><p><strong>Timestamp assignment</strong>: This read operation is assigned a timestamp that is after the last write operation’s timestamp but before the prepared transaction’s commit timestamp. This ensures the read operation is serializable, meaning it is placed between the last completed write and the pending write.</p>
</li>
</ul>
</li>
<li><p><strong>Individual Item Write Operations</strong></p>
<p>In most cases, DynamoDB allows individual item write operations to be executed immediately, often before prepared transactions:</p>
<ul>
<li><p><strong>Directly routed to the storage node</strong>: Non-transactional <code>PutItem</code> and other modification operations are routed directly to the storage node, bypassing the transaction coordinator.</p>
</li>
<li><p><strong>Timestamp ordering</strong>: The storage node assigns a timestamp to the write operation that is typically earlier than any prepared transactions (since those have not yet written).</p>
</li>
<li><p><strong>Exceptions</strong>: If a prepared transaction includes a condition check on the item (e.g., checking a bank account balance), the system will not allow a new write to bypass the prepared transaction. For example, if a transaction is checking that there are enough funds to withdraw $100, a new transaction cannot make a withdrawal or delete the item during that check.</p>
</li>
</ul>
</li>
<li><p><strong>Delayed Execution of Write Operations</strong></p>
<p>In certain scenarios, the system can delay write operations instead of rejecting them:</p>
<ul>
<li><p><strong>Buffering writes</strong>: If a new write operation conflicts with a prepared transaction’s conditions (e.g., by modifying the item’s state), the storage node can buffer the write operation in a queue until the prepared transaction is complete. This prevents the need to reject the write and require the client to resubmit it.</p>
</li>
<li><p><strong>Processing buffered writes after the transaction completes</strong>: Once the prepared transaction completes (committed or canceled), the buffered write can be assigned a new timestamp and executed. Typically, the delay caused by waiting for the transaction to complete is short, so this strategy doesn’t significantly increase latency.</p>
</li>
<li><p><strong>Unconditional writes</strong>: If the storage node receives a <code>PutItem</code> or <code>DeleteItem</code> operation without any preconditions, these operations can be executed immediately. They are assigned a timestamp later than any prepared transactions, ensuring the correctness of transactions. If a previously prepared transaction is committed with an earlier timestamp, its write operations will be ignored.</p>
</li>
</ul>
</li>
<li><p><strong>Write Transactions with Older Timestamps</strong></p>
<p>DynamoDB supports accepting write transactions with older timestamps:</p>
<ul>
<li><p><strong>Handling after already committed writes</strong>: If a write transaction with an older timestamp arrives at a storage node where a later write has already been processed, the node can still accept the older transaction and mark it as prepared. If the transaction is eventually committed, its write will be ignored, as the earlier write has already been overwritten by the newer one.</p>
</li>
<li><p><strong>Exceptions for partial updates</strong>: This rule applies to full overwrites of data items (like <code>PutItem</code>), but not to partial updates (like <code>UpdateItem</code>). If the last write was a partial update, the operations must be executed in strict timestamp order to ensure correctness.</p>
</li>
</ul>
</li>
<li><p><strong>Multiple Transactions Writing to the Same Item</strong></p>
<p>DynamoDB allows multiple transactions to simultaneously prepare to write the same data item:</p>
<ul>
<li><p><strong>Simultaneous transaction preparation</strong>: For a given item, a series of transactions can enter the prepared state simultaneously, without waiting for the previous transaction to commit. This increases concurrency and allows multiple transactions to proceed in parallel.</p>
</li>
<li><p><strong>Order of transaction commits</strong>: If the write operations are full item overwrites (like <code>PutItem</code> or <code>DeleteItem</code>), the transactions can be committed in any order, as long as the last <code>PutItem</code> or <code>DeleteItem</code> operation (with the latest timestamp) is the final one executed.</p>
</li>
<li><p><strong>Restrictions for partial updates</strong>: For transactions performing partial updates (like <code>UpdateItem</code>), the transactions must be executed in timestamp order, as the final state of the item depends on the sequence of updates.</p>
</li>
</ul>
</li>
<li><p><strong>Optimized Single-Phase Read Transactions</strong></p>
<p>DynamoDB introduces optimizations for read transactions, allowing certain read transactions to be completed in a single phase without requiring a two-phase commit protocol:</p>
<ul>
<li><p><strong><code>GetItemWithTimestamp</code></strong>: Assuming storage nodes support the <code>GetItemWithTimestamp</code> operation, it allows a read timestamp to be passed as a parameter. This operation returns the latest value of the item, provided its last write timestamp is earlier than the given read timestamp and any prepared transactions have timestamps later than the read timestamp; otherwise, the request is rejected.</p>
</li>
<li><p><strong>Single-phase completion of read transactions</strong>: When a read transaction involves multiple items, the transaction coordinator issues <code>GetItemWithTimestamp</code> requests for each item and buffers the returned values. If all storage nodes accept the requests without conflict, the coordinator can return the buffered values to the client, completing the transaction. If any node rejects the request, the read transaction fails.</p>
</li>
<li><p><strong>Serialization issues</strong>: This optimization is optimistic but can lead to potential serialization issues. If a storage node later accepts a write with a timestamp earlier than a previously executed read transaction, it may cause the transaction to be non-serializable. To avoid this, storage nodes need to track both the last read and write timestamps for each item. Future write transactions must ensure that their timestamps are later than the last read&#x2F;write timestamps of all the items they modify.</p>
</li>
</ul>
</li>
<li><p><strong>Optimizations for Single-Partition Write Transactions</strong></p>
<p>DynamoDB further optimizes write transactions that involve multiple items within a single partition, allowing them to be completed in a single phase without a two-phase commit protocol:</p>
<ul>
<li><p><strong>Single-partition transaction processing</strong>: If all the items being written in a transaction reside within the same partition (and thus are stored on the same storage node), there is no need for separate prepare and commit phases. The storage node can perform all the necessary precondition checks and immediately execute the write operations.</p>
</li>
<li><p><strong>Reduced communication overhead</strong>: This approach significantly reduces the communication overhead between the transaction coordinator and storage nodes, especially in highly concurrent environments, improving system performance.</p>
</li>
</ul>
</li>
</ol>
<h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h1><p><strong>Why does DynmoDB not use the two-phase locking protocol?</strong> </p>
<p>While two-phase locking is used traditionally to prevent concurrent transactions from reading and writing the same data items, it has drawbacks. Locking <strong>restricts concurrency</strong> and can lead to <strong>deadlocks</strong>. Moreover, it requires <strong>a recovery mechanism</strong> to release locks when an application fails after acquiring locks as part of a transaction but before that transaction commits. To simplify the design and take advantage of low-contention workloads, DynamoDB uses an optimistic concurrency control scheme that avoids locking altogether.</p>
<p><strong>With DynamoDB, what is the role of a transaction coordinator?</strong></p>
<ul>
<li>The <strong>Transaction Coordinator</strong> plays a central role in handling transactions that span multiple items or storage nodes. The TC is responsible for</li>
<li><ul>
<li>breaking down the transaction into individual operations and coordinating these operations across the necessary storage nodes.</li>
<li>ensuring that the operations follow two-phase commit and all parts of the transaction are either completed successfully or rolled back.</li>
<li>assigning timestamps to ensure the correct ordering of operations and managing any potential conflicts between concurrent transactions.</li>
</ul>
</li>
</ul>
<p><strong>Is DynamoDB a relational database management system?</strong></p>
<p>No, DynamoDB is not a relational database management system (RDBMS). It is a NoSQL database, specifically a key-value and document store. Here’s how it differs from an RDBMS:</p>
<ol>
<li><strong>Data Model</strong>: DynamoDB does not use tables with fixed schemas like relational databases. Instead, it stores data as key-value pairs or documents (JSON-like structure). Each item can have different attributes, and there’s no need for predefined schemas.</li>
<li><strong>Relationships</strong>: Relational databases focus on managing relationships between data (using joins, foreign keys, etc.), while DynamoDB is optimized for storing large amounts of data without complex relationships between the data items.</li>
<li><strong>Querying</strong>: RDBMSs typically use <strong>SQL</strong> for querying data, which allows for complex joins and aggregations. DynamoDB uses its own API for querying and does not support SQL natively. While it allows querying by primary key and secondary indexes, it doesn’t support joins.</li>
<li><strong>Consistency and Transactions</strong>: DynamoDB supports <strong>eventual consistency</strong> or <strong>strong consistency</strong> for reads, while traditional relational databases typically ensure strong consistency through ACID transactions. DynamoDB has introduced <strong>transactions</strong>, but they work differently compared to those in relational databases.</li>
<li><strong>Scalability</strong>: DynamoDB is designed for horizontal scalability across distributed systems, allowing it to handle very large amounts of traffic and data by automatically partitioning data. In contrast, RDBMSs are typically vertically scaled and are not as naturally distributed.</li>
</ol>
<p><strong>How is DynamoDB’s transaction coordinator different than Gamma’s scheduler?</strong> </p>
<ul>
<li>DynamoDB’s transaction coordinator uses Optimistic Concurrency Control (OCC) to manage distributed transactions, ensuring atomicity without 2PC, focusing on scalability and performance in a globally distributed system.</li>
<li>Gamma’s scheduler, on the other hand, uses the traditional Two-Phase Locking (2PL) protocol to guarantee strong consistency in a distributed environment, prioritizing strict coordination across nodes.</li>
</ul>
<p><strong>Name one difference between FoundationDB and DynamoDB?</strong></p>
<p>FoundationDB: FoundationDB is a multi-model database that offers a core key-value store as its foundation, but it allows you to build other data models (such as documents, graphs, or relational) on top of this key-value layer. It’s highly flexible and provides transactional support for different types of data models via layers.</p>
<p>DynamoDB: DynamoDB is a NoSQL key-value and document store with a fixed data model designed specifically for highly scalable, distributed environments. It does not offer the flexibility of building different models on top of its architecture and is focused on high-performance operations with automatic scaling.</p>
<p><strong>What partitioning strategy does FoundationDB use to distribute key-value pairs across its StorageServers?</strong></p>
<p>FoundationDB uses a range-based partitioning strategy to distribute key-value pairs across its StorageServers.</p>
<p>Here’s how it works:</p>
<ol>
<li><strong>Key Ranges</strong>: FoundationDB partitions the key-value pairs by dividing the key space into <strong>contiguous ranges</strong>. Each range of keys is assigned to a specific <strong>StorageServer</strong>.</li>
<li><strong>Dynamic Splitting</strong>: The key ranges are <strong>dynamically split</strong> and adjusted based on data distribution and load. If a particular range grows too large or becomes a hotspot due to frequent access, FoundationDB will automatically split that range into smaller sub-ranges and distribute them across multiple <strong>StorageServers</strong> to balance the load.</li>
<li><strong>Data Movement</strong>: When a key range is split or needs to be rebalanced, the corresponding data is migrated from one <strong>StorageServer</strong> to another without manual intervention, ensuring even distribution of data and load across the system.</li>
</ol>
<p><strong>Why do systems such as Nova-LSM separate storage of data from its processing?</strong> </p>
<ul>
<li><strong>Independent Scaling</strong>: Storage and processing resources can scale independently to meet varying load demands.</li>
<li><strong>Resource Optimization</strong>: Storage nodes focus on data persistence and I&#x2F;O performance, while processing nodes handle computation, improving overall resource efficiency.</li>
<li><strong>Fault Tolerance</strong>: Data remains safe in storage even if processing nodes fail, ensuring high availability.</li>
</ul>
<p>Reference: </p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.usenix.org/system/files/atc23-idziorek.pdf">https://www.usenix.org/system/files/atc23-idziorek.pdf</a></li>
<li><a target="_blank" rel="noopener" href="https://www.usenix.org/system/files/atc22-elhemali.pdf">https://www.usenix.org/system/files/atc22-elhemali.pdf</a></li>
</ul>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/undefined/MySQL/2024/09/27/MySQL/%E4%BA%8B%E5%8A%A1/" rel="prev" title="事务">
      <i class="fa fa-chevron-left"></i> 事务
    </a></div>
      <div class="post-nav-item">
    <a href="/undefined/MySQL/2024/10/04/MySQL/MySQL%20%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/" rel="next" title="MySQL 体系结构">
      MySQL 体系结构 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9E%B6%E6%9E%84"><span class="nav-number">1.</span> <span class="nav-text">架构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%8E%E9%A2%84%E9%85%8D%E7%BD%AE%E5%88%B0%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9"><span class="nav-number">2.</span> <span class="nav-text">从预配置到弹性伸缩</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AA%81%E5%8F%91%E5%AE%B9%E9%87%8F"><span class="nav-number">2.1.</span> <span class="nav-text">突发容量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%87%AA%E9%80%82%E5%BA%94%E5%AE%B9%E9%87%8F"><span class="nav-number">2.2.</span> <span class="nav-text">自适应容量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%A8%E5%B1%80%E5%87%86%E5%85%A5%E6%8E%A7%E5%88%B6"><span class="nav-number">2.3.</span> <span class="nav-text">全局准入控制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B9%B3%E8%A1%A1%E6%B6%88%E8%80%97%E7%9A%84%E5%AE%B9%E9%87%8F"><span class="nav-number">2.4.</span> <span class="nav-text">平衡消耗的容量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8B%86%E5%88%86%E6%B6%88%E8%B4%B9"><span class="nav-number">2.5.</span> <span class="nav-text">拆分消费</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8C%89%E9%9C%80%E9%85%8D%E7%BD%AE"><span class="nav-number">2.6.</span> <span class="nav-text">按需配置</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Durability-and-correctness"><span class="nav-number"></span> <span class="nav-text">Durability and correctness</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Hardware-failures"><span class="nav-number">1.</span> <span class="nav-text">Hardware failures</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Silent-data-errors"><span class="nav-number">2.</span> <span class="nav-text">Silent data errors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Continuous-verification"><span class="nav-number">3.</span> <span class="nav-text">Continuous verification</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Backups-and-restores"><span class="nav-number">4.</span> <span class="nav-text">Backups and restores</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Availability"><span class="nav-number"></span> <span class="nav-text">Availability</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Write-and-consistent-read-availability"><span class="nav-number">1.</span> <span class="nav-text">Write and consistent read availability</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Failure-detection"><span class="nav-number">2.</span> <span class="nav-text">Failure detection</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Metadata-availability"><span class="nav-number">3.</span> <span class="nav-text">Metadata availability</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Programming-Interface"><span class="nav-number"></span> <span class="nav-text">Programming Interface</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Transactions"><span class="nav-number"></span> <span class="nav-text">Transactions</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Transaction-execution"><span class="nav-number"></span> <span class="nav-text">Transaction execution</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Two-phase-commit-2PC"><span class="nav-number"></span> <span class="nav-text">Two-phase commit (2PC)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Adapting-timestamp-ordering-for-key-value-operations"><span class="nav-number"></span> <span class="nav-text">Adapting timestamp ordering for key-value operations</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Questions"><span class="nav-number"></span> <span class="nav-text">Questions</span></a></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Yihang Wei</p>
  <div class="site-description" itemprop="description">聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">47</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        
  <div class="languages">
    <label class="lang-select-label">
      <i class="fa fa-language"></i>
      <span>简体中文</span>
      <i class="fa fa-angle-up" aria-hidden="true"></i>
    </label>
    <select class="lang-select" data-canonical="">
      
        <option value="zh-CN" data-href="/undefined/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2024/10/03/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/DynamoDB/" selected="">
          简体中文
        </option>
      
        <option value="en" data-href="/en/undefined/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2024/10/03/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/DynamoDB/" selected="">
          English
        </option>
      
    </select>
  </div>

        
  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">京ICP备2025131880号-1 </a>
  </div>

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yihang Wei</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
<script src="https://cdn.jsdelivr.net/npm/darkmode-js@1.5.7/lib/darkmode-js.min.js"></script>

<script>
var options = {
  bottom: '50%',
  right: '32px',
  left: 'unset',
  time: '0.5s',
  mixColor: '#fff',
  backgroundColor: '#fff',
  buttonColorDark: '#100f2c',
  buttonColorLight: '#fff',
  saveInCookies: true,
  label: '明暗',
  autoMatchOsTheme: true
}
const darkmode = new Darkmode(options);
window.darkmode = darkmode;
darkmode.showWidget();
</script>

</body>
</html>
