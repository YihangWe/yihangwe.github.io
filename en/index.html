<!DOCTYPE html>
<html lang="zh-CN,en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yihangwe.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。">
<meta property="og:type" content="website">
<meta property="og:title" content="EthanWeee">
<meta property="og:url" content="https://yihangwe.github.io/en/index.html">
<meta property="og:site_name" content="EthanWeee">
<meta property="og:description" content="聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Yihang Wei">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://yihangwe.github.io/en/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>EthanWeee</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start --><script>(function() {function calculateHeight(element) {let height = 0;const items = element.children;for (let i = 0; i < items.length; i++) {height += items[i].offsetHeight || 25;const child = items[i].querySelector(".nav-child");if (child && child.style.display !== "none") {height += calculateHeight(child);}}return height;}function generateToc(lang, container) {const content = document.getElementById(lang + "-content");if (!content) return;const headers = Array.from(content.querySelectorAll("h1, h2, h3, h4, h5, h6"));if (headers.length === 0) return;const ol = document.createElement("ol");ol.className = "nav";let currentLevel = 1;let currentOl = ol;let stack = [ol];let counters = [0, 0, 0, 0, 0, 0];headers.forEach((header, index) => {const level = parseInt(header.tagName[1]);counters[level - 1]++;for (let i = level; i < 6; i++) counters[i] = 0;const li = document.createElement("li");li.className = "nav-item nav-level-" + level;if (level === 1 && index === 0) {li.classList.add("active", "active-current");}const link = document.createElement("a");link.className = "nav-link";if (level === 1 && index === 0) link.classList.add("active");link.href = "#" + header.id;const numSpan = document.createElement("span");numSpan.className = "nav-number";numSpan.textContent = counters.slice(0, level).filter(n => n > 0).join(".");const textSpan = document.createElement("span");textSpan.className = "nav-text";textSpan.textContent = header.textContent;link.appendChild(numSpan);link.appendChild(document.createTextNode(" "));link.appendChild(textSpan);li.appendChild(link);if (level > currentLevel) {const newOl = document.createElement("ol");newOl.className = "nav-child";if (currentLevel === 1) {newOl.style.display = "block";stack[currentLevel - 1].lastElementChild.classList.add("active");}stack[currentLevel - 1].lastElementChild.appendChild(newOl);stack[level - 1] = newOl;currentOl = newOl;} else if (level < currentLevel) {currentOl = stack[level - 1];}currentOl.appendChild(li);currentLevel = level;});container.appendChild(ol);setTimeout(() => {const navHeight = calculateHeight(ol);ol.style.setProperty("--height", navHeight + "px");const navChilds = ol.getElementsByClassName("nav-child");Array.from(navChilds).forEach(child => {if (child.style.display === "block") {const childHeight = calculateHeight(child);child.style.setProperty("--height", childHeight + "px");}});}, 0);return ol;}function updateActiveHeading() {const activeLang = document.getElementById("en-content").style.display === "block" ? "en" : "zh";const content = document.getElementById(activeLang + "-content");const toc = document.getElementById(activeLang + "-toc");if (!content || !toc) return;const headers = Array.from(content.querySelectorAll("h1, h2, h3, h4, h5, h6"));const scrollPos = window.scrollY + window.innerHeight / 3;let activeHeader = null;for (let i = headers.length - 1; i >= 0; i--) {const header = headers[i];const headerTop = header.getBoundingClientRect().top + window.scrollY;if (headerTop <= scrollPos) {activeHeader = header;break;}}const links = toc.getElementsByClassName("nav-link");Array.from(links).forEach(link => {link.classList.remove("active");const parentLi = link.parentElement;if (parentLi) {parentLi.classList.remove("active", "active-current");}});if (activeHeader) {const activeLink = toc.querySelector(`a[href="#${activeHeader.id}"]`);if (activeLink) {activeLink.classList.add("active");let parent = activeLink.parentElement;while (parent && parent.classList) {if (parent.classList.contains("nav-item")) {parent.classList.add("active");if (parent.classList.contains("nav-level-1")) {parent.classList.add("active-current");}}parent = parent.parentElement;}}}}function initTippy() {document.querySelectorAll(".refplus-num").forEach((ref) => {if (ref._tippy) {ref._tippy.destroy();}let refid = ref.firstChild.href.replace(location.origin+location.pathname,"");let refel = document.querySelector(refid);if (!refel) return;let refnum = refel.dataset.num;let ref_content = refel.innerText.replace(`[${refnum}]`,"");tippy(ref, {content: ref_content,});});}function initToc() {const originalToc = document.querySelector(".post-toc-wrap");if (!originalToc || !document.getElementById("langToggle")) return;const tocContainer = document.createElement("div");tocContainer.className = "post-toc-wrap sidebar-panel sidebar-panel-active";const enToc = document.createElement("div");enToc.id = "en-toc";enToc.className = "post-toc motion-element";enToc.style.display = "block";const zhToc = document.createElement("div");zhToc.id = "zh-toc";zhToc.className = "post-toc motion-element";zhToc.style.display = "none";generateToc("en", enToc);generateToc("zh", zhToc);tocContainer.appendChild(enToc);tocContainer.appendChild(zhToc);originalToc.parentNode.replaceChild(tocContainer, originalToc);window.addEventListener("scroll", updateActiveHeading);setTimeout(updateActiveHeading, 0);}window.toggleLanguage = function() {const enContent = document.getElementById("en-content");const zhContent = document.getElementById("zh-content");const enToc = document.getElementById("en-toc");const zhToc = document.getElementById("zh-toc");const button = document.getElementById("langToggle");if (!enContent || !zhContent || !enToc || !zhToc || !button) return;const isEnglish = enContent.style.display === "block";enContent.style.display = isEnglish ? "none" : "block";zhContent.style.display = isEnglish ? "block" : "none";enToc.style.display = isEnglish ? "none" : "block";zhToc.style.display = isEnglish ? "block" : "none";button.querySelector(".button-text").textContent = isEnglish ? "Switch to English" : "切换中文";setTimeout(updateActiveHeading, 0);setTimeout(initTippy, 100);};document.addEventListener("DOMContentLoaded", function() {initToc();setTimeout(initTippy, 3000);});})();</script><style>.post-toc { transition: all 0.2s ease-in-out; }.post-toc .nav { padding-left: 0; }.post-toc .nav-child { padding-left: 1em; }.post-toc .nav-item { line-height: 1.8; }.post-toc .nav-link { color: #555; }.post-toc .nav-link:hover { color: #222; }.post-toc .nav-link.active { color: #fc6423; }.post-toc .active > .nav-link { color: #fc6423; }.post-toc .active-current > .nav-link { color: #fc6423; }</style><!-- hexo injector head_end end --><style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">EthanWeee</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN,en">
    <link itemprop="mainEntityOfPage" href="https://yihangwe.github.io/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/04/06/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Review%20Report%20-%20Managing%20Cold%20Data%20in%20a%20Memory-Optimized%20Database/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yihang Wei">
      <meta itemprop="description" content="聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EthanWeee">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/04/06/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Review%20Report%20-%20Managing%20Cold%20Data%20in%20a%20Memory-Optimized%20Database/" class="post-title-link" itemprop="url">Managing Cold Data in a Memory-Optimized Database</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-04-06 00:00:00" itemprop="dateCreated datePublished" datetime="2025-04-06T00:00:00-07:00">2025-04-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-05-31 23:04:49" itemprop="dateModified" datetime="2025-05-31T23:04:49-07:00">2025-05-31</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/" itemprop="url" rel="index"><span itemprop="name">高级数据存储</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>The paper addresses 2 problems:</p>
<ol>
<li>How to migrate records to and from the cold store.</li>
<li>How to read and update records in the cold store in a transactionally consistent manner.</li>
</ol>
<p>The paper provides 3 novel ideas and elaborates the proposed approach for the implementation of each idea:</p>
<ol>
<li>A unified interface that hides the physical location of a record to higher layer: the collaboration among cold store, access filters, private cache, and update memo.</li>
<li>Minimizing the overhead caused by accessing secondary storage: each transaction has its own private cache.</li>
<li>Seamless migration between hot and cold stores: the system performs migration using insert and delete operations in a transaction.</li>
</ol>
<p>Analytical and experimental findings: The paper evaluates the performance of Siberia on both the YCSB Benchmark and Multi-step read&#x2F;update workload, showing the following conclusions. With realistic client delay, the throughput loss is only 3%. Even under extreme cold access data rate, the in-memory Siberia machinery results in a low performance loss. When live migration is active, the system’s performance remains stable. The overhead of accessing the memo is expensive, which means that memo cleaning is important for improving performance. For read-only transactions at realistic cold data access rates of 5% and 10%, the performance losses are 7% and 14% respectively, which are acceptable. For update-only transactions, 5% cold data updates lead to 8% throughput loss, 10% cold data update rates lead to 13% throughput loss, which are also acceptable. For the YCSB workload, as the access skew decreases and the memory to database size ratio increases, performance degrades, and read-heavy workloads exhibit lower abort rates for transactions at higher skew rates compared to write-heavy workloads.</p>
<h1 id="Paper-Strength"><a href="#Paper-Strength" class="headerlink" title="Paper Strength"></a>Paper Strength</h1><ul>
<li>The paper provides a comprehensive literature review. In the HEKATON STORAGE AND INDEXING section, the paper briefly outlines the index and data storage structure of HEKATON and its read and update operations based on MVCC. In the RELATED WORK section, the paper analyzes how existing database systems handle cold data, explaining that Hyper manages cold data using virtual pages, Stoica et al propose separating hot and cold data into different memory locations. Finally, the paper describes the working principle of Anti-caching and highlights its 2 drawbacks: limited space savings and repeated execution.</li>
<li>The paper provides a detailed description of the working principles after integrating SIBERIA into HEKATON. It presents the workflow of 2 transactions used during data migration to the cold store. Insert and update operations ensure that data is placed into the hot store to avoid the overhead of checking the cold store. Delete and read operations utilize notices in the update memo to perform concurrency control and conflict detection. Cold store cleaning is also driven by the update memo, which enables the timely removal of records from the cold store that are no longer visible to any active transactions. Furthermore, validation leverages the notices in the update memo as well and computes TsBoundSer to ensure the correctness of serializable transactions, thereby enhancing phantom detection.</li>
<li>The paper presents the relatively comprehensive experiment. The experiments are based on the YCSB Benchmark and Multi-step read&#x2F;update workload, which allow for testing Siberia’s performance under different workloads. Moreover, the paper evaluates the pure in-memory overhead of Siberia, the overhead of running live migration, and the overhead of the update memo on the path to accessing a cold record. Furthermore, under the YCSB workload, it demonstrates the relationship among workload skew, memory to database size ratios, and workload performance.</li>
</ul>
<h1 id="Paper-Weakness"><a href="#Paper-Weakness" class="headerlink" title="Paper Weakness"></a>Paper Weakness</h1><ul>
<li>The paper does not describe the process of integrating Siberia in HEKATON at the code level, but only mentions integration at the level of data processing and storage mechanisms. It details the cold data migration process and explains how update memo notices in the insert, delete, read, and update operations work in collaboration with HEKATON’s versioning and concurrency control. However, the paper does not address how Siberia is integrated into HEKATON at the code level, such as by identifying core functions, code segments, and the corresponding modifications. This omission makes it difficult for readers to easily re-achieve the Siberia. Therefore, the paper should at least provide an outline of the code modifications.</li>
<li>In the Synthetic End-to-End Workload section, the paper does not discuss the throughput loss under moderate to high cold data access rates. The paper only presents the throughput loss at 5% and 10% cold data access rates, claiming these are realistic cold data access rates. First, the paper fails to explain which report or literature supports that 5% and 10% are “realistic cold data access rates” in the Read-Only Transactions section. Second, we assume the above data is accurate, but the paper does not describes how the throughput loss changes when cold data access rates exceed 10%. This omission prevents readers from gaining a comprehensive understanding of the performance of handling workload in Siberia. Therefore, the paper should explain how the realistic cold data access rates were determined and describe the changes in throughput loss under moderate to high cold data access rates.</li>
<li>The paper does not discuss Siberia’s performance limitations or the conditions under which its performance might degenerate, despite the Experiments section showcasing impressive performance. It is possible that such impressive performance comes at the cost of high hardware utilization such as high CPU usage. Alternatively, while integrating Siberia in HEKATON may enhance the handling of hot and cold data, it could potentially compromise some of HEKATON’s original features. Therefore, the paper should clarify the situations under which Siberia’s performance may degenerate.</li>
</ul>
<p>Reference: <a target="_blank" rel="noopener" href="https://www.vldb.org/pvldb/vol7/p931-eldawy.pdf">https://www.vldb.org/pvldb/vol7/p931-eldawy.pdf</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN,en">
    <link itemprop="mainEntityOfPage" href="https://yihangwe.github.io/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/03/18/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Review%20Report%20-%20TicToc/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yihang Wei">
      <meta itemprop="description" content="聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EthanWeee">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/03/18/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Review%20Report%20-%20TicToc/" class="post-title-link" itemprop="url">TicToc</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-03-18 00:00:00" itemprop="dateCreated datePublished" datetime="2025-03-18T00:00:00-07:00">2025-03-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-05-31 23:02:32" itemprop="dateModified" datetime="2025-05-31T23:02:32-07:00">2025-05-31</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/" itemprop="url" rel="index"><span itemprop="name">高级数据存储</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>The paper addresses 1 problem:</p>
<ol>
<li>How to design an efficient concurrency control algorithm to improve scalability of OLTP DBMSs in the multi-core environment?</li>
</ol>
<p>The paper provides 4 novel ideas and elaborates the proposed approach for the implementation of each idea:</p>
<ol>
<li>TicToc algorithm: Implemented on top of OCC, it ensures a transaction’s timestamp will be calculated lazily at the commit time based on tuples this transaction process, which will improve the parallelism as well.</li>
<li>No-wait locking in validation phase: If a transaction fails to acquire a lock for a tuple in the write set, the validation phase will be aborted immediately. TicToc will restarts this phase after a period of time.</li>
<li>Preemptive aborts: Based on an approximate commit timestamp together with the local rts and wts, it is possible to determine whether to abort a transaction before locking the tuples in its write set.</li>
<li>Timestamp history: When a read tuple’s local rts is lower than the commit_ts and its wts differs from the latest wts, further inspection of the tuple’s history buffer is conducted to decide whether to start the validation phase.</li>
</ol>
<p>Analytical and experimental findings: The paper compares five algorithms: TicToc, Silo, HEKATON, DL_DETECT, and NO_WAIT. In the TPC-C results, with 4 warehouses, TicToc achieves the highest throughput and a lower abort rate than Silo. As the number of warehouses increases, TicToc’s throughput is eventually surpassed by Silo around 80 warehouses, but its abort rate remains lower than that of Silo. In the YCSB results, when processing read-only transactions, TicToc’s throughput is close to Silo’s and higher than that of the other algorithms; for read-write transactions under medium contention, TicToc maintains throughput similar to SIlo’s while its abort rate is significantly lower than those of Silo, HEKATON, and NO_WAIT; under high contention conditions, TicToc’s throughput far surpasses that of Silo, although its abort rate becomes more close to Silo’s. Tests for optimization indicate that most of the performance improvements come from the no-wait and preemptive aborts. Furthermore, TicToc’s timestamp growth rate is substantially lower than that of TS_ALLOC. When the isolation level is lower, TicToc shows improved throughput and a reduced abort rate, but the degree of these changes is not as pronounced compared to the other algorithms.</p>
<h1 id="Paper-Strength"><a href="#Paper-Strength" class="headerlink" title="Paper Strength"></a>Paper Strength</h1><ul>
<li>The paper provides a clear description of the background knowledge and the problem to be addressed. It elaborates on the weaknesses of the 2PL strategy and highlights that the T&#x2F;O strategy, such as MVCC and OCC, has gradually become mainstream. It then points out that the centralized timestamp allocator and the CPU’s cache coherence protocol in traditional T&#x2F;O algorithms have led to a timestamp allocation bottleneck. Moreover, all the hardware solutions mentioned in the paper fail to perfectly align with the architecture of most modern CPUs, and their performance remains suboptimal even if implemented. Furthermore, the paper briefly describes the execution phases of OCC and introduces 2 optimized approaches based on OCC, that is DTA and Silo, and highlights that both solutions still suffer from scalability bottlenecks. In order to tackle these problems, the paper presents TicToc algorithm.</li>
<li>The paper provides code, charts, and an example for the core processes of the TicToc algorithm, enabling readers to quickly understand the implementation details and workflow. In Section 3.2, the paper presents pseudocode for the Read Phase, Validation Phase, and Write Phase, which clearly illustrates the design considerations in addressing conflicts in concurrent and parallel scenarios and the decentralized timestamp assignment. In Section 3.6, the paper demonstrates the structure used for storing read and write timestamps and, through pseudocode, effectively presents a solution to the potential overflow problem of the delta attribute. Moreover, in Section 3.3, the paper provides an example of interleaved transaction execution, accompanied by a bar chart, clearly displaying TicToc’s high flexibility and performance in handling concurrency and parallelism challenges.</li>
<li>The paper presents a comprehensive experiment of TicToc on DBx1000. It assesses TicToc’s performance in both TPC-C and YCSB scenarios, comparing throughput and abort rate under various contention levels and different numbers of warehouses, with Silo, HEKATON, DL_DETECT, and NO_WAIT. The paper also evaluates TicToc optimizations, emphasizing the contributions of the no-wait and pre-abort to performance improvements. Moreover, the paper compares TicToc’s timestamp growth rate and linear timestamp growth rate, and the differences in throughput and abort rate between TicToc and other 4 algorithms under different isolation levels.</li>
</ul>
<h1 id="Paper-Weakness"><a href="#Paper-Weakness" class="headerlink" title="Paper Weakness"></a>Paper Weakness</h1><ul>
<li>The paper does not show the process of integrating the TicToc into DBx1000. As a concurrency control algorithm, TicToc must be interfaced with other key components such as transactions, indexes, and logs, which involves a considerable amount of work. However, the paper fails to address this aspect, thereby preventing readers from easily re-achieving the algorithm. Therefore, the paper should at least provide a brief outline of the necessary steps to help readers implement this functionality.</li>
<li>The paper’s experiments fail to demonstrate the general applicability of the TicToc across a range of databases. The evaluation was conducted only in the DBx1000 environment, thereby only substantiating TicToc’s high performance within DBx1000. But many commercially available databases, such as SQL Server and MySQL etc., exhibit distinct characteristics under varying workloads, which could potentially lead to different performance when using TicToc. However, the paper is entirely silent on this aspect. Therefore, the paper should also incorporate integration and testing of TicToc on these mainstream databases.</li>
<li>The paper fails to provide code or explanations for certain key concepts in the critical OPTIMIZATIONS section. According to the experimental results, the no-wait and preemptive aborts lead to significant performance improvements. However, the OPTIMIZATIONS section does not present any relevant code. For instance, in the No-Wait Locking in Validation Phase section, the paper does not clarify what thrashing problems mean in the given context, nor does it showcase the code for the no-wait or highlight its modifications relative to the original TicToc implementation. Therefore, the paper should include the optimization code and explanations for concepts.</li>
</ul>
<p>Reference: <a target="_blank" rel="noopener" href="https://people.csail.mit.edu/sanchez/papers/2016.tictoc.sigmod.pdf">https://people.csail.mit.edu/sanchez/papers/2016.tictoc.sigmod.pdf</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN,en">
    <link itemprop="mainEntityOfPage" href="https://yihangwe.github.io/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/03/02/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Review%20Report%20-%20Adaptive%20Execution%20of%20Compiled%20Queries/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yihang Wei">
      <meta itemprop="description" content="聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EthanWeee">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/03/02/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Review%20Report%20-%20Adaptive%20Execution%20of%20Compiled%20Queries/" class="post-title-link" itemprop="url">Adaptive Execution of Compiled Queries</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-03-02 00:00:00" itemprop="dateCreated datePublished" datetime="2025-03-02T00:00:00-08:00">2025-03-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-05-31 23:01:14" itemprop="dateModified" datetime="2025-05-31T23:01:14-07:00">2025-05-31</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/" itemprop="url" rel="index"><span itemprop="name">高级数据存储</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>The paper addresses 3 problems:</p>
<ol>
<li>How to reduce the compilation time of complex but fast queries?</li>
<li>How to reduce the compilation time of extremely large queries?</li>
<li>How to reduce the compilation time of the first incoming query?</li>
</ol>
<p>The paper provides 2 novel ideas and elaborates the proposed approach for the implementation of each idea:</p>
<ol>
<li>Adaptive execution: For a specific query pipeline, the paper tracks the progress of worker threads, predicts the remaining workload duration under 3 execution modes based on the overall state of all threads in the pipeline, and finally selects the mode with the shortest duration to apply to all threads.</li>
<li>Fast bytecode interpretation: Based on register machine, the paper implements linear-time liveness computation through processing basic blocks in intervals and using algorithms such as the disjoint set and path compression, which optimizes register allocation further. Furthermore, the bytecode interpreter behaves equivalently to the generated machine code, ensuring seamless switching between interpretation and machine code.</li>
</ol>
<p>Analytical and experimental findings: For different scale factors, adaptive execution can switch to the mode with the optimal performance, ensuring the lowest execution time compared to other static mode selections. For action, adaptive execution can immediately start to process pipeline morsels on all available worker threads and dynamically switch modes for pipelines with heavy workloads, allowing it to finish queries 10%, 40%, and 80% faster than its competitors. While interpreted code is slower than compiled code, it is faster than PostgreSQL and scales as well as compiled code when using multiple cores. Furthermore, the byte interpreter scales perfectly and can process the large query in a short time.</p>
<h1 id="Paper-Strength"><a href="#Paper-Strength" class="headerlink" title="Paper Strength"></a>Paper Strength</h1><ul>
<li>The paper provides a clear and detailed description of the problem to be addressed. In Section II, it presents the multi-step process of a SQL query in HyPer through a flowchart, highlighting that the LLVM compilation tasks takes the majority of the overall execution time. By comparing the compilation and execution times of different execution modes on TPC-H Query 1 on scale factor 1, the paper introduces the trade-off between interpreters and compilers, demonstrating that different execution modes can be applied to different parts of the same query. Furthermore, the paper analyzes the largest TPC-H and TPC-DS queries, concluding that compilation time grows super-linearly with the query size.</li>
<li>The paper provides a comprehensive literature review. In Section VI, it references experimental results from other papers on compilation time, concluding that compiling to LLVM IR is faster than compiling to C. Based on the personal experience, the paper highlights that query compilation latency becomes a major problem in production environments, this makes adaptive execution a crucial component for making query compilation truly practical. It then explores the feasibility of integrating adaptive execution into database systems such as MemSQL, LegoBase, and Microsoft Hekaton. Furthermore, the paper demonstrates the advantages of adaptive execution over automatic plan caching, i.e. the ability to re-optimize queries on every execution. Finally, the paper discusses the similarities and differences between adaptive execution and execution engines in programming languages, such as JVM, V8, and CLR.</li>
<li>The paper achieves significant improvements, the linear-time liveness computation. The traditional solution for computing the liveness of each block individually usually takes $O(n^2)$ runtime. However, the paper proposes a linear-time algorithm. The algorithm labels all basic blocks in reverse postorder and organizes them into a dominator tree, which allows interpreter to determine the relationships of basic blocks in $O(1)$ time and paves the way for identifying loops. It identifies the innermost enclosing loop of each basic block by using the disjoint set with path compression, and, based on the the distribution of basic blocks related to the definition and uses of a certain value, determines the lifetime of that value. The low cost of the computation is primarily attributed to the appropriate data structures.</li>
</ul>
<h1 id="Paper-Weakness"><a href="#Paper-Weakness" class="headerlink" title="Paper Weakness"></a>Paper Weakness</h1><ul>
<li>The paper does not provide a clear explanation of the basic concepts. In Section II, it does not explain the meaning of latency and throughput in the context of HyPer, nor the relationship between them, so readers may not realize the significance of the tradeoff and possibly do not understand how performance improvements in later experimental results are achieved. For example, readers might not figure out why interpreters can achieve very low latency by sacrificing throughput. Therefore, the paper should explain these concepts.</li>
<li>The paper’s experiments are not comprehensive enough. As a core component in data processing and storage, adaptive execution framework is only shown to have an advantage in execution time, while experiments demonstrating its physical device utilization, stability and fault recovery performance are lacking. These metrics are also critical in evaluating the overall performance of the framework. For example, for the same set of queries, if the execution time is short but the CPU and memory usage are extremely high, or if the probability of throwing an exception is high and a large amount of time is required for fault recovery, then the framework still has room for improvement. Therefore, the paper should include experimental results for these metrics.</li>
<li>The paper does not provide a detailed explanation of how to translate into VM code. In Section IV-B, the paper mentions that subsumed instructions will not be translated, but it does not specify which types of instructions are subsumed or in what manner they are subsumed. These omissions can confuse readers and hinder their understanding of the translation pseudocode. Therefore, the paper should explain principles behind subsumed instructions.</li>
</ul>
<p>Reference: <a target="_blank" rel="noopener" href="https://db.in.tum.de/~leis/papers/adaptiveexecution.pdf">https://db.in.tum.de/~leis/papers/adaptiveexecution.pdf</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN,en">
    <link itemprop="mainEntityOfPage" href="https://yihangwe.github.io/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/02/11/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Review%20Report%20-%20Orca/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yihang Wei">
      <meta itemprop="description" content="聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EthanWeee">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/02/11/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Review%20Report%20-%20Orca/" class="post-title-link" itemprop="url">Orca - A Modular Query Optimizer Architecture for Big Data</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-02-11 00:00:00" itemprop="dateCreated datePublished" datetime="2025-02-11T00:00:00-08:00">2025-02-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-05-31 23:05:29" itemprop="dateModified" datetime="2025-05-31T23:05:29-07:00">2025-05-31</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/" itemprop="url" rel="index"><span itemprop="name">高级数据存储</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>The paper addresses 2 problems:</p>
<ol>
<li>How to design a query optimizer that can handle big data and complex analytical queries while ensuring the generation of efficient query plans.</li>
<li>Exploring the application of advanced query optimization theories in production environments.</li>
</ol>
<p>The paper provides 4 novel ideas and elaborates the proposed approach for the implementation of each idea:</p>
<ol>
<li>Decoupling the optimizer from the DB systems through DXL: Different DB systems need to implement 3 translators, Query2DXL, MD Provider, and DXL2Plan, to support Orca.</li>
<li>Use Memo and Group Hash Tables to optimize: Each group in the Memo stores all logically equivalent group expressions for a given operation, including enforcer operators. The group hash tables record the optimal implementation for each optimization request, i.e., the best group expressions. During query optimization, by retrieving the best group expression (best GExprs) corresponding to a given optimization request for each group and its child groups, these best GExprs are linked together to form the best execution plan.</li>
<li>Implementing the parallel query optimization with jobs dependency graph and job queues: If a group is currently processing an optimization job, other jobs will be placed in a queue to wait. Once the job is completed, its results can be utilized by subsequent jobs.</li>
<li>Developed efficient tools for testing: AMPERe is used to catch errors and generate dump files for later replaying to debug. TAQO samples plans uniformly based on the optimization requests’ linkage structure and evaluates the optimizer’s accuracy by calculating the correlation score between the ranking of sampled plans based on estimated costs and their ranking based on actual costs.</li>
</ol>
<p>Analytical and experimental findings: Based on the TPC-DS Benchmark, a limited set of queries was used to test GPDB legacy query optimizer (111 queries, MPP) and Orca, as well as Impala (31 queries, Hadoop), Stinger (19 queries, Hadoop), Presto (12 queries, Hadoop) and HAWQ. The results concluded that Orca matched or outperformed the GPDB optimizer in 80% of query executions. For 14 queries, Orca achieved a speed-up ratio of at least 1000× compared to the GPDB optimizer. Presto failed to process any TPC-DS queries under all test conditions, and query execution performance on HAWQ was generally superior to that on Impala and Stinger.</p>
<h1 id="Paper-Strength"><a href="#Paper-Strength" class="headerlink" title="Paper Strength"></a>Paper Strength</h1><ul>
<li>The paper provides a comprehensive literature review and covers the prerequisite knowledge needed to understand Orca. In the PRELIMINARIES, the paper briefly analyzes GPDB and explains its 3 core components: master, segments, and the interconnect layer, explains how SQL and query optimizers have been integrated into big data processing components such as Hadoop. Furthermore, it analyzes the advantages of the HAWQ architecture which is optimized by Orca compared to Impala and Presto. In the RELATED WORK, the paper introduces Volcano and Cascades, highlighting that Cascades offers greater flexibility than Volcano, then discusses various query optimizer implementations for big data in MPP databases, such as PDW and SCOPE. Finally, the paper reviews existing efforts to integrate SQL with Hadoop, such as converting queries into MapReduce jobs (Hive) and co-location of DBMS and Hadoop technologies (Hadapt).</li>
<li>The paper presents highly valuable solutions for query optimization on big data: DXL and Parallel Query Optimization. Different DBs only need to implement their own Query2DXL and DXL2Plan translators to achieve compatibility with Orca, giving Orca the potential to be adapted to any existing database system. To satisfy the core requirement of big data, concurrent processing, Orca constructs an optimization jobs dependency graph to determine the dependencies between jobs. Parent jobs can only be executed after their child jobs are completed, while independent jobs can run in parallel. For handling resource contention, Orca places incoming jobs in a job queue, where they wait until the running job is finished. These waiting jobs can then leverage the results generated by the completed jobs.</li>
<li>The paper elaborates steps of Orca’s optimization in the QUERY OPTIMIZATION section. In the Exploration phase, Orca creates logically equivalent expressions and deduplicates them using the Memo. In the Statistics Derivation phase, Orca estimates the cardinality and data skew for Memo groups. In the Implementation phase, Orca generates physical implementations of logical expressions. In the Optimization phase, multiple execution plans are generated, incorporating enforcer operators when necessary. The cost model is then used to select the execution plan with the lowest cost. These details effectively help readers gain a high-level understanding of Orca’s working principles.</li>
</ul>
<h1 id="Paper-Weakness"><a href="#Paper-Weakness" class="headerlink" title="Paper Weakness"></a>Paper Weakness</h1><ul>
<li>The paper lacks a description of how execution plan costs are computed during the Optimization phase. Specifically, there is a complete absence of discussion on the cost model, which should be a core functionality of Orca. This is particularly crucial when dealing with big data and a shared-nothing architecture, where the cost model here may differ from the Selinger’s cost model by incorporating coordination and communication across multiple worker nodes and need to account for network bandwidth. I recommend that the paper include a detailed description of the cost model and discuss its behavior in both monolithic and distributed DB systems.</li>
<li>The paper’s experimental evaluation for MPP databases is based on a limited dataset. Orca was only compared against the GPDB legacy query optimizer using 119 queries. Both the number of queries and the number of MPP database optimizer being compared are insufficient to convincingly demonstrate Orca’s advantages over other MPP database optimizers. Therefore, the experiment should conduct comparisons with a broader range of MPP databases, such as Amazon Redshift and Teradata Aster, to provide a more comprehensive evaluation.</li>
<li>The paper’s experiments do not reflect Orca’s hardware utilization, such as CPU usage, memory consumption, etc. Orca will possibly be used in a shared-nothing architecture, it will run across multiple servers. However, in the production environment, these servers will be not dedicated solely to Orca, other processes including databases that Orca will optimize is going to be probably running on the same server where Orca will be. If Orca has excessively high CPU or memory usage, it could negatively impact those databases’ query execution and the performance of other applications. This effect could accumulate across multiple servers, leading to significant performance degradation. Therefore, the paper should also include an evaluation of Orca’s hardware resource consumption.</li>
</ul>
<p>Reference: <a target="_blank" rel="noopener" href="https://dl.acm.org/doi/10.1145/2588555.2595637">https://dl.acm.org/doi/10.1145/2588555.2595637</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN,en">
    <link itemprop="mainEntityOfPage" href="https://yihangwe.github.io/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/01/25/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Review%20Report%20-%20AnalyticDB%20Real-time%20OLAP%20Database%20System%20at%20Alibaba%20Cloud/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yihang Wei">
      <meta itemprop="description" content="聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EthanWeee">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/01/25/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Review%20Report%20-%20AnalyticDB%20Real-time%20OLAP%20Database%20System%20at%20Alibaba%20Cloud/" class="post-title-link" itemprop="url">AnalyticDB - Real-time OLAP Database System at Alibaba Cloud</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-01-25 00:00:00" itemprop="dateCreated datePublished" datetime="2025-01-25T00:00:00-08:00">2025-01-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-05-31 23:05:39" itemprop="dateModified" datetime="2025-05-31T23:05:39-07:00">2025-05-31</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/" itemprop="url" rel="index"><span itemprop="name">高级数据存储</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>The paper addresses 3 problems:</p>
<ol>
<li>How to process more complicated and diverse queries of users with low latency;</li>
<li>How to design a friendly and unified data layout that is compatible with column-stores and row-stores and is able to process the complex data type, with low latency;</li>
<li>How to process massive requests per second with low latency.</li>
</ol>
<p>The paper provides 5 novel ideas and elaborates the proposed approach for the implementation of each idea:</p>
<ol>
<li>Read&#x2F;write decoupling, a worker node processes either read or write operation, guarantees that read operations do not interfere with read operations. In the real-time read mode, version verification is introduced to ensure that each query retrieves the latest data, i.e., the $\text{latest version} &#x3D; max⁡(V_1,V_2)$. Furthermore, after each write operation is completed, the write node actively pulls the latest version to the corresponding read node to avoid high latency in subsequent read operations.</li>
<li>The hybrid row-columnar storage for storing complex-typed data, a detail file &#x3D; $n$ row groups, a row group &#x3D; $k$ data blocks, a data block &#x3D; $p$ FBlocks, a FBlock &#x3D; $x$ values of a certain column of a partial row to many rows.</li>
<li>Efficient index management includes the building and maintenance of indexes for both baseline data and incremental data. For baseline data, AnalyticDB builds inverted indexes and introduces a filter ratio to optimize read operations. For incremental data, AnalyticDB constructs lightweight sorted indexes on read nodes to expedite read operations before the asynchronous construction of the inverted index of this type of data is finished.</li>
<li>For the optimizer, AnalyticDB introduces the STARs framework to evaluate both the capability of storage and relational algebra ability and adopts dynamic programming, in order to achieve efficient predicate push-down. This database minimizes the cost of shuffling tables for join push-down. For index-based join and aggregation, it employs the LeftDeepTree to efficiently utilize index-on-all-columns while also pushing down predicates and aggregations. Furthermore, the optimizer and execution engine perform sampling-based cardinality estimation with caching previously sampled results, optimized sampling algorithm, and improved derived cardinality.</li>
<li>The execution engine is able to operate directly on serialized binary data rather than Java objects, eliminating the expensive costs of serialization and deserialization during the process of shuffling big data.</li>
</ol>
<p>Analytical and experimental findings: AnalyticDB outperforms PrestoDB, Druid, Spark-SQL, and Greenplum in performance on the 1TB dataset, and its performance is not affected dramatically when scaled to the 10TB dataset. As the number of write nodes increases, the write throughput of AnalyticDB exhibits steady growth. In the TPC-H Benchmark, AnalyticDB completes 20 out of 22 queries in half the time required by the second-fastest database. However, for Query 2, AnalyticDB is slower than PrestoDB and Greenplum due to selecting a different join order.</p>
<h1 id="Paper-Strength"><a href="#Paper-Strength" class="headerlink" title="Paper Strength"></a>Paper Strength</h1><ul>
<li>3 challenges outlined in the paper precisely target the critical obstacles faced by OLAP systems in achieving real-time and efficient response. Addressing these challenges not only significantly enhances the database’s compatibility with diverse queries and complex data types, but also improves its responsiveness in the production environment, underscoring the high research value. The integration of read-write decoupling with version verification ensures that read and write operations remain isolated, while consistently providing read queries with the latest data. The design of the hybrid data layout and indexes incorporates support for complex data types such as JSON, full-text, and vector data, enabling a unified access interface for diverse data operations. This significantly broadens the applicability of AnalyticDB to a wider range of use cases. Furthermore, the execution engine, which combines sampling-based cardinality estimation with caching and optimized sampling algorithms, etc, achieves high estimation accuracy at low overhead and minimal latency. In conclusion, the advancements and optimizations introduced in AnalyticDB represent a major step forward in enhancing data versatility and real-time responsiveness in OLAP systems, the comprehensive solution will fully demonstrate its capabilities in high-concurrency e-commerce scenarios.</li>
<li>The paper provides a comprehensive literature review. The 2. Related Work section discusses the shortcomings of different databases. For example, expensive index updates in OLTP databases can degrade throughput and increase latency, and column-store in OLAP databases, such as TeradataDB and Greenplum, causes high random I&#x2F;O costs for point-lookup queries. Those issues above are effectively addressed in AnalyticDB. Furthermore, the paper outlines AnalyticDB’s improvements over Amazon Redshift and differences in query and aggregation compared to Google BigQuery.</li>
<li>The paper provides the detailed description of processes of functionalities in AnalyticDB, including:<ol>
<li>A thorough explanation of the read-write decoupling process from both reading and writing perspectives, accompanied by a flowchart specifically illustrating the more complex read operations.</li>
<li>Pseudocode and comments of key instructions for 3 algorithms involved in Query Execution.</li>
<li>A diagram outlining the merging process of baseline data and incremental data, broken down into 3 phases.</li>
</ol>
</li>
</ul>
<h1 id="Paper-Weakness"><a href="#Paper-Weakness" class="headerlink" title="Paper Weakness"></a>Paper Weakness</h1><ul>
<li>The description of some functionalities in the paper is not complete. In Section 3.4 Read&#x2F;Write Decoupling of the paper, only the real-time read is mentioned, while the bounded-staleness read is missed. For OLAP, reading outdated data is acceptable, and the bounded-staleness read allows read nodes to only access the latest data on write nodes after a certain delay following write operations, so it ensures fast responses in AnalyticDB to some extent. However, this type of read is not explained in the paper.</li>
<li>The paper lacks clarity in its description of certain newly introduced concepts. In Section 5.1.1, the discussion on predicate push-down provides only a brief overview of the STARs framework, without explaining how it applies relational algebra, how cost calculations are performed, and how the optimizer uses dynamic programming to encapsulate relational algebra operators. These omissions may leave readers confused.</li>
<li>The performance evaluation experiments in the paper are relatively simplistic. First, only 3 SQL statements were tested, focusing on a narrow range of query types, specific table partitioning strategies, specific tables and fields, and specific data types. The tests did not address complex data types such as JSON. Second, the experiments only tested datasets of 1TB and 10 TB. However, in production environments, daily new data can reach tens or even hundreds of petabytes. On peak promotional days like Double 11 or 618, the daily data processing amount can reach hundreds or even thousands of petabytes. For example, during the 2022 Double 11, Taobao and Tmall experienced a peak order payment rate of 583000 transactions per second. Thus, the datasets used in the experiments fall far short of reflecting the scale of real-world scenarios. Third, the tests based on the TPC-H Benchmark evaluated only 22 queries, which is insufficient to comprehensively reflect the true performance of these 5 databases. Therefore, it is recommended to include all data and queries involved in the production environment, such as MySQL binlogs, ElasticSearch index logs and Kafka logs, etc, and a stability test lasting one week or longer should be conducted on these 5 databases to provide a more realistic evaluation.</li>
</ul>
<p>Reference: <a target="_blank" rel="noopener" href="https://www.vldb.org/pvldb/vol12/p2059-zhan.pdf">https://www.vldb.org/pvldb/vol12/p2059-zhan.pdf</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/en/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/en/page/7/">7</a><a class="extend next" rel="next" href="/en/page/2/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Yihang Wei</p>
  <div class="site-description" itemprop="description">聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">35</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        
  <div class="languages">
    <label class="lang-select-label">
      <i class="fa fa-language"></i>
      <span>English</span>
      <i class="fa fa-angle-up" aria-hidden="true"></i>
    </label>
    <select class="lang-select" data-canonical="">
      
        <option value="zh-CN" data-href="/index.html" selected="">
          简体中文
        </option>
      
        <option value="en" data-href="/en/index.html" selected="">
          English
        </option>
      
    </select>
  </div>

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yihang Wei</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
<script src="https://cdn.jsdelivr.net/npm/darkmode-js@1.5.7/lib/darkmode-js.min.js"></script>

<script>
var options = {
  bottom: '50%',
  right: '32px',
  left: 'unset',
  time: '0.5s',
  mixColor: '#fff',
  backgroundColor: '#fff',
  buttonColorDark: '#100f2c',
  buttonColorLight: '#fff',
  saveInCookies: true,
  label: '明暗',
  autoMatchOsTheme: true
}
const darkmode = new Darkmode(options);
window.darkmode = darkmode;
darkmode.showWidget();
</script>

</body>
</html>
