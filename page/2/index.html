<!DOCTYPE html>
<html lang="zh-CN,en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yihangwe.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。">
<meta property="og:type" content="website">
<meta property="og:title" content="EthanWeee">
<meta property="og:url" content="https://yihangwe.github.io/page/2/index.html">
<meta property="og:site_name" content="EthanWeee">
<meta property="og:description" content="聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Yihang Wei">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://yihangwe.github.io/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>EthanWeee</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start --><script>(function() {function calculateHeight(element) {let height = 0;const items = element.children;for (let i = 0; i < items.length; i++) {height += items[i].offsetHeight || 25;const child = items[i].querySelector(".nav-child");if (child && child.style.display !== "none") {height += calculateHeight(child);}}return height;}function generateToc(lang, container) {const content = document.getElementById(lang + "-content");if (!content) return;const headers = Array.from(content.querySelectorAll("h1, h2, h3, h4, h5, h6"));if (headers.length === 0) return;const ol = document.createElement("ol");ol.className = "nav";let currentLevel = 1;let currentOl = ol;let stack = [ol];let counters = [0, 0, 0, 0, 0, 0];headers.forEach((header, index) => {const level = parseInt(header.tagName[1]);counters[level - 1]++;for (let i = level; i < 6; i++) counters[i] = 0;const li = document.createElement("li");li.className = "nav-item nav-level-" + level;if (level === 1 && index === 0) {li.classList.add("active", "active-current");}const link = document.createElement("a");link.className = "nav-link";if (level === 1 && index === 0) link.classList.add("active");link.href = "#" + header.id;const numSpan = document.createElement("span");numSpan.className = "nav-number";numSpan.textContent = counters.slice(0, level).filter(n => n > 0).join(".");const textSpan = document.createElement("span");textSpan.className = "nav-text";textSpan.textContent = header.textContent;link.appendChild(numSpan);link.appendChild(document.createTextNode(" "));link.appendChild(textSpan);li.appendChild(link);if (level > currentLevel) {const newOl = document.createElement("ol");newOl.className = "nav-child";if (currentLevel === 1) {newOl.style.display = "block";stack[currentLevel - 1].lastElementChild.classList.add("active");}stack[currentLevel - 1].lastElementChild.appendChild(newOl);stack[level - 1] = newOl;currentOl = newOl;} else if (level < currentLevel) {currentOl = stack[level - 1];}currentOl.appendChild(li);currentLevel = level;});container.appendChild(ol);setTimeout(() => {const navHeight = calculateHeight(ol);ol.style.setProperty("--height", navHeight + "px");const navChilds = ol.getElementsByClassName("nav-child");Array.from(navChilds).forEach(child => {if (child.style.display === "block") {const childHeight = calculateHeight(child);child.style.setProperty("--height", childHeight + "px");}});}, 0);return ol;}function updateActiveHeading() {const activeLang = document.getElementById("en-content").style.display === "block" ? "en" : "zh";const content = document.getElementById(activeLang + "-content");const toc = document.getElementById(activeLang + "-toc");if (!content || !toc) return;const headers = Array.from(content.querySelectorAll("h1, h2, h3, h4, h5, h6"));const scrollPos = window.scrollY + window.innerHeight / 3;let activeHeader = null;for (let i = headers.length - 1; i >= 0; i--) {const header = headers[i];const headerTop = header.getBoundingClientRect().top + window.scrollY;if (headerTop <= scrollPos) {activeHeader = header;break;}}const links = toc.getElementsByClassName("nav-link");Array.from(links).forEach(link => {link.classList.remove("active");const parentLi = link.parentElement;if (parentLi) {parentLi.classList.remove("active", "active-current");}});if (activeHeader) {const activeLink = toc.querySelector(`a[href="#${activeHeader.id}"]`);if (activeLink) {activeLink.classList.add("active");let parent = activeLink.parentElement;while (parent && parent.classList) {if (parent.classList.contains("nav-item")) {parent.classList.add("active");if (parent.classList.contains("nav-level-1")) {parent.classList.add("active-current");}}parent = parent.parentElement;}}}}function initTippy() {document.querySelectorAll(".refplus-num").forEach((ref) => {if (ref._tippy) {ref._tippy.destroy();}let refid = ref.firstChild.href.replace(location.origin+location.pathname,"");let refel = document.querySelector(refid);if (!refel) return;let refnum = refel.dataset.num;let ref_content = refel.innerText.replace(`[${refnum}]`,"");tippy(ref, {content: ref_content,});});}function initToc() {const originalToc = document.querySelector(".post-toc-wrap");if (!originalToc || !document.getElementById("langToggle")) return;const tocContainer = document.createElement("div");tocContainer.className = "post-toc-wrap sidebar-panel sidebar-panel-active";const enToc = document.createElement("div");enToc.id = "en-toc";enToc.className = "post-toc motion-element";enToc.style.display = "block";const zhToc = document.createElement("div");zhToc.id = "zh-toc";zhToc.className = "post-toc motion-element";zhToc.style.display = "none";generateToc("en", enToc);generateToc("zh", zhToc);tocContainer.appendChild(enToc);tocContainer.appendChild(zhToc);originalToc.parentNode.replaceChild(tocContainer, originalToc);window.addEventListener("scroll", updateActiveHeading);setTimeout(updateActiveHeading, 0);}window.toggleLanguage = function() {const enContent = document.getElementById("en-content");const zhContent = document.getElementById("zh-content");const enToc = document.getElementById("en-toc");const zhToc = document.getElementById("zh-toc");const button = document.getElementById("langToggle");if (!enContent || !zhContent || !enToc || !zhToc || !button) return;const isEnglish = enContent.style.display === "block";enContent.style.display = isEnglish ? "none" : "block";zhContent.style.display = isEnglish ? "block" : "none";enToc.style.display = isEnglish ? "none" : "block";zhToc.style.display = isEnglish ? "block" : "none";button.querySelector(".button-text").textContent = isEnglish ? "Switch to English" : "切换中文";setTimeout(updateActiveHeading, 0);setTimeout(initTippy, 100);};document.addEventListener("DOMContentLoaded", function() {initToc();setTimeout(initTippy, 3000);});})();</script><style>.post-toc { transition: all 0.2s ease-in-out; }.post-toc .nav { padding-left: 0; }.post-toc .nav-child { padding-left: 1em; }.post-toc .nav-item { line-height: 1.8; }.post-toc .nav-link { color: #555; }.post-toc .nav-link:hover { color: #222; }.post-toc .nav-link.active { color: #fc6423; }.post-toc .active > .nav-link { color: #fc6423; }.post-toc .active-current > .nav-link { color: #fc6423; }</style><!-- hexo injector head_end end --><style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">EthanWeee</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN,en">
    <link itemprop="mainEntityOfPage" href="https://yihangwe.github.io/undefined/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/01/25/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Review%20Report%20-%20AnalyticDB%20Real-time%20OLAP%20Database%20System%20at%20Alibaba%20Cloud/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yihang Wei">
      <meta itemprop="description" content="聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EthanWeee">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/undefined/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/01/25/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/Review%20Report%20-%20AnalyticDB%20Real-time%20OLAP%20Database%20System%20at%20Alibaba%20Cloud/" class="post-title-link" itemprop="url">AnalyticDB - 阿里云的实时 OLAP 数据库系统</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-01-25 00:00:00" itemprop="dateCreated datePublished" datetime="2025-01-25T00:00:00-08:00">2025-01-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-06-20 16:52:00" itemprop="dateModified" datetime="2025-06-20T16:52:00-07:00">2025-06-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/" itemprop="url" rel="index"><span itemprop="name">高级数据存储</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>该论文解决了三个问题：</p>
<ol>
<li>如何以低延迟处理用户更复杂多样的查询；</li>
<li>如何设计一种友好且统一的数据布局，使其兼容列式存储和行式存储，能够处理复杂数据类型，并保持低延迟；</li>
<li>如何以低延迟处理每秒海量请求。</li>
</ol>
<p>该论文提出了 5 个创新性想法，并详细阐述了每个想法的实现方法：</p>
<ol>
<li><strong>读写分离：</strong> 工作节点专用于处理读操作或写操作，确保读操作不会干扰写操作。在实时读模式下，引入版本验证机制（<code>最新版本 = max(V₁, V₂)</code>）以保证每次查询都能检索到最新数据。此外，每次写操作完成后，写节点会主动将最新版本拉取到相应的读节点，以避免后续读操作出现高延迟。</li>
<li><strong>混合行列存储：</strong> 用于存储复杂类型数据。一个明细文件 (detail file) 由 <code>n</code> 个行组 (row group) 组成；一个行组由 <code>k</code> 个数据块组成；一个数据块由 <code>p</code> 个 FBlock 组成；一个 FBlock 存储一个或多个行的部分行中某一列的 <code>x</code> 个值。</li>
<li><strong>高效索引管理：</strong> 包括对基线数据和增量数据的索引构建与维护。对于基线数据，AnalyticDB 构建倒排索引并引入过滤比 (filter ratio) 来优化读操作。对于增量数据，AnalyticDB 在读节点上构建轻量级的排序索引，以加速在完成该类型数据的倒排索引异步构建之前的读操作。</li>
<li><strong>优化器：</strong> AnalyticDB 引入了 STARs 框架来同时评估存储能力和关系代数能力，并采用动态规划技术，以实现高效的谓词下推 (predicate push-down)。该数据库最小化了联接下推 (join push-down) 所需的表重排 (shuffling) 成本。对于基于索引的联接和聚合，它采用左深树 (LeftDeepTree) 来高效利用全列索引 (index-on-all-columns)，同时下推谓词和聚合操作。此外，优化器和执行引擎采用基于采样的基数估计 (cardinality estimation)，辅以缓存先前采样结果、优化的采样算法和改进的派生基数 (derived cardinality)。</li>
<li><strong>执行引擎：</strong> 能够直接在序列化的二进制数据上操作，而非 Java 对象，从而消除了在大数据重排过程中序列化和反序列化的高昂开销。</li>
</ol>
<p><strong>分析与实验结果：</strong> 在 1TB 数据集上，AnalyticDB 的性能优于 PrestoDB、Druid、Spark SQL 和 Greenplum，并且在扩展到 10TB 数据集时，其性能未受到显著影响。随着写节点数量的增加，AnalyticDB 的写入吞吐量呈现稳定增长。在 TPC-H 基准测试中，AnalyticDB 在 22 个查询中的 20 个上，其完成时间仅为次快数据库所需时间的一半。然而，对于查询 2，由于选择了不同的联接顺序，AnalyticDB 的速度慢于 PrestoDB 和 Greenplum。</p>
<h1 id="论文优势"><a href="#论文优势" class="headerlink" title="论文优势"></a>论文优势</h1><ul>
<li>论文中概述的 3 项挑战精准地指向了 OLAP 系统在实现实时高效响应时所面临的关键障碍。解决这些挑战不仅能显著提升数据库对多样化查询和复杂数据类型的兼容性，还能改善其在生产环境中的响应能力，突显了其高度的研究价值。读写分离与版本验证的结合确保了读写操作的隔离性，同时始终为读查询提供最新数据。混合数据布局和索引的设计融入了对 JSON、全文和向量数据等复杂数据类型的支持，为多样化的数据操作提供了统一的访问接口。这极大地拓宽了 AnalyticDB 在更广泛用例中的适用性。此外，执行引擎将基于采样的基数估计与缓存、优化的采样算法等技术相结合，以低开销和最小延迟实现了高精度的估计。总而言之，AnalyticDB 引入的改进和优化方案代表了在增强 OLAP 系统数据多样性和实时响应能力方面迈出的重要一步，其综合性解决方案将在高并发电商场景中充分展现其能力。</li>
<li>论文提供了全面的文献综述。第 2 节 Related Work 讨论了不同数据库的不足。例如，OLTP 数据库中昂贵的索引更新会降低吞吐量并增加延迟；而 OLAP 数据库（如 TeradataDB 和 Greenplum）中的列式存储会导致点查 (point-lookup) 查询产生高昂的随机 I&#x2F;O 成本。上述问题在 AnalyticDB 中得到了有效解决。此外，论文还概述了 AnalyticDB 相较于 Amazon Redshift 的改进，以及与 Google BigQuery 在查询和聚合方面的差异。</li>
<li>论文详细描述了 AnalyticDB 中各项功能的过程，包括：<ol>
<li>从读和写两个角度对读写分离过程进行了透彻的解释，并附有流程图专门说明更复杂的读操作。</li>
<li>查询执行 (Query Execution) 涉及的 3 个算法的关键指令的伪代码和注释。</li>
<li>将基线数据与增量数据合并过程分解为 3 个阶段的示意图。</li>
</ol>
</li>
</ul>
<h1 id="论文不足"><a href="#论文不足" class="headerlink" title="论文不足"></a>论文不足</h1><ul>
<li>论文中对某些功能的描述不够完整。在论文第 3.4 节 Read&#x2F;Write Decoupling 中，仅提到了实时读 (real-time read)，而遗漏了有限延迟读 (bounded-staleness read)。对于 OLAP 而言，读取过时数据是可以接受的，有限延迟读允许读节点在写操作完成后的特定延迟之后才访问写节点上的最新数据，因此它在一定程度上确保了 AnalyticDB 的快速响应。然而，论文中并未解释这种读取模式。</li>
<li>论文对某些新引入概念的描述不够清晰。在第 5.1.1 节中，关于谓词下推的讨论仅对 STARs 框架做了简要概述，没有解释它如何应用关系代数、如何进行成本计算，以及优化器如何使用动态规划来封装关系代数运算符。这些遗漏可能会让读者感到困惑。</li>
<li>论文中的性能评估实验相对简单。首先，仅测试了 3 条 SQL 语句，覆盖的查询类型范围狭窄，且仅针对特定的表分区策略、特定的表和字段以及特定的数据类型。测试并未涉及如 JSON 等复杂数据类型。其次，实验仅测试了 1TB 和 10TB 的数据集。然而，在生产环境中，每日新增数据量可达数十甚至数百 PB。在双 11 或 618 等高峰促销日，每日数据处理量可达数百甚至数千 PB。例如，在 2022 年双 11 期间，淘宝和天猫的订单支付峰值达到每秒 583,000 笔。因此，实验所用的数据集远远不足以反映真实场景的规模。第三，基于 TPC-H 基准的测试仅评估了 22 个查询，不足以全面反映这 5 个数据库的真实性能。因此，建议纳入生产环境中涉及的所有数据和查询，例如 MySQL binlog、ElasticSearch 索引日志和 Kafka 日志等，并在这 5 个数据库上开展为期一周或更长时间的稳定性测试，以提供更真实的评估。</li>
</ul>
<p>参考文献：<a target="_blank" rel="noopener" href="https://www.vldb.org/pvldb/vol12/p2059-zhan.pdf">https://www.vldb.org/pvldb/vol12/p2059-zhan.pdf</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN,en">
    <link itemprop="mainEntityOfPage" href="https://yihangwe.github.io/undefined/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/01/20/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/OLAP%20%E7%B4%A2%E5%BC%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yihang Wei">
      <meta itemprop="description" content="聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EthanWeee">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/undefined/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/01/20/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/OLAP%20%E7%B4%A2%E5%BC%95/" class="post-title-link" itemprop="url">OLAP 索引</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-01-20 00:00:00" itemprop="dateCreated datePublished" datetime="2025-01-20T00:00:00-08:00">2025-01-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-06-06 21:47:43" itemprop="dateModified" datetime="2025-06-06T21:47:43-07:00">2025-06-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/" itemprop="url" rel="index"><span itemprop="name">高级数据存储</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Data-Skipping"><a href="#Data-Skipping" class="headerlink" title="Data Skipping"></a>Data Skipping</h1><p>我们可以利用辅助数据结构标识表中哪些部分可以跳过扫描，避免对每一行（tuple）都做判断。</p>
<p><strong>OLAP 场景下为什么要用 Data Skipping？</strong></p>
<p>在 OLAP 场景中，查询往往是扫描大量历史数据，筛选满足某种复杂条件的子集，典型例子如数据仓库的多维分析、报表查询等。此时：</p>
<ol>
<li><strong>表非常大</strong>：可能有数十亿、上百亿行，逐行检查每个行是否满足条件，代价非常高。</li>
<li><strong>查询通常按若干列做过滤</strong>：比如 <code>WHERE 年份 = 2024 AND 地区 = &#39;北京&#39;</code>，而且常常只要少量数据就够了（高选择性场景）。</li>
<li><strong>批量扫描 vs. 随机读取</strong>：读整个表，会触发大量 I&#x2F;O；如果能一眼就知道哪些数据页根本不用读，就能省下大量 I&#x2F;O 时间。</li>
</ol>
<p>因此，Data Skipping 的核心思路，就是通过在数据块或分区级别维护一些<strong>辅助信息</strong>，让查询在执行过滤时能够判断“某个数据块（比如一个文件区块、一个数据页、一个段&#x2F;partition）肯定不包含满足过滤条件的行，就直接跳过，不去读取和解析该块中的每一行”，从而大幅减少 I&#x2F;O，以及后续的行级计算。</p>
<p>常见的 Data Skipping 技术主要有以下几类：</p>
<ol>
<li><strong>Zone Map &#x2F; Min-Max 索引</strong><ul>
<li>每个数据块（block 或 segment）存一对最小值和最大值，例如按时间分块后，记录该块中时间列的 [min_timestamp, max_timestamp]。</li>
<li>查询时，如果查询条件为 <code>timestamp BETWEEN &#39;2024-01-01&#39; AND &#39;2024-03-01&#39;</code>，当某个块的最大时间都早于 ‘2024-01-01’，或者最小时间都晚于 ‘2024-03-01’，就可以完全跳过该块。</li>
<li>优点：实现简单、维护开销低；适用于列值分布相对平缓的场景。</li>
<li>缺点：如果一个块里 min–max 范围很宽（分布倾斜或块太大），就容易出现“区间重叠”，跳不过去，效率下降。</li>
</ul>
</li>
<li><strong>位图索引（Bitmap Index）</strong><ul>
<li>针对低基数的列（如性别、地区、状态等），为每个可能的离散取值维护一个位图（bitset）。</li>
<li>每个数据块也可以维护该位图的摘要（比如每 N 行分一个小位图），查询时快速根据位图判断该数据段中是否存在某个值，若不存在就跳过。</li>
<li>优点：在基数较低、数据倾斜度不高时，效果很好；位图操作位运算开销低。</li>
<li>缺点：对于高基数列，位图会很大，且维护成本高。</li>
</ul>
</li>
<li><strong>布隆过滤器（Bloom Filter）</strong><ul>
<li>保存每个数据页中的列值集合的 Bloom Filter，当查询时先检查 Bloom Filter 是否可能包含该值，若 Bloom Filter 结果为不可能存在，则跳过整个页。</li>
<li>优点：Bloom Filter 占用空间小，查询时布尔判断开销低。</li>
<li>缺点：存在误报率（false-positive），即有时候 Bloom Filter 误判可能存在，需要再回退到读页；但绝不会误判真正存在而跳过，保证正确性。</li>
</ul>
</li>
<li><strong>Skip List／Skip Table 结构</strong><ul>
<li>某些列可以对数据块按值范围做多级跳跃索引，比如最外层根据范围将整个表划分为若干区域，里层再分页索引。</li>
<li>OLAP 引擎（如 Apache Parquet、ORC）通常在文件格式层面（列存格式）会同时维护多层次的自底向上的统计信息（Statistics）。</li>
<li>Query Planner 就会根据统计信息决定哪些 Row Group（行组）或 Stride（步长）可以跳过。</li>
</ul>
</li>
<li><strong>分区表（Partitioning）</strong><ul>
<li>将大表水平拆分成多个分区（按时间、地区、业务线等），在查询时如果过滤条件里包含分区键（如 date），可以直接分区剪裁，跳过不相关分区。</li>
<li>其实分区本质也是一种粗粒度的 Data Skipping，跳过整个分区文件。</li>
</ul>
</li>
</ol>
<p><strong>设计 Data Skipping 时的关键考虑点</strong></p>
<p><strong>1. 谓词选择性</strong></p>
<ul>
<li><p><strong>低选择性场景</strong></p>
<p>比如查询 <code>WHERE gender = &#39;M&#39;</code>，如果全表大约一半行都是 <code>gender=&#39;M&#39;</code>，则满足谓词的行很多，跳过就算跳掉了另一半行，也意味着还要扫描一半行，节省有限。</p>
</li>
<li><p><strong>高选择性场景</strong></p>
<p>比如查询 <code>WHERE customer_id = 123456789</code>，或 <code>WHERE event_date = &#39;2025-06-01&#39; AND region = &#39;北京&#39;</code>，只会有极少量行符合条件。此时如果辅助结构能识别掉绝大多数数据块，就能极大节省 I&#x2F;O。</p>
</li>
</ul>
<p><strong>2. 列值分布</strong></p>
<ul>
<li>如果某列的值高度偏斜，例如某个列绝大多数行都是同一个值，其余值极少，Zone Map 或基于统计的跳过就不太准。<ul>
<li>举例：某列几乎全是 ‘A’，只有很少行是 ‘B’，若文件切分并不按照该列聚簇，那么即便大多数块里都是 ‘A’，但每块的最小值&#x2F;最大值同样会显示为 ‘A’，所有块看起来都可能包含 ‘B’，无法跳过。</li>
</ul>
</li>
<li>因此，一般会结合<strong>物理排序（clustering）或分桶（bucketing）</strong>：<ul>
<li>在生成文件时先按该列做排序&#x2F;分桶，这样相同值会被写到同一数据块里；</li>
<li>有了同一数据块里只有一个值的特性，块级统计就变得非常有效。</li>
</ul>
</li>
</ul>
<h1 id="Bitmap-Indexes"><a href="#Bitmap-Indexes" class="headerlink" title="Bitmap Indexes"></a>Bitmap Indexes</h1><p><strong>位图索引</strong>为某个属性（列）的每个不同取值，都存储一份单独的位图，位图中的第 <em>i</em> 位对应了表中第 <em>i</em> 条记录。</p>
<p>对于下表的原始数据：</p>
<table>
<thead>
<tr>
<th>order_id</th>
<th>paid</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>Y</td>
</tr>
<tr>
<td>2</td>
<td>Y</td>
</tr>
<tr>
<td>3</td>
<td>Y</td>
</tr>
<tr>
<td>4</td>
<td>N</td>
</tr>
</tbody></table>
<p>压缩后的数据如下：</p>
<table>
  <thead>
    <tr>
      <th>order_id</th>
      <th colspan="2">paid</th>
    </tr>
    <tr>
      <td></td>
      <td>Y</td>
      <td>N</td>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>

<p>对于多列多值的组合过滤，Bitmap 索引支持高效的按位与（AND）、或（OR）、非（NOT）等位运算。</p>
<p>如果把整个表的行数记为 <em>N</em>，那么一个属性值对应的位图长度就是 <em>N</em> 位。当表非常大（数千万、上亿行），单张位图也会变得很大。为避免一次性分配庞大、连续的内存块，常见做法是分段（segment&#x2F;chunk）：把总行数 <em>N</em> 划分成若干个固定大小的块（例如每块 1 百万行），那么位图也相应地分成若干个子段，每个子段只需要维护该区间内的位。查询时只需要扫描与目标区间重叠的位段。</p>
<p>思考：</p>
<p>为什么使用 Bitmap？</p>
<ol>
<li><p><strong>空间利用率较高</strong></p>
<p>位图本质上是一个位数组，对于低基数或中等基数的列，位图能精确记录行与属性值的映射，且只需 1 位&#x2F;行。</p>
</li>
<li><p><strong>位运算速度快，适合多条件混合过滤</strong></p>
<p>多列过滤条件时，只要获取每个条件对应的位图，对它们做位与&#x2F;或&#x2F;非等操作，就能快速算出满足所有条件的行集合。</p>
</li>
</ol>
<p>为什么位图索引适合压缩？</p>
<ul>
<li>如果某个取值非常稀疏地分布在整个表中，那么位图中绝大多数位都是 0，只有少数位置是 1。或者，若有些连续行都满足该取值，又会出现连续的 1 序列。利用这种长串 0 或长串 1 可用<strong>压缩算法</strong>（如 Run-Length Encoding、WAH、Roaring Bitmap 等）进一步缩小存储空间。</li>
<li>现代 OLAP 引擎（例如 Apache Druid、ClickHouse、Presto 等）在底层都会选择一些成熟的压缩位图实现，这些实现不仅压缩率高，而且能够在压缩态下做位运算，避免了每次查询都需要先把整个位图解压到内存。</li>
</ul>
<h1 id="常见的四种编码技术"><a href="#常见的四种编码技术" class="headerlink" title="常见的四种编码技术"></a>常见的四种编码技术</h1><p>位图索引常见的四种编码技术：等值编码（Equality Encoding）、区间编码（Range Encoding）、分层编码（Hierarchical Encoding）和位切片编码（Bit-sliced Encoding）。</p>
<ol>
<li><p><strong>等值编码</strong></p>
<p>为某一列（属性）中的每个<strong>唯一取值</strong>都维护一份独立的位图。也就是说，如果该列有 m 个不同取值，则总共有 m 个位图，每份位图长度为表的总行数 N。这种编码形式上类似 One-Hot 独热编码。具体示例可参考之前的两张表。</p>
<p>优点：直观简单并且等值查询高效。</p>
<p>缺点：占用大量空间。</p>
</li>
<li><p><strong>区间编码</strong></p>
<p>与等值编码不同，不为每个<strong>单一取值</strong>都建一份位图，而是按照若干有意义的区间（interval）来划分，每个区间对应一份位图。</p>
<p>举例：以一个数值列 age 为例，表中 age 范围在 0–100 岁之间，可以把区间划分为 [0–17]、[18–30]、[31–50]、[51–70]、[71–100]。</p>
<p>为每个区间建一份位图：</p>
<ul>
<li>Bitmap_0_17：标记哪些行的 age 落在 0–17 之间；</li>
<li>Bitmap_18_30：标记哪些行的 age 落在 18–30 之间；</li>
<li>以此类推。</li>
</ul>
<p>优点：适合范围查询并且比等值编码更节省空间。</p>
<p>缺点：区间的粒度需要权衡。划分的区间越细，能更精准地匹配查询，但要维护的位图份数越多；划分区间越粗，则位图份数越少，但位图对应的行集合范围更大，查询时跳过的效率会下降。</p>
</li>
<li><p><strong>分层编码</strong></p>
<p>通过构建<strong>树形层次结构</strong>（hierarchy），在不同层级对值或值范围做<strong>分段统计&#x2F;位图标识</strong>，用于快速识别那些整个子树&#x2F;子范围内没有数据的情况。</p>
<p>通常从较粗的范围到较细的范围构建多层位图：</p>
<ol>
<li>第一层（根层）：记录整个列的全部可能值范围，并标注哪些子范围是非空（或者空）。</li>
<li>第二层：把根层范围继续细分为若干更小区间，分别维护各自的标识。</li>
<li>依次向下，直到最底层是单个取值或某个可接受的最小分区。</li>
</ol>
<p>以一列 zipcode（邮政编码）为例，取值范围是 00000–99999，总计 100,000 个可能值。如果直接对每个具体的 5 位数字都建一份位图，太耗空间。改用分层编码：</p>
<ol>
<li><strong>第一层</strong>：只看邮编的第一位，共 10 种可能（0、1、2、…、9），<ul>
<li>构建 10 个顶层位图，分别标记表中哪些行的 zipcode 第一位是 0、哪些行的第一位是 1，以此类推。</li>
</ul>
</li>
<li><strong>第二层</strong>：假设在第一层为前缀 &#x3D; 3（假设查询潜在目标值的前缀为 3）的情况下，第二层把 zipcode 的前两位 30 ～ 39 这 10 个前缀，各自再建位图；</li>
<li><strong>第三层</strong>：再细分为 300 ～ 309 等前缀，递归向下，直到精确到具体 5 位。</li>
</ol>
<p>优点：快速剪裁空范围且适用于高基数&#x2F;稀疏分布的列。</p>
<p>缺点：存储与维护复杂度更高。需要为每层维护对应的位图，并保持各层之间的一致性。</p>
</li>
<li><p><strong>位切片编码</strong></p>
<p>不是将每个取值或每个区间映射到一份位图，而是针对某个<strong>数值列的二进制表示</strong>，维护<strong>按位的位置拆分的一组位图</strong>。</p>
<p>假设有一个 8 位的整数列，如下：</p>
<table>
<thead>
<tr>
<th><strong>行号</strong></th>
<th>value（原始值）</th>
<th><strong>value（二进制）</strong></th>
<th><strong>Bit_0</strong></th>
<th><strong>Bit_1</strong></th>
<th><strong>Bit_2</strong></th>
<th><strong>Bit_3</strong></th>
<th><strong>Bit_4</strong></th>
<th><strong>Bit_5</strong></th>
<th><strong>Bit_6</strong></th>
<th><strong>Bit_7</strong></th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>5</td>
<td>00000101</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>2</td>
<td>18</td>
<td>00010010</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>3</td>
<td>7</td>
<td>00000111</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>4</td>
<td>25</td>
<td>00011001</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
</tbody></table>
<p>上表中，Bit_0 代表的是最低位，Bit_7 代表最高位。</p>
<p>位切片编码中，如果要基于上表中的数据进行如下条件过滤：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> tbl <span class="keyword">WHERE</span> <span class="keyword">value</span> <span class="operator">&gt;</span> <span class="number">17</span>;</span><br></pre></td></tr></table></figure>

<p>我们先将 17 转换成二进制：10001，并在位切片编码过的位图索引中搜索并过滤：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">10100000</span><br><span class="line">01001000</span><br><span class="line">11100000</span><br><span class="line">10011000</span><br><span class="line">--------</span><br><span class="line">10001000 # 17</span><br></pre></td></tr></table></figure>

<p>我们先找出 17 的最高位是 Bit_4，并得出表中 4 行的这一位以及更高位中只有第 2 和第 4 行是和 17 至少一样大，因此可以快速过滤掉第 1 和第 3 行。</p>
<p>优点：</p>
<ol>
<li><strong>支持任意数值比较</strong>：当需要执行 WHERE value &gt; K 或 WHERE value BETWEEN L AND R 之类的数值比较时，只需根据 K、L、R 的二进制表现，结合多份 Bit_j 位图做<strong>布尔代数运算</strong>（AND、OR、NOT），就能快速构造出满足条件的行号位图。</li>
<li><strong>对高基数数值列尤为合适</strong>：与等值编码相比，高基数字段如果直接为每个取值建位图会产生海量位图；而位切片只需按二进制位宽度建 B 份位图，无论具体取值基数多大，都只需 B 份（例如 32 或 64）位图。</li>
</ol>
<p>缺点：</p>
<ol>
<li><strong>查询时位运算代价较大</strong>：与简单的等值位图（只要读取并返回一份位图）、区间位图（只要读取一份或几份位图）相比，位切片编码在做数值比较或范围查询时，需要对多份位图做组合运算（AND&#x2F;OR&#x2F;NOT），逻辑比较稍复杂，CPU 开销更高。但<strong>总体仍比全表扫描或传统 B+ 树索引的多次随机 I&#x2F;O 要高效得多</strong>，尤其在 OLAP 大规模并行计算场景下，位运算的吞吐量很大。</li>
</ol>
</li>
</ol>
<h1 id="BitWeaving"><a href="#BitWeaving" class="headerlink" title="BitWeaving"></a>BitWeaving</h1><p>BitWeaving 项目由威斯康星大学 Quickstep 团队提出和实现，旨在在主内存分析型 DBMS 中以“裸机”速度运行全表扫描操作  。</p>
<p>它利用处理器的位级并行性，将来自多个元组和列的位在单个时钟周期内同时处理，从而将每列的扫描周期降低到低于 1 个周期的级别 。</p>
<p>为支持复杂谓词评估，BitWeaving 提出了算术框架，将列值编码转换为适合位操作的格式，并生成结果位向量，用于后续布尔组合运算 。</p>
<p><strong>与传统列式存储的比较</strong></p>
<ul>
<li><strong>传统列式存储</strong>：将压缩后或原始列值按值连续存储，为了适配 SIMD 指令集，通常需要将每个值填充到固定边界（如 32 位、64 位），这会造成大量空间浪费，并增加对齐开销 。</li>
<li><strong>SIMD 扫描</strong>：将多个字典编码值打包到 SIMD 寄存器槽中，利用向量指令并行比较，但依然存在填充浪费和对齐处理两个瓶颈 。</li>
<li><strong>BitWeaving&#x2F;V</strong>：将每个列值的同一比特位聚集存储，实现完整利用字宽，且通过“早期剪枝”可在满足或不满足条件时跳过后续比特的处理，极大减少处理位数和内存带宽 。</li>
<li><strong>BitWeaving&#x2F;H</strong>：将编码后的整值按交错方式存储，并在每个值中预留一位结果标记，既可支持快速位级扫描，也可在需要完整重构列值时一次性提取，兼顾扫描和输出需求 。</li>
</ul>
<p>BitWeaving 包括两种主要存储布局：</p>
<ul>
<li><strong>BitWeaving&#x2F;Vertical</strong>：按位平面（bit-plane）垂直存储，每个比特位平面连续排列，天然支持按位剪枝；</li>
<li><strong>BitWeaving&#x2F;Horizontal</strong>：按元组水平交错存储，附加一位用于记录谓词结果，便于整值提取和多阶段谓词级联</li>
</ul>
<p>以下详细说明 Horizontal 和 Vertical Storage。</p>
<h2 id="Horizontal-storage"><a href="#Horizontal-storage" class="headerlink" title="Horizontal storage"></a>Horizontal storage</h2><p>把每条记录的全部 k 位 code 串成一块，按记录依次存放。</p>
<p>在内存中，一个 SIMD 寄存器会同时装入多条记录的全部位，对这些记录做并行比较。</p>
<p>我们以某个整数类型的字段为例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Segment#1:</span><br><span class="line">t0: bits=[0, 0, 1] -&gt; 1</span><br><span class="line">t1: bits=[1, 0, 1] -&gt; 5</span><br><span class="line">t2: bits=[1, 1, 0] -&gt; 6</span><br><span class="line">t3: bits=[0, 0, 1] -&gt; 1</span><br><span class="line">t4: bits=[1, 1, 0] -&gt; 6</span><br><span class="line">t5: bits=[1, 0, 0] -&gt; 4</span><br><span class="line">t6: bits=[0, 0, 0] -&gt; 0</span><br><span class="line">t7: bits=[1, 1, 1] -&gt; 7</span><br><span class="line"></span><br><span class="line">Segment#2:</span><br><span class="line">t8: bits=[1, 0, 0] -&gt; 4</span><br><span class="line">t9: bits=[0, 1, 1] -&gt; 3</span><br></pre></td></tr></table></figure>

<p>以上内容中，t0 到 t9 为行号，bits 为该字段的二进制表示，箭头右边的是原始数据。全部的数据被分成了多个段。</p>
<p>假设一个处理器 word 只能容纳 8 个 bit 用于并行处理，那么以上代码块中的内容会被表示为如下结构：</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_bitweaving_h.drawio.png" alt="img"></p>
<blockquote>
<p>[!NOTE]</p>
<p><strong>Word</strong> 是处理器一次能够自然处理的固定长度数据单元，其长度称为<strong>字长</strong>（word length 或 word size），通常是处理器数据总线宽度的整数倍或分数。字长决定了CPU在单次操作中能读取、写入或传输的数据量，同时影响指令长度、寄存器宽度、寻址能力等关键特性。</p>
</blockquote>
<p>如果要处理如下 SQL 指令：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> tbl <span class="keyword">WHERE</span> val <span class="operator">&lt;</span> <span class="number">5</span>;</span><br></pre></td></tr></table></figure>

<p>那么会进行如下 SIMD 计算（以 t0 和 t4 为例）：</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_bitweaving_h_cal.drawio.png" alt="img"></p>
<p>最终，分割符为 1 的就是符合条件的数据。</p>
<p>但是之后我们需要如何汇总所有的过滤结果来确定要获取哪些数据呢？</p>
<p>我们可以通过 shift 操作输出所有的过滤结果到一个 bitmap 中，这个 bitmap 的每一位对应表中数据的行号。我们以 Segment#1 为例给出汇总过程：</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_bitweaving_h_bitmap.drawio.png" alt="img"></p>
<p>上图中的位图也被称为 selection vector。</p>
<p>现在我们汇总得到了哪些数据符合条件以及哪些不符合，那要如何转成实际的下标或者是偏移量呢？</p>
<p>有两种常见的方法：</p>
<ol>
<li><p>迭代扫描</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">List&lt;Integer&gt; sel = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; N; i++) &#123;</span><br><span class="line">  <span class="keyword">if</span> (selectionVector[i] == <span class="number">1</span>) &#123;</span><br><span class="line">    sel.add(i);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>优点</strong>：实现简单，不需要预处理。</p>
<p><strong>缺点</strong>：每次都要检查 N 位，分支预测失效会有开销；对于高选择率或低选择率都要遍历全阵列。</p>
</li>
<li><p>预计算位置表</p>
<p>把 selection vector（这里是 8 位）转换成十进制数据作为表的 key，而下标数组作为 payload。</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_bitweaving_h_pre_tbl.drawio.png" alt="img"></p>
<p><strong>优点</strong>：避免了每个位的分支判断，大大提高吞吐；字节级批量处理，利用了查表的连续读缓存。</p>
<p><strong>缺点</strong>：需要额外的 256 条查表开销，及存储这些小列表。</p>
</li>
</ol>
<h2 id="Vertical-storage"><a href="#Vertical-storage" class="headerlink" title="Vertical storage"></a>Vertical storage</h2><p>把所有记录在同一位位置 i 上的 bit 聚到一起，形成一条长长的位向量，然后依次存放各个位向量（从最低位到最高位）。</p>
<p>在内存中，一个 SIMD 寄存器会拿到同一位向量的一大段数据，一次性对所有记录的该位进行逻辑运算。</p>
<p>还是用之前的例子，数据如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Segment#1:</span><br><span class="line">t0: bits=[0, 0, 1] -&gt; 1</span><br><span class="line">t1: bits=[1, 0, 1] -&gt; 5</span><br><span class="line">t2: bits=[1, 1, 0] -&gt; 6</span><br><span class="line">t3: bits=[0, 0, 1] -&gt; 1</span><br><span class="line">t4: bits=[1, 1, 0] -&gt; 6</span><br><span class="line">t5: bits=[1, 0, 0] -&gt; 4</span><br><span class="line">t6: bits=[0, 0, 0] -&gt; 0</span><br><span class="line">t7: bits=[1, 1, 1] -&gt; 7</span><br><span class="line"></span><br><span class="line">Segment#2:</span><br><span class="line">t8: bits=[1, 0, 0] -&gt; 4</span><br><span class="line">t9: bits=[0, 1, 1] -&gt; 3</span><br></pre></td></tr></table></figure>

<p>在 Vertical Storage 中，以上数据会被表示为以下结构：</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_bitweaving_v.drawio.png" alt="img"></p>
<p>也就是说，同一 segment 的 bits 数组中的同一下标的数据会被放到一个 word 中处理。</p>
<p>如果我们要处理如下命令：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> tbl <span class="keyword">WHERE</span> val <span class="operator">=</span> <span class="number">2</span>;</span><br></pre></td></tr></table></figure>

<p>会进行如下计算：</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_bitweaving_v_cal.drawio.png" alt="img"></p>
<p>这里在处理完 col1 之后，我们观察到结果已经全是 0（即没有任何记录同时满足前两位匹配），就可以 <strong>跳过</strong> 第三轮比较（早剪枝），直接得出最终结果全 0。</p>
<p>优点：</p>
<ul>
<li>极高的查询性能：在 OLAP 场景下，Bit Weaving 能在压缩数据上直接进行位运算（如 AND、OR、XOR 等），极大提升聚合、过滤、排序等操作的速度。</li>
<li>空间效率高：采用位存储和压缩技术，极大节省磁盘和内存空间，同时也减少了 I&#x2F;O 成本。</li>
<li>良好的向量化和 SIMD 支持：在现代 CPU（如 AVX、SSE）下可充分利用 SIMD 指令集，实现高并发、高吞吐量的位级操作。</li>
</ul>
<p>缺点：</p>
<ul>
<li>对点查询不友好：相较于 B+ 树等结构，Bit Weaving 在单点查找或小范围查找时效率较低，主要优势在大范围数据扫描和聚合分析中。</li>
</ul>
<h1 id="近似位图索引"><a href="#近似位图索引" class="headerlink" title="近似位图索引"></a>近似位图索引</h1><p>传统的位图索引对每一个值都精确地维护一个 bitmap，而近似位图索引只保留粗略信息，牺牲部分准确性（即可能出现 false positives，假阳性），以便在常见查询场景下更快速地过滤大部分不匹配的元组。</p>
<p>当位图判断某条记录可能匹配时，还需要回到原始数据进行最后一次精确检查，从而消除 false positives。</p>
<p><strong>两种主流技术</strong></p>
<ul>
<li><p><strong>Column Imprints（列印迹）</strong></p>
<p>将列值按块（如每 64 或 128 个值）划分，对每个块维护一个小位图，位图的每一位对应一个值范围（bucket）。</p>
<p>查询时只需查块级位图，快速过滤掉整个块都不可能包含目标值的部分；再对剩余块逐条扫描。</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_approx_bitmap_col.drawio.png" alt="img"></p>
<p>或者更通用的方式是：</p>
<p>在 Column Imprint 中，每个 0 或 1 表示的是缓存行中的信息。具体来说，每一位表示某个直方图区间是否在对应的缓存行中有数据值：</p>
<ul>
<li><p>如果缓存行中的某些值落入某个区间，则该区间对应的位被设置为 1；</p>
</li>
<li><p>如果缓存行中的数据都不在该区间中，则该区间对应的位为 0。</p>
</li>
</ul>
<p>一个缓存行可以包含多个数据值（例如 64 字节的数据）。Column Imprint 并不记录每个数据值的精确位置，而是粗粒度地表示这些值的分布范围。</p>
<p>同样用之前的例子，假设缓存行中有三个值：1，8，4。</p>
<p>这些值会被映射到直方图的不同区间，例如：值 1 属于区间 [1, 2)；值 8 属于区间 [8, 9)；值 4 属于区间 [4, 5)。</p>
<p>最终的位向量可能是 10010001，其中：第 1 位表示缓存行中有值落入区间 [1, 2)；第 4 位表示缓存行中有值落入区间 [4, 5)；第 8 位表示缓存行中有值落入区间 [8, 9)。</p>
<p>如果之后要查询如 <code>val BETWEEN 4 AND 8</code> → 对应要检查的 bins 为 B₃…B₇ → mask &#x3D; 00011111：</p>
<ul>
<li>位向量 <code>AND mask</code> ≠ 0 → 说明该缓存行<strong>可能</strong>包含符合条件的值 → 需要回表做精确过滤；</li>
<li>位向量 <code>AND mask</code> &#x3D; 0 → 直接跳过整个缓存行。</li>
</ul>
</li>
<li><p><strong>Column Sketches（列摘要&#x2F;草图）</strong></p>
<p>用固定长度码（通常只有几位）替代完整位图。每个记录只存一个小码，表示它属于哪几个预定义区间。</p>
<p>整体流程如下：</p>
<p>首先根据列的值分布，在直方图中将整个值域划分成若干区间。之后为每个区间分配一个固定长度的二进制码，每条记录的 sketch，就是它所属区间的那个短码。</p>
<p>假设原数据为 [13, 191, 56, 92, 81, 140, 231, 172]，那么分布直方图和用于映射区间和 compression map 如下：</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_approx_bitmap_skch_hist.drawio.png" alt="img"></p>
<p>map 中的对应关系代表：小于 60 的数据映射到 00 代码，小于 132 大于 60 的数据映射到 01 代码，以此类推。</p>
<p>因此原数据对应的 sketched column 为：[‘00’, ‘11’, ‘00’, ‘01’, ‘01’, ‘10’, ‘11’, ‘11’]。</p>
<p>此时，如果我们要执行如下命令：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> tbl <span class="keyword">WHERE</span> val <span class="operator">&lt;</span> <span class="number">90</span>;</span><br></pre></td></tr></table></figure>

<p>首先会确定要在区间 [0, 60] 和 (60, 132] 中找数据，接着对于代码为 00 的数据可直接确定为符合条件，对于代码为 01 的数据则要回表查看实际数据是否小于 90。</p>
<p>也就是，对于 [‘00’, ‘11’, ‘00’, ‘01’, ‘01’, ‘10’, ‘11’, ‘11’] 中的 01，我们要查看原数据，分别是 92 和 81，92 &gt; 90，因此排除掉 92，保留 81。</p>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN,en">
    <link itemprop="mainEntityOfPage" href="https://yihangwe.github.io/undefined/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/01/13/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E5%B8%83%E5%B1%80/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yihang Wei">
      <meta itemprop="description" content="聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EthanWeee">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/undefined/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/2025/01/13/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E5%B8%83%E5%B1%80/" class="post-title-link" itemprop="url">数据存储布局</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-01-13 00:00:00" itemprop="dateCreated datePublished" datetime="2025-01-13T00:00:00-08:00">2025-01-13</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-06-02 21:23:35" itemprop="dateModified" datetime="2025-06-02T21:23:35-07:00">2025-06-02</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/" itemprop="url" rel="index"><span itemprop="name">高级数据存储</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>数据存储格式决定了数据如何在物理介质上组织与编码，这直接影响了系统的读写性能与资源使用效率。在大数据环境下，不同的格式会带来显著的 I&#x2F;O 差异，从而影响查询响应时间和吞吐量  。此外，恰当的存储格式有助于提高压缩比，实现更高的数据密度，降低存储成本，并减少网络传输开销 。对于需要长期保留的数据，选择稳定且可持续的格式至关重要，否则会面临文件格式过时与不可读的风险。最后，不同应用场景（如 OLTP 与 OLAP）对读写模式有不同要求，合适的存储格式既能满足高并发事务访问，也能兼顾批量分析查询，实现系统的整体优化。</p>
<p>当前常用的数据存储格式有以下三种：</p>
<ol>
<li><strong>行式存储（Row-oriented Layout）</strong></li>
<li><strong>列式存储（Column-oriented Layout）</strong></li>
<li><strong>混合式存储（Hybrid Layout）</strong></li>
</ol>
<h1 id="行式存储"><a href="#行式存储" class="headerlink" title="行式存储"></a>行式存储</h1><p>行式存储将同一行的所有字段值连续存储在物理介质上，因而非常适合事务型（OLTP）操作，能够快速插入、更新和检索整行数据，同时在点查询时性能较优，因为一次查询往往需要访问同一行数据的多个字段值。</p>
<p>行式存储下，数据库通常需要小页面。因为：</p>
<ol>
<li>磁盘是按照页来读取数据的，无论实际需要一页中的多少数据（哪怕只需要一行数据），都会加载整个页面。这种情况下如果页面较大，数据库就会反复加载无关数据，从而浪费磁盘和内存带宽。</li>
<li>数据库在执行事务的时候会锁住索引中被操作的叶子节点（数据页）来保持一致性，因此如果页面越大，那么被锁住的无关数据也就会越多，从而加剧了锁竞争。</li>
</ol>
<p>比如，我们有一个表 <code>user</code>，内容如下：</p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Age</th>
<th>Address</th>
</tr>
</thead>
<tbody><tr>
<td>Sam</td>
<td>18</td>
<td>Los Angeles</td>
</tr>
<tr>
<td>John</td>
<td>16</td>
<td>London</td>
</tr>
<tr>
<td>Alice</td>
<td>16</td>
<td>New York</td>
</tr>
</tbody></table>
<p>那么行式存储格式如下：</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_row_layout.drawio.png" alt="img"></p>
<p>因此在上图中，我们可以通过页号 + slot 号来确定一个页的位置。</p>
<p>思考：</p>
<ol>
<li><p>上图中为什么 Slots Array 和具体的数据要放在一个页的两端并且从两端向中间增加数据，而不是放在一起呢？</p>
<p>因为系统在插入时并不知道一页能容纳多少条可变长度的记录。把真实数据区从页面尾部往中间分配，就能在新增槽条目（在页面头部扩展）和写数据（在页面尾部收缩）之间形成一个松紧自适应的自由空间。如果数据紧跟在槽数组后面，那么插入时槽数组增长会挤占数据区，就必须把数据整体往后搬移，造成大量的内存（或磁盘页）移动开销。将数据放到页尾之后，每次插入都只在两端各做一小步，不会触及中间已存数据，从而极大降低了插入时的成本。</p>
<p>此外，系统只需要比较槽数组末尾指针和数据区末尾指针是否交错，即可判断该页是否还有足够余量插入新行。</p>
</li>
<li><p>频繁的指针访问（Pointer Access）在这里会引发什么问题？</p>
<ol>
<li><p>Cache Misses（缓存未命中）</p>
<p>指针场景下的实际数据往往在内存中彼此不连续放置，CPU 需要不断跳转到新的地址才能访问下一个数据，这种非顺序的内存访问会导致缓存行频繁未命中。</p>
</li>
<li><p>Memory Indirection（内存间接访问）</p>
<p>当程序想读取一个字段值时，通常先要读取槽数组里保存的偏移量（offset），然后去跳转到真正的物理地址。对于可变长度属性，元组头里还可能保存了再一层次的 pointer（比如 varchars 可能存放在页外溢出页），导致额外一跳。这会触发二次甚至多次的内存访问。</p>
<p>如果该偏移地址对应的缓存行当前不在 L1&#x2F;L2&#x2F;L3 缓存中，就必须从主存加载数据，导致高昂的内存访问延迟（几十到上百纳秒），远高于高速缓存访问延迟（几纳秒）。</p>
</li>
<li><p>Branch Prediction and Speculation Issues（分支预测与推测执行）</p>
<p>如果访问逻辑里要做大量的指针非空检查或可变长度判断，会引入很多条件分支。当 CPU 的分支预测器频繁猜错，就会导致流水线冲刷和重新预测，进一步影响性能。</p>
</li>
<li><p>TLB Misses（TLB 未命中）</p>
<p>大页、小页切换、可变长度数据放在页外时，程序要根据虚拟地址到物理地址多次查表。如果 TLB 不命中，CPU 就要走更慢的页表遍历，也会严重拖慢访问速度。</p>
</li>
</ol>
</li>
</ol>
<p><strong>优点</strong>：</p>
<ul>
<li><p>适合需要访问整条记录（整个元组）的查询。</p>
</li>
<li><p>适合插入、更新和删除操作（OLTP 工作负载）。</p>
</li>
</ul>
<p><strong>缺点</strong>：</p>
<ul>
<li><p>不适合需要访问整列数据（整个列）的查询。</p>
<p>例如，在行式布局下，如果执行</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT <span class="title function_">SUM</span><span class="params">(colA)</span>, AVG(colC)</span><br><span class="line">  FROM xxx</span><br><span class="line">  WHERE colA &gt; <span class="number">1000</span>;</span><br></pre></td></tr></table></figure>

<p>每一行会被遍历两遍，也就是说要为每条记录分别读取 colA 和 colC，重复读取同一条数据，无法做到顺序访问。</p>
</li>
<li><p>不适合大规模扫描和读取（OLAP 工作负载）。</p>
<p>因为数据是散落在每行里的，无法连续读取（非 sequential access），会产生大量指针跳转，开销很高。</p>
</li>
<li><p>不利于压缩节省。</p>
<p>不同列的数据往往混杂在一起，数据类型不一致，压缩效率会下降。</p>
</li>
</ul>
<h1 id="列式存储"><a href="#列式存储" class="headerlink" title="列式存储"></a>列式存储</h1><p>列式存储则将同一列的所有数值放在一起，便于对单列或少量列进行聚合及分析查询，尤其在数据仓库和在线分析处理（OLAP）场景下能够显著减少 I&#x2F;O 开销和提升查询效率。</p>
<p>该布局使得聚合操作变成了顺序读，因此 CPU 会进行预取操作，降低了缓存未命中的情况。并且列式存储布局更适合大页面，因为 OLAP 查询通常会一次性处理整个列的数据，大页面可以将更多的列数据存储在一个连续区域中，从而减少磁盘 I&#x2F;O 次数。同时，列式存储中的数据类型通常是同质化的（比如 Name 列都是 Char 类型的），这使得压缩算法在列式存储中的效果更好。</p>
<p><code>user</code> 表在列式存储下的结构为：</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_col_layout.drawio.png" alt="img"></p>
<p>在列式布局中，不再需要页号 + 槽号来唯一标识一条记录。相应地，我们只要给每列分配一个简单的偏移索引（即行号，从 0 开始到 N−1），就能唯一定位到该列对应行的值。</p>
<p>实际业务中往往会有可变长度字段（如 VARCHAR、TEXT、BLOB）。这时常见的做法是：往往会把这一列中的每一行真正的值存放在一个连续的数据区，而在该列文件中同时保留一个偏移量数组。偏移量数组里的第 i 项记录了第 i 行的数据在数据区里的起始位置和长度。</p>
<p>上图中，紧接在 Header 后面，会放一个 Null Bitmap，并且假设当前列有 M 行（行号从 0 到 M−1），则 Bitmap 通常是 M 位（二进制位），第 i 位为 1 表示第 i 行对应列值为 NULL，为 0 表示不为 NULL。</p>
<p>思考：</p>
<p>这里采用 Null Bitmap 的好处是什么？</p>
<ol>
<li>空值稀疏时，可以节省存储空间，不必给每个空值都分配实际存储字节。</li>
<li>在做向量化扫描时，可以直接跳过 NULL 行，提升 CPU 缓存命中率。</li>
</ol>
<blockquote>
<p>[!NOTE]</p>
<p>对于变长数据，我们还能怎么处理？</p>
<ol>
<li>在实际内容后面追加特殊字符，让每条记录占用的存储空间都达到一个统一的固定大小。但是当全表有成千上万行，其中大部分都比最大长度要短得多时，累积起来的无用填充就会非常庞大，导致磁盘空间和内存的浪费，还会降低 I&#x2F;O 和缓存利用率。</li>
<li>把本来可变字段都映射到某个定长标识上，那么存储时就无需再让每条记录都占用不同的字节数。比如有一个国家名称列，实际内容只有中国&#x2F;美国&#x2F;英国&#x2F;法国&#x2F;德国……这几十个明确的枚举值，那么我们可以先构建一个字典，给每个国家分配一个固定长度的编码（比如 2 字节、4 字节的整数）。在真实数据页里，只存整数编码（定长字段），而把对应的国家名称及其编码关系放在一个独立的字典里（通常在内存或元数据结构中）。如此一来，表里的国家列就变成了一个定长的整数列，检索时再通过字典查回实际名称。</li>
</ol>
</blockquote>
<p><strong>优点</strong>：</p>
<ul>
<li>适合需要访问整列数据的查询（例如聚合查询）。</li>
<li>适合大规模扫描与读取（OLAP 工作负载）。</li>
<li>能实现更紧凑的存储：与各种数据压缩技术天然契合，可显著减少磁盘与内存占用。</li>
<li>更好的局部性与缓存重用：单列数据连续存放，CPU 预取与缓存命中率更高，加快查询处理速度。</li>
</ul>
<p><strong>缺点</strong>：</p>
<ul>
<li>不适合需要访问整条记录的查询：若一次要读回多列，就必须在多个列文件之间来回跳转并重组整个元组，开销较大。</li>
<li>不适合插入、更新和删除操作（OLTP 工作负载）：单条写入会涉及多个列文件的维护与重组，随机 I&#x2F;O 开销较高。</li>
</ul>
<h1 id="混合式存储"><a href="#混合式存储" class="headerlink" title="混合式存储"></a>混合式存储</h1><blockquote>
<p>理论上，纯列式布局对“只扫描一两列”非常高效；但实际 OLAP 查询往往不仅仅要过滤某列，还需要把过滤后的结果组装为“完整行”，甚至会用到其他列或多列联合过滤。</p>
<p>如果直接把所有列彻底拆开，各列之间又没有任何物理地域上的联系，就会让行重建的开销变得十分巨大。</p>
<p><strong>因此，需要一种折中布局：既要保证列连续以获得压缩和大规模顺序扫描的优势，又要让同一行的各列值彼此在磁盘&#x2F;内存中相对接近，好在需要时快速组装回完整元组。</strong></p>
</blockquote>
<p>混合式存储（PAX）融合了行式与列式两者的优点，通过在写入时同时维护行与列两种视图来兼顾高并发点查和批量分析，但会带来额外的存储开销与维护成本，需要根据业务场景权衡选择。</p>
<p>混合存储的核心思想是：水平分区 + 垂直分区。</p>
<p>首先，将整个表的所有行（Row #0、Row #1、…、Row #5）按照一定的行数分成多个行组（Row Group）。在每个行组内部，再进一步将行组里的各列分开存放。也就是说，组内的所有行先把同一列的值放一起，然后再放下一列的值。</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_hybrid_layout.drawio.png" alt="img"></p>
<p>因此混合存储通过这种方式，就在一个页或一个文件片段（segment）内部，既保留了局部行按顺序聚集的信息，也保留了同一列值连续存放的好处。</p>
<h1 id="水平分区"><a href="#水平分区" class="headerlink" title="水平分区"></a>水平分区</h1><p>将原本集中存储在单一服务器或单个存储介质上的数据，按照某种策略拆分成多份，分别放到不同的物理节点或不同的磁盘上。</p>
<p><strong>为什么要这样做？</strong></p>
<ol>
<li><strong>扩展性能</strong>：当数据量或并发请求量超过单台机器的承载能力时，把数据拆分到多台机器能够并行处理，提升吞吐量。</li>
<li><strong>扩展存储容量</strong>：单个磁盘或服务器空间有限，把数据分散到多台机器才能存下更多数据。</li>
<li><strong>可用性&#x2F;容错</strong>：如果某台机器或某个磁盘出现故障，只会影响部分分片的数据，整体系统仍可继续对其它分片提供服务（可结合副本机制进一步提高容灾）。</li>
</ol>
<p>两种分区模式：</p>
<ol>
<li><p>逻辑分区（Logically, Shared Storage）</p>
<p>多个分区虽然在逻辑上被看作是分散的，但底层共用同一个存储介质。换句话说，数据切分为多个逻辑分区，但这些分区的数据仍然落在同一套磁盘或存储系统上。</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_shared_storage.drawio.png" alt="img"></p>
<p>优点：部署相对简单，无需管理多台物理机器；数据仍然集中在一起，备份和维护方便。</p>
<p>缺点：底层物理存储是共享的 I&#x2F;O 总线，如果并发量很大，仍然会遇到单个存储后端的带宽瓶颈；并不能真正摆脱单点故障。</p>
</li>
<li><p>物理分区（Physically, Shared Nothing）</p>
<p>每个分区都完全独占自己的计算与存储资源，真正做到各自为政、不共享存储，也就是典型的 Shared‐Nothing 架构。</p>
<p><img src="/../../images/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/adv_db_shared_nothing.drawio.png" alt="img"></p>
<p>优点：可线性扩展，新增机器即可增加吞吐和存储；不同分区之间互不干扰，故障隔离更好，一个节点挂掉只影响该分区，其他节点仍可正常提供服务。</p>
<p>缺点：架构更复杂，需要维护多台机器，多副本同步、路由与协调也更困难；跨分区的事务和 JOIN 查询会额外复杂且性能成本更高。</p>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN,en">
    <link itemprop="mainEntityOfPage" href="https://yihangwe.github.io/undefined/MySQL/2024/11/26/MySQL/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yihang Wei">
      <meta itemprop="description" content="聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EthanWeee">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/undefined/MySQL/2024/11/26/MySQL/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/" class="post-title-link" itemprop="url">分库分表</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-11-26 00:00:00" itemprop="dateCreated datePublished" datetime="2024-11-26T00:00:00-08:00">2024-11-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-06-22 15:15:35" itemprop="dateModified" datetime="2025-06-22T15:15:35-07:00">2025-06-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MySQL/" itemprop="url" rel="index"><span itemprop="name">MySQL</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>分库分表主要是为了解决单库单表在海量数据和高并发场景下的性能瓶颈：当数据量达到千万级甚至亿级时，单表查询效率和索引更新速度都会明显下降，备份恢复也变得极其缓慢；而在高并发写入时，单实例的 CPU、内存、I&#x2F;O 资源易成为瓶颈，锁竞争也会导致事务阻塞。通过将大表拆成多张子表、或将数据分散到多个数据库实例，不仅能降低单表、单库的数据规模，提升读写性能，还能分散并发压力、减少锁冲突，从而显著提高系统的可用性和扩展能力。</p>
<p>垂直分库通过将不同业务模块或功能独立到各自的数据库，既降低了数据之间的耦合度，又提升了整体可用性；水平分库则将同一业务的数据按一定策略分散到多台实例，分担了单库的 CPU、I&#x2F;O 和网络压力；垂直分表是把表中不同类型的数据拆分到多张表中，进一步削弱耦合；水平分表则把一张大表按范围或哈希划分成多张子表，从而减少索引深度并加快查询。</p>
<p>若仍使用单库单表模式，会因热点数据频繁访问导致缓冲区不足、磁盘 I&#x2F;O 激增，又因大量请求而引发网络带宽瓶颈，此外 SQL 处理也会占用过多 CPU 资源，最终形成性能瓶颈。分库分表的核心思想就是通过分散存储，将单一数据库或表的数据规模控制在可承载范围内，进而显著缓解 I&#x2F;O、CPU 和网络方面的压力。</p>
<h2 id="拆分策略"><a href="#拆分策略" class="headerlink" title="拆分策略"></a>拆分策略</h2><h3 id="垂直拆分"><a href="#垂直拆分" class="headerlink" title="垂直拆分"></a>垂直拆分</h3><p>垂直拆分主要包括两种形式：<strong>垂直分库</strong>和<strong>垂直分表</strong>。其中，垂直分库是以表为单位、根据业务模块将不同的表拆分到各自独立的数据库实例中，使得每个库只包含某一类业务的表，从而降低数据耦合度并提升可用性；而垂直分表则是以字段为依据，将同一张宽表中访问频次不同或性质相异的字段拆分到多张子表，通过主键—外键关联保持数据完整性，以减小单表宽度、优化查询性能。在实践中，垂直分库常用于按业务边界隔离数据，而垂直分表则侧重于对单表内部结构的精细化拆分，两者结合能够更好地满足系统的可扩展性与维护性需求。</p>
<p><img src="/../../images/MySQL/mysql_partition_v.drawio.png" alt="img"></p>
<h3 id="水平拆分"><a href="#水平拆分" class="headerlink" title="水平拆分"></a>水平拆分</h3><p>水平拆分是一种以<strong>行</strong>为单位对数据进行切割的策略：水平分库是将同一表的若干行数据按照某种分片键（如用户ID范围或哈希）分散到多个数据库实例，每个实例存储一部分数据，从而分担 CPU、I&#x2F;O 和网络负载；而水平分表则是在同一数据库实例内部将表数据行按相同策略分布到多张结构相同的子表中，以减少单表的索引层数，提升查询性能和并发处理能力。无论是分库还是分表，都可通过范围切片、哈希切片或列表切片等算法来保证数据的均衡分布，进一步降低锁竞争与热点访问问题。</p>
<p>在业界，这种做法通常也被称为分片（sharding），每个分片可以是独立的数据存储节点。此外，在云服务环境下，水平分区是实现水平扩展（scale-out）的核心方式，通过动态增加分片或实例来处理更大规模的请求和数据量；它还能与读写分离、缓存策略等机制结合，共同构建高可用、高性能的数据库架构。</p>
<p><img src="/../../images/MySQL/mysql_partition_h.drawio.png" alt="img"></p>
<h3 id="水平分表的路由方式"><a href="#水平分表的路由方式" class="headerlink" title="水平分表的路由方式"></a>水平分表的路由方式</h3><p>要实现水平分表，必须设计一个路由策略，根据<strong>分片键</strong>（Sharding Key）决定每条记录应写入哪张子表。理想的分片键应该具备以下特征：</p>
<p>一是<strong>高区分度</strong>，使数据均匀分布，避免某些表过热或过载；</p>
<p>二是<strong>查询频率高</strong>，优先选取常在 WHERE 条件中出现的字段，以确保绝大多数查询能直接定位到目标表，提升查询效率；</p>
<p>三是<strong>写入频率高</strong>，将频繁更新或插入的字段作为分片键，有助于将写负载均衡地分散到各个子表，从而减少单表写入瓶颈。</p>
<p>范围路由、哈希路由和配置路由是水平分表中最常用的三种策略。</p>
<p>范围路由通过将分片键按值的连续区间映射到不同的表，例如按时间戳或订单号切分，优势在于实现简单且可以平滑扩容，但容易出现部分分片数据过多的倾斜问题。</p>
<p><img src="/../../images/MySQL/mysql_partition_range.drawio.png" alt="img"></p>
<p>哈希路由则对分片键取哈希值并取模分表，可以较均匀地分散数据，避免单表热点，但执行范围查询时需要访问多个分片，查询性能有所下降。</p>
<p><img src="/../../images/MySQL/mysql_partition_hash.drawio.png" alt="img"></p>
<p>配置路由则通过维护一张映射表，显式指定每个分片键对应的目标表，灵活性最高，能够应对分片键分布不均或规则多变的场景，但需要额外的配置表来管理路由映射，运维成本和复杂度也相对更高。</p>
<p><img src="/../../images/MySQL/mysql_partition_route.drawio.png" alt="img"></p>
<p>以上的路由方式可以根据场景的不同组合使用，比如：首先根据业务维度（如订单月份）将数据划分到不同的<strong>分组</strong>，每个分组再映射到若干<strong>物理节点</strong>，形成按月分组的“范围切分”策略。然后在每个分组内部，对分片键（如 orderId）计算哈希并取模，将其均匀分配到该组的各节点上，兼顾了哈希路由的负载均衡效果。</p>
<h3 id="不停机扩容"><a href="#不停机扩容" class="headerlink" title="不停机扩容"></a>不停机扩容</h3><p>不停机扩容通常分为三个阶段，以确保旧库和新库在业务不中断的情况下平滑过渡。</p>
<p>第一阶段是<strong>在线双写、老库查询</strong>：在此阶段，先在新环境中建立与旧库完全相同的库表结构，然后将所有新增写操作同时写入旧库和新库，业务查询仍然走旧库；接着，通过专用迁移程序对旧库中的历史数据进行全量迁移，并通过定时校验任务对比新旧库的数据一致性，实时补齐任何差异。</p>
<p><img src="/../../images/MySQL/mysql_partition_scale1.drawio.png" alt="img"></p>
<p>第二阶段是<strong>完成同步并切换读流量</strong>：当确认历史数据已经成功迁移且新库中的写入与旧库始终保持一致后，就可以将所有读操作从旧库切换到新库，从而开始验证新库的查询性能和稳定性。</p>
<p><img src="/../../images/MySQL/mysql_partition_scale2.drawio.png" alt="img"></p>
<p>第三阶段是<strong>停止旧库写入并下线</strong>：在确认旧库不再接收任何新写后，需要等待一段时间以清空剩余连接与缓冲，然后可以安全地关闭或拆除旧库，实现真正的无缝下线。通过这种三阶段流程，在整个扩容过程中既保证了业务的连续性，也维持了数据的一致性和可用性。</p>
<p><img src="/../../images/MySQL/mysql_partition_scale3.drawio.png" alt="img"></p>
<p>尽管在线双写与写时复制在延迟复制、零停机思想上有交集，但它们在层级、触发条件、技术依赖和一致性模型上都有本质区别。在线双写更适合数据库扩容与数据迁移场景；写时复制则是操作系统与存储层面优化内存和文件复制的通用技术。两者均为提升可用性和性能的重要手段，但并非同一机制。</p>
<h2 id="分库分表的问题"><a href="#分库分表的问题" class="headerlink" title="分库分表的问题"></a>分库分表的问题</h2><p>在分库后，单机事务的强一致性优势不再适用，必须引入分布式事务（如两阶段提交或 TCC）来保证跨库的事务完整性；同时，由于数据库实例被拆分，原生的跨库 JOIN 无法直接执行，只能在业务代码中先查询一个库的数据再查询另一个库并进行合并，或通过冗余字段将常用关联信息（如名称）复制到当前表，减少关联请求；另一种思路是利用 binlog 同步等机制将需要跨库关联的数据异构到 Elasticsearch 等专用存储，再由 ES 实现联合查询。</p>
<p>在分表场景下，跨分片的聚合计算（如 COUNT、ORDER BY、GROUP BY）只能通过业务端或中间件对各分表结果进行汇总、排序与分页才能实现；同时，需要在切分前对数据迁移、容量规划及未来扩容的可行性进行充分评估，以避免二次拆分带来的复杂度和风险。更重要的是，表被水平切分后已不能再依赖数据库自身的自增主键机制来保证全局唯一性，常见的替代方案包括：设置不同的自增步长与初始值（例如三张表分别以步长 3、初始值 1、2、3 生成 ID），从而避免冲突；使用 UUID 生成全局唯一主键，但要警惕随机主键可能导致 B-Tree 页分裂、写放大和性能下降；或者采用分布式 ID 生成算法（如 Twitter Snowflake），通过时间戳、节点 ID 及序列号的组合方式高效生成可排序的全局唯一 ID，兼顾性能与一致性。</p>
<p>更多内容可参考：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://developer.aliyun.com/article/1232122">基因法与倒排索引在MySQL分库分表的应用</a></li>
<li><a target="_blank" rel="noopener" href="https://developer.aliyun.com/article/1627841">美团面试：百亿级分片，如何设计基因算法？</a></li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/xGYM0pXAHfaLMpTxBJvLBg">字节面试：百亿级存储，怎么设计？只是分库分表？</a></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN,en">
    <link itemprop="mainEntityOfPage" href="https://yihangwe.github.io/undefined/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/2024/11/22/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/MapReduce/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yihang Wei">
      <meta itemprop="description" content="聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EthanWeee">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/undefined/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/2024/11/22/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/MapReduce/" class="post-title-link" itemprop="url">MapReduce</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-11-22 00:00:00" itemprop="dateCreated datePublished" datetime="2024-11-22T00:00:00-08:00">2024-11-22</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-06-20 17:10:24" itemprop="dateModified" datetime="2025-06-20T17:10:24-07:00">2025-06-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/" itemprop="url" rel="index"><span itemprop="name">数据库系统</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="编程模型-Programming-Model"><a href="#编程模型-Programming-Model" class="headerlink" title="编程模型 (Programming Model)"></a>编程模型 (Programming Model)</h1><p><strong>输入与输出 (Input and Output):</strong></p>
<ul>
<li>接收一组<strong>输入键&#x2F;值对 (input key&#x2F;value pairs)</strong>。</li>
<li>生成一组<strong>输出键&#x2F;值对 (output key&#x2F;value pairs)</strong>。</li>
</ul>
<p><strong>用户自定义函数 (User-Defined Functions):</strong></p>
<ul>
<li><strong>映射函数 (Map Function)</strong>:<ul>
<li>由用户编写。</li>
<li>处理每个输入键&#x2F;值对。</li>
<li>生成一组<strong>中间键&#x2F;值对 (intermediate key&#x2F;value pairs)</strong>。</li>
</ul>
</li>
<li><strong>归约函数 (Reduce Function)</strong>:<ul>
<li>同样由用户编写。</li>
<li>接收一个中间键 <code>I</code> 及其关联的<strong>值集合 (set of values)</strong>。</li>
<li>合并这些值以产生一个<strong>更小集合 (smaller set)</strong> 的输出值，通常为零个或一个值。</li>
</ul>
</li>
</ul>
<p><strong>中间数据处理 (Intermediate Data Handling):</strong></p>
<ul>
<li><strong>MapReduce 库 (MapReduce library)</strong> 将中间值按其键 (<code>I</code>) 分组，并将它们发送给归约函数。</li>
<li>中间值通过<strong>迭代器 (iterator)</strong> 提供给归约函数，从而能够高效处理因数据量过大而无法全部放入内存的数据集。</li>
</ul>
<p><strong>容错性与可扩展性 (Fault Tolerance and Scalability):</strong></p>
<ul>
<li>通过将任务分解成更小的独立计算单元，MapReduce 确保了即使在大型分布式环境中也能实现可扩展性和容错性。</li>
</ul>
<h1 id="实现-Implementation"><a href="#实现-Implementation" class="headerlink" title="实现 (Implementation)"></a>实现 (Implementation)</h1><p><a target="_blank" rel="noopener" href="https://../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F//mapred_exe_overview.png"><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/mapred_exe_overview.png" alt="img"></a></p>
<p><strong>数据分割与任务分配 (Data Splitting and Task Assignment):</strong></p>
<ul>
<li><strong>输入数据划分</strong>: MapReduce 库自动将输入文件分割成 M 个片段（通常每个片段大小为 16MB 到 64MB，可由用户控制）。</li>
<li><strong>启动程序实例</strong>: 在集群中启动多个程序副本。</li>
<li><strong>角色分配</strong>: 其中一个程序实例被指定为<strong>主节点 (master)</strong>，其余的作为<strong>工作节点 (workers)</strong>。</li>
</ul>
<p><strong>任务调度 (Task Scheduling):</strong></p>
<ul>
<li><strong>主节点的职责</strong>: 主节点负责管理 M 个 map 任务和 R 个 reduce 任务。</li>
<li><strong>任务分配</strong>: 主节点将空闲的工作节点分配给 map 任务或 reduce 任务。</li>
</ul>
<p><strong>Map 阶段 (Map Phase):</strong></p>
<ul>
<li><strong>读取数据</strong>: 被分配 map 任务的工作节点读取对应的输入片段。</li>
<li><strong>处理数据</strong>: 解析出键&#x2F;值对，并将其传递给用户定义的 Map 函数。</li>
<li><strong>生成中间结果</strong>: <strong>Map 函数产生的中间键&#x2F;值对会存储在本地磁盘中。</strong></li>
</ul>
<p><strong>中间数据处理 (Intermediate Data Processing):</strong></p>
<ul>
<li><strong>写入本地磁盘</strong>: **缓存的中间结果会定期写入本地磁盘，<strong>并根据分区函数划分为 R 个区域 (partitioned into R regions)。</strong></li>
<li><strong>通知主节点</strong>: 工作节点将这些中间数据的位置告知主节点，主节点负责将这些信息传递给 reduce 工作节点。</li>
</ul>
<p><strong>Reduce 阶段准备 (Reduce Phase Preparation):</strong></p>
<ul>
<li><strong>读取中间数据</strong>: reduce 工作节点收到主节点的通知后，通过<strong>远程过程调用 (RPC - Remote Procedure Call)</strong> 从 map 工作节点的本地磁盘读取中间数据。</li>
<li><strong>排序数据</strong>: reduce 工作节点将所有中间数据按键排序，以确保相同的键聚集在一起。如果数据量过大，无法全部加载到内存，会采用<strong>外部排序 (external sort)</strong>。</li>
</ul>
<p><strong>Reduce 阶段 (Reduce Phase):</strong></p>
<ul>
<li><strong>执行 Reduce 函数</strong>: reduce 工作节点遍历排序后的中间数据，对于每个唯一的中间键，将键和对应的值列表传递给用户定义的 Reduce 函数。</li>
<li><strong>生成最终输出</strong>: Reduce 函数的输出被追加到该 reduce 分区的最终输出文件中。</li>
</ul>
<p><strong>任务完成与结果返回 (Task Completion and Result Retrieval):</strong></p>
<ul>
<li><strong>任务监控</strong>: 当所有的 map 和 reduce 任务都完成后，主节点会唤醒用户程序。</li>
<li><strong>返回结果</strong>: 此时，用户程序中的 MapReduce 调用返回，用户可以获取 R 个输出文件（每个 reduce 任务对应一个输出文件）。</li>
</ul>
<p><strong>额外说明 (Additional Notes):</strong></p>
<ul>
<li><strong>数据处理链</strong>: 通常用户不需要将这 R 个输出文件合并成一个文件，因为这些文件可以直接作为下一个 MapReduce 调用的输入，或者被能够处理多文件输入的分布式应用程序使用。</li>
<li><strong>流程图参考</strong>: 上图👆用于展示 MapReduce 操作的整体流程（对应上述 7 个步骤）。</li>
</ul>
<h2 id="主节点数据结构-Master-Data-Structure"><a href="#主节点数据结构-Master-Data-Structure" class="headerlink" title="主节点数据结构 (Master Data Structure)"></a>主节点数据结构 (Master Data Structure)</h2><p><strong>任务状态跟踪 (Task State Tracking):</strong></p>
<ul>
<li>对于每个 <strong>map</strong> 和 <strong>reduce 任务</strong>，主节点存储：<ul>
<li><strong>状态</strong>:<ul>
<li><code>idle</code> (空闲): 任务尚未分配。</li>
<li><code>in-progress</code> (执行中): 任务正在被执行。</li>
<li><code>completed</code> (已完成): 任务执行完毕。</li>
</ul>
</li>
<li><strong>工作节点标识 (Worker Identity)</strong>: 处理该任务的工作机器（针对非空闲任务）。</li>
</ul>
</li>
</ul>
<p><strong>中间数据管理 (Intermediate Data Management):</strong></p>
<ul>
<li>主节点充当将中间数据从 map 任务传递到 reduce 任务的<strong>管道 (conduit)</strong>。</li>
<li>对于每个已完成的 map 任务：<ul>
<li>它记录所生成的 <code>R</code> 个中间文件区域的<strong>位置</strong> 和<strong>大小</strong>。</li>
<li>这些数据对于 reduce 任务从相应的 map 工作节点获取中间结果至关重要。</li>
</ul>
</li>
</ul>
<p><strong>动态更新 (Dynamic Updates):</strong></p>
<ul>
<li>随着 map 任务完成，主节点持续更新其记录的中间文件位置和大小。</li>
<li>这些更新会增量式地推送给当前正在执行中的 reduce 工作节点。</li>
</ul>
<h2 id="容错机制-Fault-Tolerance"><a href="#容错机制-Fault-Tolerance" class="headerlink" title="容错机制 (Fault Tolerance)"></a>容错机制 (Fault Tolerance)</h2><p><strong>工作节点故障 (Worker Failure)</strong></p>
<ul>
<li><strong>故障检测 (Failure Detection)</strong>:<ul>
<li><strong>主节点</strong>定期向<strong>每个工作节点</strong>发送 <strong>ping</strong>。</li>
<li>如果工作节点在特定时间窗口内未响应，主节点将其标记为<strong>故障</strong>。</li>
</ul>
</li>
<li><strong>任务重新调度 (Task Rescheduling)</strong>:<ul>
<li><strong>Map 任务 (Map Tasks)</strong>:<ul>
<li><strong>已完成的 Map 任务 (Completed Map Tasks)</strong>:<ul>
<li>如果故障工作节点已完成 map 任务，其输出将变得不可访问（存储在故障机器的本地磁盘上）。</li>
<li>这些任务被重置为<strong>空闲状态 (idle state)</strong> 并在其他工作节点上重新执行。</li>
</ul>
</li>
<li><strong>执行中的 Map 任务 (In-Progress Map Tasks)</strong>:<ul>
<li>类似地，执行中的任务被标记为空闲并重新分配给可用的工作节点。</li>
</ul>
</li>
</ul>
</li>
<li><strong>Reduce 任务 (Reduce Tasks)</strong>:<ul>
<li><strong>已完成的 Reduce 任务 (Completed Reduce Tasks)</strong>:<ul>
<li>这些任务<strong>不需要</strong>重新执行，因为它们的输出存储在<strong>全局文件系统 (global file system)</strong> 中，即使发生故障也仍然可访问。</li>
</ul>
</li>
<li><strong>执行中的 Reduce 任务 (In-Progress Reduce Tasks)</strong>:<ul>
<li>如果某些 reduce 工作节点尚未读取中间数据，它们会从新的（重新执行的 map 任务的）结果中读取数据。</li>
</ul>
</li>
</ul>
</li>
<li><strong>数据协调 (Data Coordination)</strong>:<ul>
<li>当 map 任务在新的工作节点上重新执行时：<ul>
<li><strong>通知 (Notification)</strong>: 所有 reduce 工作节点会被告知该重新执行。</li>
<li><strong>数据重定向 (Data Redirection)</strong>: 尚未从故障工作节点获取中间数据的 reduce 工作节点将改为从新的工作节点获取数据。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>主节点故障 (Master Failure)</strong></p>
<ul>
<li>可以很方便地让主节点定期将上述主节点数据结构写入<strong>检查点 (checkpoints)</strong>。如果主节点任务终止，可以从最后一个检查点状态启动一个新的副本。</li>
<li>然而，考虑到只有一个主节点，其故障的可能性很低；<strong>因此我们当前的实现在主节点故障时会中止 MapReduce 计算。</strong> 客户端可以检测到此情况，并在需要时重试 MapReduce 操作。</li>
</ul>
<h2 id="数据本地化-Locality"><a href="#数据本地化-Locality" class="headerlink" title="数据本地化 (Locality)"></a>数据本地化 (Locality)</h2><ul>
<li><strong>存储设计</strong>: 数据存储在 <strong>Google 文件系统 (GFS - Google File System)</strong> 中。GFS 将每个文件分割为 64 MB 的块 (blocks)，并在不同的机器上保存多个副本（通常是 3 个）。</li>
<li><strong>任务调度优先级</strong>:<ul>
<li><strong>优先本地化调度</strong>: 主节点优先将 map 任务分配给<strong>包含对应数据块副本的同一台机器</strong>上的工作节点。</li>
<li><strong>次优调度</strong>: 如果本地调度不可行（例如，拥有数据块副本的工作节点繁忙），主节点将任务分配给靠近副本的机器，例如同一机架 (rack) 或数据中心 (data center) 内的机器。</li>
</ul>
</li>
<li><strong>实际效果</strong>: 在运行大型 MapReduce 操作时，大部分输入数据会从本地磁盘读取。因为数据本地化，减少了跨网络传输的数据量，从而节省网络带宽。</li>
</ul>
<h2 id="任务粒度-Task-Granularity"><a href="#任务粒度-Task-Granularity" class="headerlink" title="任务粒度 (Task Granularity)"></a>任务粒度 (Task Granularity)</h2><ol>
<li><strong>Map 和 Reduce 阶段的划分</strong><ul>
<li><strong>任务数量 (M 和 R)</strong>: Map 阶段被划分为 M 个任务。Reduce 阶段被划分为 R 个任务。</li>
<li><strong>划分原则</strong>: 理想情况下，M 和 R 的数量应该<strong>远大于</strong>工作节点的数量（即机器的数量）。</li>
</ul>
</li>
<li><strong>多任务划分的好处</strong><ul>
<li><strong>动态负载均衡</strong>: 每个工作节点可执行多个任务，这样可以动态调整任务分配，避免某些节点过载或闲置。</li>
<li><strong>故障恢复加速</strong>: 如果某个工作节点失败，其已完成的多个任务可以分散到其他节点重新执行，恢复速度更快。</li>
</ul>
</li>
<li><strong>任务划分的实际限制</strong><ul>
<li><strong>调度开销</strong>: 主节点需要进行 O(M + R) 次调度决策，且需要存储 O(M × R) 的状态信息。虽然每对 map&#x2F;reduce 任务对仅占用约 1 字节内存，但过多任务会增加内存需求和调度复杂性。</li>
<li><strong>输出文件限制</strong>: R 的大小往往受到用户需求限制，因为每个 reduce 任务会生成一个独立的输出文件。输出文件过多会导致文件管理复杂。</li>
</ul>
</li>
<li><strong>实际任务大小选择</strong><ul>
<li><strong>Map 阶段</strong>: 每个 map 任务通常处理 <strong>16 MB 到 64 MB</strong> 的输入数据。这样的任务大小可以充分利用<strong>数据本地化优化</strong>（即尽量从本地磁盘读取数据）。</li>
<li><strong>Reduce 阶段</strong>: R 通常是工作节点数量的几倍，以充分利用并行能力。在一个典型的大规模 MapReduce 计算中：<ul>
<li>M &#x3D; 200,000（Map 阶段任务数）。</li>
<li>R &#x3D; 5,000（Reduce 阶段任务数）。</li>
<li>工作节点 &#x3D; 2,000（机器数量）。</li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 id="备份任务-Backup-Tasks"><a href="#备份任务-Backup-Tasks" class="headerlink" title="备份任务 (Backup Tasks)"></a>备份任务 (Backup Tasks)</h2><ol>
<li><strong>什么是拖后腿的任务（Straggler Tasks）？</strong><ul>
<li><strong>定义</strong>: 拖后腿任务指的是 MapReduce 作业中运行速度<strong>远慢于</strong>其他任务的任务（map 或 reduce），从而<strong>延迟整个作业的完成</strong>。</li>
</ul>
</li>
<li><strong>解决方法</strong>:<ul>
<li><strong>备份任务机制</strong>: 当 MapReduce 计算接近完成时，主节点会为<strong>未完成的任务</strong>安排<strong>备份执行 (Backup Executions)</strong>。同一任务的多个副本在不同的工作节点上<strong>同时运行</strong>。只要其中一个副本完成，任务即被标记为完成。</li>
<li><strong>资源开销</strong>: 调整后的机制只增加少量（通常是几个百分点）的计算资源使用。通过备份执行，能够<strong>显著缩短</strong>总执行时间。</li>
</ul>
</li>
</ol>
<h1 id="优化与增强-Refinement"><a href="#优化与增强-Refinement" class="headerlink" title="优化与增强 (Refinement)"></a>优化与增强 (Refinement)</h1><p><strong>分区函数 (Partitioning Function)</strong></p>
<ol>
<li><strong>Reduce 任务与分区</strong><ul>
<li>用户通过设置 <strong>R</strong> 来指定需要的 reduce 任务数或输出文件数。</li>
<li>数据在这些 reduce 任务之间分区，分区方式取决于<strong>分区函数</strong>。</li>
</ul>
</li>
<li><strong>默认分区方式</strong><ul>
<li>默认使用<strong>哈希函数</strong>。</li>
<li><strong>分区规则</strong>: <code>hash(key) mod R</code>。</li>
<li><strong>优势</strong>: 通常能实现较为<strong>均衡的分区</strong>（即数据均匀分布到不同 reduce 任务中）。</li>
</ul>
</li>
<li><strong>自定义分区方式</strong><ul>
<li>有时默认的哈希分区不满足实际需求，需要根据特定逻辑对数据进行分区。例如：数据的键是 URL，用户希望所有来自<strong>同一主机 (host)</strong> 的条目存储在同一个输出文件中。</li>
<li><strong>解决方案</strong>: 用户可以定义自己的分区函数，例如：<code>hash(Hostname(urlkey)) mod R</code>：根据 URL 的<strong>主机名 (hostname)</strong> 分区。这样，来自同一主机的所有条目会被分配到<strong>相同的 reduce 任务</strong>中。</li>
</ul>
</li>
</ol>
<p><strong>排序保证 (Ordering Guarantees)</strong></p>
<ol>
<li><strong>排序保证</strong><ul>
<li>在 MapReduce 的<strong>每个分区内</strong>，中间的键&#x2F;值对（key&#x2F;value pairs）会按照<strong>键的递增顺序</strong> 进行处理。</li>
<li><strong>目标</strong>: 确保每个分区的输出文件是<strong>有序的</strong>。</li>
</ul>
</li>
<li><strong>排序的作用</strong><ul>
<li><strong>生成有序输出文件</strong>: 每个 reduce 任务生成的输出文件是按键排序的，直接支持有序数据的存储。</li>
<li><strong>支持高效随机访问</strong>: 有序数据便于通过键值实现高效的随机访问。</li>
<li><strong>用户便利</strong>: 用户使用这些输出文件时，通常不需要额外排序。</li>
</ul>
</li>
</ol>
<p><strong>合并函数 (Combiner Function)</strong></p>
<ol>
<li><strong>问题背景</strong><ul>
<li>在某些情况下，中间键<strong>重复率较高</strong>，每个 map 任务可能会生成大量重复的中间键记录。<strong>示例</strong>: 在单词计数任务中（例如 <code>&lt;the, 1&gt;</code>），常见单词（如 “the”）会频繁出现。</li>
<li><strong>结果</strong>: 这些重复记录需要通过网络传输到同一个 reduce 任务，增加了网络负载。</li>
</ul>
</li>
<li><strong>Combiner 函数的解决方案</strong><ul>
<li><strong>定义</strong>: Combiner 是一个<strong>可选的、局部的聚合函数</strong>，<strong>用于在 map 任务所在机器上对中间数据进行部分合并。</strong></li>
<li><strong>工作原理</strong>:<ul>
<li><strong>执行位置</strong>: Combiner 在 map 任务的机器上运行。</li>
<li><strong>功能</strong>: 对<strong>重复键</strong>的中间结果进行<strong>局部汇总</strong>，减少需要传输的数据量。</li>
<li><strong>例如</strong>: 将 <code>&lt;the, 1&gt;</code>、<code>&lt;the, 1&gt;</code>、<code>&lt;the, 1&gt;</code> 合并为 <code>&lt;the, 3&gt;</code>。</li>
</ul>
</li>
</ul>
</li>
<li><strong>Combiner 和 Reduce 的区别</strong><ul>
<li><strong>相同点</strong>: 通常，Combiner 的代码与 Reduce 函数的代码<strong>相同</strong>。都用于对数据进行<strong>聚合处理</strong>。</li>
<li><strong>不同点</strong>:<ul>
<li><strong>Combiner</strong>: 输出的是<strong>中间结果</strong>，数据会<strong>继续传递</strong>给 Reduce 任务。</li>
<li><strong>Reduce</strong>: 输出的是<strong>最终结果</strong>，数据写入最终的输出文件。</li>
</ul>
</li>
</ul>
</li>
<li><strong>优化效果</strong><ul>
<li><strong>减少网络传输量</strong>: 通过提前合并数据，Combiner 显著减少了从 map 任务到 reduce 任务的数据量。例如，不传输 1000 条 <code>&lt;the, 1&gt;</code>，而是只传输 1 条 <code>&lt;the, 1000&gt;</code>。</li>
<li><strong>提升性能</strong>: 对于重复率高的任务，Combiner 能显著加快 MapReduce 操作的速度。</li>
</ul>
</li>
</ol>
<p><strong>输入与输出类型 (Input and Output Types)</strong></p>
<ol>
<li><strong>输入数据格式的支持</strong><ul>
<li><strong>预定义格式</strong>:<ul>
<li><strong>文本模式</strong>: 每行数据被视为一个键&#x2F;值对。<ul>
<li>键：文件中该行的<strong>偏移量</strong>。</li>
<li>值：该行的<strong>内容</strong>。</li>
</ul>
</li>
<li><strong>排序键&#x2F;值对模式 (sorted key&#x2F;value mode)</strong>: 存储的键&#x2F;值对按键排序，便于按范围处理。</li>
</ul>
</li>
<li><strong>自动分割范围</strong>: 每种输入格式都有<strong>分割机制</strong>，可将输入数据划分为适合 map 任务处理的范围。例如，文本模式会确保分割发生在<strong>行边界</strong>，而不是行中间，保证数据的完整性。</li>
<li><strong>用户自定义格式</strong>: 用户可以通过实现简单的<strong>读取接口 (reader interface)</strong>，支持新的输入类型。<ul>
<li><strong>非文件输入</strong>: 数据可以来自其他来源，如数据库或内存中的数据结构，而不一定是文件。</li>
</ul>
</li>
</ul>
</li>
<li><strong>输出数据格式的支持</strong><ul>
<li>类似输入格式，MapReduce 也支持多种输出格式：<ul>
<li><strong>预定义格式</strong>: 提供了一些常用的输出格式。</li>
<li><strong>自定义格式</strong>: 用户可以通过实现新的接口定义输出数据格式。</li>
</ul>
</li>
</ul>
</li>
</ol>
<p><strong>跳过错误记录 (Skipping Bad Records)</strong></p>
<ol>
<li><strong>问题背景</strong><ul>
<li><strong>用户代码缺陷</strong>: Map 或 Reduce 函数中可能存在错误（如某些记录引发崩溃）。</li>
<li><strong>确定性崩溃</strong>: 对特定记录，每次处理都会发生崩溃。</li>
<li><strong>问题影响</strong>: 这类错误可能<strong>阻止整个 MapReduce 操作完成</strong>。</li>
<li><strong>无法修复的情况</strong>: 错误可能在<strong>第三方库</strong>中，用户无法访问源代码。</li>
</ul>
</li>
<li><strong>MapReduce 提供的解决方案</strong><ul>
<li><strong>跳过问题记录</strong>: MapReduce 允许系统检测引发崩溃的记录，并跳过这些记录以继续操作。</li>
<li><strong>实现机制</strong>:<ul>
<li><strong>信号处理</strong>: 每个工作节点安装<strong>信号处理器</strong>，捕获<strong>段错误 (segmentation violations)</strong> 和<strong>总线错误 (bus errors)</strong>。</li>
<li><strong>记录错误序号</strong>: 在调用用户的 Map 或 Reduce 函数之前，系统将参数的<strong>序列号 (sequence number)</strong> 存储在全局变量中。</li>
<li><strong>发送错误报告</strong>: 如果用户代码触发错误，信号处理器会发送一个 <strong>“最后的喘息” (last gasp)</strong> UDP 数据包，包含引发错误的记录序号，通知主节点。</li>
<li><strong>主节点决策</strong>: 如果一条记录多次导致失败，主节点指示在下次重试该任务时<strong>跳过 (skip)</strong> 这条记录。</li>
</ul>
</li>
</ul>
</li>
</ol>
<p><strong>本地执行 (Local Execution)</strong></p>
<ol>
<li><strong>分布式调试的挑战</strong><ul>
<li><strong>复杂性</strong>: Map 和 Reduce 函数的实际计算是在分布式系统上完成，涉及数千台机器。主节点动态分配任务，调试难以直接定位问题。</li>
<li><strong>常见问题</strong>: 分布式环境下的日志、任务状态和数据流使得问题排查更加困难。</li>
</ul>
</li>
<li><strong>本地执行模式的设计</strong><ul>
<li><strong>功能</strong>: MapReduce 提供了一种<strong>本地执行的替代实现</strong>，在<strong>单台机器</strong>上<strong>顺序执行</strong>整个 MapReduce 操作。</li>
<li><strong>特点</strong>: 所有任务按顺序运行，无需分布式调度。用户可以<strong>限制计算范围</strong>，仅调试特定的 map 任务。</li>
</ul>
</li>
</ol>
<p><strong>计数器 (Counter)</strong></p>
<ul>
<li>计数器用于跟踪 MapReduce 操作期间特定事件的发生次数，例如：<ul>
<li>用户定义的<strong>自定义事件</strong>（例如，单词计数、检测特定模式）。</li>
<li><strong>系统定义的指标</strong>，如处理的输入&#x2F;输出键值对数量。</li>
</ul>
</li>
</ul>
<p><strong>计数器工作原理 (How Counters Work)</strong></p>
<ul>
<li><strong>传播到主节点 (Propagation to the Master)</strong>: 来自各个工作节点的计数器值通过 <strong>ping 响应</strong> 发送到<strong>主节点</strong>。</li>
<li><strong>聚合 (Aggregation)</strong>:<ul>
<li>主节点聚合所有已完成任务的计数器值。</li>
<li>它通过忽略重复的任务执行（例如，由于重新执行或备份任务）来确保<strong>没有重复计数</strong>。</li>
</ul>
</li>
</ul>
<p><strong>监控与报告 (Monitoring and Reporting)</strong></p>
<ul>
<li><strong>实时监控 (Real-Time Monitoring)</strong>: 当前的计数器值显示在<strong>主节点状态页面</strong> 上，允许用户观察计算的进度。</li>
<li><strong>最终报告 (Final Reporting)</strong>: 当 MapReduce 作业完成时，聚合后的计数器值返回给用户程序。</li>
</ul>
<h1 id="问题-Questions"><a href="#问题-Questions" class="headerlink" title="问题 (Questions)"></a>问题 (Questions)</h1><p><strong>假设 M&#x3D;10 且 R&#x3D;20，映射器 (mappers) 产生的文件总数是多少？</strong></p>
<blockquote>
<p>总文件数 &#x3D; M × R &#x3D; 10 × 20 &#x3D; 200</p>
</blockquote>
<p><strong>为什么 MapReduce 将 Reduce 的输出存储在 Google 文件系统 (GFS) 中？</strong></p>
<blockquote>
<ul>
<li><strong>高可用性 (High Availability)</strong>: GFS 通过在多个机器上<strong>复制数据 (replicating data)</strong> 提供容错能力。这确保了即使一台机器故障，输出也不会丢失。</li>
<li><strong>可扩展性 (Scalability)</strong>: GFS 专为处理大规模数据存储而设计，适用于 MapReduce 作业产生的大量输出。</li>
</ul>
</blockquote>
<p><strong>拖后腿任务 (straggler) 的目的是什么？</strong></p>
<blockquote>
<ul>
<li><strong>“拖后腿任务 (Straggler)” 指的是运行缓慢的任务</strong>，通常是 map 或 reduce 任务，它们会<strong>显著延迟</strong> MapReduce 作业的完成。</li>
<li><strong>解决方法</strong>:<ul>
<li><strong>备份执行 (Backup Execution)</strong>: 主节点在其它可用工作节点上为拖后腿任务安排备份执行。</li>
</ul>
</li>
</ul>
</blockquote>
<p><strong>判断对错：可以在没有模式 (schema) 的情况下，对 CSV 数据文件使用 SQL++。</strong></p>
<blockquote>
<p><strong>正确 (True)</strong>: SQL++ 可以操作半结构化数据，包括 CSV 文件，而<strong>不需要</strong>预定义的模式。</p>
</blockquote>
<p><strong>在 SQL++ 中，pivot 和 unpivot 有什么区别？</strong></p>
<blockquote>
<p><strong>Pivot (透视)</strong>:</p>
<ul>
<li><strong>目的</strong>: 将<strong>行 (rows)</strong> 转换为<strong>属性 (attributes) &#x2F; 列 (columns)</strong>。</li>
<li><strong>示例</strong>:<ul>
<li>输入: <code>[ &#123; &quot;symbol&quot;: &quot;amzn&quot;, &quot;price&quot;: 1900 &#125;, &#123; &quot;symbol&quot;: &quot;goog&quot;, &quot;price&quot;: 1120 &#125;, &#123; &quot;symbol&quot;: &quot;fb&quot;, &quot;price&quot;: 180 &#125; ]</code></li>
<li>查询: <code>PIVOT sp.price AT sp.symbol FROM today_stock_prices sp;</code></li>
<li>输出: <code>&#123; &quot;amzn&quot;: 1900, &quot;goog&quot;: 1120, &quot;fb&quot;: 180 &#125;</code></li>
</ul>
</li>
</ul>
<p><strong>Unpivot (逆透视)</strong>:</p>
<ul>
<li><strong>目的</strong>: 将<strong>属性 (attributes) &#x2F; 列 (columns)</strong> 转换为<strong>行 (rows)</strong>。</li>
<li><strong>示例</strong>:<ul>
<li>输入: <code>&#123; &quot;date&quot;: &quot;4/1/2019&quot;, &quot;amzn&quot;: 1900, &quot;goog&quot;: 1120, &quot;fb&quot;: 180 &#125;</code></li>
<li>查询: <code>UNPIVOT c AS price AT sym FROM closing_prices c WHERE sym != &#39;date&#39;;</code></li>
<li>输出: <code>[ &#123; &quot;date&quot;: &quot;4/1/2019&quot;, &quot;symbol&quot;: &quot;amzn&quot;, &quot;price&quot;: 1900 &#125;, &#123; &quot;date&quot;: &quot;4/1/2019&quot;, &quot;symbol&quot;: &quot;goog&quot;, &quot;price&quot;: 1120 &#125;, &#123; &quot;date&quot;: &quot;4/1/2019&quot;, &quot;symbol&quot;: &quot;fb&quot;, &quot;price&quot;: 180 &#125; ]</code></li>
</ul>
</li>
</ul>
</blockquote>
<p><strong>使用 BG ，可以通过其 SoAR (Satisfaction of Agreement Ratio) 来总结数据存储的性能。计算数据存储 SoAR 的 BG 输入是什么？</strong></p>
<blockquote>
<p><strong>1. SLA 规范 (SLA Specifications)</strong></p>
<p>服务等级协议 (SLA) 定义了计算 SoAR 的条件。SLA 包括：</p>
<ul>
<li><strong>α</strong>: 必须观察到响应时间小于或等于 β 的请求百分比（例如，95%）。</li>
<li><strong>β</strong>: 最大可接受响应时间（例如，100 毫秒）。</li>
<li><strong>τ</strong>: 观察到不可预测（过时或不一致）数据的请求的最大允许百分比（例如，0.01%）。</li>
<li><strong>Δ</strong>: SLA 必须被满足的持续时间（例如，10 分钟）。</li>
</ul>
<p><strong>2. 数据库配置 (Database Configuration)</strong></p>
<p>关于被测数据存储的详细信息：</p>
<ul>
<li><strong>逻辑模式 (Logical Schema)</strong>: 数据存储使用的数据模型（例如，关系模式、NoSQL 的类 JSON 模式）。</li>
<li><strong>物理设置 (Physical Setup)</strong>: 硬件配置，包括：<ul>
<li>节点数量。</li>
<li>存储和内存资源。</li>
<li>网络能力。</li>
</ul>
</li>
<li><strong>数据量大小 (Population Size)</strong>:<ul>
<li><strong>M</strong>: 数据库中的成员数量。</li>
<li><strong>ϕ</strong>: 每个成员的关注者&#x2F;朋友数量。</li>
<li><strong>ρ</strong>: 每个成员的资源数量。</li>
</ul>
</li>
</ul>
<p><strong>3. 工作负载参数 (Workload Parameters)</strong></p>
<p>工作负载指定了 BG 将模拟的操作的性质和强度：</p>
<ul>
<li><strong>操作混合比例 (Mix of Actions)</strong>:<ul>
<li>社交网络操作的类型（例如，查看个人资料、列出朋友、查看好友请求）。</li>
<li>每种操作类型的百分比（读密集型、写密集型或混合工作负载）。</li>
</ul>
</li>
<li><strong>思考时间 (ϵ - Think Time)</strong>: 单个线程执行连续操作之间的延迟。</li>
<li><strong>到达间隔时间 (ψ - Inter-Arrival Time)</strong>: 新用户会话之间的延迟。</li>
</ul>
<p><strong>4. 环境参数 (Environmental Parameters)</strong></p>
<p>关于 BG 如何生成和管理工作负载的详细信息：</p>
<ul>
<li><strong>BGClients 数量 (N)</strong>: 负责生成请求的实例数。</li>
<li><strong>线程数量 (T)</strong>: 并发级别（每个 BGClient 的线程数）。</li>
<li><strong>D-Zipfian 分布参数 (θ)</strong>: 定义访问模式（例如，热门数据与冷门数据的访问频率）。</li>
</ul>
</blockquote>
<p><strong>考虑键值对优先级 (priority) 的以下二进制表示：00101001。其精度为 4 的 CAMP 舍入 (CAMP rounding) 结果是什么？</strong></p>
<blockquote>
<p>00101000<br><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/bg_bm_rounding.png" alt="img"></p>
</blockquote>
<p><strong>什么是惊群效应 (thundering herd)？IQ 框架如何防止它导致持久化数据存储成为瓶颈？</strong></p>
<blockquote>
<p><strong>惊群效应问题 (Thundering Herd Problem)</strong>:</p>
<ul>
<li>当一个键值对在键值存储 (KVS) 中<strong>未找到</strong>（发生 <strong>KVS 未命中 (KVS miss)</strong>）时，多个读取会话可能会<strong>同时</strong>查询关系数据库管理系统 (RDBMS) 以获取该值。</li>
<li>这可能在<strong>高并发</strong>情况下使 RDBMS <strong>过载</strong>并导致性能下降。</li>
</ul>
<p><strong>IQ 框架的解决方案</strong>:</p>
<ul>
<li>当<strong>第一个</strong>读取会话遇到 KVS 未命中时，它会为该键请求一个 <strong>I 租约 (I lease)</strong>。</li>
<li>一旦 I 租约被授予，KVS 会<strong>阻止</strong>其他读取会话为同一个键查询 RDBMS。</li>
<li>所有其他读取会话必须 <strong>“回退 (back off)”</strong> 并等待持有 I 租约的会话将值更新到 KVS 中。</li>
</ul>
<blockquote>
<p>(补充解释) 惊群效应发生在特定键经历<strong>大量读写活动</strong>时。</p>
<ul>
<li>写入操作<strong>重复地使缓存失效 (invalidate the cache)</strong>。</li>
<li>所有读取操作都<strong>被迫查询数据库</strong>。</li>
</ul>
<p><strong>I 租约解决了这个问题</strong>：</p>
<ul>
<li>对特定键的<strong>第一次读取</strong>被授予 I 租约。</li>
<li>所有其他读取观察到未命中并<strong>回退</strong>。</li>
<li>持有 I 租约的读取查询 RDBMS，计算缺失的值，并将该值<strong>填充 (populate)</strong> 到缓存中。</li>
<li>所有其他读取随后会<strong>观察到缓存命中 (cache hit)</strong>。</li>
</ul>
</blockquote>
</blockquote>
<p><strong>参考</strong>: <a target="_blank" rel="noopener" href="https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/mapreduce-osdi04.pdf">https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/mapreduce-osdi04.pdf</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/9/">9</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Yihang Wei</p>
  <div class="site-description" itemprop="description">聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">42</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        
  <div class="languages">
    <label class="lang-select-label">
      <i class="fa fa-language"></i>
      <span>简体中文</span>
      <i class="fa fa-angle-up" aria-hidden="true"></i>
    </label>
    <select class="lang-select" data-canonical="">
      
        <option value="zh-CN" data-href="/page/2/index.html" selected="">
          简体中文
        </option>
      
        <option value="en" data-href="/en/page/2/index.html" selected="">
          English
        </option>
      
    </select>
  </div>

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yihang Wei</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
<script src="https://cdn.jsdelivr.net/npm/darkmode-js@1.5.7/lib/darkmode-js.min.js"></script>

<script>
var options = {
  bottom: '50%',
  right: '32px',
  left: 'unset',
  time: '0.5s',
  mixColor: '#fff',
  backgroundColor: '#fff',
  buttonColorDark: '#100f2c',
  buttonColorLight: '#fff',
  saveInCookies: true,
  label: '明暗',
  autoMatchOsTheme: true
}
const darkmode = new Darkmode(options);
window.darkmode = darkmode;
darkmode.showWidget();
</script>

</body>
</html>
