<!DOCTYPE html>
<html lang="zh-CN,en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yihangwe.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。">
<meta property="og:type" content="website">
<meta property="og:title" content="EthanWeee">
<meta property="og:url" content="https://yihangwe.github.io/page/3/index.html">
<meta property="og:site_name" content="EthanWeee">
<meta property="og:description" content="聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Yihang Wei">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://yihangwe.github.io/page/3/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>EthanWeee</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start --><script>(function() {function calculateHeight(element) {let height = 0;const items = element.children;for (let i = 0; i < items.length; i++) {height += items[i].offsetHeight || 25;const child = items[i].querySelector(".nav-child");if (child && child.style.display !== "none") {height += calculateHeight(child);}}return height;}function generateToc(lang, container) {const content = document.getElementById(lang + "-content");if (!content) return;const headers = Array.from(content.querySelectorAll("h1, h2, h3, h4, h5, h6"));if (headers.length === 0) return;const ol = document.createElement("ol");ol.className = "nav";let currentLevel = 1;let currentOl = ol;let stack = [ol];let counters = [0, 0, 0, 0, 0, 0];headers.forEach((header, index) => {const level = parseInt(header.tagName[1]);counters[level - 1]++;for (let i = level; i < 6; i++) counters[i] = 0;const li = document.createElement("li");li.className = "nav-item nav-level-" + level;if (level === 1 && index === 0) {li.classList.add("active", "active-current");}const link = document.createElement("a");link.className = "nav-link";if (level === 1 && index === 0) link.classList.add("active");link.href = "#" + header.id;const numSpan = document.createElement("span");numSpan.className = "nav-number";numSpan.textContent = counters.slice(0, level).filter(n => n > 0).join(".");const textSpan = document.createElement("span");textSpan.className = "nav-text";textSpan.textContent = header.textContent;link.appendChild(numSpan);link.appendChild(document.createTextNode(" "));link.appendChild(textSpan);li.appendChild(link);if (level > currentLevel) {const newOl = document.createElement("ol");newOl.className = "nav-child";if (currentLevel === 1) {newOl.style.display = "block";stack[currentLevel - 1].lastElementChild.classList.add("active");}stack[currentLevel - 1].lastElementChild.appendChild(newOl);stack[level - 1] = newOl;currentOl = newOl;} else if (level < currentLevel) {currentOl = stack[level - 1];}currentOl.appendChild(li);currentLevel = level;});container.appendChild(ol);setTimeout(() => {const navHeight = calculateHeight(ol);ol.style.setProperty("--height", navHeight + "px");const navChilds = ol.getElementsByClassName("nav-child");Array.from(navChilds).forEach(child => {if (child.style.display === "block") {const childHeight = calculateHeight(child);child.style.setProperty("--height", childHeight + "px");}});}, 0);return ol;}function updateActiveHeading() {const activeLang = document.getElementById("en-content").style.display === "block" ? "en" : "zh";const content = document.getElementById(activeLang + "-content");const toc = document.getElementById(activeLang + "-toc");if (!content || !toc) return;const headers = Array.from(content.querySelectorAll("h1, h2, h3, h4, h5, h6"));const scrollPos = window.scrollY + window.innerHeight / 3;let activeHeader = null;for (let i = headers.length - 1; i >= 0; i--) {const header = headers[i];const headerTop = header.getBoundingClientRect().top + window.scrollY;if (headerTop <= scrollPos) {activeHeader = header;break;}}const links = toc.getElementsByClassName("nav-link");Array.from(links).forEach(link => {link.classList.remove("active");const parentLi = link.parentElement;if (parentLi) {parentLi.classList.remove("active", "active-current");}});if (activeHeader) {const activeLink = toc.querySelector(`a[href="#${activeHeader.id}"]`);if (activeLink) {activeLink.classList.add("active");let parent = activeLink.parentElement;while (parent && parent.classList) {if (parent.classList.contains("nav-item")) {parent.classList.add("active");if (parent.classList.contains("nav-level-1")) {parent.classList.add("active-current");}}parent = parent.parentElement;}}}}function initTippy() {document.querySelectorAll(".refplus-num").forEach((ref) => {if (ref._tippy) {ref._tippy.destroy();}let refid = ref.firstChild.href.replace(location.origin+location.pathname,"");let refel = document.querySelector(refid);if (!refel) return;let refnum = refel.dataset.num;let ref_content = refel.innerText.replace(`[${refnum}]`,"");tippy(ref, {content: ref_content,});});}function initToc() {const originalToc = document.querySelector(".post-toc-wrap");if (!originalToc || !document.getElementById("langToggle")) return;const tocContainer = document.createElement("div");tocContainer.className = "post-toc-wrap sidebar-panel sidebar-panel-active";const enToc = document.createElement("div");enToc.id = "en-toc";enToc.className = "post-toc motion-element";enToc.style.display = "block";const zhToc = document.createElement("div");zhToc.id = "zh-toc";zhToc.className = "post-toc motion-element";zhToc.style.display = "none";generateToc("en", enToc);generateToc("zh", zhToc);tocContainer.appendChild(enToc);tocContainer.appendChild(zhToc);originalToc.parentNode.replaceChild(tocContainer, originalToc);window.addEventListener("scroll", updateActiveHeading);setTimeout(updateActiveHeading, 0);}window.toggleLanguage = function() {const enContent = document.getElementById("en-content");const zhContent = document.getElementById("zh-content");const enToc = document.getElementById("en-toc");const zhToc = document.getElementById("zh-toc");const button = document.getElementById("langToggle");if (!enContent || !zhContent || !enToc || !zhToc || !button) return;const isEnglish = enContent.style.display === "block";enContent.style.display = isEnglish ? "none" : "block";zhContent.style.display = isEnglish ? "block" : "none";enToc.style.display = isEnglish ? "none" : "block";zhToc.style.display = isEnglish ? "block" : "none";button.querySelector(".button-text").textContent = isEnglish ? "Switch to English" : "切换中文";setTimeout(updateActiveHeading, 0);setTimeout(initTippy, 100);};document.addEventListener("DOMContentLoaded", function() {initToc();setTimeout(initTippy, 3000);});})();</script><style>.post-toc { transition: all 0.2s ease-in-out; }.post-toc .nav { padding-left: 0; }.post-toc .nav-child { padding-left: 1em; }.post-toc .nav-item { line-height: 1.8; }.post-toc .nav-link { color: #555; }.post-toc .nav-link:hover { color: #222; }.post-toc .nav-link.active { color: #fc6423; }.post-toc .active > .nav-link { color: #fc6423; }.post-toc .active-current > .nav-link { color: #fc6423; }</style><!-- hexo injector head_end end --><style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">EthanWeee</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN,en">
    <link itemprop="mainEntityOfPage" href="https://yihangwe.github.io/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/2024/11/08/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/IQ/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yihang Wei">
      <meta itemprop="description" content="聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EthanWeee">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/2024/11/08/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/IQ/" class="post-title-link" itemprop="url">IQ</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-11-08 00:00:00" itemprop="dateCreated datePublished" datetime="2024-11-08T00:00:00-08:00">2024-11-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-05-31 21:00:45" itemprop="dateModified" datetime="2025-05-31T21:00:45-07:00">2025-05-31</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/" itemprop="url" rel="index"><span itemprop="name">数据库系统</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="What-is-the-IQ-Framework"><a href="#What-is-the-IQ-Framework" class="headerlink" title="What is the IQ Framework?"></a>What is the IQ Framework?</h1><p>The IQ framework is a solution designed for Cache-Augmented SQL (CASQL) systems, which combine relational databases (RDBMS) and key-value stores (KVS) to boost performance by caching database query results. However, CASQL systems often face challenges related to stale data and race conditions. The IQ framework ensures strong consistency while maintaining high performance.</p>
<h1 id="Challenges-in-CASQL-Systems"><a href="#Challenges-in-CASQL-Systems" class="headerlink" title="Challenges in CASQL Systems"></a>Challenges in CASQL Systems</h1><ol>
<li><p><strong>Stale Data in Cache</strong>:</p>
<ul>
<li><p>Cached data in the KVS can become outdated if updates to the RDBMS are not properly synchronized.</p>
</li>
<li><p>For example, if a record in the database is modified, but the corresponding cache entry isn’t updated, subsequent reads might return incorrect values.</p>
</li>
</ul>
</li>
<li><p><strong>Concurrency Issues</strong>:</p>
<ul>
<li><p>Multiple sessions accessing and modifying the same key in KVS concurrently can lead to inconsistent results.</p>
</li>
<li><p>Example:</p>
<ul>
<li>One session updates a value while another session modifies it based on outdated data.</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>RDBMS and Cache Coordination</strong>:</p>
<ul>
<li>While RDBMS ensures transactional consistency, KVS often lacks this capability, making it difficult to synchronize their states.</li>
</ul>
</li>
</ol>
<h1 id="Key-Features-of-the-IQ-Framework"><a href="#Key-Features-of-the-IQ-Framework" class="headerlink" title="Key Features of the IQ Framework"></a>Key Features of the IQ Framework</h1><ol>
<li><strong>Lease Mechanism: Inhibit (I) and Quarantine (Q)</strong>:<ol>
<li><strong>I Lease</strong> (for reads):<ol>
<li>Ensures that only one session can query the RDBMS for a cache miss and update the KVS.</li>
<li>Other sessions attempting to read the same key must “back off” and wait.</li>
</ol>
</li>
<li><strong>Q Lease</strong> (for writes):<ol>
<li>Required for modifying, deleting, or incrementally updating keys in the KVS.</li>
<li>If an I lease exists, the Q lease invalidates it to ensure the write operation’s integrity.</li>
<li>The KVS ignores I’s write operation because this I lease is no longer valid.</li>
</ol>
</li>
</ol>
</li>
<li><strong>Lease Expiry</strong>:<ol>
<li>A lease for a key has a fixed life time and is granted to one KVS connection (thread) at a time.</li>
<li>Expired leases are automatically released, ensuring system availability.</li>
<li>The finite life time enables the KVS to release the lease and continue processing operations in the presence of node failures hosting the application.</li>
</ol>
</li>
<li><strong>Session-based Model</strong>:<ol>
<li>The framework operates through sessions, similar to the <strong>two-phase locking protocol</strong>.</li>
<li>Leases can be acquired either before or during an RDBMS transaction, providing flexibility.</li>
</ol>
</li>
</ol>
<h2 id="Implementing-ACID-Properties"><a href="#Implementing-ACID-Properties" class="headerlink" title="Implementing ACID Properties"></a>Implementing ACID Properties</h2><p>原子性 (Atomicity)： IQ 框架确保事务的操作同时在数据库 (RDBMS) 和缓存 (KVS) 中执行。也就是说，操作不会只在数据库中完成而没有更新缓存。这种设计假设 KVS 中的数据是 RDBMS 数据的一部分，因此如果遇到问题，可以直接删除 KVS 中的数据来保持一致。</p>
<p>一致性 (Consistency)： IQ 框架保证事务在数据库和缓存中的数据状态从一个有效状态变为另一个有效状态。如果数据库的事务回滚 (abort)，那么缓存中的操作也不会被应用，确保不会留下无效的缓存数据。</p>
<p>隔离性 (Isolation)： 即使有多个会话 (session) 同时执行，IQ 框架也让每个会话看起来像是独立执行的，避免了并发问题。例如，即使两个用户同时读写相同的数据，他们看到的结果也是正确且一致的。</p>
<p>持久性 (Durability)： 持久性是由数据库 (RDBMS) 提供的，而缓存 (KVS) 则作为数据库的一部分镜像。KVS 存储的数据是在内存中的副本，但一旦数据库中的事务提交，数据就会被持久保存。</p>
<blockquote>
<p>CAS 操作只能保证单一操作的原子性，但无法在多个并发会话中保证强一致性。 由于数据库和缓存系统中的操作顺序可能不一致，会导致数据不同步。</p>
<p>在并发场景下：CAS 无法感知其他会话在其读取后对数据的更改。 多个会话同时执行 CAS 操作时，可能导致更新丢失或顺序混乱，如本例中 S2 的更新被 S1 覆盖。</p>
<p>Q 租约用于写操作，确保某一时刻只有一个会话能够修改目标键值。如果某个键值已有 Q 租约，其他会话（如 S1）会被要求退避（back off）或中止操作。</p>
</blockquote>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/RDBMS_KVS_OPER.png" alt="img"></p>
<h1 id="Invalidate"><a href="#Invalidate" class="headerlink" title="Invalidate"></a>Invalidate</h1><h2 id="What-is-Snapshot-Isolation"><a href="#What-is-Snapshot-Isolation" class="headerlink" title="What is Snapshot Isolation?"></a>What is Snapshot Isolation?</h2><p>Snapshot isolation is a multi-version concurrency control mechanism commonly used in RDBMS to allow concurrent transactions to execute efficiently. It guarantees:</p>
<ol>
<li><strong>Consistent Snapshot</strong>: All reads in a transaction observe the same consistent state of the database, as it existed at the transaction’s start.</li>
<li><strong>Conflict Detection</strong>: A transaction can only commit if its updates do not conflict with updates made by other transactions since its snapshot was taken.</li>
</ol>
<h3 id="The-Problem"><a href="#The-Problem" class="headerlink" title="The Problem"></a>The Problem</h3><p>Snapshot isolation can cause a race condition between a write session (S1) and a read session (S2) when KVS is involved. The issue unfolds as follows:</p>
<ol>
<li><p><strong>Write Session (S1)</strong>:</p>
<ul>
<li><p>S1 modifies the RDBMS and triggers a delete operation in the KVS to invalidate outdated key-value pairs.</p>
</li>
<li><p>S1 commits the transaction after completing its changes in the RDBMS.</p>
</li>
</ul>
</li>
<li><p><strong>Read Session (S2)</strong>:</p>
<ul>
<li><p>S2 starts after S1’s delete operation in the KVS. It observes a <strong>KVS miss</strong> for a key-value pair because S1 has invalidated it.</p>
</li>
<li><p>S2 queries the RDBMS to recompute the key-value pair. However, because snapshot isolation allows S2 to read an <strong>older snapshot of the database</strong>, it retrieves outdated (stale) data.</p>
</li>
<li><p>S2 inserts this <strong>stale data</strong> back into the KVS before S1 commits its changes to the RDBMS.</p>
</li>
</ul>
</li>
<li><p><strong>Inconsistency</strong>:</p>
<ul>
<li>After both sessions complete, the KVS contains a stale key-value pair inconsistent with the RDBMS, leading to incorrect results for future reads.</li>
</ul>
</li>
</ol>
<h3 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h3><p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/invalidate_tbl.png" alt="img"></p>
<p>I Lease (Inhibit Lease):</p>
<ul>
<li>Used by <strong>read sessions</strong> (e.g., S2).</li>
<li>When a read session observes a <strong>KVS miss</strong>, it requests an I lease for the key (<code>k_j</code>) from the KVS server.</li>
<li>The I lease allows the read session to query the RDBMS, compute a value, and insert the computed key-value pair into the KVS.</li>
<li>If a Q lease is already in place, the I lease is denied, and the read session is told to <strong>back off</strong> and retry later.</li>
</ul>
<p>Q Lease (Quarantine Lease):</p>
<ul>
<li>Used by <strong>write sessions</strong> (e.g., S1).</li>
<li>When a write session plans to invalidate a key in the KVS, it requests a Q lease for the key (<code>k_j</code>).</li>
<li>The Q lease prevents other sessions (including those holding I leases) from modifying or inserting the key in the KVS.</li>
<li>Multiple Q leases can be granted for the same key since deleting a key is idempotent (doesn’t create conflicts).</li>
</ul>
<h1 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h1><h2 id="The-Problem-1"><a href="#The-Problem-1" class="headerlink" title="The Problem"></a>The Problem</h2><ul>
<li>In the original scenario, <strong>write sessions (e.g., S1)</strong> immediately delete key-value pairs in the KVS as soon as they acquire a Q lease (e.g., Step 1.3 in Figure 3).</li>
<li>This can cause <strong>read sessions (e.g., S2)</strong> to encounter KVS misses, triggering redundant operations like querying the RDBMS, recalculating values, and reinserting them into the KVS.</li>
</ul>
<h2 id="The-Proposed-Optimization"><a href="#The-Proposed-Optimization" class="headerlink" title="The Proposed Optimization"></a>The Proposed Optimization</h2><p><strong>Deferring Key Deletion Until Write Commit</strong></p>
<ol>
<li><p><strong>Key Changes</strong>:</p>
<ul>
<li><p>Instead of deleting the key immediately in Step 1.3, the write session (S1) holds the Q lease and <strong>defers the deletion</strong> until the write session commits (Step 1.5).</p>
</li>
<li><p>While S1 is mid-flight, the invalidated key-value pair remains in the KVS for other read sessions (S2) to observe.</p>
</li>
</ul>
</li>
<li><p><strong>Handling KVS Hits</strong>:</p>
<ul>
<li><p>Read sessions like S2 that encounter a <strong>KVS hit</strong> consume the “stale” key-value pair, treating it as valid.</p>
</li>
<li><p>This is acceptable because S2’s actions can be <strong>serialized to occur before</strong> S1, which is still in progress and has not yet committed its RDBMS changes.</p>
</li>
</ul>
</li>
<li><p><strong>Handling Write Aborts</strong>:</p>
<ul>
<li><p>If a write session (S1) encounters an exception and aborts, the Q lease is released without deleting the key.</p>
</li>
<li><p>The current key-value pair in the KVS remains valid and accessible to other sessions.</p>
</li>
</ul>
</li>
</ol>
<h2 id="Implementation-Details"><a href="#Implementation-Details" class="headerlink" title="Implementation Details"></a>Implementation Details</h2><ol>
<li><p><strong>Versioning Concept</strong>:</p>
<ul>
<li><p>The optimization can be conceptualized as maintaining a <strong>temporary version</strong> of the key-value pair for use by all sessions except the one currently invalidating it (S1).</p>
</li>
<li><p>Once S1 commits, the temporary version is removed.</p>
</li>
</ul>
</li>
<li><p><strong>Abort Command</strong>:</p>
<ul>
<li><p>If a write session (S1) aborts due to constraints or exceptions, an <strong>abort command</strong> releases all Q leases held by S1 without deleting the key-value pair.</p>
</li>
<li><p>Without this command, Q leases would expire naturally after a timeout, during which no other session could modify or access the key.</p>
</li>
</ul>
</li>
</ol>
<p><strong>Re-Arrangement Window</strong>:</p>
<ul>
<li>With this optimization, S2 and S1 can be <strong>re-arranged</strong> in a serializable schedule where S2 logically occurs before S1.</li>
<li>Without the optimization, the re-arrangement window shrinks to zero because S2 would have already queried the RDBMS for stale data, violating consistency.</li>
</ul>
<h1 id="Refresh-and-Incremental-Update"><a href="#Refresh-and-Incremental-Update" class="headerlink" title="Refresh and Incremental Update"></a>Refresh and Incremental Update</h1><h2 id="Key-Issues-with-Compare-and-Swap-CAS"><a href="#Key-Issues-with-Compare-and-Swap-CAS" class="headerlink" title="Key Issues with Compare-and-Swap (CAS)"></a>Key Issues with Compare-and-Swap (CAS)</h2><ul>
<li><p><strong>CAS Limitation</strong>:</p>
<ul>
<li>CAS alone cannot ensure strong consistency. It provides atomic updates to a single key-value pair but does not coordinate these updates with RDBMS transactions.</li>
</ul>
</li>
<li><p><strong>Example (Figure 2)</strong>:</p>
<ul>
<li><p>KVS writes can occur either:</p>
<ol>
<li><p><strong>Prior to</strong> the RDBMS transaction, or</p>
</li>
<li><p><strong>As part of</strong> the RDBMS transaction.</p>
</li>
</ol>
</li>
<li><p><strong>Problem</strong>: If the RDBMS transaction aborts, the KVS will retain the modified key-value pair, potentially exposing <strong>dirty reads</strong> to other sessions.</p>
</li>
</ul>
</li>
<li><p><strong>Figure 6 (Dirty Read Problem)</strong>:</p>
<ul>
<li>Write session S1 modifies a key-value pair in KVS.</li>
<li>S1’s transaction later aborts, but the intermediate KVS value is consumed by a read session S2 before the rollback, leading to inconsistencies.</li>
</ul>
</li>
<li><p><strong>Developer Responsibility</strong>:</p>
<ul>
<li>Without additional mechanisms, developers must implement complex logic to restore KVS key-value pairs to their original values when RDBMS transactions abort.</li>
</ul>
</li>
</ul>
<h2 id="Race-Conditions-with-Incremental-Updates-δ-Operations"><a href="#Race-Conditions-with-Incremental-Updates-δ-Operations" class="headerlink" title="Race Conditions with Incremental Updates (δ Operations)"></a>Race Conditions with Incremental Updates (δ Operations)</h2><ul>
<li><p><strong>Figure 7 (Snapshot Isolation with δ Operations)</strong>:</p>
</li>
<li><ul>
<li>Write session S1 updates the RDBMS and KVS using an incremental update (e.g., appending to a value).</li>
<li>Concurrently, read session S2 queries the RDBMS and overwrites the key-value pair in the KVS.</li>
<li><strong>Result</strong>: The KVS reflects inconsistent state, as S2’s overwrite may invalidate S1’s incremental change.</li>
</ul>
</li>
<li><p><strong>Figure 8 (Reordering KVS Operations)</strong>:</p>
</li>
<li><ul>
<li>Delaying KVS updates until after the RDBMS transaction doesn’t solve the problem.</li>
</ul>
</li>
<li><p><strong>Example in Figure 8</strong>:</p>
</li>
<li><ul>
<li>S1 appends a change to a value based on its RDBMS view.</li>
<li>S2 modifies the RDBMS during S1’s execution, which S1 unknowingly incorporates into its KVS update.</li>
<li><strong>Problem</strong>: S2’s modifications are reflected twice in the KVS, introducing inconsistencies.</li>
</ul>
</li>
</ul>
<h2 id="Solution-1"><a href="#Solution-1" class="headerlink" title="Solution"></a>Solution</h2><p><strong>Key Concepts in the Solution</strong></p>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/refresh_tbl.png" alt="img"></p>
<ol>
<li><p><strong>Q Leases for Write Sessions</strong>:</p>
<ul>
<li><p>A <strong>Q lease</strong> must be obtained for each key-value pair that a session intends to update.</p>
</li>
<li><p>This prevents race conditions by locking the key-value pair until the session completes its operations.</p>
</li>
</ul>
</li>
<li><p><strong>Steps for Write Sessions</strong>:</p>
<ul>
<li><p><strong>Step 1</strong>: Obtain Q leases for the keys to be updated before committing the RDBMS transaction. This can happen:</p>
<ul>
<li><p>Before starting the RDBMS transaction.</p>
</li>
<li><p>As part of the RDBMS transaction.</p>
</li>
</ul>
</li>
<li><p><strong>Step 2</strong>: Write the updated key-value pairs to the KVS after committing the RDBMS transaction.</p>
</li>
<li><p><strong>Step 3</strong>: Release the Q leases once the KVS is updated.</p>
</li>
<li><p><strong>Automatic Cleanup</strong>: If a Q lease expires, the KVS deletes the associated key-value pair to avoid stale data.</p>
</li>
</ul>
</li>
<li><p><strong>Command Design for Write Operations</strong>:</p>
<ul>
<li><p><strong>QaRead (Quarantine-and-Read)</strong>:</p>
<ul>
<li><p>Acquires a Q lease on the referenced key and reads its value from the KVS.</p>
</li>
<li><p>If a Q lease for the same key is already held by another session, the requesting session receives an <strong>abort message</strong>, must roll back its RDBMS transaction, release all leases, back off, and retry later.</p>
</li>
<li><p>If no value exists in the KVS (a <strong>KVS miss</strong>), the application can:</p>
<ul>
<li>Skip updating the key, or</li>
<li>Query the RDBMS, compute a new value, and insert it using <strong>SaR</strong> (below).</li>
</ul>
</li>
<li><p>If a <strong>QaRead lease</strong> encounters an <strong>I lease</strong> held by a read session, it invalidates the I lease to prevent race conditions.</p>
</li>
</ul>
</li>
<li><p><strong>SaR (Swap-and-Release)</strong>:</p>
<ul>
<li>Updates the value of a key in the KVS with the new value and releases the Q lease.</li>
<li>If the new value is <code>null</code>, the Q lease is simply released without updating the KVS.</li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 id="Handling-Race-Conditions"><a href="#Handling-Race-Conditions" class="headerlink" title="Handling Race Conditions"></a>Handling Race Conditions</h2><ol>
<li><p><strong>Q Leases for Concurrent Write Sessions</strong>:</p>
<ul>
<li><p>If two write sessions request Q leases for the same key, the KVS resolves the conflict by:</p>
<ul>
<li>Aborting one session.</li>
<li>Ensuring the aborted session retries later, serializing its updates after the session holding the Q lease.</li>
</ul>
</li>
<li><p>This guarantees a valid serial schedule in the RDBMS and KVS.</p>
</li>
</ul>
</li>
<li><p><strong>Read Sessions and I Leases</strong>:</p>
<ul>
<li><p>Read sessions use <strong>I leases</strong> to avoid race conditions when querying the KVS.</p>
</li>
<li><p>If a write session issues a <strong>QaRead</strong> that encounters an existing <strong>I lease</strong>, the <strong>I lease</strong> is invalidated to ensure the KVS reflects the latest updates from the RDBMS.</p>
</li>
</ul>
</li>
</ol>
<h2 id="Integration-with-Two-Phase-Locking"><a href="#Integration-with-Two-Phase-Locking" class="headerlink" title="Integration with Two-Phase Locking"></a>Integration with Two-Phase Locking</h2><ul>
<li><p>The Q lease mechanism resembles <strong>two-phase locking</strong>:</p>
<ol>
<li><p><strong>Growing Phase</strong>: The session acquires all necessary Q leases using <strong>QaRead</strong> before committing its RDBMS transaction.</p>
</li>
<li><p><strong>Shrinking Phase</strong>: The session releases all Q leases using <strong>SaR</strong> after committing its RDBMS transaction.</p>
</li>
</ol>
</li>
<li><p>Flexibility:</p>
<ul>
<li>A session can issue <strong>QaRead</strong> commands either before starting the RDBMS transaction or as part of the transaction.</li>
</ul>
</li>
</ul>
<h2 id="Key-Concepts-of-Incremental-Updates"><a href="#Key-Concepts-of-Incremental-Updates" class="headerlink" title="Key Concepts of Incremental Updates"></a>Key Concepts of Incremental Updates</h2><ol>
<li><p><strong>Incremental Update Command: IQ-δ</strong>:</p>
<ul>
<li><p><strong>Purpose</strong>: Allows a write session to perform an incremental update, such as appending data to an existing key-value pair.</p>
</li>
<li><p><strong>Syntax</strong>: <code>IQ-δ(ki, δi)</code></p>
<ul>
<li><code>ki</code>: The key to be updated.</li>
<li><code>δi</code>: The incremental change to apply (e.g., the value to append).</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Similarities to QaRead</strong>:</p>
<ul>
<li><p><strong>Q Lease Requirement</strong>: Before issuing the <code>IQ-δ</code> command, the session must obtain a <strong>Q lease</strong> for the key <code>ki</code> to ensure exclusive access.</p>
</li>
<li><p><strong>Abort on Conflict</strong>:</p>
<ul>
<li><p>If another session already holds a Q lease on the same key (<code>ki</code>), the <strong>KVS returns an abort message</strong>.</p>
</li>
<li><p>The write session must:</p>
<ol>
<li><p>Release all its leases.</p>
</li>
<li><p>Abort its ongoing RDBMS transaction (if any).</p>
</li>
<li><p>Retry the operation later.</p>
</li>
</ol>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<h1 id="优化关键点总结"><a href="#优化关键点总结" class="headerlink" title="优化关键点总结"></a>优化关键点总结</h1><ol>
<li><p><strong>保留旧版本（Older Version）</strong>：</p>
<ul>
<li><p>当写会话（S1）更新某键值对 (<code>ki-vi</code>) 时，KVS 暂时保留该键值对的旧版本 (<code>ki-vi_old</code>)，直到 S1 提交。</p>
</li>
<li><p>这避免了读会话在写会话更新期间遇到 <strong>KVS miss</strong>。</p>
</li>
</ul>
</li>
<li><p>写会话的更新视图：</p>
<ul>
<li><p>写会话（S1）在更新期间必须能够看到自己的修改结果（<code>ki-vi_new</code>）。</p>
</li>
<li><p>KVS 确保为 S1 提供其最新的更新视图。</p>
</li>
</ul>
</li>
</ol>
<h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h1><p><strong>Why is it acceptable for invalidate to delete cache entries?</strong></p>
<p>Consistency Assurance: The cache entry being invalidated represents stale data that is no longer consistent with the current state of the RDBMS. Deleting it prevents read sessions from accessing outdated information.</p>
<p><strong>How is a lease different than a lock?</strong> </p>
<ul>
<li><strong>Lease</strong>: Has a fixed lifetime and expires automatically after a certain duration. This makes leases useful in distributed systems where failures or delays could otherwise cause indefinite blocking.</li>
<li><strong>Lock</strong>: Typically remains active until explicitly released, which can lead to deadlocks or indefinite resource contention if not managed properly.</li>
</ul>
<p><strong>True or False: IQ leases require changes to the RDBMS software.</strong></p>
<p>False:</p>
<p>IQ leases do not require changes to the RDBMS software.</p>
<p>Instead, they extend the functionality of the Key-Value Store (KVS) by introducing new lease-based commands (e.g., <code>QaRead</code> and <code>SaR</code>) to coordinate operations between the KVS and the RDBMS. This design leverages existing RDBMS features without altering its underlying implementation.</p>
<p><strong>What factors does CAMP consider when selecting a victim?</strong></p>
<p>H(p) &#x3D; L + size(p) &#x2F; cost(p)</p>
<p><strong>What is the definition of cost? Provide an example.</strong></p>
<ul>
<li><strong>Computation Time</strong>: The time required to regenerate or recompute the data if it is evicted from memory.</li>
<li><strong>Access Latency</strong>: The time it would take to fetch the data from disk or another slower storage tier.</li>
<li><strong>Importance</strong>: The priority or weight assigned to the data based on how frequently or critically it is used.</li>
</ul>
<p><strong>How does CAMP insert a key-value pair in memory?</strong></p>
<p>When a new key-value pair p needs to be inserted into memory, CAMP performs the following steps:</p>
<p><strong>1. Check Cache Capacity</strong></p>
<ul>
<li>If there is <strong>enough memory</strong> to store the new key-value pair:</li>
<li><ul>
<li>The pair is inserted directly into the appropriate <strong>priority group</strong> based on its cost-to-size ratio.</li>
<li>L is not updated.</li>
</ul>
</li>
<li>If the cache is <strong>full</strong>:</li>
<li><ul>
<li>CAMP selects one or more key-value pairs to <strong>evict</strong> based on their H(p) values.</li>
<li>It removes the pair(s) with the <strong>lowest H(p)</strong> values until there is sufficient space for the new pair.</li>
</ul>
</li>
</ul>
<p><strong>2. Insert the New Pair</strong></p>
<ul>
<li>The new key-value pair p is added to the cache, and its H(p) value is computed and recorded.</li>
<li>The pair is placed in the appropriate priority queue based on its cost-to-size ratio.</li>
</ul>
<p><strong>With BG, what is the definition of Service Level Agreement, SLA?</strong></p>
<p>SLA, e.g., 95% of requests to observe a response time equal to or faster than 100 msec with at most 0.1% of requests observing unpredictable data for 10 minutes.</p>
<p><strong>Name one reason why a system may produce unpredictable data?</strong></p>
<p>Eventual consistency. Or multiple threads are updating the same data item.</p>
<p>Reference: <a target="_blank" rel="noopener" href="https://dl.acm.org/doi/abs/10.1145/2663165.2663318">https://dl.acm.org/doi/abs/10.1145/2663165.2663318</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN,en">
    <link itemprop="mainEntityOfPage" href="https://yihangwe.github.io/MySQL/2024/11/03/MySQL/%E8%A1%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yihang Wei">
      <meta itemprop="description" content="聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EthanWeee">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/MySQL/2024/11/03/MySQL/%E8%A1%A8/" class="post-title-link" itemprop="url">表</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-11-03 00:00:00" itemprop="dateCreated datePublished" datetime="2024-11-03T00:00:00-07:00">2024-11-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-06-19 14:30:37" itemprop="dateModified" datetime="2025-06-19T14:30:37-07:00">2025-06-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MySQL/" itemprop="url" rel="index"><span itemprop="name">MySQL</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>索引是一种可以帮助 MySQL 高效获取数据的数据结构，也是有序结构。</p>
<p>优点</p>
<ul>
<li>提高数据检索效率，降低数据库 I&#x2F;O 成本。</li>
<li>通过索引列对数据进行排序，降低数据排序成本，降低 CPU 的消耗。</li>
</ul>
<p>缺点</p>
<ul>
<li>占用空间。</li>
<li>降低了更新表的效率，如 INSERT、UPDATE、DELETE。</li>
</ul>
<p>因此，若索引太多，应用程序的性能可能会受到影响。而索引太少，对查询性能又会产生影响。要找到一个合适的平衡点，这对应用程序的性能至关重要。</p>
<h2 id="索引结构"><a href="#索引结构" class="headerlink" title="索引结构"></a>索引结构</h2><p>MySQL 索引是在引擎层实现的，不同的存储引擎支持不同的索引结构。</p>
<table>
<thead>
<tr>
<th>索引结构</th>
<th>描述</th>
<th>InnoDB</th>
<th>MyISAM</th>
<th>Memory</th>
</tr>
</thead>
<tbody><tr>
<td>B+Tree 索引</td>
<td>最常见的索引类型，大部分引擎支持 B+Tree索引</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
</tr>
<tr>
<td>Hash 索引</td>
<td>底层数据结构由哈希表实现，只有精确匹配索引列的查询才有效，不支持查询范围</td>
<td>不支持</td>
<td>不支持</td>
<td>支持</td>
</tr>
<tr>
<td>R-Tree 空间索引</td>
<td>空间索引是 MyISAM 引擎的一个特殊索引类型，主要用于地理空间数据类型</td>
<td>不支持</td>
<td>支持</td>
<td>不支持</td>
</tr>
<tr>
<td>Full-Text 全文索引</td>
<td>一种通过建立倒排索引来快速匹配文档的方式</td>
<td>5.6版本之后支持</td>
<td>支持</td>
<td>不支持</td>
</tr>
</tbody></table>
<h2 id="InnoDB-索引分类"><a href="#InnoDB-索引分类" class="headerlink" title="InnoDB 索引分类"></a>InnoDB 索引分类</h2><p><img src="/Users/yihangwei/blog/source/images/MySQL/index_type.png" alt="img"></p>
<table>
<thead>
<tr>
<th>索引类别</th>
<th>含义</th>
<th>特点</th>
<th>关键字</th>
</tr>
</thead>
<tbody><tr>
<td>主键索引</td>
<td>针对表中<strong>主键</strong>创建的索引</td>
<td>默认自动创建，只能有一个</td>
<td>PRIMARY</td>
</tr>
<tr>
<td>唯一索引</td>
<td><strong>避免</strong>同一个表中某数据列中的值<strong>重复</strong></td>
<td>可以有多个</td>
<td>UNIQUE</td>
</tr>
<tr>
<td>常规索引</td>
<td>快速定位特定数据</td>
<td>可以有多个</td>
<td></td>
</tr>
<tr>
<td>全文索引</td>
<td><strong>查找</strong>文本中的<strong>关键字</strong>，而不是比较索引中的值</td>
<td>可以有多个</td>
<td>FULLTEXT</td>
</tr>
</tbody></table>
<p>根据索引存储形式，可分为以下两种：</p>
<table>
<thead>
<tr>
<th>分类</th>
<th>含义</th>
<th>特点</th>
</tr>
</thead>
<tbody><tr>
<td>聚集索引</td>
<td><strong>将数据存储与索引放到了一块</strong>，索引结构的叶子节点保存了行数据</td>
<td>必须有，而且只有一个</td>
</tr>
<tr>
<td>二级索引</td>
<td><strong>将数据与索引分开存储</strong>，索引结构的叶子节点关联的是对应的<strong>主键</strong></td>
<td>可以存在多个</td>
</tr>
</tbody></table>
<p>InnoDB 支持以下索引：</p>
<ul>
<li>B+ 树索引</li>
<li>全文索引</li>
<li>自适应 Hash 索引</li>
</ul>
<p>B+ 树索引就是传统意义上的索引，这是目前关系型数据库系统中查找最为高效且被认为有效的索引。B+ 树索引的构造类似于二叉树，根据键值（Key Value）快速找到数据。B+ 树索引能找到的只是被查找数据所在的页。然后数据库通过把页读入到内存，再在内存中进行查找，最后得到要查找的数据。</p>
<p>整体流程：</p>
<p>B+ 树 Root &#x3D;&gt; B+ 树索引节点 &#x3D;&gt; B+ 树叶子节点 &#x3D;&gt; Page Directory 中的一个 Slot &#x3D;&gt; 目标行数据。</p>
<p>InnoDB 存储引擎支持的哈希索引是自适应的，InnoDB 存储引擎会根据表的使用情况自动为表生成哈希索引，不能人为干预是否在一张表中生成哈希索引。</p>
<p>InnoDB 的主键使用的是聚簇索引，而 MyISAM 中，不管是主键索引还是二级索引使用的都是非聚簇索引。</p>
<p>InnoDB 中的全表扫描会顺序读取聚集索引上的数据页（即叶子节点），等价于按主键顺序逐行扫描表中所有行。</p>
<h2 id="全表扫描"><a href="#全表扫描" class="headerlink" title="全表扫描"></a>全表扫描</h2><p>在 InnoDB 中，一条简单的 <code>SELECT * FROM A</code> 在执行时会经过以下几层，才能把表 A 中的每一行读出来。下面分段结合关键源码，逐步说明一个典型的全表扫描流程。</p>
<p><strong>一、Handler 接口</strong>：<code>ha_rnd_next</code> 循环读取</p>
<p><code>TableScanIterator::Read()</code> 中：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> ((tmp = <span class="built_in">table</span>()-&gt;file-&gt;<span class="built_in">ha_rnd_next</span>(m_record))) &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (tmp == HA_ERR_RECORD_DELETED &amp;&amp; !<span class="built_in">thd</span>()-&gt;killed) <span class="keyword">continue</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">HandleError</span>(tmp);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><p><code>ha_rnd_next(m_record)</code>：MySQL 存储引擎统一接口，每次调用读一行到 <code>m_record</code>。</p>
</li>
<li><p>跳过 DELETED：MyISAM 在并发删时会返回 <code>HA_ERR_RECORD_DELETED</code>，此处跳过。</p>
</li>
<li><p>返回码：0 表示成功取到一行；非 0 则调用 <code>HandleError(tmp)</code> 终止扫描。</p>
</li>
</ul>
<p>对于 InnoDB，<code>ha_rnd_next</code> 内部实现为：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">handler::ha_rnd_next</span><span class="params">(uchar *buf)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">MYSQL_TABLE_IO_WAIT</span>(..., &#123; result = <span class="built_in">rnd_next</span>(buf); &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!result &amp;&amp; m_update_generated_read_fields)</span><br><span class="line"></span><br><span class="line">      <span class="built_in">update_generated_read_fields</span>(buf, table);</span><br><span class="line"></span><br><span class="line">  table-&gt;<span class="built_in">set_row_status_from_handler</span>(result);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>二、InnoDB 读取流程</strong>：<code>rnd_next</code> → <code>general_fetch</code> → <code>row_search_mvcc</code></p>
<p><code>rnd_next(buf)</code> 中的核心调用如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (m_start_of_scan) &#123;</span><br><span class="line"></span><br><span class="line">  error = <span class="built_in">index_first</span>(buf);</span><br><span class="line"></span><br><span class="line">  m_start_of_scan = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"></span><br><span class="line">  error = <span class="built_in">general_fetch</span>(buf, ROW_SEL_NEXT, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> error;</span><br></pre></td></tr></table></figure>

<ul>
<li>首次扫描 调用 <code>index_first(buf)</code> 定位到最左叶节点的第一条记录；</li>
<li>后续扫描 一律调用 <code>general_fetch</code>。</li>
</ul>
<p><code>general_fetch(buf, ROW_SEL_NEXT, 0)</code> 中的核心调用如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (!intrinsic) <span class="comment">// 普通表</span></span><br><span class="line"></span><br><span class="line">  ret = <span class="built_in">row_search_mvcc</span>(buf, PAGE_CUR_UNSUPP, m_prebuilt, <span class="number">0</span>, ROW_SEL_NEXT);</span><br><span class="line"></span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 再把 dberr_t 转成 MySQL 错误码返回给 rnd_next</span></span><br></pre></td></tr></table></figure>

<p>row_search_mvcc</p>
<p><code>row_search_mvcc</code> 中的核心调用如下：</p>
<ul>
<li>首次 (<code>direction == 0</code>)：构造或恢复一个 B-树游标 pcur，调用 <code>pcur-&gt;open_no_init()</code>（或 <code>open_at_side</code>）从根节点一路走到左最叶，定位第一条记录。</li>
<li>后续 (<code>direction == ROW_SEL_NEXT</code>)：直接在叶节点上调用 <code>pcur-&gt;move_to_next(&amp;mtr)</code>，利用叶节点之间的双向链表遍历下一条记录，无需再从根节点重查。</li>
<li>循环过滤（<code>rec_loop</code>）：<ul>
<li>跳过 infimum&#x2F;supremum 伪记录，检查页内偏移合法性；</li>
<li>MVCC 版本检查：如果当前版本不可见，调用 undo log 回溯到可见版本；</li>
<li>删除标记：跳过 delete-marked；</li>
<li>索引条件下推（此例没有 WHERE，相当于 <code>match_mode == 0</code>，所有行都通过）；</li>
<li>转换格式：调用 <code>row_sel_store_mysql_rec(buf, …)</code> 将内部二进制行转成 MySQL 客户端格式；</li>
<li>预取缓存：若启用缓存则放入队列，否则直接写入 buf 并 <code>return DB_SUCCESS</code>。</li>
</ul>
</li>
<li>退出：当 <code>move_to_next</code> 返回 false（无更多记录），函数最终返回 <code>DB_END_OF_INDEX</code> 或 <code>DB_RECORD_NOT_FOUND</code>，上层映射为 <code>HA_ERR_END_OF_FILE</code>。</li>
</ul>
<p>在 <code>row_search_mvcc</code> 的整个执行过程中，游标（pcur）的状态会在多处被保存和恢复，其核心目的有两个：</p>
<ol>
<li>跨页扫描时保持定位：当 B- 树叶节点遍历到一页的末尾，需要切换到下一页时，InnoDB 会提交当前 mini-transaction（<code>mtr_commit(&amp;mtr)</code>）并重新开启一个新的 mini-transaction（mtr_start(&amp;mtr)）。提交会释放当前页面的读锁（latch），以避免死锁或锁的过度持有。但一旦释放，就无法再在页内继续定位，于是必须在释放前存储当前位置，切换后再恢复，才能从下一个页的正确位置继续扫描。</li>
<li>出现锁等待或错误时的回退：如果在给某条记录加锁过程中遇到锁等待（<code>DB_LOCK_WAIT</code>）或其他可重试的错误，函数会<ul>
<li>在释放 mini-transaction、让出 latch 之前存储游标位置，</li>
<li>等待锁或错误解决后，再恢复游标，继续当前记录或下一条记录的扫描，保证最终不会漏读也不重复读。</li>
</ul>
</li>
</ol>
<p><strong>完整调用链一览</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mysql_select()</span><br><span class="line"> └─ join_read_table() / read_table_rows()</span><br><span class="line">   	└─ handler::ha_rnd_next(buf)</span><br><span class="line">       └─ rnd_next(buf)</span><br><span class="line">          ├─ index_first(buf)     // 第一次，从根到左叶</span><br><span class="line">          └─ general_fetch(buf,…)  // 后续，调用 row_search_mvcc</span><br><span class="line">         		 └─ row_search_mvcc(buf,…)</span><br><span class="line">                ├─ pcur-&gt;open_no_init()   // 定位（首次）</span><br><span class="line">                ├─ pcur-&gt;move_to_next()   // 遍历（后续）</span><br><span class="line">                └─ row_sel_store_mysql_rec // 转换格式</span><br></pre></td></tr></table></figure>

<p>此外，整个过程主要涉及两类锁：</p>
<p><strong>元数据锁（MDL，Metadata Lock）</strong></p>
<ul>
<li><code>MDL_SHARED_READ</code>：在执行任何 SELECT 时，MySQL 都会在打开表的时候对表结构加一个元数据读锁，类型叫 <code>MDL_SHARED_READ</code>。<ul>
<li>作用：保证在查询进行时，表定义（DDL）不会被改动（比如 <code>ALTER TABLE</code>）。</li>
<li>持续时间：从打开表到查询结束（<code>close_tables()</code>）为止。</li>
</ul>
</li>
</ul>
<p><strong>InnoDB 内部的短期页锁（Latch）与 MVCC</strong></p>
<ul>
<li>页锁（Page Latch）：为了从缓冲池安全地读取 B+ 树节点和行记录，InnoDB 在内存页上会拿短期的读或写 latch（互斥锁），确保数据页在读取&#x2F;解码时不被并发修改。<ul>
<li>这不是 SQL 层面的锁，你在 <code>SHOW ENGINE INNODB STATUS</code> 能看到它们，但在 <code>SHOW OPEN TABLES</code> 或 <code>INFORMATION_SCHEMA.INNODB_TRX</code> 中看不到。</li>
</ul>
</li>
<li>MVCC 版本控制：<strong>默认一致性读不会向行上加记录锁或间隙锁</strong>；它通过读视图加上 undo log 回溯来返回符合快照的行版本。<ul>
<li>不产生任何行锁，也不会阻塞并发的 UPDATE&#x2F;DELETE。</li>
<li>只有在遇到刚提交的、版本不可见的行时，InnoDB 会临时读取 undo log 中的旧版本，但这也是通过读取 undo 区块，不会在真正的索引上留下锁。</li>
</ul>
</li>
</ul>
<p>而且需要注意的是，整个流程中的数据是被一条条地读取并存储到 Record Buffer 中的，这就是 Valcano 风格的 pull-based Iteration Model 的体现。</p>
<h3 id="并行化增强"><a href="#并行化增强" class="headerlink" title="并行化增强"></a>并行化增强</h3><p>我们可以对全表扫描进行<strong>并行化增强</strong>。因为 MySQL 在 InnoDB 层引入了并行扫描功能，用于加速需要全表扫描的操作，该功能自 8.0.14 版本开始支持，通过将 B+ 树划分为多个子树并由多个工作线程并行扫描来实现。要启用并行全表扫描，只需将会话级或全局变量 <code>innodb_parallel_read_threads</code> 设置为大于 1 的值，MySQL 会根据该值和实际子树数量来决定并行线程数。</p>
<p>配置参数 <code>innodb_parallel_read_threads</code>：</p>
<ul>
<li>作用：控制 InnoDB 层并行扫描主键索引时的线程数，仅支持主键（聚簇索引）扫描，不支持二级索引扫描。</li>
<li>默认值：默认值为可用逻辑处理器数除以 8，至少 4；MySQL 8.4 之前始终为 4。</li>
<li>范围：1 至 256，总线程数上限为 256（跨所有会话）; 达到上限后会话会回退到单线程扫描。</li>
</ul>
<p>动态修改：支持会话级和全局级动态设置，例如：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SET GLOBAL innodb_parallel_read_threads = 16;</span><br><span class="line">SET SESSION innodb_parallel_read_threads = 8;</span><br></pre></td></tr></table></figure>

<p>然后执行需要全表扫描的 SQL 即可利用并行扫描。</p>
<h3 id="其他相关参数"><a href="#其他相关参数" class="headerlink" title="其他相关参数"></a>其他相关参数</h3><ul>
<li><code>innodb_ddl_threads</code>：控制并行创建二级索引或重建表时的排序和 B+ 树构建线程数。</li>
<li><code>innodb_ddl_buffer_size</code>：并行 DDL 操作的排序缓冲区总大小，应配合 <code>innodb_parallel_read_threads</code> 一同调优。</li>
</ul>
<h4 id="并行扫描原理"><a href="#并行扫描原理" class="headerlink" title="并行扫描原理"></a>并行扫描原理</h4><p>MySQL 并行查询实际上是对 B+ 树的并行扫描。核心流程如下：</p>
<ol>
<li>调用扫描接口：用户线程执行如 <code>SELECT COUNT(*)</code> 等语句后，进入 InnoDB 并行扫描逻辑，从 <code>row_scan_index_for_mysql</code> 接口开始分发任务。</li>
<li>预分片（coarse-grained sharding）：用户线程先对整个聚簇索引做粗粒度分片，将每个子树（Range），由 <code>[start, end)</code> 两个游标标记，放入任务队列。其中分片的步骤如下：<ol>
<li>用户线程在预分片期间对整个索引加 INDEX S 锁，并对根页加 ROOT PAGE S 锁，确保树在分片时不会发生页分裂或新增子树。 </li>
<li>根页每条记录都包含一个指向子树的指针。用户线程依次读取这些指针，对应第 i 条指针即第 i 个子树。</li>
<li>对于每个指针，沿 B+ 树从该指针所在页向下定位到最左叶记录。</li>
<li>在遍历过程中，对每个经过的页加 S 锁，定位完成后创建一个 Iter，其中包含原始记录指针 <code>m_rec</code> 和持久化游标 <code>m_pcur</code>，用于后续线程快速定位。</li>
</ol>
</li>
<li>创建工作线程：根据 <code>innodb_parallel_read_threads</code> 值启动相应数量的工作线程，然后等待所有工作线程完成。</li>
<li>工作线程取任务：每个工作线程从队列中取出一个 Range，如粒度过大（分片数 ＞ 线程数）则再基于该 RANGE 的键值范围按同样方式二次切分，然后依次扫描该范围内的记录，通过内部函数 <code>row_search_mvcc</code> 获取每条记录并执行回调（如计数或检查）。</li>
<li>结果汇总：各线程扫描完毕后，用户线程收集各子树的统计结果或校验结果，并返回给 SERVER 层。</li>
</ol>
<h4 id="分片（Sharding）机制"><a href="#分片（Sharding）机制" class="headerlink" title="分片（Sharding）机制"></a>分片（Sharding）机制</h4><p>并行扫描将 B+ 树划分为多个子树，每个子树对应一个 RANGE 结构体：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">RANGE</span> &#123;</span><br><span class="line"> Iter start; <span class="comment">// 子树起始记录位置</span></span><br><span class="line"> Iter end;  <span class="comment">// 子树结束记录位置（右开区间）</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>其中 Iter 包含了记录指针和 B+ 树游标，用于定位扫描边界。工作线程可对粒度过大的 Range 再次细分，以提高负载均衡。</p>
<p>Iter 的结构如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** Boundary of the range to scan. */</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Iter</span> &#123;</span><br><span class="line"> <span class="comment">/** Destructor. */</span></span><br><span class="line"> ~<span class="built_in">Iter</span>();</span><br><span class="line"> <span class="comment">/** Heap used to allocate m_rec, m_tuple and m_pcur. */</span></span><br><span class="line"> <span class="type">mem_heap_t</span> *m_heap&#123;&#125;;   <span class="comment">// 分配迭代所需内存（记录副本、tuple、游标等）</span></span><br><span class="line"> <span class="comment">/** m_rec column offsets. */</span></span><br><span class="line"> <span class="type">const</span> ulint *m_offsets&#123;&#125;; <span class="comment">// 原始记录中各列的偏移数组</span></span><br><span class="line"> <span class="comment">/** Start scanning from this key. Raw data of the row. */</span></span><br><span class="line"> <span class="type">const</span> <span class="type">rec_t</span> *m_rec&#123;&#125;;   <span class="comment">// 指向边界记录的原始数据</span></span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Tuple representation inside m_rec,</span></span><br><span class="line"><span class="comment">  * for two Iter instances in a range m_tuple will be [first-&gt;m_tuple, second-&gt;m_tuple).</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="type">const</span> <span class="type">dtuple_t</span> *m_tuple&#123;&#125;; <span class="comment">// m_rec 对应的解析后 tuple，方便按列访问</span></span><br><span class="line"> <span class="comment">/** Persistent cursor. */</span></span><br><span class="line"> <span class="type">btr_pcur_t</span> *m_pcur&#123;&#125;;   <span class="comment">// 用于快速定位 m_rec 所在页的 B+ 树游标</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="字段说明"><a href="#字段说明" class="headerlink" title="字段说明"></a>字段说明</h3><ol>
<li><code>m_heap</code>：用于在堆上分配和管理该 Iter 所需的临时内存，包括存放记录副本、tuple 结构和游标状态等。</li>
<li><code>m_offsets</code>：指向一组 ulint，用于记录 m_rec 中每列在页面上的偏移位置，以便快速定位列值。</li>
<li><code>m_rec</code>：原始记录指针（raw record），标记分片边界的具体行数据。</li>
<li><code>m_tuple</code>：m_rec 的逻辑封装（<code>dtuple_t</code>），两端 Iter 的 <code>m_tuple</code> 共同定义了扫描区间；扫描时常直接基于 <code>m_tuple</code> 进行比较和移动。</li>
<li><code>m_pcur</code>：持久化游标（<code>btr_pcur_t*</code>），用于记录定位 <code>m_rec</code> 所在页面和行号，后续扫描可通过该游标快速恢复上次位置，而无需从根节点重定位。</li>
</ol>
<h4 id="支持的语句类型"><a href="#支持的语句类型" class="headerlink" title="支持的语句类型"></a>支持的语句类型</h4><p>目前，InnoDB 并行扫描支持以下全表操作场景：</p>
<ul>
<li><code>SELECT COUNT(*) FROM table1;</code> 完整扫描主键索引并行计数。</li>
<li><code>CHECK TABLE table1;</code> 第二次扫描主键索引时可并行校验。</li>
<li><code>CREATE INDEX … ON table1</code> &#x2F; <code>ALTER TABLE … ADD INDEX …</code> 扫描和排序阶段支持并行，B+ 树构建阶段仍为单线程。</li>
<li><code>ALTER TABLE … ENGINE=InnoDB</code> &#x2F; <code>OPTIMIZE TABLE</code> 重建表阶段扫描主键索引不并行，排序和索引构建支持并行。</li>
</ul>
<h4 id="限制与注意事项"><a href="#限制与注意事项" class="headerlink" title="限制与注意事项"></a>限制与注意事项</h4><ul>
<li>并行扫描仅适用于主键索引，不支持二级索引扫描或包含虚拟列、全文索引、空间索引的表。</li>
<li>并行线程读取的数据页会被放到缓冲池 LRU 链表尾部，避免在扫描时占用过多热页。</li>
<li>当并行线程数超过子树数量时，实际使用的线程数取两者中的最小值。</li>
</ul>
<h2 id="B-树索引"><a href="#B-树索引" class="headerlink" title="B+ 树索引"></a>B+ 树索引</h2><p>B+ 树是为磁盘或其他直接存取辅助设备设计的一种自平衡的多路查找树。在 B+ 树中，所有记录节点都是按键值的大小顺序放在同一层的叶子节点上，由各叶子节点指针进行连接。</p>
<p>B+ 树的非叶子节点只存储键值，不存储数据，而叶子节点存储了所有的数据，并且构成了一个有序双向链表。因此，范围查询时就可以直接通过叶子节点间的指针顺序访问整个查询范围内的所有记录，而无需对树进行多次遍历。</p>
<p>在B+ 树的实现中，节点的大小往往被设计为与磁盘页大小相同（或者是其整数倍）。相比于 B 树（非叶子节点中存储指针和数据），B+ 树的非叶子节点能够存储更多的指针，提升索引查找的效率并且减少磁盘 I&#x2F;O 次数，因为每次从磁盘中加载的节点携带了更多的指针信息。</p>
<p>以下是 B-Tree 的结构（绿色代表子节点的地址，黄色代表记录的主键，红色代表单条记录中除主键外的数据，之后的图也是如此）：</p>
<p><img src="/Users/yihangwei/blog/source/images/MySQL/mysql_index_bt.drawio.png" alt="img"></p>
<p>B-Tree可视化：<a target="_blank" rel="noopener" href="https://www.cs.usfca.edu/~galles/visualization/BTree.html">B-Tree Visualization</a></p>
<p>以下是 B+ 树的结构：</p>
<p><img src="/Users/yihangwei/blog/source/images/MySQL/mysql_index_bpt.drawio.png" alt="img"></p>
<p>B+ 树可视化：<a target="_blank" rel="noopener" href="https://www.cs.usfca.edu/~galles/visualization/BPlusTree.html">B+ Tree Visualization</a></p>
<p>也就是说，MySQL 索引数据结构在经典 B-Tree 的基础上，增加了一个指向相邻左右叶子节点的链表指针，形成了双向循环链表，这样可以方便范围查询和反向遍历。</p>
<p>如果需要在 B+树中从大值向小值进行范围查询，可以按以下步骤操作：</p>
<ul>
<li>定位到最右侧节点：首先，找到包含最大值的叶子节点。这通常通过从根节点开始向右遍历树的方式实现。</li>
<li>反向遍历：一旦定位到了最右侧的叶子节点，可以利用叶节点间的双向链表向左遍历。</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/rjzheng/p/12316685.html">为什么Mongodb索引用B树，而MySQL用B+树?</a>：在关系型数据库中，遍历操作比较常见，因此采用 B+ 树作为索引比较合适。而在非关系型数据库中，单一查询比较常见，因此采用 B 树作为索引比较合适。</p>
<p>B+ 树对于 B 树的优势：</p>
<ol>
<li>更高的查询效率： B+ 树叶子节点的双向链表使得范围查询时无需从根节点开始进行多次索引查询，只需顺序遍历双向链表即可。</li>
<li>更高的空间利用率：B+ 树非叶子节点只存储指针，使得单个节点能够存储更多的指针只指向子节点，且单次磁盘 I&#x2F;O 读取更多信息，减少 I&#x2F;O 读取次数。</li>
<li>更稳定的查询效率：B+ 树叶子节点深度相同，数据查询路径长度相同。</li>
</ol>
<p>B+ 树对于二叉树的优势：</p>
<ol>
<li>B+ 树的每个节点可以有 m 个子节点，而红黑树和二叉平衡树都只有 2 个。</li>
<li>普通二叉树存在退化的情况，如果它退化成链表，就相当于全表扫描。</li>
<li>读取数据的时候，是从磁盘先读到内存。平衡二叉树的每个节点只存储一个键值和数据，而 B+ 树可以存储更多的节点数据，树的高度也会降低，因此读取磁盘的次数就会下降，查询效率就快。</li>
</ol>
<p>为什么 InnoDB 存储引擎选择使用 B+Tree 索引结构？</p>
<ol>
<li>相比于二叉树（顺序插入数据行的情况下会退化成链表），B+Tree 更平衡，层级更少，搜索效率高。</li>
<li>就B-Tree（或 BST）而言，无论叶子节点还是非叶子节点都会保留数据，这样导致一页中存储的键减少，指针也减少了，要保存大量数据，只能增加树的高度，导致性能降低。</li>
<li>相比于 Hash 索引，B+Tree 支持范围匹配及排序操作。</li>
</ol>
<p>一棵 B+ 树能存储多少数据？</p>
<p>假如我们的主键 ID 是 bigint 类型，长度为 8 个字节。指针大小在 InnoDB 源码中设置为 6 字节，这样一共 14 字节。所以非叶子节点(一页)可以存储 $16384&#x2F;14&#x3D;1170$ 个这样的单元(键值+指针)。</p>
<p>一个指针指向一个存放记录的页，一页可以放 16 条数据，树深度为 2 的时候，可以存放 $1170*16&#x3D;18720$ 条数据。</p>
<p>同理，树深度为 3 的时候，可以存储的数据为 $1170<em>1170</em>16&#x3D;21902400$ 条记录。</p>
<p>理论上，在 InnoDB 存储引擎中，B+树的高度一般为 2-4 层，就可以满足千万级数据的存储。查找数据的时候，一次页的查找代表一次 IO，当我们通过主键索引查询的时候，最多只需要 2-4 次 IO 就可以了。</p>
<h3 id="B-树的插入操作"><a href="#B-树的插入操作" class="headerlink" title="B+ 树的插入操作"></a>B+ 树的插入操作</h3><p>B+ 树的插入必须保证插入后叶子节点中的记录依然排序，同时需要考虑插入到 B+ 树的三种情况，每种情况都可能会导致不同的插入算法。具体如下：</p>
<p>叶子节点未满，索引节点未满：直接将记录插入到目标叶子节点的合适位置（保持有序）。</p>
<p>叶子节点已满，索引节点未满：</p>
<ul>
<li>拆分叶子节点为左右两个节点。</li>
<li>将中间键值提升为分隔键，插入到父级索引页。</li>
<li>原叶子节点中：<ul>
<li>小于中间键值的记录 → 左侧新页；</li>
<li>大于等于中间键值的记录 → 右侧新页。</li>
</ul>
</li>
</ul>
<p>叶子节点和索引节点都已满：</p>
<ul>
<li><p>拆分叶子节点（Leaf Page）：</p>
<ul>
<li>小于中间键值的记录 → 左页；</li>
<li>大于等于中间键值的记录 → 右页；</li>
</ul>
</li>
<li><p>将中间键值提升为分隔键，插入到父级索引页。</p>
</li>
<li><p>由于父级索引页也已满，继续处理其溢出：</p>
<ul>
<li>拆分 Index Page：<ul>
<li>小于中间索引值的记录 → 左侧索引页；</li>
<li>大于中间索引值的记录 → 右侧索引页；</li>
</ul>
</li>
<li>将新的中间索引项继续提升到上一层索引页中。</li>
</ul>
</li>
<li><p>若上一层索引页仍满，则继续递归，直到根节点；若根节点也满，最终会导致根节点分裂，树高度增加。</p>
</li>
</ul>
<p>因此，不管怎么变化，B+ 树总是会保持平衡。但是为了保持平衡，对于新插入的键值可能需要做大量的拆分页操作。因为 B+ 树结构主要用于磁盘，页的拆分意味着磁盘的操作，所以应当在可能的情况下尽量减少页的拆分操作。因此，B+ 树同样提供了类似于平衡二叉树的旋转功能。</p>
<p>旋转发生在叶子页（Leaf Page）已经满，但其左右兄弟节点没有满的情况下。这时 B+ 树并不会急于做拆分页的操作，而是将记录移到所在页的兄弟节点上。在通常情况下，会首先检查左兄弟以执行旋转操作。在下面的例子中：若插入键值 70，B+ 树并不会立即拆分叶子节点，而是先做旋转操作。</p>
<p><img src="/Users/yihangwei/blog/source/images/MySQL/mysql_index_insert.drawio.png" alt="img"></p>
<p>我们可以看到，旋转操作使得 B+ 树减少了一次页的拆分操作，同时这棵 B+ 树的高度依然为 2。</p>
<h3 id="B-树的删除操作"><a href="#B-树的删除操作" class="headerlink" title="B+ 树的删除操作"></a>B+ 树的删除操作</h3><p>B+ 树使用填充因子（fill factor）来控制树的删除变化，50% 是填充因子可设的最小值。B+ 树的删除操作同样必须保证删除后叶子节点中的记录依然排序。与插入一样，B+ 树的删除操作同样需要考虑三种情况，根据填充因子的变化来衡量是否需要进行节点合并或旋转操作。</p>
<table>
<thead>
<tr>
<th>叶子节点小于填充因子</th>
<th>中间节点小于填充因子</th>
<th>操作</th>
</tr>
</thead>
<tbody><tr>
<td>No</td>
<td>No</td>
<td>直接将记录从叶子节点删除，如果该节点还是 Index Page 的节点，用该节点的右兄弟节点代替</td>
</tr>
<tr>
<td>Yes</td>
<td>No</td>
<td>合并叶子节点和它的兄弟节点，同时更新对应的 Index Page</td>
</tr>
<tr>
<td>Yes</td>
<td>Yes</td>
<td>1. 合并叶子节点和它的兄弟节点  <br>2. 更新对应的 Index Page  <br>3. 合并 Index Page 和它的兄弟节点</td>
</tr>
</tbody></table>
<p>对于第一种情况的后半部分的解释：</p>
<p>在以下 B+ 树中，我们删除键值为 25 的记录，因为该值也是 Index Page 中的值，所以在删除之后，需要将 25 的右兄弟节点的 28 更新到 Index Page 中。</p>
<p><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXc-3feMxr84B_-kt25mWBV_8u0WGGMDr5gmKSFlKRcTF_uq4uQdVsI4Hre595QP04zMbtHcznOTb5-EqCHfMAk_CGq-vdPCPmNo75z6aEP_rdd1qsGJTvQsUUPMNeVHKhlRNPT0FQ?key=axl_AuXN1-d7hfqfHYm2Ng" alt="img"></p>
<p>以下是删除之后的 B+ 树。</p>
<p><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfHxhdAff5evZoJ42nTnSvwbE_j91Z1OYfhYwAq3TpVYhnaNd7TflZv2TmOGUcHkSzHgiWKS0ZNdVBLAgoo5qzfa4zeYxihLJxp5wMqylc86ka--Z25IpaeMTB8X9Y125oIP8au?key=axl_AuXN1-d7hfqfHYm2Ng" alt="img"></p>
<p>这时，如果删除 Leaf Page 中键值为 60 的记录，那么 Fill Factor 小于 50%，需要做合并操作；同样，在删除 Index Page 中相关记录后，需要做 Index Page 的合并操作。结果如下：</p>
<p><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXd4ndTr3qO9S2l_Ubs0XkAmBGf-yQEHFyCZRL6VyaTvFUBgWuT4uLfk33B1pF-CNBf0VpaQGfYZw5Tbd1H-xu873jWWNvWLbLCS2eidNeqLQNQEIzkZgXAKKYAHIzvrq-7zcJ7p?key=axl_AuXN1-d7hfqfHYm2Ng" alt="img"></p>
<p>注意：页面合并时，<strong>首先</strong>尝试与<strong>左侧</strong>直接相邻的兄弟页合并；仅在左侧不符合条件时，才会检查右侧兄弟页。如果左右两侧都没有足够的空间容纳当前页的所有记录，合并操作将不会执行，页面将保持“半空”状态，直到后续操作（如父节点合并或树高度调整）触发新的重组逻辑。合并成功后，还需在父节点中删除对应的指针条目，并在必要时向上递归合并或降高。</p>
<h3 id="聚集索引"><a href="#聚集索引" class="headerlink" title="聚集索引"></a>聚集索引</h3><p>数据库中的 B+ 树索引可以分为聚集索引（clustered index）和辅助索引（secondary index）。但是无论是聚集索引还是辅助索引，其内部结构都是 B+ 树，即高度平衡的，且叶子节点存放所有的数据。聚集索引与辅助索引的不同之处在于：叶子节点存放的是否是一整行的信息。</p>
<p>之前已经介绍过，InnoDB 存储引擎表是索引组织表，即表中数据按照主键顺序存放。而聚集索引（clustered index）就是按照每张表的主键构造一棵 B+ 树，同时叶子子节点中存放的即为整张表的行记录数据，也将聚集索引的叶子节点称为数据页。聚集索引的这个特性决定了索引组织表中数据也是索引的一部分。同 B+ 树数据结构一样，每个数据页都通过一个双向链表来进行链接。</p>
<p>由于实际的数据页只能按照一棵 B+ 树进行排序，因此每张表只能拥有一个聚集索引。在多数情况下，查询优化器倾向于采用聚集索引。因为聚集索引能够在 B+ 树索引的叶子节点上直接找到数据。此外，由于定义了数据的逻辑顺序，聚集索引能够特别快速地访问针对范围值的查询。查询优化器能够快速发现某一段范围的数据页需要扫描。</p>
<p>例如：</p>
<p>CREATE TABLE t (</p>
<p> a INT NOT NULL,</p>
<p> b VARCHAR(8000),</p>
<p> c INT NOT NULL,</p>
<p> PRIMARY KEY (a),</p>
<p> KEY idx_c (c)</p>
<p>) ENGINE&#x3D;InnoDB;</p>
<p>INSERT INTO t SELECT 1, REPEAT(‘a’, 7000), -1;</p>
<p>INSERT INTO t SELECT 2, REPEAT(‘a’, 7000), -2;</p>
<p>INSERT INTO t SELECT 3, REPEAT(‘a’, 7000), -3;</p>
<p>INSERT INTO t SELECT 4, REPEAT(‘a’, 7000), -4;</p>
<p>我们可以发现数据页上存放的是完整的每行记录，而在非数据页的索引页中，存放的仅仅是键值及指向数据页的偏移量，而不是一个完整的行记录。具体结构如下：</p>
<p><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcUw-Wi_-u8YThoxSz_9ChyHQgVpgR_xz7VCDquhNQjalygS8JgE3yV-oTbAQlwSHIbanb2IAp7Y9h9d9RTzvbOJNxH7Xcl7FMYuKewIMQFFAcKrTEc-0wu7692FYn5PJTu0pre3w?key=axl_AuXN1-d7hfqfHYm2Ng" alt="img"></p>
<p>许多资料会说：聚集索引按照顺序物理地存储数据。但是试想一下，如果聚集索引必须按照特定顺序存放物理记录，则维护成本显得非常之高。所以，聚集索引的存储并不是物理上连续的，而是逻辑上连续的。这其中有两点： </p>
<ol>
<li>前面说过的页通过双向链表链接，页按照主键的顺序排列； </li>
<li>每个页中的记录也是通过双向链表进行维护的，物理存储上可以不按主键存放。</li>
</ol>
<p>说白了，就是在物理存储时，不同页和页内记录的数据块可以散布在数据文件各处，通过上述链表结构保证逻辑遍历顺序，从而大幅降低维护开销。</p>
<p>聚集索引的另一个好处是，它对于主键的排序查找和范围查找速度非常快。叶子节点的数据就是用户所要查询的数据。</p>
<p>还有就是范围查询（range query），即如果要查找主键某一范围内的数据，通过叶子节点的上层中间节点就可以得到页的范围，之后直接读取数据页即可。</p>
<p>此外，聚集索引存在如下选取规则：</p>
<ul>
<li>如果存在主键，主键索引就是聚集索引。</li>
<li>如果不存在主键，将使用第一个遇到的唯一索引作为聚集索引。</li>
<li>如果既没有主键也没有合适的唯一索引，则自动生成一个以单调递增的 row ID 作为键的隐藏聚集索引。</li>
</ul>
<h3 id="辅助索引"><a href="#辅助索引" class="headerlink" title="辅助索引"></a>辅助索引</h3><p><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcYrKiTVUZvUrprdCQhKjOU4-9RZ83DsLAvnEoEtFMSH73d0EuH_Ij8DiBxaF_Qg6oVyCj1zTSUp-cOQkeSMhffe1KsxzX3zCdds49bCKoi80q1-_HyEbukZQJ7VSJgQhxZHFCINVXoa7MJT-6kGUef2Kjp?key=axl_AuXN1-d7hfqfHYm2Ng" alt="img"></p>
<p>对于辅助索引（Secondary Index，也称非聚集索引），叶子节点并不包含行记录的全部数据。也就是说，叶子节点除了包含键值以外，每个叶子节点中的索引行中还包含了一个书签。该书签用来告诉 InnoDB 存储引擎哪里可以找到与该索引行对应的行数据。由于 InnoDB 存储引擎表是索引组织表，因此辅助索引的书签就是相应行数据在聚集索引中的聚集索引键。</p>
<p>辅助索引的存在并不影响数据在聚集索引中的组织，因此每张表上可以有多个辅助索引。当通过辅助索引来寻找数据时，InnoDB 存储引擎会：</p>
<ol>
<li>遍历辅助索引树，到达叶子节点后获得对应行的聚集索引键；</li>
<li>再通过聚集索引树查找该主键，定位到完整的行记录所在的数据页。</li>
</ol>
<p>举例来说，如果辅助索引树的高度为 3，则需要 3 次查找才能找到指定的主键；若聚集索引树的高度也为 3，则还需要额外 3 次查找才能在聚集索引中定位到完整行的数据页。因此，总共需要 6 次逻辑 I&#x2F;O 访问，才能得到最终的数据页。</p>
<p>示例：</p>
<p>在之前的表 t 上新增一列 c，并对列 c 创建聚集索引：</p>
<p>mysql&gt; ALTER TABLE t</p>
<p>  -&gt; ADD c INT NOT NULL;</p>
<p>Query OK, 4 rows affected (0.24 sec)</p>
<p>Records: 4 Duplicates: 0 Warnings: 0</p>
<p>mysql&gt; UPDATE t SET c &#x3D; 0 - a;</p>
<p>Query OK, 4 rows affected (0.04 sec)</p>
<p>Rows matched: 4 Changed: 4 Warnings: 0</p>
<p>mysql&gt; ALTER TABLE t ADD KEY idx_c (c);</p>
<p>Query OK, 4 rows affected (0.28 sec)</p>
<p>Records: 4 Duplicates: 0 Warnings: 0</p>
<p>更改之后的索引结构如下：</p>
<p><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXem5N3Wx-sM9UcsAiX24vlZjyIDcMVC_0_QD_fUo3rKUbwzUweng0IflJNq7mqYuth4y9v7MXaadPAuW01nGsrKzHXP0Q9jZJSeInArt3E653HoWvur7JGL48wvzqAB5MeRSqV6?key=axl_AuXN1-d7hfqfHYm2Ng" alt="img"></p>
<p>上图显示了表 t 中辅助索引 idx_c 和聚集索引的关系。可以看到辅助索引的叶子节点中包含了列 c 的值和主键的值。因为这里的键值为负值，所以会发现以 7f ff ff ff 的方式进行内部存储。7（0111）最高位为 0，代表负值，实际的值应该取反后加 1，即得 -1。</p>
<h3 id="B-树索引的分裂"><a href="#B-树索引的分裂" class="headerlink" title="B+ 树索引的分裂"></a>B+ 树索引的分裂</h3><p>之前介绍的 B+ 树分裂是最为简单的一种情况，这和数据库中 B+ 树索引的实际情况可能略有不同，因为并未涉及并发，而这才是 B+ 树索引实现中最为困难的部分。</p>
<p>B+ 树索引页的分裂并不总是从页的中间记录开始，这样可能会导致页空间的浪费。例如下面的记录：</p>
<p>1, 2, 3, 4, 5, 6, 7, 8, 9</p>
<p>插入是根据自增顺序进行的，若此时插入第 10 条记录后需要进行页的分裂操作，那么根据之前介绍的分裂方法，会将记录 5 作为分裂点记录，分裂后得到下面两个页：</p>
<p>Page 1: 1, 2, 3, 4</p>
<p>Page 2: 5, 6, 7, 8, 9, 10</p>
<p>由于插入是顺序的，P1 这个页将不会再有新记录被插入，从而导致空间浪费；而 P2 又会再次进行分裂。</p>
<p>InnoDB 存储引擎的 Page Header 中有以下几个部分用来保存在页中记录插入的顺序信息：</p>
<p>PAGE_LAST_INSERT<br>PAGE_DIRECTION<br>PAGE_N_DIRECTION</p>
<p>通过这些信息，InnoDB 存储引擎可以决定是向左还是向右进行分裂，同时决定将分裂点记录为哪一个。若插入是随机的，则取页中的中间记录作为分裂点记录，这和之前介绍的相同。若往同一方向进行插入的记录数量为 5，并且目前已定位（cursor）到的记录（该记录为待插入记录的前一条记录）之后还有 3 条记录，则分裂点记录为定位到的记录后的第三条记录；否则，分裂点记录就是待插入的记录。</p>
<p>示例：</p>
<p>下面来看一个向右分裂的例子，并且定位到的记录之后还有 3 条记录，则分裂点记录如下：</p>
<p><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXeiZuh6_PEBlVj1ngCKWYQrfOQvPINJsgJsooOhjYMYF8vDKduqFKQjaZ1zPJkB_8JNptfqGxeXcnj6hOj37C_f9fWcImaY_TNFr6L4KkMUjDgq2kQ-IpgwhAaLiXn8GT8KhDBgkw?key=axl_AuXN1-d7hfqfHYm2Ng" alt="img"></p>
<p>最终结果如下：</p>
<p><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcE08dhMdi4n6OXHo8iWhd2duiV1hnF7JZSsTUq1mE9V_g4EQEpYjpdKRvAt38k2xJXg4PBjfUSrpcT2_v4fPF67ZqKs2txcGa1F6LXN_2uYkrKx4gEzhsNcQ0l2bgOMw8i_raCpA?key=axl_AuXN1-d7hfqfHYm2Ng" alt="img"></p>
<p>接着是分裂点就为插入记录本身：</p>
<p><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXeaURjNR8u_V3mQKkIFycutUccQ44oY4bnIh2RjxaWyCFz7WevKWs6m3YIoJArzqc8o2Aroh-5lmue20wQyk_dt5XhzPbiIVjnUQXfaYPkms78zQNbOdg7s3HYBgyUMMNUKhqIEoQ?key=axl_AuXN1-d7hfqfHYm2Ng" alt="img"></p>
<h3 id="B-树的管理"><a href="#B-树的管理" class="headerlink" title="B+ 树的管理"></a>B+ 树的管理</h3><h4 id="索引管理"><a href="#索引管理" class="headerlink" title="索引管理"></a>索引管理</h4><p>索引的创建和删除可以通过两种方法，一种是 ALTER TABLE，另一种是 CREATE&#x2F;DROP INDEX。通过 ALTER TABLE 创建索引的语法为：</p>
<p>ALTER TABLE tbl_name</p>
<p> ADD [INDEX|KEY] [index_name]</p>
<p> [index_type] (index_col_name, …) [index_option] …</p>
<p>ALTER TABLE tbl_name</p>
<p> DROP PRIMARY KEY</p>
<p> | DROP {INDEX|KEY} index_name</p>
<p>CREATE&#x2F;DROP INDEX 的语法同样很简单：</p>
<p>CREATE [UNIQUE] INDEX index_name</p>
<p> [index_type]</p>
<p> ON tbl_name (index_col_name, …)</p>
<p>DROP INDEX index_name ON tbl_name</p>
<p>用户可以设置对整个列的数据进行索引，也可以只索引一列的开头部分数据，如前面创建的表 t，列 b 为 varchar(8000)，但是用户可以只索引前 100 个字段，如：</p>
<p>mysql&gt; ALTER TABLE t</p>
<p>  -&gt; ADD KEY idx_b (b(100));</p>
<p>Query OK, 4 rows affected (0.32 sec)</p>
<p>Records: 4 Duplicates: 0 Warnings: 0</p>
<p>若用户想要查看表中索引的信息，可以使用命令 SHOW INDEX。我们以主键列为例，结果如下：</p>
<p>mysql&gt; SHOW INDEX FROM t\G;</p>
<p>*************************** 1. row ***************************</p>
<p>​    Table: t</p>
<p>​    Non_unique: 0</p>
<p>​    Key_name: PRIMARY</p>
<p>​    Seq_in_index: 1</p>
<p>​    Column_name: a</p>
<p>​    Collation: A</p>
<p>​    Cardinality: 2</p>
<p>​    Sub_part: NULL</p>
<p>​    Packed: NULL</p>
<p>​    Null: </p>
<p>​    Index_type: BTREE</p>
<p>​    Comment: </p>
<p>…</p>
<p>以上结果中每列的含义如下：</p>
<p><strong>Table</strong>：索引所在的表名。</p>
<p><strong>Non_unique</strong>：非唯一的索引，可以看到 primary key 是 0，因为必须是唯一的。</p>
<p><strong>Key_name</strong>：索引的名字，用户可以通过这个名字来执行 DROP INDEX。</p>
<p><strong>Seq_in_index</strong>：索引中该列的位置，如果看联合索引 idx_a_c 就比较直观了。</p>
<p><strong>Column_name</strong>：索引列的名称。</p>
<p><strong>Collation</strong>：列以什么方式存储在索引中。可以是 A 或 NULL。B+ 树索引总是 A，即排序的。如果使用了 Heap 存储引擎，并且建立了 Hash 索引，这里就会显示 NULL 了。因为 Hash 根据 Hash 桶存放索引数据，而不是对数据进行排序。</p>
<p><strong>Cardinality</strong>：非常关键的值，表示索引中唯一值的数目的估计值。Cardinality 表的行数应尽可能接近 1，如果非常小，那么用户需要考虑是否可以删除此索引。</p>
<p><strong>Sub_part</strong>：是否是列的部分被索引。如果看到 idx_b 这个索引，这里显示 100，表示只对 b 列的前 100 字符进行索引。如果索引整个列，则该字段为 NULL。</p>
<p><strong>Packed</strong>：关键字如何被压缩。如果没有被压缩，则为 NULL。</p>
<p><strong>Null</strong>：是否索引的列含有 NULL 值。可以看到 idx_b 这里为 Yes，因为定义的列 b 允许 NULL 值。</p>
<p><strong>Index_type</strong>：索引的类型。InnoDB 存储引擎只支持 B+ 树索引，所以这里显示的都是 BTREE。</p>
<p><strong>Comment</strong>：注释。</p>
<p>Cardinality 值非常关键，优化器会根据这个值来判断是否使用这个索引。但是这个值并不是实时更新的，即并非每次索引的更新都会更新该值，因为这样代价太大了。因此这个值是不太准确的，只是一个大概的值。上面显示的结果主键的 Cardinality 为 2，但是很显然我们表中有 4 条记录，这个值应该是 4。如果需要更新索引 Cardinality 的信息，可以使用 ANALYZE TABLE 命令。</p>
<p>另一个问题是 MySQL 数据库对于 Cardinality 计数的问题，在运行一段时间后，可能会看到下面的结果：</p>
<p>mysql&gt; show index from Profile\G;</p>
<p>*************************** 1. row ***************************</p>
<p>​    Table: Profile</p>
<p>​    Non_unique: 0</p>
<p>​    Key_name: UserName</p>
<p>​    Seq_in_index: 1</p>
<p>​    Column_name: username</p>
<p>​    Collation: A</p>
<p>​    Cardinality: NULL</p>
<p>​    Sub_part: NULL</p>
<p>​    Packed: NULL</p>
<p>​    Null: </p>
<p>​    Index_type: BTREE</p>
<p>​    Comment: </p>
<p><strong>Cardinality</strong> 为 NULL，在某些情况下可能会发生索引建立了却没有用到的情况。或者对两条基本一样的语句执行 EXPLAIN，但是最终出来的结果不一样：一个使用索引，另外一个使用全表扫描。</p>
<p>这时最好的解决办法就是做一次 ANALYZE TABLE 的操作。因此建议在一个非高峰时间，对应用程序下的几张核心表做 ANALYZE TABLE 操作，这能使优化器和索引更好地为你工作。</p>
<h4 id="Fast-Index-Creation"><a href="#Fast-Index-Creation" class="headerlink" title="Fast Index Creation"></a>Fast Index Creation</h4><p>MySQL 5.5 版本之前（不包括 5.5）存在的一个普遍被人诟病的问题是 MySQL 数据库对于索引的添加或者删除的这类 DDL 操作，MySQL 数据库的操作过程是：</p>
<ul>
<li>首先创建一张新的临时表，表结构为通过命令 ALTER TABLE 新定义的结构。</li>
<li>然后把原表中数据导入到临时表。</li>
<li>接着删除原表。</li>
<li>最后把临时表重名为原来的表名。</li>
</ul>
<p>可以发现，若用户对一张大表进行索引的添加和删除操作，那么会花费很长的时间。更关键的是，若有大量事务需要访问正在被修改的表，这意味着数据库服务不可用。</p>
<p><strong>InnoDB</strong> 存储引擎从 <strong>InnoDB 1.0.x</strong> 版本开始支持一种称为 <strong>Fast Index Creation（快速索引创建）</strong> 的索引创建方式——简称 <strong>FIC</strong>。</p>
<p>对于辅助索引的创建，InnoDB 存储引擎会对创建索引的表加上一个 <strong>S 锁</strong>。在创建的过程中，不需要重建表，因此速度较之前提高很多，并且数据库的可用性也得到了提高。<br> 删除辅助索引操作就更简单了，InnoDB 存储引擎只需更新内部视图，并将辅助索引的空间标记为可用，同时触发 MySQL 数据库内部视图上对该索引定义即可以。</p>
<p>这里需要特别注意的是，临时表的创建路径是通过参数 tmpdir 进行设置的。用户必须保证 tmpdir 有足够的空间可以存放临时表，否则会导致创建索引失败。</p>
<p>由于 FIC 在索引的创建中对表加上了 S 锁，因此在创建的过程中只能对该表进行 <strong>读操作</strong>，若有大量的事务需要对目标表进行写操作，那么数据库的服务同样不可用。此外，FIC 方法只限用于 <strong>辅助索引</strong>，对于主键的创建和删除同样需要重建一张表。</p>
<h4 id="Online-Schema-Change"><a href="#Online-Schema-Change" class="headerlink" title="Online Schema Change"></a>Online Schema Change</h4><p>Online Schema Change（OSC）是一种用于 <strong>在线执行 MySQL DDL 操作</strong> 的技术，最早由 Facebook 推出并开源，旨在解决传统 DDL 操作期间数据库不可用的问题。通过 OSC，用户可以在 <strong>不中断业务访问的前提下</strong> 对表结构进行修改，如添加索引、修改字段等。</p>
<p>其核心思想是通过复制原表结构创建一张临时表，并在数据迁移和结构变更过程中，借助触发器记录原表的变更操作（DML）。在数据导入和变更同步完成后，再将原表与新表进行原子性“换名”操作，从而实现无缝切换。</p>
<h4 id="Online-DDL"><a href="#Online-DDL" class="headerlink" title="Online DDL"></a>Online DDL</h4><p>虽然 FIC 可以让 InnoDB 存储引擎避免创建临时表，从而提高索引创建的效率，但正如前面章节所说的，索引创建时会阻塞表上的 DML 操作。OSC 虽然解决了上述的部分问题，但还是有很大的局限性。</p>
<p>MySQL 从 5.6 版本开始支持 <strong>Online DDL（在线数据定义）</strong> 操作，其允许在辅助索引创建的同时，还允许其他诸如 INSERT、UPDATE、DELETE 这类 DML 操作，这极大地提高了 MySQL 数据库在生产环境中的可用性。</p>
<p>此外，不仅是辅助索引，以下几类 DDL 操作都可以通过“在线”的方式进行操作：</p>
<ul>
<li><p>辅助索引的创建与删除</p>
</li>
<li><p>改变自增长值</p>
</li>
<li><p>添加或删除外键约束</p>
</li>
<li><p>列的重命名</p>
</li>
</ul>
<p>通过新的 ALTER TABLE 语法，用户可以选择索引的创建方式：</p>
<p>ALTER TABLE tbl_name</p>
<p> ADD [INDEX|KEY] [index_name]</p>
<p> [index_type] (index_col_name,…) [index_option] …</p>
<p> ALGORITHM [&#x3D;] {DEFAULT|INPLACE|COPY}</p>
<p> LOCK [&#x3D;] {DEFAULT|NONE|SHARED|EXCLUSIVE}</p>
<p><strong>ALGORITHM</strong> 指定了创建或删除索引的算法：</p>
<ul>
<li>COPY 表示按 MySQL 5.1 版本之前的工作模式，即创建临时表的方式。</li>
<li>INPLACE 表示索引创建或删除操作不需要创建临时表。</li>
<li>DEFAULT 表示根据参数 old_alter_table 判断是否使用 INPLACE 或 COPY 算法，默认值为 OFF，即采用 INPLACE 方式。</li>
</ul>
<p>LOCK 部分表示在创建或删除索引时对表加锁的情况，可选值包括：</p>
<ol>
<li>**NONE：**执行索引创建或删除操作时，对目标表不添加任何锁，即事务仍然可以进行读写操作，不会受到阻塞。因此该模式可以获得最大的并发度。</li>
<li>**SHARE：**与 FIC 类似，执行索引创建或删除操作时，对目标表加上一个 S 锁。对于读操作不影响，但会阻塞写操作。</li>
<li>**EXCLUSIVE：**执行索引创建或删除操作时，对目标表加上一个 X 锁。此时所有事务都不能进行，等同于 COPY 方式运行时的状态，但不需要创建临时表。</li>
<li>**DEFAULT：**默认模式下，系统会判断当前操作是否可以使用 NONE 模式，若不能，则判断是否可以使用 SHARE，最后才判断是否可以使用 EXCLUSIVE 模式。DEFAULT 会根据当前事务的最大并发性来自动选择 DDL 执行的锁定模式。</li>
</ol>
<p>InnoDB 存储引擎在执行 Online DDL 的过程中，会将 INSERT、UPDATE、DELETE 等 DML 操作的日志写入一个缓冲区，待索引创建完成后再将这些日志应用到表上，以此保证数据一致性。</p>
<p>这个缓冲区的大小由参数 innodb_online_alter_log_max_size 控制，默认值为 <strong>128MB</strong>。若在创建过程中遇到大量写事务，而缓冲区不够，会报错：</p>
<p>Error: 1799 SQLSTATE: HY000 (ER_INNODB_ONLINE_LOG_TOO_BIG)</p>
<p>Message: Creating index ‘idx_aaa’ required more than ‘innodb_online_alter_log_max_size’ bytes of modification log. Please try again.</p>
<p>为避免该错误，可通过调整 innodb_online_alter_log_max_size 获取更大的日志缓冲空间。此外，也可以设置 ALTER TABLE 的 LOCK &#x3D; SHARE 模式，以避免记录过多的 DML 日志。</p>
<p>需要特别注意的是，<strong>在 Online DDL 结束后，MySQL 会通过重放日志达到数据最终一致性</strong>。因此在索引创建过程中，SQL 优化器不会选择正在创建的索引。</p>
<h2 id="Cardinality"><a href="#Cardinality" class="headerlink" title="Cardinality"></a>Cardinality</h2><p>概念：Cardinality ≈ 列中不同值的数量 → 反映列的选择性。</p>
<p>判断索引价值</p>
<ul>
<li><p>高选择性（Cardinality ≈ 表行数）：建 B+ 树索引，能显著加速查询。</p>
</li>
<li><p>低选择性（取值极少，如性别、地区）：索引作用有限，通常不建。</p>
</li>
</ul>
<p>衡量方法：SHOW INDEX 查看 Cardinality；用 Cardinality &#x2F; 总行数 估算选择性。</p>
<p>注意：Cardinality 仅是估值，可能不精确，仍需结合实际查询频率和过滤比例综合判断。</p>
<h3 id="InnoDB-存储引擎的-Cardinality-统计"><a href="#InnoDB-存储引擎的-Cardinality-统计" class="headerlink" title="InnoDB 存储引擎的 Cardinality 统计"></a>InnoDB 存储引擎的 Cardinality 统计</h3><p>InnoDB 不会在每次索引变动时都重新计算 Cardinality，而是通过采样（Sample）方式周期性更新，以避免频繁统计带来的性能开销。更新时机主要有两个条件：</p>
<ol>
<li><p>表中已有数据发生变化占比 ≥ 1&#x2F;16</p>
<ol>
<li>上次统计后，若有至少六分之一的数据被插入或删除，则触发 Cardinality 重新计算。 </li>
<li>目的是：当表数据量大幅变化时，统计结果才会显著偏离实际。</li>
</ol>
</li>
<li><p>stat_modified_counter &gt; 2,000,000,000 </p>
<ol>
<li>InnoDB 内部维护一个计数器 stat_modified_counter，用于记录自上次索引统计（Cardinality 更新）以来，对表中<strong>单行数据</strong>执行 INSERT&#x2F;UPDATE 之类操作的累计次数；</li>
<li>若对某行数据的更新非常频繁——即使该表总行数未增减，但同一行被多次修改，也会触发 Cardinality 更新； </li>
<li>当 stat_modified_counter 累积值超过 20 亿，则认为存量数据“实质”发生变化，从而重新采样计算。</li>
</ol>
</li>
</ol>
<p>这种双重策略保证在“数据量变化大”或“单行更新极其频繁”时，InnoDB 能及时刷新索引选择性估计；平时不会因频繁 INSERT&#x2F;UPDATE 而频繁统计，以降低系统负担。 </p>
<p>InnoDB 通过对 B+ 树叶子页（Leaf Page）进行随机采样，估算索引的 Cardinality 值（不保证精确）。默认采样 8 个叶子页，步骤如下：</p>
<ol>
<li>获取叶子页总数：设定为 A，即 B+ 树索引中叶子节点的总数量。</li>
<li>随机选取 8 个叶子节点：对这 8 个数据页，分别统计每页中不同记录的个数，记为 P1、P2、…、P8。</li>
<li>计算估算值：Cardinality ≈ (P1 + P2 + … + P8) × A &#x2F; 8</li>
</ol>
<p>每次采样都可能选到不同的 8 个叶子页，故同一索引的 Cardinality 值会有所波动。也就是说，这是一个估算值，并非精准统计。</p>
<p>当表的叶子页数 ≤ 8 时，InnoDB 默认会对所有叶子页进行采样（即采样页数 ≥ 表叶子页数）。这意味着每次执行索引统计，选到的都是相同的页，导致观测到的 Cardinality 值始终一致。</p>
<p>InnoDB 采样配置</p>
<ol>
<li>innodb_stats_sample_pages</li>
</ol>
<p>用途：设置每次计算 Cardinality 时要采样的叶子页数量。</p>
<p>默认值：8。</p>
<p>如果将该值调小，采样精度会下降；调大则统计开销增加。</p>
<ol>
<li>innodb_stats_method<br> 控制统计时对索引列中 NULL 值的处理方式，可选取：<ul>
<li>nulls_equal（默认）：将所有 NULL 视为相同值。</li>
<li>nulls_unequal：将不同 NULL 视为不同值。</li>
<li>nulls_ignored：完全忽略 NULL 记录，不计入不同值。</li>
</ul>
</li>
</ol>
<p>示例<br>针对某页记录：NULL, NULL, 1, 2, 2, 3, 3, 3</p>
<ul>
<li>nulls_equal → 视为 {NULL, 1, 2, 3}, Cardinality &#x3D; 4</li>
<li>nulls_unequal → 视为 {NULL₁, NULL₂, 1, 2, 3}, Cardinality &#x3D; 5</li>
<li>nulls_ignored → 只计 {1, 2, 3}, Cardinality &#x3D; 3</li>
</ul>
<p>当执行 SQL 语句 ANALYZE TABLE、SHOW TABLE STATUS、SHOW INDEX 以及访问 INFORMATION_SCHEMA 架构下的表 TABLES 和 STATISTICS 时，会导致 InnoDB 存储引擎去重新计算索引的 Cardinality 值。若表中的数据量非常大，并且表中存在多个辅助索引时，执行上述这些操作可能会非常慢。虽然用户可能并不希望去更新 Cardinality 值。</p>
<p>Cardinality 的设置参数如下：</p>
<p><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdLAEWT92atDGwimmkVrUQqxBOkqhtQcR3CaKJWpa1_awhknxGVcTxly6YXm0m4i_0Yk8_0A_PA43NeyFVSSqINsmC92voGbusCrtXlxP51MDhoBsxahRmSQklgEUKfAKLe-e4eQA?key=axl_AuXN1-d7hfqfHYm2Ng" alt="img"></p>
<p>最后两个参数的区别：</p>
<p>persistent_sample_pages：针对“持久化统计”（ANALYZE TABLE 等）时使用，采样页数较多以提高持久化统计精度。</p>
<p>transient_sample_pages：针对“临时统计”（SHOW INDEX、SHOW TABLE STATUS、INFORMATION_SCHEMA 查询、或 innodb_stats_persistent&#x3D;OFF 时的抽样）时使用，采样页数较少以减少临时统计的开销。</p>
<h2 id="B-树索引的使用"><a href="#B-树索引的使用" class="headerlink" title="B+ 树索引的使用"></a>B+ 树索引的使用</h2><p>OLTP（联机事务处理）场景下，单次查询通常只访问非常少量的记录（往往 ≤ 10 条，有时甚至只取 1 条）。此时建立的 B+ 树索引主要用于通过主键或少量条件快速定位对应记录。只有当索引能够显著减少 IO、提高查询效率时才有意义，否则即使创建了索引，优化器也可能绕过直接全表扫描。</p>
<p>OLAP（联机分析处理）场景下，查询往往涉及对表中大量数据的聚合与统计，面向决策支持（如按月统计销售额、环比增长等）。此类查询关注“宏观视角”，索引设计应基于整体分析需求，而非针对单条记录检索。一般情况下，不会对诸如“姓名”等仅偶尔单独查询的字段建立索引；但常见做法是对用作分区或筛选条件的<strong>时间字段</strong>建索引，因为大多数统计都是基于时间维度进行过滤。<br>在多表联接（JOIN）操作中，若使用 Hash Join 等算法，索引的重要性会相对降低，需要结合具体执行计划来权衡是否添加索引。</p>
<p>因此，索引添加策略需“Think Different”，结合实际查询特点（选择性、扫描量、计算开销）和执行计划采样结果。</p>
<h3 id="联合索引"><a href="#联合索引" class="headerlink" title="联合索引"></a>联合索引</h3><p>单列索引：一个索引只包含单个列。</p>
<p>联合索引：一个索引包含多个列。</p>
<p>以下代码创建了一张 t 表，并且索引 idx_a_b 是联合索引，联合的列为 (a, b)。</p>
<p>CREATE TABLE t (</p>
<p>  a INT,</p>
<p>  b INT,</p>
<p>  PRIMARY KEY (a),</p>
<p>  KEY idx_a_b (a, b)</p>
<p>) ENGINE&#x3D;INNODB;</p>
<p>该表对应的联合索引结构如下：</p>
<p><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcsjKAQFNlnXm-hovx3m5Hpw8hdBpKXIc1LhdahBiBBh3XshfleJF14c9WMjdtkp30vUGweln8A5I8eUFjf-XV_vSqwAdEz0NOj4Kp2KCxtDCL9XPsvKdIwID6diDhF9_3b8MNl?key=axl_AuXN1-d7hfqfHYm2Ng" alt="img"></p>
<p>因此，对于查询 SELECT * FROM TABLE WHERE a&#x3D;xxx and b&#x3D;xxx，显然是可以使用 (a, b) 这个联合索引的。对于单个 a 列查询 SELECT * FROM TABLE WHERE a&#x3D;xxx，也可以使用这个 (a, b) 索引。但对于 b 列的查询 SELECT * FROM TABLE WHERE b&#x3D;xxx，则不可以使用这棵 B+ 树索引。可以发现叶子节点上的 b 值为 1、2、1、4、1、2，显然不是排序的，因此对于 b 列的查询使用不到 (a, b) 的索引。</p>
<p>联合索引的第二个好处是已经对第二个键值进行了排序处理。例如，在很多情况下应用程序都需要查询某个用户的购物情况，并按照时间进行排序，最后取出最近三次的购买记录，这时使用联合索引可以避免多一次的排序操作，因为索引本身在叶子节点已经排好了。</p>
<p>在业务场景中，如果存在多个查询条件，考虑针对查询字段建立索引时，建议建立联合索引，而非单列索引。</p>
<p>多条件联合查询时，MySQL 优化器会评估哪个字段的索引效率更高并且选择对应索引完成本次查询。</p>
<h3 id="覆盖索引"><a href="#覆盖索引" class="headerlink" title="覆盖索引"></a>覆盖索引</h3><p>在 InnoDB 中，覆盖索引（Covering Index）指的是查询只访问辅助索引就能获取所需字段的数据，不需要回表到主键索引（聚集索引）中再取数据。</p>
<p>此外，统计查询也能利用覆盖索引：</p>
<p>CREATE TABLE buy_log (</p>
<p>  userid INT UNSIGNED NOT NULL,</p>
<p>  buy_date DATE</p>
<p>) ENGINE&#x3D;InnoDB;</p>
<p>SELECT COUNT(*) FROM buy_log;</p>
<p>对于这个 SQL 语句，InnoDB 并不会选择通过查询聚集索引来进行统计，因为 buy_log 表上还有辅助索引，而辅助索引远小于聚集索引，这有助于减少 I&#x2F;O 操作。</p>
<p>而且，对于以下 SQL 语句：</p>
<p>SELECT COUNT(*) FROM buy_log</p>
<p>WHERE buy_date &gt;&#x3D; ‘2011-01-01’ AND buy_date &lt; ‘2011-02-01’;</p>
<p>即使查询条件中只用到联合索引的第二列 buy_date，但因为查询是统计操作，且能完全由索引提供数据，优化器依然会选择 (userid, buy_date) 联合索引作为覆盖索引使用。</p>
<h3 id="前缀索引"><a href="#前缀索引" class="headerlink" title="前缀索引"></a>前缀索引</h3><p>当字段类型为 varchar，text 等时，有时候需要索引很长的字符串，这会让索引变得很大，查询时消费大量的磁盘 I&#x2F;O。因此我们可对字符串的<strong>前缀</strong>建立索引，可极大节省索引空间，提高索引效率。</p>
<p><strong>create</strong> <strong>index</strong> idx_xxx <strong>on</strong> table_name(column_name(n));</p>
<p>前缀长度选择：根据索引的选择性（和区分度类似）来决定，选择性是指不重复的索引值和数据表的记录总数的比值，索引选择性越高则查询效率越高（选择性最高为 1）。</p>
<p><strong>select</strong> <strong>count</strong>(<strong>distinct</strong> email) &#x2F; <strong>count</strong>(*) <strong>from</strong> table_name;</p>
<p><strong>select</strong> <strong>count</strong>(<strong>distinct</strong> <strong>substring</strong>(email, <strong>start</strong>, <strong>end</strong>)) &#x2F; <strong>count</strong>(*) <strong>from</strong> table_name;</p>
<p>查询流程</p>
<ol>
<li>构建聚集索引和 email 指定长度的前缀索引。</li>
<li>获取 where 后的条件查询字符串的指定长度的前缀，在对应 email 的索引中匹配获取对应行的 id，回表查询获取完整行。</li>
<li>比较该行中的 email 字符串是否等于查询字符串；如果是，则返回结果，之后查询 B+Tree 中下一个元素是否匹配 email 前缀，重复操作。</li>
<li>组装数据。</li>
</ol>
<h3 id="优化器选择不使用索引的情况"><a href="#优化器选择不使用索引的情况" class="headerlink" title="优化器选择不使用索引的情况"></a>优化器选择不使用索引的情况</h3><p>在某些场景下，即使有可用索引，执行 EXPLAIN 会发现优化器 没有选择索引，而是采用了 全表扫描（table scan） 或 聚集索引扫描（PRIMARY key scan），而不是使用辅助索引。</p>
<p>查询语句如下：</p>
<p>SELECT * FROM orderdetails WHERE orderid &gt; 10000 AND orderid &lt; 102000;</p>
<p>该语句选择扫描聚集索引，也就是全表扫描。</p>
<p>原因分析</p>
<ol>
<li>索引无法覆盖查询字段<ul>
<li>由于 SELECT * 需要返回整行记录，而 OrderID 是辅助索引，无法覆盖所有字段，导致必须回表。</li>
<li>回表的过程需要通过主键访问聚集索引数据页，这会产生额外的 I&#x2F;O。</li>
</ul>
</li>
<li>顺序读 vs 随机读<ul>
<li>聚集索引在磁盘上是物理顺序存储的，直接扫描比辅助索引 + 回表更高效（尤其当命中率低时）。</li>
<li>特别是在机械硬盘环境下，顺序读（聚集索引）性能远优于多次随机读（回表）。</li>
</ul>
</li>
<li>数据访问比例高时<ul>
<li>当查询返回的数据行占总行数较大（例如 &gt;20%）时，优化器认为直接顺序扫描整张表更快。</li>
</ul>
</li>
</ol>
<p>对于机械硬盘来说，顺序读取（聚集索引或全表扫描）远快于随机读（辅助索引 + 回表）。因此，当查询返回的行数占表的较大比例（≈20％ 或更高）时，优化器往往选择全表扫描，而不是使用辅助索引。</p>
<p>如果底层存储是固态硬盘（SSD），随机读性能就足够高，且对性能的影响较小，我们可以强制使用辅助索引来减少扫描行数。</p>
<p>USE INDEX 只是告诉优化器可以选择该索引，但实际上优化器还是会根据自己的判断进行选择。</p>
<p>FORCE INDEX 则强制优化器必须使用该索引。</p>
<p><strong>select</strong> * <strong>from</strong> <strong>table</strong> <strong>use</strong> <strong>index</strong>(idx) <strong>where</strong> …;<br><strong>select</strong> * <strong>from</strong> <strong>table</strong> <strong>ignore</strong> <strong>index</strong>(idx) <strong>where</strong> …;<br><strong>select</strong> * <strong>from</strong> <strong>table</strong> <strong>force</strong> <strong>index</strong>(idx) <strong>where</strong> …;</p>
<h3 id="Multi-Range-Read-MRR-优化"><a href="#Multi-Range-Read-MRR-优化" class="headerlink" title="Multi-Range Read (MRR) 优化"></a>Multi-Range Read (MRR) 优化</h3><p>从 MySQL 5.6.0 开始，InnoDB 和 MyISAM 存储引擎支持 MRR（多范围读取）优化。</p>
<p>目标：尽可能减少磁盘的随机读，将随机访问转换为相对顺序的访问，以提升 I&#x2F;O 密集型查询的性能。</p>
<p>适用场景：对索引范围（range）、引用（ref）或等值引用（eq_ref）类型查询，尤其是在需要根据辅助索引快速定位大量匹配行，然后回表查数据的场景。</p>
<p>MRR 优化的几个好处：</p>
<p><strong>使数据访问变得更顺序</strong></p>
<ul>
<li><p>首先通过辅助索引找出所有符合条件的索引键值，把它们缓存在内存里（已经是按索引顺序排列的）。</p>
</li>
<li><p>然后按照主键（或聚簇索引）顺序对这些键值进行排序，最后再一次性按排好序的顺序访问实际数据页，从而将随机 I&#x2F;O 转为顺序 I&#x2F;O。</p>
</li>
</ul>
<p><strong>减少缓冲池中页被置换的次数</strong></p>
<ul>
<li>由于访问顺序更可预测，针对热点数据页的重复访问更集中，降低了缓存页被逐出后又立刻被读回的情况。</li>
</ul>
<p><strong>批量处理对键值的查询操作</strong></p>
<ul>
<li>将多个单独的索引查找合并成一次批量处理，更好地利用缓存和预取，提高吞吐量。</li>
</ul>
<p>MRR 的工作流程（以 InnoDB 和 MyISAM 为例）</p>
<ol>
<li>收集辅助索引键值<ul>
<li>执行范围或引用类型的索引查找时，先把所有满足条件的辅助索引键值（包含对应的 RowID 或主键）一次性读到一个临时缓冲区中。此时缓冲区中的键值已经是按辅助索引顺序排列的。</li>
</ul>
</li>
<li>对键值进行排序<ul>
<li>根据读到的所有主键（RowID）值，对缓冲区内记录按主键顺序排序（这一步把索引顺序转换为主键顺序）。</li>
</ul>
</li>
<li>按主键顺序批量访问数据页<ul>
<li>根据排好序的主键顺序依次访问 InnoDB&#x2F; MyISAM 数据文件，从而尽可能采用顺序读，减少随机 I&#x2F;O。</li>
</ul>
</li>
<li>注意缓冲池大小的影响<ul>
<li>如果 InnoDB 或 MyISAM 的缓冲池&#x2F;缓存（Buffer Pool &#x2F; Key Cache）足够大，可以一次性容纳整个表或者大部分热数据页，则 MRR 优化效果最明显。</li>
<li>若缓冲池不足以存放大量页，那么在批量读回过程中仍可能引起页被换出和换入，导致性能下降。</li>
</ul>
</li>
</ol>
<p>MRR 还可以将 <strong>复合索引</strong>（联合索引）上的多列范围查询拆分为一系列更细粒度的“键值对”，并对它们批量执行查询，从而在拆分过程中进一步“过滤”掉不符合条件的记录，避免不必要的回表。</p>
<p>假设 t 表有联合索引 (key_part1, key_part2)，当执行以下查询时：</p>
<p>SELECT *</p>
<p> FROM t</p>
<p> WHERE key_part1 &gt;&#x3D; 1000</p>
<p>  AND key_part1 &lt; 2000</p>
<p>  AND key_part2 &#x3D; 10000;</p>
<p><strong>若不启用 MRR</strong>，优化器会先做一个 <strong>范围（Range）索引扫描</strong>：</p>
<ol>
<li>从联合索引按照 key_part1 &gt;&#x3D; 1000 AND key_part1 &lt; 2000 条件，扫描出所有满足第一个条件的叶子节点记录，无视 key_part2 是否等于 10000；</li>
<li>读出这些记录后，再在应用层对 key_part2 &#x3D; 10000 做过滤。<br> 这种做法可能会将大量 key_part2 ≠ 10000 的行读到缓冲区，却最终被丢弃，导致“无用 I&#x2F;O”。</li>
</ol>
<p><strong>若启用 MRR</strong>，优化器会把原来的查询“拆分”成一系列“点查”——也就是把范围 [1000, 2000) 细分为多个 (key_part1, key_part2) 对，例如 (1000, 10000)、(1001, 10000)、(1002, 10000) … (1999, 10000)；</p>
<ol>
<li>这些拆分出的 (key_part1, key_part2) 对本质上是更小的 “等值查询” 或 “等值范围查询” 的组合；</li>
<li>引擎对每个 (key_part1, key_part2) 直接通过索引查找，而不是先把所有 key_part1 的记录读出再过滤 key_part2；</li>
<li>最终在索引页上就能“剪掉”那些 key_part2 ≠ 10000 的记录，不会将它们读出到排序&#x2F;回表阶段；</li>
<li>这样做等价于把“先按 key_part1 范围 → 再过滤 key_part2”改成“先将范围拆为 (key_part1, key_part2) → 直接点查”，避免无用读。</li>
</ol>
<h3 id="Index-Condition-Pushdown（索引条件下推）"><a href="#Index-Condition-Pushdown（索引条件下推）" class="headerlink" title="Index Condition Pushdown（索引条件下推）"></a>Index Condition Pushdown（索引条件下推）</h3><p>MySQL 数据库会在取出索引的同时判断是否可以进行 WHERE 条件的过滤，也就是将 WHERE 的部分过滤操作放在了存储引擎层。在某些查询下，可以大大减少上层 SQL 层对记录的索取，从而提高数据库的整体性能。</p>
<p>Index Condition Pushdown 优化支持 range、ref、eq_ref、ref_or_null 类型的查询，当前支持 MyISAM 和 InnoDB 存储引擎。当优化器选择 Index Condition Pushdown 优化时，可在执行计划的 Extra 列看到 Using index condition 提示。</p>
<p>假设某张表有联合索引 (zip_code, last_name, first_name)，并且查询语句如下：</p>
<p>SELECT * FROM people</p>
<p> WHERE zipcode &#x3D; ‘95054’</p>
<p>  AND lastname LIKE ‘%etrunia%’</p>
<p>  AND address LIKE ‘%Main Street%’;</p>
<p>对于上述语句，MySQL 数据库可以通过索引定位 zipcode &#x3D; ‘95054’ 的记录，但是索引对 WHERE 条件的 lastname LIKE ‘%etrunia%’ 和 address LIKE ‘%Main Street%’ 没有任何帮助。若不支持 Index Condition Pushdown 优化，则数据库需要先通过索引取出所有 zipcode &#x3D; ‘95054’ 的记录，然后再对这部分记录执行 lastname LIKE ‘%etrunia%’ AND address LIKE ‘%Main Street%’ 的过滤，才能最终得到结果。</p>
<p>若支持 Index Condition Pushdown 优化，则在索引扫描阶段，MySQL 存储引擎会先判断 zipcode &#x3D; ‘95054’ 这一部分（因为这是索引的第一列条件），然后在“取出”符合该索引前缀的行时，立即在存储引擎层对 lastname LIKE ‘%etrunia%’ AND address LIKE ‘%Main Street%’ 这两个条件进行过滤，只把同时满足三个条件的记录交给上层 SQL 层做最终读取。这样就极大地减少了上层 SQL 层对行的 fetch 次数，从而提高查询效率。当然，WHERE 中被下推的条件必须是“索引范围能够覆盖到”的列，否则无法下推。例如 lastname LIKE ‘%abc%’ 或者 address LIKE ‘%xyz%’ 带有前缀通配符（前面有 %），在大多数情况下并不属于索引可下推的范围；只有当索引是覆盖该列并且能够使用“范围扫描”或“等值比较”时，条件下推才有效。</p>
<h2 id="InnoDB-中的哈希算法"><a href="#InnoDB-中的哈希算法" class="headerlink" title="InnoDB 中的哈希算法"></a>InnoDB 中的哈希算法</h2><p><strong>哈希表基本结构与冲突解决</strong></p>
<ul>
<li>InnoDB 在缓冲池中维护一个哈希表，用于物理页号 → 缓冲池页地址的快速映射。</li>
<li>哈希冲突时采用链表方式：每个缓冲池页有一个指向同一哈希值下链上下一个页的指针，形成冲突链。</li>
</ul>
<p><strong>哈希函数：除法散列法（Division Method）</strong></p>
<ul>
<li>InnoDB 选取的哈希函数为 <strong>除法散列</strong>，即：<br>hash_value  &#x3D;  K   mod   m 其中，<ul>
<li>K 是“查询页标识”的整数键；</li>
<li>m 是哈希表大小（槽位数）。</li>
</ul>
</li>
<li>为了尽量均匀分布并减少冲突，InnoDB 通常将 m 选为略大于“缓冲池页总数 ×2”的<strong>质数</strong>。<ul>
<li>例如，若 innodb_buffer_pool_size &#x3D; 10 MB，则缓冲池中总页数约为 10MB÷16KB&#x3D;640 页。</li>
<li>按“2 倍页数”原则，需要 640×2&#x3D;1280 个槽位，但 1280 不是质数，于是取下一个比 1280 稍大的质数 1399 作为哈希表槽数。</li>
</ul>
</li>
</ul>
<p><strong>构造查询键 K</strong></p>
<ul>
<li>InnoDB 中，每个页都有两个重要标识：<ol>
<li><strong>space_id</strong>：表示该页所属的表空间（tablespace）编号；</li>
<li><strong>offset</strong>：表示该页在表空间内的偏移量（即“第几个 16 KB 页”）。</li>
</ol>
</li>
<li>InnoDB 将这两个值合并成一个整数键 K，其计算公式通常为：K  &#x3D;  (space_id  ≪  20)  +  offset。</li>
<li>得到的 K 用于与哈希表槽数 m 做除法取余运算，确定该页在哈希表中对应的槽。</li>
</ul>
<h3 id="哈希索引"><a href="#哈希索引" class="headerlink" title="哈希索引"></a>哈希索引</h3><p><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXeY93sTTtJW2wzZWROk5xY2eXsa75mRa-IQjAMCh7AkYNf1JyQc7MC0vn_eEFtw1frz57X1PbyUWbQ2tlimRkPbQwJ7E8md8Jay9Z4BnnM6kFZ_mP-LLoYt9KvPWWwzt9TE-kwDgHyHAxgB6jMRHNsjJ9xw?key=axl_AuXN1-d7hfqfHYm2Ng" alt="img"></p>
<p>该索引采用哈希算法把键值换算成新的 hash 值，映射到对应的位置上，然后存储在 hash 表中。</p>
<ul>
<li>特点<ul>
<li>只能用于对等比较（&#x3D;，in），不支持范围查询（between，&gt;，&lt;，…）；</li>
<li>无法利用索引完成排序操作；</li>
<li>查询效率高，通常只需要一次索引就可以了，效率通常要高于 B+Tree 索引（不发生 hash 冲突的情况下）。</li>
</ul>
</li>
<li>存储引擎支持<ul>
<li>支持 hash 索引的是 Memory 和 NDB 存储引擎，而 InnoDB 中具有<strong>自适应 hash 索引</strong>。</li>
</ul>
</li>
</ul>
<p><strong>Hash 索引和 B+ 树索引的区别</strong></p>
<ol>
<li>B+ 树索引可以进行范围查询，Hash 索引不能。</li>
<li>B+ 树索引支持联合索引的最左侧原则，Hash 索引不支持。</li>
<li>B+ 树索引支持 order by 排序，Hash 索引不支持。</li>
<li>B+ 树使用 like 进行模糊查询的时候，LIKE ‘abc%’ 的话可以起到索引优化的作用，Hash 索引无法进行模糊查询。</li>
<li>Hash 索引在等值查询上比 B+ 树索引效率更高。</li>
</ol>
<h3 id="自适应哈希索引"><a href="#自适应哈希索引" class="headerlink" title="自适应哈希索引"></a>自适应哈希索引</h3><p>自适应哈希索引（Adaptive Hash Index，AHI）是 <strong>InnoDB 存储引擎在运行时自动创建的一种轻量级哈希结构</strong>，用于加速对 B+ 树叶子页中热点记录的等值查找。InnoDB 会监测查询模式，一旦检测到某个叶子页或某条索引项的访问频率过高，便在 Buffer Pool 中为该叶子页构造哈希表节点，使后续对该页的等值查找可以通过哈希函数直接定位，而无需再遍历 B+ 树路径。</p>
<p><strong>适用场景</strong></p>
<ul>
<li>等值查询：AHI 仅对形如 SELECT * FROM table WHERE indexed_col &#x3D; constant 的等值匹配操作有效。如果是范围查询（BETWEEN、&gt;, &lt; 等）或排序（ORDER BY）、模糊匹配（LIKE ‘%…%’），则不能使用 AHI，只能回退到常规的 B+ 树扫描或其他索引操作。</li>
<li>热点数据页：在大表中，如果某个 B+ 树叶子页承载了大量相同或相近的等值访问（例如同一个二级索引项被频繁查询），AHI 能极大减少 B+ 树遍历的层级开销，将随机 I&#x2F;O 降低为直接在内存哈希表查找。</li>
</ul>
<h2 id="全文检索"><a href="#全文检索" class="headerlink" title="全文检索"></a>全文检索</h2><p>MySQL 的全文检索（Full-Text Search）功能主要基于倒排索引实现，在 MyISAM 和 InnoDB 存储引擎中均提供了不同的支持方式。其核心原理是在数据写入时将文本字段拆分成词汇单元，并建立一个词–文档或词–行号的映射表，从而使得在查询时能够快速检索包含指定关键词的记录。虽然 MySQL 的全文检索功能对于轻量级应用已经十分实用，但与专业搜索引擎（如 Lucene、Solr、Elasticsearch 等）相比，功能较为基础。</p>
<h2 id="创建索引的注意点"><a href="#创建索引的注意点" class="headerlink" title="创建索引的注意点"></a>创建索引的注意点</h2><ul>
<li>使用合适的列作为索引<ul>
<li>经常作为查询条件（WHERE 子句）、排序条件（ORDER BY 子句）、分组条件（GROUP BY 子句）的列是建立索引的好候选。</li>
<li>区分度低（唯一值比例低）的字段，例如性别，不要建索引。</li>
<li>频繁更新的字段，不要作为主键或者索引。</li>
<li>不建议用无序的值(例如身份证、UUID )作为索引，当主键具有不确定性，会造成叶子节点频繁分裂，出现磁盘存储的碎片化。</li>
</ul>
</li>
<li>避免过多的索引<ul>
<li>每个索引都需要占用额外的磁盘空间。</li>
<li>更新表（INSERT、UPDATE、DELETE 操作）时，所有的索引都需要被更新。</li>
<li>维护索引文件需要成本；还会导致页分裂，IO 次数增多。</li>
</ul>
</li>
<li>利用前缀索引和索引列的顺序<ul>
<li>对于字符串类型的列，可以考虑使用前缀索引来减少索引大小。</li>
<li>在创建复合索引时，应该根据查询条件将最常用作过滤条件的列放在前面。</li>
</ul>
</li>
</ul>
<h2 id="使用索引的注意点"><a href="#使用索引的注意点" class="headerlink" title="使用索引的注意点"></a>使用索引的注意点</h2><ul>
<li>最左前缀法则<ul>
<li>如果索引了多列（联合索引），要遵循最左前缀法则。最左前缀法则指的是查询从索引的最左列开始，并且不跳过索引中的列。如果跳过了某一列，索引将部分失效（后面的字段索引失效）。</li>
</ul>
</li>
<li>范围查询<ul>
<li>联合索引中出现范围查询（&gt;, &lt;），范围查询右侧的列索引失效。因为范围查询会存在一次性获取大量符合条件的指针，这些指针指向 B+ 树中的子节点。这些子节点中都可能会包含右侧的列索引键，因此无法使用索引。<strong>规避方法：业务允许的情况下，使用 &gt;&#x3D;, &lt;&#x3D;。</strong></li>
</ul>
</li>
<li>索引列运算：在索引列上进行运算操作（各种函数），索引将失效。</li>
<li>字符串不加引号：使用字符串类型字段时，不加引号（会造成<strong>隐式类型转换</strong>），索引将失效。</li>
<li>模糊查询：如果仅仅是尾部模糊匹配，索引不会失效，如果是<strong>头部模糊匹配</strong>，索引失效。因为索引无法确定开头部分是什么内容。</li>
<li>or 连接的条件：用 or 分割开的条件，如果 or 前面的条件中的列有索引，而后面的列中没有索引，那么涉及的索引都不会被用到。</li>
<li>数据分布的影响<ul>
<li>如果 MySQL 评估使用索引比全表更慢，则不使用索引。</li>
<li>如果某个数据占比小，那么使用索引；否则，使用全表查询。</li>
</ul>
</li>
</ul>
<h2 id="索引设计原则"><a href="#索引设计原则" class="headerlink" title="索引设计原则"></a>索引设计原则</h2><ol>
<li>数据量较大（数据行超过 1M 条），查询操作频繁的表建立索引。</li>
<li>经常作为查询条件（where），排序（order by），分组（group by）操作的字段建立索引。</li>
<li>区分度高的列建立索引（区分度高，索引效率高）。</li>
<li>长字符串、大文本字段建立前缀索引。</li>
<li>尽量使用联合索引（覆盖索引），减少单列索引，避免回表。</li>
<li>控制索引数量，维护大量索引代价高。</li>
<li>如果索引列不能存储 NULL 值，请对其使用 NOT NULL 约束（方便优化器确定哪个索引更高效）。</li>
</ol>
<h2 id="索引失效的情况"><a href="#索引失效的情况" class="headerlink" title="索引失效的情况"></a>索引失效的情况</h2><ul>
<li>在索引列上<strong>使用函数或表达式</strong>，索引可能无法使用，因为数据库无法预先计算出函数或表达式的结果。例如：<strong>SELECT</strong> * <strong>FROM</strong> <strong>table_name</strong> <strong>WHERE</strong> <strong>YEAR</strong>(date_column) &#x3D; 2021。</li>
<li>使用<strong>不等于（&lt;&gt;）或者 NOT 操作</strong>通常会使索引失效，因为它们会扫描全表。</li>
<li>如果 LIKE 的模式串是<strong>以“%”或者“_”开头的</strong>，那么索引也无法使用。例如：<strong>SELECT</strong> * <strong>FROM</strong> <strong>table_name</strong> <strong>WHERE</strong> <strong>column</strong> <strong>LIKE</strong> <strong>‘%abc’</strong>。</li>
<li>如果查询条件中使用了 <strong>OR</strong>，并且 OR 两边的条件分别涉及不同的索引，那么这些索引可能都无法使用。</li>
<li>如果 MySQL 估计使用全表扫描比使用索引更快时（通常是小表或者大部分行都满足 WHERE 子句），也不会使用索引。</li>
<li>联合索引不满足最左前缀原则时，索引会失效。</li>
</ul>
<p><strong>百万级别以上的数据如何删除？</strong></p>
<p>先删除索引，然后删除其中的无用数据，删除完成后重新创建索引。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN,en">
    <link itemprop="mainEntityOfPage" href="https://yihangwe.github.io/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/2024/11/01/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/CAMP/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yihang Wei">
      <meta itemprop="description" content="聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EthanWeee">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/2024/11/01/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/CAMP/" class="post-title-link" itemprop="url">CAMP</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-11-01 00:00:00" itemprop="dateCreated datePublished" datetime="2024-11-01T00:00:00-07:00">2024-11-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-05-31 20:59:33" itemprop="dateModified" datetime="2025-05-31T20:59:33-07:00">2025-05-31</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/" itemprop="url" rel="index"><span itemprop="name">数据库系统</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Greedy-Dual-Size-GDS-algorithm"><a href="#Greedy-Dual-Size-GDS-algorithm" class="headerlink" title="Greedy Dual Size (GDS) algorithm"></a>Greedy Dual Size (GDS) algorithm</h1><p>Key Concepts:</p>
<ol>
<li><strong>Variable Size and Cost</strong>:<ul>
<li>Unlike simple algorithms that treat all objects equally, GDS takes into account:<ul>
<li><strong>Size of the object</strong> (<code>size(p)</code>): Larger objects take up more space in memory.</li>
<li><strong>Cost of the object</strong> (<code>cost(p)</code>): This can represent factors like time to retrieve the object, computational effort, or other resource usage.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Score H(p)</strong>:<ul>
<li>Each key-value pair ppp in the cache is assigned a score H(p). This score reflects the <strong>benefit of keeping the object</strong> in memory and is calculated using:<ul>
<li>A <strong>global parameter L</strong>, which adjusts dynamically based on cache state.</li>
<li>The <strong>size(p)</strong> of the object.</li>
<li>The <strong>cost(p)</strong> associated with the object.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Eviction Strategy</strong>:<ul>
<li>When the cache is full, and a new object needs to be added, GDS removes the object with the <strong>lowest score H(p)</strong>. This process continues until there is enough space for the new object.</li>
</ul>
</li>
</ol>
<h2 id="Proposition-1"><a href="#Proposition-1" class="headerlink" title="Proposition 1"></a>Proposition 1</h2><p><strong>L is non-decreasing over time.</strong></p>
<ul>
<li>The global parameter L, which reflects the minimum priority H(p) among all key-value pairs in the KVS, will either stay the same or increase with each operation. This ensures stability and helps prioritize eviction decisions consistently.</li>
</ul>
<p>For any key-value pair ppp in the KVS, the relationship holds:</p>
<p><strong>L ≤ H(p) ≤ L + cost(p) &#x2F; size(p)</strong></p>
<ul>
<li>H(p), the priority of p, always lies between the global minimum L and L + cost(p) &#x2F; size(p), ensuring H(p) reflects both its retrieval cost and size relative to other elements.</li>
</ul>
<p><strong>Intuition Behind Proposition 1:</strong></p>
<ul>
<li>As L increases over time (reflecting the minimum H(p)), less recently used or less “valuable” pairs become increasingly likely to be evicted. This ensures that newer and higher-priority pairs stay in the KVS longer.</li>
</ul>
<p><strong>Key Insights from Proposition 1:</strong></p>
<ol>
<li><strong>Delayed Eviction:</strong><ul>
<li>When p is requested again while in memory, its H(p) increases to L + cost(p) &#x2F; size(p), delaying its eviction.</li>
</ul>
</li>
<li><strong>Impact of Cost-to-Size Ratio:</strong><ul>
<li>Pairs with higher cost(p) &#x2F; size(p) stay longer in the KVS. For example, if one pair’s ratio is c times another’s, it will stay approximately c times longer.</li>
</ul>
</li>
</ol>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/chart3.png" alt="img"></p>
<h2 id="Key-Points-in-the-Diagram"><a href="#Key-Points-in-the-Diagram" class="headerlink" title="Key Points in the Diagram"></a>Key Points in the Diagram</h2><ol>
<li><strong>Cost-to-Size Ratios</strong>:<ol>
<li>Key-value pairs are grouped into <strong>queues</strong> according to their cost-to-size ratio.</li>
<li>Each queue corresponds to a specific cost-to-size ratio.</li>
</ol>
</li>
<li><strong>Grouping by Ratio</strong>:<ol>
<li>Within each queue, key-value pairs are managed using the <strong>Least Recently Used (LRU)</strong> strategy.</li>
</ol>
</li>
<li><strong>Priority Management</strong>:<ol>
<li>The <strong>priority (H-value)</strong> of a key-value pair is based on: <strong>H(p) &#x3D; L + cost(p) &#x2F; size(p)</strong><ol>
<li>L: The global non-decreasing variable.</li>
<li>cost(p) &#x2F; size(p): The cost-to-size ratio of the key-value pair.</li>
</ol>
</li>
</ol>
</li>
<li><strong>Efficient Eviction</strong>:<ol>
<li>CAMP maintains a <strong>heap</strong> that points to the <strong>head of each queue</strong>, storing the minimum H(p) from every queue.</li>
<li>To identify the next key-value pair for eviction:<ol>
<li><strong>The algorithm checks the heap to find the queue with the smallest H(p).</strong></li>
<li><strong>It then evicts the key-value pair at the front of that queue (i.e., the least recently used pair in that cost-to-size group).</strong></li>
</ol>
</li>
</ol>
</li>
</ol>
<h2 id="Rounding-in-CAMP"><a href="#Rounding-in-CAMP" class="headerlink" title="Rounding in CAMP"></a>Rounding in CAMP</h2><p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/bg_bm_rounding.png" alt="img"></p>
<ol>
<li><strong>Purpose</strong>: To improve performance, CAMP <strong>reduces the number of LRU queues</strong> by grouping key-value pairs with <strong>similar cost-to-size ratios</strong> into the same queue.</li>
<li><strong>Key Idea</strong>: Preserve the most significant bits proportional to the value’s size.</li>
</ol>
<h2 id="Proposition-2-Explanation-of-Rounding-and-Distinct-Values"><a href="#Proposition-2-Explanation-of-Rounding-and-Distinct-Values" class="headerlink" title="Proposition 2: Explanation of Rounding and Distinct Values"></a>Proposition 2: Explanation of Rounding and Distinct Values</h2><h3 id="Implications"><a href="#Implications" class="headerlink" title="Implications"></a>Implications</h3><ol>
<li><p><strong>Trade-Off Between Precision and Efficiency</strong>:</p>
<ul>
<li><p>A higher p preserves more precision but increases the number of distinct values (and thus computational complexity).</p>
</li>
<li><p>Lower p reduces the number of distinct values, making CAMP more efficient but less precise.</p>
</li>
</ul>
</li>
<li><p><strong>Rounding Efficiency</strong>:</p>
<ul>
<li>By limiting the number of distinct values, CAMP minimizes the number of LRU queues, reducing overhead while still approximating GDS closely.</li>
</ul>
</li>
</ol>
<h2 id="Proposition-3-Competitive-Ratio-of-CAMP"><a href="#Proposition-3-Competitive-Ratio-of-CAMP" class="headerlink" title="Proposition 3: Competitive Ratio of CAMP"></a>Proposition 3: Competitive Ratio of CAMP</h2><h3 id="Practical-Implications"><a href="#Practical-Implications" class="headerlink" title="Practical Implications"></a>Practical Implications</h3><ol>
<li><p><strong>Precision ppp</strong>:</p>
<ul>
<li><p>The smaller the ϵ (higher ppp), the closer CAMP approximates GDS.</p>
</li>
<li><p>For sufficiently large p, CAMP performs nearly as well as GDS.</p>
</li>
</ul>
</li>
<li><p><strong>Trade-off</strong>:</p>
<ul>
<li>Higher p increases precision but also increases the number of distinct cost-to-size ratios and computational overhead.</li>
</ul>
</li>
</ol>
<h3 id="CAMP’s-Improvement-Over-GDS"><a href="#CAMP’s-Improvement-Over-GDS" class="headerlink" title="CAMP’s Improvement Over GDS:"></a>CAMP’s Improvement Over GDS:</h3><ol>
<li><strong>Approximation:</strong> CAMP simplifies H(p) by <strong>rounding</strong> the cost-to-size ratio, reducing the precision but making the algorithm more efficient.</li>
<li><strong>Grouping:</strong> Key-value pairs are <strong>grouped</strong> by similar cost-to-size ratios, reducing the number of queues and simplifying priority management.</li>
<li><strong>Tie-Breaking:</strong> CAMP uses <strong>LRU within each group</strong> to determine the eviction order, making it computationally cheaper.</li>
</ol>
<h3 id="Figure-4-Heap-Node-Visits"><a href="#Figure-4-Heap-Node-Visits" class="headerlink" title="Figure 4: Heap Node Visits"></a>Figure 4: Heap Node Visits</h3><p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/chart4.png" alt="img"></p>
<p>This figure compares the number of heap node visits for GDS and CAMP as a function of cache size:</p>
<ol>
<li><p><strong>GDS</strong>:</p>
<ul>
<li><p><strong>Heap size equals the total number of key-value pairs in the cache.</strong></p>
</li>
<li><p>Every heap update (insertion, deletion, or priority change) requires visiting O(log⁡n) nodes, where n is the number of cache entries.</p>
</li>
<li><p>As cache size increases, GDS’s overhead grows significantly.</p>
</li>
</ul>
</li>
<li><p><strong>CAMP</strong>:</p>
<ul>
<li><p><strong>Heap size equals the number of non-empty LRU queues, which is much smaller than the total number of cache entries.</strong></p>
</li>
<li><p>Heap updates occur only when:</p>
<ul>
<li><p>The priority of the head of an LRU queue changes.</p>
</li>
<li><p>A new LRU queue is created.</p>
</li>
</ul>
</li>
<li><p>As cache size increases, the number of non-empty LRU queues remains relatively constant, resulting in fewer heap updates.</p>
</li>
</ul>
</li>
</ol>
<h1 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h1><p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/chart5.png" alt="img"></p>
<p><strong>(a) Cost-Miss Ratio vs Precision</strong></p>
<ul>
<li><strong>横轴</strong>：精度（Precision），从低到高。</li>
<li><strong>纵轴</strong>：成本未命中比（Cost-Miss Ratio）。</li>
<li><strong>结果</strong>：<ul>
<li>不同的缓存大小比（0.01、0.1 和 0.3）在较低精度下表现一致。</li>
<li>提高精度后，成本未命中比没有显著变化。</li>
<li>说明即使使用较低精度，CAMP 的成本未命中比也能接近 GDS（标准实现）。</li>
</ul>
</li>
</ul>
<p><strong>(b) LRU Queues vs Precision</strong></p>
<ul>
<li><strong>横轴</strong>：精度（Precision）。</li>
<li><strong>纵轴</strong>：CAMP 维护的非空 LRU 队列数量。</li>
<li><strong>结果</strong>：<ul>
<li><strong>低精度</strong>（1-5）：CAMP 维持稳定的少量 LRU 队列（约 5 个）。</li>
<li><strong>高精度</strong>（&gt;10）：队列数增加，尤其是在较大的缓存大小比（如 1.0）下。</li>
<li><strong>结论</strong>：<ul>
<li>在较低精度下，CAMP 能保持较低的计算开销，同时维持高效的队列管理。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>(c) Cost-Miss Ratio vs Cache Size Ratio</strong></p>
<ul>
<li><strong>横轴</strong>：缓存大小比（Cache Size Ratio），即缓存大小与 trace 文件中唯一键值对总大小的比值。</li>
<li><strong>纵轴</strong>：成本未命中比（Cost-Miss Ratio）。</li>
<li><strong>结果</strong>：<ul>
<li><strong>CAMP</strong>：<ul>
<li>在所有缓存大小下，成本未命中比最低。</li>
<li>说明 CAMP 在高成本键值对管理上更具效率。</li>
</ul>
</li>
<li><strong>Pooled LRU</strong>：<ul>
<li>在较小缓存下表现稍差，但随着缓存增加，接近 CAMP。</li>
</ul>
</li>
<li><strong>LRU</strong>：<ul>
<li>成本未命中比始终最高。</li>
</ul>
</li>
<li><strong>结论</strong>：<ul>
<li>CAMP 优于 LRU 和 Pooled LRU，尤其是在小缓存下。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>(d) Miss Rate vs Cache Size Ratio</strong></p>
<ul>
<li><strong>横轴</strong>：缓存大小比（Cache Size Ratio）。</li>
<li><strong>纵轴</strong>：未命中率（Miss Rate）。</li>
<li><strong>结果</strong>：<ul>
<li><strong>CAMP</strong>：<ul>
<li>未命中率显著低于 LRU 和 Pooled LRU，尤其在小缓存下表现最优。</li>
</ul>
</li>
<li><strong>Pooled LRU</strong>：<ul>
<li>未命中率随着缓存增大而下降，但始终高于 CAMP。</li>
<li>最低成本池（cheapest pool）未命中率接近 100%，次低成本池未命中率达到 65%。</li>
</ul>
</li>
<li><strong>LRU</strong>：<ul>
<li>始终高于 CAMP 和 Pooled LRU。</li>
</ul>
</li>
<li><strong>结论</strong>：<ul>
<li>CAMP 在多种缓存大小下都保持较低的未命中率，且比 Pooled LRU 更均衡。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="CAMP-的适应能力：访问模式变化的分析"><a href="#CAMP-的适应能力：访问模式变化的分析" class="headerlink" title="CAMP 的适应能力：访问模式变化的分析"></a>CAMP 的适应能力：访问模式变化的分析</h1><p>实验设置：</p>
<ul>
<li>使用 10 个不同的 trace 文件，每个文件包含 400 万个键值对引用。</li>
<li>每个 trace 文件（如 TF1、TF2 等）中的请求在其结束后不会再被引用，模拟访问模式的突然变化。</li>
<li>访问模式具有倾斜分布（如 Zipf 分布），每个 trace 文件中的高成本对象可能在下一次访问中完全无效。</li>
</ul>
<p>目标：</p>
<ul>
<li>比较 <strong>CAMP</strong>、<strong>Pooled LRU</strong> 和 <strong>LRU</strong> 在不同缓存大小下对访问模式突变的适应能力。</li>
<li>评估三种算法在突然变化后清除旧的高成本键值对的效率，以及对总体性能（如成本未命中比和未命中率）的影响。</li>
</ul>
<p>不同算法的行为分析</p>
<ol>
<li><p><strong>LRU</strong>：</p>
<ul>
<li><p>按最近使用排序，当新请求的总大小超过缓存大小时清除旧数据。</p>
</li>
<li><p>当缓存大小比为 1 时，清除 TF1 数据的时间点对应于 TF3 开始请求的第一个键值对。</p>
</li>
</ul>
</li>
<li><p><strong>Pooled LRU</strong>：</p>
<ul>
<li><p>将键值对按成本分组，每组分配固定比例的缓存空间。</p>
</li>
<li><p>高成本池占据 99% 的缓存空间，因此在每个新 trace 开始时会突然清除一批旧数据。</p>
</li>
<li><p>对于缓存大小比 2&#x2F;3 或更高的情况，直到 TF4（约 800 万请求后）才会清除所有 TF1 数据。</p>
</li>
</ul>
</li>
<li><p><strong>CAMP</strong>：</p>
<ul>
<li><p>对每个成本-大小比维护 LRU 队列，这些队列的大小可以动态调整。</p>
</li>
<li><p><strong>优先淘汰较低优先级的数据，但高成本数据即使来自旧 trace，也具有一定保留优先级。</strong></p>
</li>
<li><p><strong>当新数据的总大小超过缓存时，旧 trace 的高成本数据才会被逐步清除。</strong></p>
</li>
</ul>
</li>
</ol>
<p><img src="/../../images/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/chart6.png" alt="img"></p>
<p><strong>图 6c：缓存比 0.25（小缓存）</strong></p>
<ol>
<li><p><strong>LRU</strong>：</p>
<ul>
<li><p>清除最快，仅需 <strong>2.1 万次请求</strong> 即完全清除 Trace 1 的所有键值对。</p>
</li>
<li><p>由于 LRU 优先淘汰最久未使用的数据，小缓存下表现最佳。</p>
</li>
</ul>
</li>
<li><p><strong>Pooled LRU</strong>：</p>
<ul>
<li><p>清除速度较慢，需要 <strong>13.1 万次请求</strong>。</p>
</li>
<li><p>原因：Pooled LRU 按成本对键值对分组，高成本池占用较多缓存空间，导致清除滞后。</p>
</li>
</ul>
</li>
<li><p><strong>CAMP</strong>：</p>
<ul>
<li><p>初期清除速度比 Pooled LRU 更快，但最后完全清除所有键值对需到 <strong>TF3 结束（770 万次请求）</strong>。</p>
</li>
<li><p>然而，这些未被清除的 Trace 1 数据仅占缓存的 <strong>2%</strong>，说明 CAMP 优先保留了高成本键值对。</p>
</li>
</ul>
</li>
</ol>
<p><strong>图 6d：缓存比 0.75（大缓存）</strong></p>
<ol>
<li><p><strong>LRU</strong>：</p>
<ul>
<li><p>同样清除最快，几乎在 Trace 2 开始时就清除掉大部分 Trace 1 的数据。</p>
</li>
<li><p>说明即使缓存较大，LRU 仍然倾向淘汰旧数据。</p>
</li>
</ul>
</li>
<li><p><strong>Pooled LRU</strong>：</p>
<ul>
<li><p>清除延迟显著，需要 <strong>730 万次请求</strong>，接近 TF3 结束。</p>
</li>
<li><p>原因：高成本池占用过多缓存空间，延迟清除低成本和无用数据。</p>
</li>
</ul>
</li>
<li><p><strong>CAMP</strong>：</p>
<ul>
<li><p>大部分 Trace 1 数据在较早阶段被淘汰，仅保留少量最昂贵的键值对（占缓存比小于 <strong>0.6%</strong>）。</p>
</li>
<li><p>即使在 <strong>4000 万次请求</strong>后，这些高成本键值对仍在缓存中，但对整体缓存利用影响极小。</p>
</li>
</ul>
</li>
</ol>
<p>针对不同大小但成本相同的键值对，CAMP 优先保留较小的键值对，从而降低未命中率和成本未命中比。</p>
<p>针对相同大小但成本不同的键值对，CAMP 优先保留高成本键值对，在成本未命中比上显著优于其他算法。</p>
<p>与其他算法的对比：</p>
<ul>
<li><p>LRU：适用于简单场景，但无法处理成本差异。</p>
</li>
<li><p>Pooled LRU：小缓存情况下表现不错，但静态分区策略限制了其大缓存场景的效率。</p>
</li>
</ul>
<p>CAMP 的适应性：在处理多样化的成本分布时，通过动态调整和四舍五入策略，CAMP 在复杂负载下表现出更高的灵活性和效率。</p>
<h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h1><p><strong>What is the time complexity of LRU to select a victim?</strong></p>
<p><strong>O(1)</strong> because the least recently used item is always at the tail of the list.</p>
<p><strong>What is the time complexity of CAMP to select a victim?</strong></p>
<p><strong>O(logk)</strong> CAMP identifies the key-value pair with the smallest priority from the heap, deletes it and then <strong>heapifies</strong>.</p>
<p><strong>Why does CAMP do rounding using the high order bits?</strong></p>
<ul>
<li>CAMP rounds cost-to-size ratios to <strong>reduce the number of distinct ratios (or LRU queues)</strong>.</li>
<li>High-order bits are retained because they represent the <strong>most significant portion of the value</strong>, ensuring that <strong>approximate prioritization is maintained</strong>.</li>
</ul>
<p><strong>How does BG generate social networking actions that are always valid?</strong></p>
<p><strong>Pre-Validation of Actions:</strong></p>
<ul>
<li>Before generating an action, BG <strong>checks</strong> the current state of the database to ensure the action is valid. For instance:<ul>
<li>A friend request is only generated if the two users are not already friends or in a “pending” relationship.</li>
<li>A comment can only be posted on a resource if the resource exists.</li>
</ul>
</li>
</ul>
<p><strong>Avoiding Concurrent Modifications:</strong></p>
<ul>
<li>BG <strong>prevents multiple threads from concurrently modifying the same user’s state</strong>.</li>
</ul>
<p><strong>How does BG scale to a large number of nodes?</strong></p>
<p>BG employs <strong>a shared-nothing architecture</strong> with the following mechanisms to scale effectively:</p>
<ol>
<li><p><strong>Partitioning Members and Resources:</strong></p>
<ul>
<li><p>BGCoord <strong>partitions</strong> the database into <strong>logical fragments</strong>, each containing <strong>a unique subset</strong> of members, their resources, and relationships.</p>
</li>
<li><p>These fragments are assigned to individual BGClients.</p>
</li>
</ul>
</li>
<li><p><strong>Multiple BGClients:</strong></p>
<ul>
<li><p>Each BGClient operates <strong>independently</strong>, generating workloads for its assigned logical fragment.</p>
</li>
<li><p>By running <strong>multiple</strong> BGClients <strong>in parallel</strong> across different nodes, BG can scale horizontally to handle millions of requests.</p>
</li>
</ul>
</li>
<li><p><strong>D-Zipfian Distribution:</strong></p>
<ul>
<li><p>To ensure realistic and scalable workloads, BG uses a decentralized Zipfian distribution (D-Zipfian) that <strong>dynamically assigns</strong> requests to BGClients based on node performance.</p>
</li>
<li><p>Faster nodes receive a larger share of the logical fragments, ensuring even workload distribution.</p>
</li>
</ul>
</li>
<li><p><strong>Concurrency Control:</strong></p>
<ul>
<li>BG <strong>prevents simultaneous threads from issuing actions for the same user</strong>, maintaining the integrity of modeled user interactions and avoiding resource contention.</li>
</ul>
</li>
</ol>
<p><strong>True or False: BG quantifies the amount of unpredictable data produced by a data store?</strong></p>
<p>True.</p>
<p>This is achieved through:</p>
<ul>
<li><strong>Validation Phase:</strong><ul>
<li>BG uses <strong>read and write log records</strong> to detect instances where a read operation observes a value <strong>outside the acceptable range</strong>, classifying it as “unpredictable data.”</li>
</ul>
</li>
<li><strong>Metrics Collection:</strong><ul>
<li>The percentage of requests that observe unpredictable data (τ) is a key metric used to evaluate the data store’s consistency.</li>
</ul>
</li>
</ul>
<p><strong>How is BG’s SoAR different than its Socialites rating?</strong></p>
<p>SoAR (Social Action Rating): Represents the <strong>maximum throughput</strong> (actions per second) a data store can achieve while meeting a given SLA.</p>
<p>Socialites Rating: Represents the <strong>maximum number of concurrent threads</strong> <strong>(users)</strong> a data store can support while meeting the SLA.</p>
<p>Reference: <a target="_blank" rel="noopener" href="https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=d6f9678772a09ca29101f5efce583960ecf53745">https://citeseerx.ist.psu.edu/document?repid=rep1&amp;type=pdf&amp;doi=d6f9678772a09ca29101f5efce583960ecf53745</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN,en">
    <link itemprop="mainEntityOfPage" href="https://yihangwe.github.io/MySQL/2024/10/31/MySQL/%E7%B4%A2%E5%BC%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yihang Wei">
      <meta itemprop="description" content="聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EthanWeee">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/MySQL/2024/10/31/MySQL/%E7%B4%A2%E5%BC%95/" class="post-title-link" itemprop="url">索引</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-10-31 00:00:00" itemprop="dateCreated datePublished" datetime="2024-10-31T00:00:00-07:00">2024-10-31</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-06-19 16:27:58" itemprop="dateModified" datetime="2025-06-19T16:27:58-07:00">2025-06-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MySQL/" itemprop="url" rel="index"><span itemprop="name">MySQL</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>索引是一种可以帮助 MySQL 高效获取数据的数据结构，也是有序结构。</p>
<p>优点</p>
<ul>
<li>提高数据检索效率，降低数据库 I&#x2F;O 成本。</li>
<li>通过索引列对数据进行排序，降低数据排序成本，降低 CPU 的消耗。</li>
</ul>
<p>缺点</p>
<ul>
<li>占用空间。</li>
<li>降低了更新表的效率，如 INSERT、UPDATE、DELETE。</li>
</ul>
<p>因此，若索引太多，应用程序的性能可能会受到影响。而索引太少，对查询性能又会产生影响。要找到一个合适的平衡点，这对应用程序的性能至关重要。</p>
<h2 id="索引结构"><a href="#索引结构" class="headerlink" title="索引结构"></a>索引结构</h2><p>MySQL 索引是在引擎层实现的，不同的存储引擎支持不同的索引结构。</p>
<table>
<thead>
<tr>
<th>索引结构</th>
<th>描述</th>
<th>InnoDB</th>
<th>MyISAM</th>
<th>Memory</th>
</tr>
</thead>
<tbody><tr>
<td>B+Tree 索引</td>
<td>最常见的索引类型，大部分引擎支持 B+Tree索引</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
</tr>
<tr>
<td>Hash 索引</td>
<td>底层数据结构由哈希表实现，只有精确匹配索引列的查询才有效，不支持查询范围</td>
<td>不支持</td>
<td>不支持</td>
<td>支持</td>
</tr>
<tr>
<td>R-Tree 空间索引</td>
<td>空间索引是 MyISAM 引擎的一个特殊索引类型，主要用于地理空间数据类型</td>
<td>不支持</td>
<td>支持</td>
<td>不支持</td>
</tr>
<tr>
<td>Full-Text 全文索引</td>
<td>一种通过建立倒排索引来快速匹配文档的方式</td>
<td>5.6版本之后支持</td>
<td>支持</td>
<td>不支持</td>
</tr>
</tbody></table>
<h2 id="InnoDB-索引分类"><a href="#InnoDB-索引分类" class="headerlink" title="InnoDB 索引分类"></a>InnoDB 索引分类</h2><p><img src="/../../images/MySQL/index_type.png" alt="img"></p>
<table>
<thead>
<tr>
<th>索引类别</th>
<th>含义</th>
<th>特点</th>
<th>关键字</th>
</tr>
</thead>
<tbody><tr>
<td>主键索引</td>
<td>针对表中<strong>主键</strong>创建的索引</td>
<td>默认自动创建，只能有一个</td>
<td>PRIMARY</td>
</tr>
<tr>
<td>唯一索引</td>
<td><strong>避免</strong>同一个表中某数据列中的值<strong>重复</strong></td>
<td>可以有多个</td>
<td>UNIQUE</td>
</tr>
<tr>
<td>常规索引</td>
<td>快速定位特定数据</td>
<td>可以有多个</td>
<td></td>
</tr>
<tr>
<td>全文索引</td>
<td><strong>查找</strong>文本中的<strong>关键字</strong>，而不是比较索引中的值</td>
<td>可以有多个</td>
<td>FULLTEXT</td>
</tr>
</tbody></table>
<p>根据索引存储形式，可分为以下两种：</p>
<table>
<thead>
<tr>
<th>分类</th>
<th>含义</th>
<th>特点</th>
</tr>
</thead>
<tbody><tr>
<td>聚集索引</td>
<td><strong>将数据存储与索引放到了一块</strong>，索引结构的叶子节点保存了行数据</td>
<td>必须有，而且只有一个</td>
</tr>
<tr>
<td>二级索引</td>
<td><strong>将数据与索引分开存储</strong>，索引结构的叶子节点关联的是对应的<strong>主键</strong></td>
<td>可以存在多个</td>
</tr>
</tbody></table>
<p>InnoDB 支持以下索引：</p>
<ul>
<li>B+ 树索引</li>
<li>全文索引</li>
<li>自适应 Hash 索引</li>
</ul>
<p>B+ 树索引就是传统意义上的索引，这是目前关系型数据库系统中查找最为高效且被认为有效的索引。B+ 树索引的构造类似于二叉树，根据键值（Key Value）快速找到数据。B+ 树索引能找到的只是被查找数据所在的页。然后数据库通过把页读入到内存，再在内存中进行查找，最后得到要查找的数据。</p>
<p>整体流程：</p>
<p>B+ 树 Root &#x3D;&gt; B+ 树索引节点 &#x3D;&gt; B+ 树叶子节点 &#x3D;&gt; Page Directory 中的一个 Slot &#x3D;&gt; 目标行数据。</p>
<p>InnoDB 存储引擎支持的哈希索引是自适应的，InnoDB 存储引擎会根据表的使用情况自动为表生成哈希索引，不能人为干预是否在一张表中生成哈希索引。</p>
<p>InnoDB 的主键使用的是聚簇索引，而 MyISAM 中，不管是主键索引还是二级索引使用的都是非聚簇索引。</p>
<p>InnoDB 中的全表扫描会顺序读取聚集索引上的数据页（即叶子节点），等价于按主键顺序逐行扫描表中所有行。</p>
<h2 id="全表扫描"><a href="#全表扫描" class="headerlink" title="全表扫描"></a>全表扫描</h2><p>在 InnoDB 中，一条简单的 <code>SELECT * FROM A</code> 在执行时会经过以下几层，才能把表 A 中的每一行读出来。下面分段结合关键源码，逐步说明一个典型的全表扫描流程。</p>
<p><strong>一、Handler 接口</strong>：<code>ha_rnd_next</code> 循环读取</p>
<p><code>TableScanIterator::Read()</code> 中：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> ((tmp = <span class="built_in">table</span>()-&gt;file-&gt;<span class="built_in">ha_rnd_next</span>(m_record))) &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (tmp == HA_ERR_RECORD_DELETED &amp;&amp; !<span class="built_in">thd</span>()-&gt;killed) <span class="keyword">continue</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">HandleError</span>(tmp);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><p><code>ha_rnd_next(m_record)</code>：MySQL 存储引擎统一接口，每次调用读一行到 <code>m_record</code>。</p>
</li>
<li><p>跳过 DELETED：MyISAM 在并发删时会返回 <code>HA_ERR_RECORD_DELETED</code>，此处跳过。</p>
</li>
<li><p>返回码：0 表示成功取到一行；非 0 则调用 <code>HandleError(tmp)</code> 终止扫描。</p>
</li>
</ul>
<p>对于 InnoDB，<code>ha_rnd_next</code> 内部实现为：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">handler::ha_rnd_next</span><span class="params">(uchar *buf)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">MYSQL_TABLE_IO_WAIT</span>(..., &#123; result = <span class="built_in">rnd_next</span>(buf); &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!result &amp;&amp; m_update_generated_read_fields)</span><br><span class="line"></span><br><span class="line">      <span class="built_in">update_generated_read_fields</span>(buf, table);</span><br><span class="line"></span><br><span class="line">  table-&gt;<span class="built_in">set_row_status_from_handler</span>(result);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>二、InnoDB 读取流程</strong>：<code>rnd_next</code> → <code>general_fetch</code> → <code>row_search_mvcc</code></p>
<p><code>rnd_next(buf)</code> 中的核心调用如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (m_start_of_scan) &#123;</span><br><span class="line"></span><br><span class="line">  error = <span class="built_in">index_first</span>(buf);</span><br><span class="line"></span><br><span class="line">  m_start_of_scan = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"></span><br><span class="line">  error = <span class="built_in">general_fetch</span>(buf, ROW_SEL_NEXT, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> error;</span><br></pre></td></tr></table></figure>

<ul>
<li>首次扫描 调用 <code>index_first(buf)</code> 定位到最左叶节点的第一条记录；</li>
<li>后续扫描 一律调用 <code>general_fetch</code>。</li>
</ul>
<p><code>general_fetch(buf, ROW_SEL_NEXT, 0)</code> 中的核心调用如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (!intrinsic) <span class="comment">// 普通表</span></span><br><span class="line"></span><br><span class="line">  ret = <span class="built_in">row_search_mvcc</span>(buf, PAGE_CUR_UNSUPP, m_prebuilt, <span class="number">0</span>, ROW_SEL_NEXT);</span><br><span class="line"></span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 再把 dberr_t 转成 MySQL 错误码返回给 rnd_next</span></span><br></pre></td></tr></table></figure>

<p>row_search_mvcc</p>
<p><code>row_search_mvcc</code> 中的核心调用如下：</p>
<ul>
<li>首次 (<code>direction == 0</code>)：构造或恢复一个 B-树游标 pcur，调用 <code>pcur-&gt;open_no_init()</code>（或 <code>open_at_side</code>）从根节点一路走到左最叶，定位第一条记录。</li>
<li>后续 (<code>direction == ROW_SEL_NEXT</code>)：直接在叶节点上调用 <code>pcur-&gt;move_to_next(&amp;mtr)</code>，利用叶节点之间的双向链表遍历下一条记录，无需再从根节点重查。</li>
<li>循环过滤（<code>rec_loop</code>）：<ul>
<li>跳过 infimum&#x2F;supremum 伪记录，检查页内偏移合法性；</li>
<li>MVCC 版本检查：如果当前版本不可见，调用 undo log 回溯到可见版本；</li>
<li>删除标记：跳过 delete-marked；</li>
<li>索引条件下推（此例没有 WHERE，相当于 <code>match_mode == 0</code>，所有行都通过）；</li>
<li>转换格式：调用 <code>row_sel_store_mysql_rec(buf, …)</code> 将内部二进制行转成 MySQL 客户端格式；</li>
<li>预取缓存：若启用缓存则放入队列，否则直接写入 buf 并 <code>return DB_SUCCESS</code>。</li>
</ul>
</li>
<li>退出：当 <code>move_to_next</code> 返回 false（无更多记录），函数最终返回 <code>DB_END_OF_INDEX</code> 或 <code>DB_RECORD_NOT_FOUND</code>，上层映射为 <code>HA_ERR_END_OF_FILE</code>。</li>
</ul>
<p>在 <code>row_search_mvcc</code> 的整个执行过程中，游标（pcur）的状态会在多处被保存和恢复，其核心目的有两个：</p>
<ol>
<li>跨页扫描时保持定位：当 B- 树叶节点遍历到一页的末尾，需要切换到下一页时，InnoDB 会提交当前 mini-transaction（<code>mtr_commit(&amp;mtr)</code>）并重新开启一个新的 mini-transaction（mtr_start(&amp;mtr)）。提交会释放当前页面的读锁（latch），以避免死锁或锁的过度持有。但一旦释放，就无法再在页内继续定位，于是必须在释放前存储当前位置，切换后再恢复，才能从下一个页的正确位置继续扫描。</li>
<li>出现锁等待或错误时的回退：如果在给某条记录加锁过程中遇到锁等待（<code>DB_LOCK_WAIT</code>）或其他可重试的错误，函数会<ul>
<li>在释放 mini-transaction、让出 latch 之前存储游标位置，</li>
<li>等待锁或错误解决后，再恢复游标，继续当前记录或下一条记录的扫描，保证最终不会漏读也不重复读。</li>
</ul>
</li>
</ol>
<p><strong>完整调用链一览</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mysql_select()</span><br><span class="line"> └─ join_read_table() / read_table_rows()</span><br><span class="line">   	└─ handler::ha_rnd_next(buf)</span><br><span class="line">       └─ rnd_next(buf)</span><br><span class="line">          ├─ index_first(buf)     // 第一次，从根到左叶</span><br><span class="line">          └─ general_fetch(buf,…)  // 后续，调用 row_search_mvcc</span><br><span class="line">         		 └─ row_search_mvcc(buf,…)</span><br><span class="line">                ├─ pcur-&gt;open_no_init()   // 定位（首次）</span><br><span class="line">                ├─ pcur-&gt;move_to_next()   // 遍历（后续）</span><br><span class="line">                └─ row_sel_store_mysql_rec // 转换格式</span><br></pre></td></tr></table></figure>

<p>此外，整个过程主要涉及两类锁：</p>
<p><strong>元数据锁（MDL，Metadata Lock）</strong></p>
<ul>
<li><code>MDL_SHARED_READ</code>：在执行任何 SELECT 时，MySQL 都会在打开表的时候对表结构加一个元数据读锁，类型叫 <code>MDL_SHARED_READ</code>。<ul>
<li>作用：保证在查询进行时，表定义（DDL）不会被改动（比如 <code>ALTER TABLE</code>）。</li>
<li>持续时间：从打开表到查询结束（<code>close_tables()</code>）为止。</li>
</ul>
</li>
</ul>
<p><strong>InnoDB 内部的短期页锁（Latch）与 MVCC</strong></p>
<ul>
<li>页锁（Page Latch）：为了从缓冲池安全地读取 B+ 树节点和行记录，InnoDB 在内存页上会拿短期的读或写 latch（互斥锁），确保数据页在读取&#x2F;解码时不被并发修改。<ul>
<li>这不是 SQL 层面的锁，你在 <code>SHOW ENGINE INNODB STATUS</code> 能看到它们，但在 <code>SHOW OPEN TABLES</code> 或 <code>INFORMATION_SCHEMA.INNODB_TRX</code> 中看不到。</li>
</ul>
</li>
<li>MVCC 版本控制：<strong>默认一致性读不会向行上加记录锁或间隙锁</strong>；它通过读视图加上 undo log 回溯来返回符合快照的行版本。<ul>
<li>不产生任何行锁，也不会阻塞并发的 UPDATE&#x2F;DELETE。</li>
<li>只有在遇到刚提交的、版本不可见的行时，InnoDB 会临时读取 undo log 中的旧版本，但这也是通过读取 undo 区块，不会在真正的索引上留下锁。</li>
</ul>
</li>
</ul>
<p>而且需要注意的是，整个流程中的数据是被一条条地读取并存储到 Record Buffer 中的，这就是 Valcano 风格的 pull-based Iteration Model 的体现。</p>
<h3 id="并行化增强"><a href="#并行化增强" class="headerlink" title="并行化增强"></a>并行化增强</h3><p>我们可以对全表扫描进行<strong>并行化增强</strong>。因为 MySQL 在 InnoDB 层引入了并行扫描功能，用于加速需要全表扫描的操作，该功能自 8.0.14 版本开始支持，通过将 B+ 树划分为多个子树并由多个工作线程并行扫描来实现。要启用并行全表扫描，只需将会话级或全局变量 <code>innodb_parallel_read_threads</code> 设置为大于 1 的值，MySQL 会根据该值和实际子树数量来决定并行线程数。</p>
<p>配置参数 <code>innodb_parallel_read_threads</code>：</p>
<ul>
<li>作用：控制 InnoDB 层并行扫描主键索引时的线程数，仅支持主键（聚簇索引）扫描，不支持二级索引扫描。</li>
<li>默认值：默认值为可用逻辑处理器数除以 8，至少 4；MySQL 8.4 之前始终为 4。</li>
<li>范围：1 至 256，总线程数上限为 256（跨所有会话）; 达到上限后会话会回退到单线程扫描。</li>
</ul>
<p>动态修改：支持会话级和全局级动态设置，例如：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SET GLOBAL innodb_parallel_read_threads = 16;</span><br><span class="line">SET SESSION innodb_parallel_read_threads = 8;</span><br></pre></td></tr></table></figure>

<p>然后执行需要全表扫描的 SQL 即可利用并行扫描。</p>
<h3 id="其他相关参数"><a href="#其他相关参数" class="headerlink" title="其他相关参数"></a>其他相关参数</h3><ul>
<li><code>innodb_ddl_threads</code>：控制并行创建二级索引或重建表时的排序和 B+ 树构建线程数。</li>
<li><code>innodb_ddl_buffer_size</code>：并行 DDL 操作的排序缓冲区总大小，应配合 <code>innodb_parallel_read_threads</code> 一同调优。</li>
</ul>
<h4 id="并行扫描原理"><a href="#并行扫描原理" class="headerlink" title="并行扫描原理"></a>并行扫描原理</h4><p>MySQL 并行查询实际上是对 B+ 树的并行扫描。核心流程如下：</p>
<ol>
<li>调用扫描接口：用户线程执行如 <code>SELECT COUNT(*)</code> 等语句后，进入 InnoDB 并行扫描逻辑，从 <code>row_scan_index_for_mysql</code> 接口开始分发任务。</li>
<li>预分片（coarse-grained sharding）：用户线程先对整个聚簇索引做粗粒度分片，将每个子树（Range），由 <code>[start, end)</code> 两个游标标记，放入任务队列。其中分片的步骤如下：<ol>
<li>用户线程在预分片期间对整个索引加 INDEX S 锁，并对根页加 ROOT PAGE S 锁，确保树在分片时不会发生页分裂或新增子树。 </li>
<li>根页每条记录都包含一个指向子树的指针。用户线程依次读取这些指针，对应第 i 条指针即第 i 个子树。</li>
<li>对于每个指针，沿 B+ 树从该指针所在页向下定位到最左叶记录。</li>
<li>在遍历过程中，对每个经过的页加 S 锁，定位完成后创建一个 Iter，其中包含原始记录指针 <code>m_rec</code> 和持久化游标 <code>m_pcur</code>，用于后续线程快速定位。</li>
</ol>
</li>
<li>创建工作线程：根据 <code>innodb_parallel_read_threads</code> 值启动相应数量的工作线程，然后等待所有工作线程完成。</li>
<li>工作线程取任务：每个工作线程从队列中取出一个 Range，如粒度过大（分片数 ＞ 线程数）则再基于该 RANGE 的键值范围按同样方式二次切分，然后依次扫描该范围内的记录，通过内部函数 <code>row_search_mvcc</code> 获取每条记录并执行回调（如计数或检查）。</li>
<li>结果汇总：各线程扫描完毕后，用户线程收集各子树的统计结果或校验结果，并返回给 SERVER 层。</li>
</ol>
<h4 id="分片（Sharding）机制"><a href="#分片（Sharding）机制" class="headerlink" title="分片（Sharding）机制"></a>分片（Sharding）机制</h4><p>并行扫描将 B+ 树划分为多个子树，每个子树对应一个 RANGE 结构体：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">RANGE</span> &#123;</span><br><span class="line"> Iter start; <span class="comment">// 子树起始记录位置</span></span><br><span class="line"> Iter end;  <span class="comment">// 子树结束记录位置（右开区间）</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>其中 Iter 包含了记录指针和 B+ 树游标，用于定位扫描边界。工作线程可对粒度过大的 Range 再次细分，以提高负载均衡。</p>
<p>Iter 的结构如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** Boundary of the range to scan. */</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Iter</span> &#123;</span><br><span class="line"> <span class="comment">/** Destructor. */</span></span><br><span class="line"> ~<span class="built_in">Iter</span>();</span><br><span class="line"> <span class="comment">/** Heap used to allocate m_rec, m_tuple and m_pcur. */</span></span><br><span class="line"> <span class="type">mem_heap_t</span> *m_heap&#123;&#125;;   <span class="comment">// 分配迭代所需内存（记录副本、tuple、游标等）</span></span><br><span class="line"> <span class="comment">/** m_rec column offsets. */</span></span><br><span class="line"> <span class="type">const</span> ulint *m_offsets&#123;&#125;; <span class="comment">// 原始记录中各列的偏移数组</span></span><br><span class="line"> <span class="comment">/** Start scanning from this key. Raw data of the row. */</span></span><br><span class="line"> <span class="type">const</span> <span class="type">rec_t</span> *m_rec&#123;&#125;;   <span class="comment">// 指向边界记录的原始数据</span></span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Tuple representation inside m_rec,</span></span><br><span class="line"><span class="comment">  * for two Iter instances in a range m_tuple will be [first-&gt;m_tuple, second-&gt;m_tuple).</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="type">const</span> <span class="type">dtuple_t</span> *m_tuple&#123;&#125;; <span class="comment">// m_rec 对应的解析后 tuple，方便按列访问</span></span><br><span class="line"> <span class="comment">/** Persistent cursor. */</span></span><br><span class="line"> <span class="type">btr_pcur_t</span> *m_pcur&#123;&#125;;   <span class="comment">// 用于快速定位 m_rec 所在页的 B+ 树游标</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="字段说明"><a href="#字段说明" class="headerlink" title="字段说明"></a>字段说明</h3><ol>
<li><code>m_heap</code>：用于在堆上分配和管理该 Iter 所需的临时内存，包括存放记录副本、tuple 结构和游标状态等。</li>
<li><code>m_offsets</code>：指向一组 ulint，用于记录 m_rec 中每列在页面上的偏移位置，以便快速定位列值。</li>
<li><code>m_rec</code>：原始记录指针（raw record），标记分片边界的具体行数据。</li>
<li><code>m_tuple</code>：m_rec 的逻辑封装（<code>dtuple_t</code>），两端 Iter 的 <code>m_tuple</code> 共同定义了扫描区间；扫描时常直接基于 <code>m_tuple</code> 进行比较和移动。</li>
<li><code>m_pcur</code>：持久化游标（<code>btr_pcur_t*</code>），用于记录定位 <code>m_rec</code> 所在页面和行号，后续扫描可通过该游标快速恢复上次位置，而无需从根节点重定位。</li>
</ol>
<h4 id="支持的语句类型"><a href="#支持的语句类型" class="headerlink" title="支持的语句类型"></a>支持的语句类型</h4><p>目前，InnoDB 并行扫描支持以下全表操作场景：</p>
<ul>
<li><code>SELECT COUNT(*) FROM table1;</code> 完整扫描主键索引并行计数。</li>
<li><code>CHECK TABLE table1;</code> 第二次扫描主键索引时可并行校验。</li>
<li><code>CREATE INDEX … ON table1</code> &#x2F; <code>ALTER TABLE … ADD INDEX …</code> 扫描和排序阶段支持并行，B+ 树构建阶段仍为单线程。</li>
<li><code>ALTER TABLE … ENGINE=InnoDB</code> &#x2F; <code>OPTIMIZE TABLE</code> 重建表阶段扫描主键索引不并行，排序和索引构建支持并行。</li>
</ul>
<h4 id="限制与注意事项"><a href="#限制与注意事项" class="headerlink" title="限制与注意事项"></a>限制与注意事项</h4><ul>
<li>并行扫描仅适用于主键索引，不支持二级索引扫描或包含虚拟列、全文索引、空间索引的表。</li>
<li>并行线程读取的数据页会被放到缓冲池 LRU 链表尾部，避免在扫描时占用过多热页。</li>
<li>当并行线程数超过子树数量时，实际使用的线程数取两者中的最小值。</li>
</ul>
<h2 id="B-树索引"><a href="#B-树索引" class="headerlink" title="B+ 树索引"></a>B+ 树索引</h2><p>B+ 树是为磁盘或其他直接存取辅助设备设计的一种自平衡的多路查找树。在 B+ 树中，所有记录节点都是按键值的大小顺序放在同一层的叶子节点上，由各叶子节点指针进行连接。</p>
<p>B+ 树的非叶子节点只存储键值，不存储数据，而叶子节点存储了所有的数据，并且构成了一个有序双向链表。因此，范围查询时就可以直接通过叶子节点间的指针顺序访问整个查询范围内的所有记录，而无需对树进行多次遍历。</p>
<p>在B+ 树的实现中，节点的大小往往被设计为与磁盘页大小相同（或者是其整数倍）。相比于 B 树（非叶子节点中存储指针和数据），B+ 树的非叶子节点能够存储更多的指针，提升索引查找的效率并且减少磁盘 I&#x2F;O 次数，因为每次从磁盘中加载的节点携带了更多的指针信息。</p>
<p>以下是 B-Tree 的结构（绿色代表子节点的地址，黄色代表记录的主键，红色代表单条记录中除主键外的数据，之后的图也是如此）：</p>
<p><img src="/../../images/MySQL/mysql_index_bt.drawio.png" alt="img"></p>
<p>B-Tree可视化：<a target="_blank" rel="noopener" href="https://www.cs.usfca.edu/~galles/visualization/BTree.html">B-Tree Visualization</a></p>
<p>以下是 B+ 树的结构：</p>
<p><img src="/../../images/MySQL/mysql_index_bpt.drawio.png" alt="img"></p>
<p>B+ 树可视化：<a target="_blank" rel="noopener" href="https://www.cs.usfca.edu/~galles/visualization/BPlusTree.html">B+ Tree Visualization</a></p>
<p>也就是说，MySQL 索引数据结构在经典 B-Tree 的基础上，增加了一个指向相邻左右叶子节点的链表指针，形成了双向循环链表，这样可以方便范围查询和反向遍历。</p>
<p>如果需要在 B+树中从大值向小值进行范围查询，可以按以下步骤操作：</p>
<ul>
<li>定位到最右侧节点：首先，找到包含最大值的叶子节点。这通常通过从根节点开始向右遍历树的方式实现。</li>
<li>反向遍历：一旦定位到了最右侧的叶子节点，可以利用叶节点间的双向链表向左遍历。</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/rjzheng/p/12316685.html">为什么Mongodb索引用B树，而MySQL用B+树?</a>：在关系型数据库中，遍历操作比较常见，因此采用 B+ 树作为索引比较合适。而在非关系型数据库中，单一查询比较常见，因此采用 B 树作为索引比较合适。</p>
<p>B+ 树对于 B 树的优势：</p>
<ol>
<li>更高的查询效率： B+ 树叶子节点的双向链表使得范围查询时无需从根节点开始进行多次索引查询，只需顺序遍历双向链表即可。</li>
<li>更高的空间利用率：B+ 树非叶子节点只存储指针，使得单个节点能够存储更多的指针只指向子节点，且单次磁盘 I&#x2F;O 读取更多信息，减少 I&#x2F;O 读取次数。</li>
<li>更稳定的查询效率：B+ 树叶子节点深度相同，数据查询路径长度相同。</li>
</ol>
<p>B+ 树对于二叉树的优势：</p>
<ol>
<li>B+ 树的每个节点可以有 m 个子节点，而红黑树和二叉平衡树都只有 2 个。</li>
<li>普通二叉树存在退化的情况，如果它退化成链表，就相当于全表扫描。</li>
<li>读取数据的时候，是从磁盘先读到内存。平衡二叉树的每个节点只存储一个键值和数据，而 B+ 树可以存储更多的节点数据，树的高度也会降低，因此读取磁盘的次数就会下降，查询效率就快。</li>
</ol>
<p>为什么 InnoDB 存储引擎选择使用 B+Tree 索引结构？</p>
<ol>
<li>相比于二叉树（顺序插入数据行的情况下会退化成链表），B+Tree 更平衡，层级更少，搜索效率高。</li>
<li>就B-Tree（或 BST）而言，无论叶子节点还是非叶子节点都会保留数据，这样导致一页中存储的键减少，指针也减少了，要保存大量数据，只能增加树的高度，导致性能降低。</li>
<li>相比于 Hash 索引，B+Tree 支持范围匹配及排序操作。</li>
</ol>
<p>一棵 B+ 树能存储多少数据？</p>
<p>假如我们的主键 ID 是 bigint 类型，长度为 8 个字节。指针大小在 InnoDB 源码中设置为 6 字节，这样一共 14 字节。所以非叶子节点(一页)可以存储 $16384&#x2F;14&#x3D;1170$ 个这样的单元(键值+指针)。</p>
<p>一个指针指向一个存放记录的页，一页可以放 16 条数据，树深度为 2 的时候，可以存放 $1170*16&#x3D;18720$ 条数据。</p>
<p>同理，树深度为 3 的时候，可以存储的数据为 $1170<em>1170</em>16&#x3D;21902400$ 条记录。</p>
<p>理论上，在 InnoDB 存储引擎中，B+树的高度一般为 2-4 层，就可以满足千万级数据的存储。查找数据的时候，一次页的查找代表一次 IO，当我们通过主键索引查询的时候，最多只需要 2-4 次 IO 就可以了。</p>
<h3 id="B-树的插入操作"><a href="#B-树的插入操作" class="headerlink" title="B+ 树的插入操作"></a>B+ 树的插入操作</h3><p>B+ 树的插入必须保证插入后叶子节点中的记录依然排序，同时需要考虑插入到 B+ 树的三种情况，每种情况都可能会导致不同的插入算法。具体如下：</p>
<p>叶子节点未满，索引节点未满：直接将记录插入到目标叶子节点的合适位置（保持有序）。</p>
<p>叶子节点已满，索引节点未满：</p>
<ul>
<li>拆分叶子节点为左右两个节点。</li>
<li>将中间键值提升为分隔键，插入到父级索引页。</li>
<li>原叶子节点中：<ul>
<li>小于中间键值的记录 → 左侧新页；</li>
<li>大于等于中间键值的记录 → 右侧新页。</li>
</ul>
</li>
</ul>
<p>叶子节点和索引节点都已满：</p>
<ul>
<li><p>拆分叶子节点（Leaf Page）：</p>
<ul>
<li>小于中间键值的记录 → 左页；</li>
<li>大于等于中间键值的记录 → 右页；</li>
</ul>
</li>
<li><p>将中间键值提升为分隔键，插入到父级索引页。</p>
</li>
<li><p>由于父级索引页也已满，继续处理其溢出：</p>
<ul>
<li>拆分 Index Page：<ul>
<li>小于中间索引值的记录 → 左侧索引页；</li>
<li>大于中间索引值的记录 → 右侧索引页；</li>
</ul>
</li>
<li>将新的中间索引项继续提升到上一层索引页中。</li>
</ul>
</li>
<li><p>若上一层索引页仍满，则继续递归，直到根节点；若根节点也满，最终会导致根节点分裂，树高度增加。</p>
</li>
</ul>
<p>因此，不管怎么变化，B+ 树总是会保持平衡。但是为了保持平衡，对于新插入的键值可能需要做大量的拆分页操作。因为 B+ 树结构主要用于磁盘，页的拆分意味着磁盘的操作，所以应当在可能的情况下尽量减少页的拆分操作。因此，B+ 树同样提供了类似于平衡二叉树的旋转功能。</p>
<p>旋转发生在叶子页（Leaf Page）已经满，但其左右兄弟节点没有满的情况下。这时 B+ 树并不会急于做拆分页的操作，而是将记录移到所在页的兄弟节点上。在通常情况下，会首先检查左兄弟以执行旋转操作。在下面的例子中：若插入键值 70，B+ 树并不会立即拆分叶子节点，而是先做旋转操作。</p>
<p><img src="/../../images/MySQL/mysql_index_insert.drawio.png" alt="img"></p>
<p>我们可以看到，旋转操作使得 B+ 树减少了一次页的拆分操作，同时这棵 B+ 树的高度依然为 2。</p>
<h3 id="B-树的删除操作"><a href="#B-树的删除操作" class="headerlink" title="B+ 树的删除操作"></a>B+ 树的删除操作</h3><p>B+ 树使用填充因子（fill factor）来控制树的删除变化，50% 是填充因子可设的最小值。B+ 树的删除操作同样必须保证删除后叶子节点中的记录依然排序。与插入一样，B+ 树的删除操作同样需要考虑三种情况，根据填充因子的变化来衡量是否需要进行节点合并或旋转操作。</p>
<table>
<thead>
<tr>
<th>叶子节点小于填充因子</th>
<th>中间节点小于填充因子</th>
<th>操作</th>
</tr>
</thead>
<tbody><tr>
<td>No</td>
<td>No</td>
<td>直接将记录从叶子节点删除，如果该节点还是 Index Page 的节点，用该节点的右兄弟节点代替</td>
</tr>
<tr>
<td>Yes</td>
<td>No</td>
<td>合并叶子节点和它的兄弟节点，同时更新对应的 Index Page</td>
</tr>
<tr>
<td>Yes</td>
<td>Yes</td>
<td>1. 合并叶子节点和它的兄弟节点  <br>2. 更新对应的 Index Page  <br>3. 合并 Index Page 和它的兄弟节点</td>
</tr>
</tbody></table>
<p>对于第一种情况的后半部分的解释：</p>
<p>在以下 B+ 树中（这里省去叶节点之间的指针），我们删除键值为 25 的记录，因为该值也是 Index Page 中的值，所以在删除之后，需要将 25 的右兄弟节点的 28 更新到 Index Page 中。</p>
<p><img src="/../../images/MySQL/mysql_index_bt_del.drawio.png" alt="img"></p>
<p>以下是删除之后的 B+ 树。</p>
<p><img src="/../../images/MySQL/mysql_index_bt_deled.drawio.png" alt="img"></p>
<p>这时，如果删除 Leaf Page 中键值为 60 的记录，那么 Fill Factor 小于 50%，需要做合并操作；同样，在删除 Index Page 中相关记录后，需要做 Index Page 的合并操作。结果如下：</p>
<p><img src="/../../images/MySQL/mysql_index_del_merge.drawio.png" alt="img"></p>
<p>注意：页面合并时，<strong>首先</strong>尝试与<strong>左侧</strong>直接相邻的兄弟页合并；仅在左侧不符合条件时，才会检查右侧兄弟页。如果左右两侧都没有足够的空间容纳当前页的所有记录，合并操作将不会执行，页面将保持“半空”状态，直到后续操作（如父节点合并或树高度调整）触发新的重组逻辑。合并成功后，还需在父节点中删除对应的指针条目，并在必要时向上递归合并或降高。</p>
<h3 id="聚集索引"><a href="#聚集索引" class="headerlink" title="聚集索引"></a>聚集索引</h3><p>数据库中的 B+ 树索引可以分为聚集索引（clustered index）和辅助索引（secondary index）。但是无论是聚集索引还是辅助索引，其内部结构都是 B+ 树，即高度平衡的，且叶子节点存放所有的数据。聚集索引与辅助索引的不同之处在于：叶子节点存放的是否是一整行的信息。</p>
<p>之前已经介绍过，InnoDB 存储引擎表是索引组织表，即表中数据按照主键顺序存放。而聚集索引就是按照每张表的主键构造一棵 B+ 树，同时叶子子节点中存放的即为整张表的行记录数据，也将聚集索引的叶子节点称为数据页。聚集索引的这个特性决定了索引组织表中数据也是索引的一部分。同 B+ 树数据结构一样，每个数据页都通过一个双向链表来进行链接。</p>
<p>由于实际的数据页只能按照一棵 B+ 树进行排序，因此每张表只能拥有一个聚集索引。在多数情况下，查询优化器倾向于采用聚集索引。因为聚集索引能够在 B+ 树索引的叶子节点上直接找到数据。此外，由于定义了数据的逻辑顺序，聚集索引能够特别快速地访问针对范围值的查询。查询优化器能够快速发现某一段范围的数据页需要扫描。</p>
<p>例如：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> t (</span><br><span class="line"> a <span class="type">INT</span> <span class="keyword">NOT NULL</span>,</span><br><span class="line"> b <span class="type">VARCHAR</span>(<span class="number">8000</span>),</span><br><span class="line"> c <span class="type">INT</span> <span class="keyword">NOT NULL</span>,</span><br><span class="line"> <span class="keyword">PRIMARY KEY</span> (a),</span><br><span class="line"> KEY idx_c (c)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB;</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT INTO</span> t <span class="keyword">SELECT</span> <span class="number">1</span>, REPEAT(<span class="string">&#x27;a&#x27;</span>, <span class="number">7000</span>), <span class="number">-1</span>;</span><br><span class="line"><span class="keyword">INSERT INTO</span> t <span class="keyword">SELECT</span> <span class="number">2</span>, REPEAT(<span class="string">&#x27;a&#x27;</span>, <span class="number">7000</span>), <span class="number">-2</span>;</span><br><span class="line"><span class="keyword">INSERT INTO</span> t <span class="keyword">SELECT</span> <span class="number">3</span>, REPEAT(<span class="string">&#x27;a&#x27;</span>, <span class="number">7000</span>), <span class="number">-3</span>;</span><br><span class="line"><span class="keyword">INSERT INTO</span> t <span class="keyword">SELECT</span> <span class="number">4</span>, REPEAT(<span class="string">&#x27;a&#x27;</span>, <span class="number">7000</span>), <span class="number">-4</span>;</span><br></pre></td></tr></table></figure>

<p>我们可以发现数据页上存放的是完整的每行记录，而在非数据页的索引页中，存放的仅仅是键值及指向数据页的偏移量，而不是一个完整的行记录。具体结构如下：</p>
<p><img src="/../../images/MySQL/mysql_index_cluster.drawio.png" alt="img"></p>
<p>许多资料会说：聚集索引按照顺序物理地存储数据。但是试想一下，如果聚集索引必须按照特定顺序存放物理记录，则维护成本显得非常之高。所以，聚集索引的存储并不是物理上连续的，而是逻辑上连续的。这其中有两点： </p>
<ol>
<li>前面说过的页通过双向链表链接，页按照主键的顺序排列； </li>
<li>每个页中的记录也是通过双向链表进行维护的，物理存储上可以不按主键存放。</li>
</ol>
<p>说白了，就是在物理存储时，不同页和页内记录的数据块可以散布在数据文件各处，通过上述链表结构保证逻辑遍历顺序，从而大幅降低维护开销。</p>
<p>聚集索引的另一个好处是，它对于主键的排序查找和范围查找速度非常快。叶子节点的数据就是用户所要查询的数据。</p>
<p>还有就是范围查询（range query），即如果要查找主键某一范围内的数据，通过叶子节点的上层中间节点就可以得到页的范围，之后直接读取数据页即可。</p>
<p>此外，聚集索引存在如下选取规则：</p>
<ul>
<li>如果存在主键，主键索引就是聚集索引。</li>
<li>如果不存在主键，将使用第一个遇到的唯一索引作为聚集索引。</li>
<li>如果既没有主键也没有合适的唯一索引，则自动生成一个以单调递增的 row ID 作为键的隐藏聚集索引。</li>
</ul>
<h3 id="辅助索引"><a href="#辅助索引" class="headerlink" title="辅助索引"></a>辅助索引</h3><p><img src="/../../images/MySQL/mysql_index_sec.drawio.png" alt="img"></p>
<p>对于辅助索引（Secondary Index，也称非聚集索引），叶子节点并不包含行记录的全部数据。也就是说，叶子节点除了包含键值以外，每个叶子节点中的索引行中还包含了一个书签。该书签用来告诉 InnoDB 存储引擎哪里可以找到与该索引行对应的行数据。由于 InnoDB 存储引擎表是索引组织表，因此辅助索引的书签就是相应行数据在聚集索引中的聚集索引键。</p>
<p>辅助索引的存在并不影响数据在聚集索引中的组织，因此每张表上可以有多个辅助索引。当通过辅助索引来寻找数据时，InnoDB 存储引擎会：</p>
<ol>
<li>遍历辅助索引树，到达叶子节点后获得对应行的聚集索引键；</li>
<li>再通过聚集索引树查找该主键，定位到完整的行记录所在的数据页。</li>
</ol>
<p>举例来说，如果辅助索引树的高度为 3，则需要 3 次查找才能找到指定的主键；若聚集索引树的高度也为 3，则还需要额外 3 次查找才能在聚集索引中定位到完整行的数据页。因此，总共需要 6 次逻辑 I&#x2F;O 访问，才能得到最终的数据页。</p>
<p>示例：</p>
<p>在之前的表 t 上新增一列 c，并对列 c 创建聚集索引：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">ALTER TABLE</span> t</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">ADD</span> c <span class="type">INT</span> <span class="keyword">NOT NULL</span>;</span><br><span class="line">Query OK, <span class="number">4</span> <span class="keyword">rows</span> affected (<span class="number">0.24</span> sec)</span><br><span class="line">Records: <span class="number">4</span> Duplicates: <span class="number">0</span> Warnings: <span class="number">0</span></span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">UPDATE</span> t <span class="keyword">SET</span> c <span class="operator">=</span> <span class="number">0</span> <span class="operator">-</span> a;</span><br><span class="line">Query OK, <span class="number">4</span> <span class="keyword">rows</span> affected (<span class="number">0.04</span> sec)</span><br><span class="line"><span class="keyword">Rows</span> matched: <span class="number">4</span> Changed: <span class="number">4</span> Warnings: <span class="number">0</span></span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">ALTER TABLE</span> t <span class="keyword">ADD</span> KEY idx_c (c);</span><br><span class="line">Query OK, <span class="number">4</span> <span class="keyword">rows</span> affected (<span class="number">0.28</span> sec)</span><br><span class="line">Records: <span class="number">4</span> Duplicates: <span class="number">0</span> Warnings: <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>更改之后的索引结构如下：</p>
<p><img src="/../../images/MySQL/mysql_index_sec_clu.drawio.png" alt="img"></p>
<p>上图显示了表 t 中辅助索引 <code>idx_c</code> 和聚集索引的关系。可以看到辅助索引的叶子节点中包含了列 c 的值和主键的值。因为这里的键值为负值，所以会发现以 <code>7f ff ff ff</code> 的方式进行内部存储。7（0111）最高位为 0，代表负值，实际的值应该取反后加 1，即得 -1。</p>
<h3 id="B-树索引的分裂"><a href="#B-树索引的分裂" class="headerlink" title="B+ 树索引的分裂"></a>B+ 树索引的分裂</h3><p>之前介绍的 B+ 树分裂是最为简单的一种情况，这和数据库中 B+ 树索引的实际情况可能略有不同，因为并未涉及并发，而这才是 B+ 树索引实现中最为困难的部分。</p>
<p>B+ 树索引页的分裂并不总是从页的中间记录开始，这样可能会导致页空间的浪费。例如下面的记录：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1, 2, 3, 4, 5, 6, 7, 8, 9</span><br></pre></td></tr></table></figure>

<p>插入是根据自增顺序进行的，若此时插入第 10 条记录后需要进行页的分裂操作，那么根据之前介绍的分裂方法，会将记录 5 作为分裂点记录，分裂后得到下面两个页：</p>
<p>Page 1: <code>1, 2, 3, 4</code>；</p>
<p>Page 2: <code>5, 6, 7, 8, 9, 10</code>。</p>
<p>由于插入是顺序的，P1 这个页将不会再有新记录被插入，从而导致空间浪费；而 P2 又会再次进行分裂。</p>
<p>InnoDB 存储引擎的 Page Header 中有以下几个部分用来保存在页中记录插入的顺序信息：</p>
<ul>
<li><code>PAGE_LAST_INSERT</code></li>
<li><code>PAGE_DIRECTION</code></li>
<li><code>PAGE_N_DIRECTION</code></li>
</ul>
<p>通过这些信息，InnoDB 存储引擎可以决定是向左还是向右进行分裂，同时决定将分裂点记录为哪一个。若插入是随机的，则取页中的中间记录作为分裂点记录，这和之前介绍的相同。若往同一方向进行插入的记录数量为 5，并且目前已定位（cursor）到的记录（该记录为待插入记录的前一条记录）之后还有 3 条记录，则分裂点记录为定位到的记录后的第三条记录；否则，分裂点记录就是待插入的记录。</p>
<p>示例：</p>
<p>下面来看一个向右分裂的例子，并且定位到的记录之后还有 3 条记录，则分裂点记录如下：</p>
<p><img src="/../../images/MySQL/mysql_index_before_split.drawio.png" alt="img"></p>
<p>分裂后的结果如下：</p>
<p><img src="/../../images/MySQL/mysql_index_after_split.drawio.png" alt="img"></p>
<p>接着是分裂点就为插入记录本身：</p>
<p><img src="/../../images/MySQL/mysql_index_split_self.drawio.png" alt="img"></p>
<h3 id="B-树的管理"><a href="#B-树的管理" class="headerlink" title="B+ 树的管理"></a>B+ 树的管理</h3><h4 id="索引管理"><a href="#索引管理" class="headerlink" title="索引管理"></a>索引管理</h4><p>索引的创建和删除可以通过两种方法，一种是 ALTER TABLE，另一种是 CREATE&#x2F;DROP INDEX。通过 ALTER TABLE 创建索引的语法为：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER TABLE</span> tbl_name</span><br><span class="line"><span class="keyword">ADD</span> [INDEX<span class="operator">|</span>KEY] [index_name]</span><br><span class="line">[index_type] (index_col_name, ...) [index_option] ...</span><br><span class="line"></span><br><span class="line"><span class="keyword">ALTER TABLE</span> tbl_name</span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">PRIMARY KEY</span> <span class="operator">|</span> <span class="keyword">DROP</span> &#123;INDEX<span class="operator">|</span>KEY&#125; index_name</span><br></pre></td></tr></table></figure>

<p>CREATE&#x2F;DROP INDEX 的语法同样很简单：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> [<span class="keyword">UNIQUE</span>] INDEX index_name</span><br><span class="line">[index_type] <span class="keyword">ON</span> tbl_name (index_col_name, ...)</span><br><span class="line"></span><br><span class="line"><span class="keyword">DROP</span> INDEX index_name <span class="keyword">ON</span> tbl_name</span><br></pre></td></tr></table></figure>

<p>用户可以设置对整个列的数据进行索引，也可以只索引一列的开头部分数据，如前面创建的表 t，列 b 为 <code>varchar(8000)</code>，但是用户可以只索引前 100 个字段，如：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">ALTER TABLE</span> t</span><br><span class="line">  <span class="operator">-</span><span class="operator">&gt;</span> <span class="keyword">ADD</span> KEY idx_b (b(<span class="number">100</span>));</span><br><span class="line">Query OK, <span class="number">4</span> <span class="keyword">rows</span> affected (<span class="number">0.32</span> sec)</span><br><span class="line">Records: <span class="number">4</span> Duplicates: <span class="number">0</span> Warnings: <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>若用户想要查看表中索引的信息，可以使用命令 SHOW INDEX。我们以主键列为例，结果如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SHOW</span> INDEX <span class="keyword">FROM</span> t\G;</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">    <span class="keyword">Table</span>: t</span><br><span class="line">    Non_unique: <span class="number">0</span></span><br><span class="line">    Key_name: <span class="keyword">PRIMARY</span></span><br><span class="line">    Seq_in_index: <span class="number">1</span></span><br><span class="line">    Column_name: a</span><br><span class="line">    <span class="keyword">Collation</span>: A</span><br><span class="line">    <span class="keyword">Cardinality</span>: <span class="number">2</span></span><br><span class="line">    Sub_part: <span class="keyword">NULL</span></span><br><span class="line">    Packed: <span class="keyword">NULL</span></span><br><span class="line">    <span class="keyword">Null</span>: </span><br><span class="line">    Index_type: BTREE</span><br><span class="line">    Comment: </span><br><span class="line">…</span><br></pre></td></tr></table></figure>

<p>以上结果中每列的含义如下：</p>
<p><strong><code>Table</code></strong>：索引所在的表名。</p>
<p><strong><code>Non_unique</code></strong>：非唯一的索引，可以看到 primary key 是 0，因为必须是唯一的。</p>
<p><strong><code>Key_name</code></strong>：索引的名字，用户可以通过这个名字来执行 DROP INDEX。</p>
<p><strong><code>Seq_in_index</code></strong>：索引中该列的位置，如果看联合索引 idx_a_c 就比较直观了。</p>
<p><strong><code>Column_name</code></strong>：索引列的名称。</p>
<p><strong><code>Collation</code></strong>：列以什么方式存储在索引中。可以是 A 或 NULL。B+ 树索引总是 A，即排序的。如果使用了 Heap 存储引擎，并且建立了 Hash 索引，这里就会显示 NULL 了。因为 Hash 根据 Hash 桶存放索引数据，而不是对数据进行排序。</p>
<p><strong><code>Cardinality</code></strong>：非常关键的值，表示索引中唯一值的数目的估计值。Cardinality 表的行数应尽可能接近 1，如果非常小，那么用户需要考虑是否可以删除此索引。</p>
<p><strong><code>Sub_part</code></strong>：是否是列的部分被索引。如果看到 <code>idx_b</code> 这个索引，这里显示 100，表示只对 b 列的前 100 字符进行索引。如果索引整个列，则该字段为 NULL。</p>
<p><strong><code>Packed</code></strong>：关键字如何被压缩。如果没有被压缩，则为 NULL。</p>
<p><strong><code>Null</code></strong>：是否索引的列含有 NULL 值。可以看到 <code>idx_b</code> 这里为 Yes，因为定义的列 b 允许 NULL 值。</p>
<p><strong><code>Index_type</code></strong>：索引的类型。InnoDB 存储引擎只支持 B+ 树索引，所以这里显示的都是 BTREE。</p>
<p><strong><code>Comment</code></strong>：注释。</p>
<p>Cardinality 值非常关键，优化器会根据这个值来判断是否使用这个索引。但是这个值并不是实时更新的，即并非每次索引的更新都会更新该值，因为这样代价太大了。因此这个值是不太准确的，只是一个大概的值。上面显示的结果主键的 Cardinality 为 2，但是很显然我们表中有 4 条记录，这个值应该是 4。如果需要更新索引 Cardinality 的信息，可以使用 <code>ANALYZE TABLE</code> 命令。</p>
<p>另一个问题是 MySQL 数据库对于 Cardinality 计数的问题，在运行一段时间后，可能会看到下面的结果：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">show</span> index <span class="keyword">from</span> Profile\G;</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">    <span class="keyword">Table</span>: Profile</span><br><span class="line">    Non_unique: <span class="number">0</span></span><br><span class="line">    Key_name: UserName</span><br><span class="line">    Seq_in_index: <span class="number">1</span></span><br><span class="line">    Column_name: username</span><br><span class="line">    <span class="keyword">Collation</span>: A</span><br><span class="line">    <span class="keyword">Cardinality</span>: <span class="keyword">NULL</span></span><br><span class="line">    Sub_part: <span class="keyword">NULL</span></span><br><span class="line">    Packed: <span class="keyword">NULL</span></span><br><span class="line">    <span class="keyword">Null</span>: </span><br><span class="line">    Index_type: BTREE</span><br><span class="line">    Comment: </span><br></pre></td></tr></table></figure>

<p><strong>Cardinality</strong> 为 NULL，在某些情况下可能会发生索引建立了却没有用到的情况。或者对两条基本一样的语句执行 EXPLAIN，但是最终出来的结果不一样：一个使用索引，另外一个使用全表扫描。</p>
<p>这时最好的解决办法就是做一次 <code>ANALYZE TABLE</code> 的操作。因此建议在一个非高峰时间，对应用程序下的几张核心表做 <code>ANALYZE TABLE</code> 操作，这能使优化器和索引更好地为你工作。</p>
<h4 id="Fast-Index-Creation"><a href="#Fast-Index-Creation" class="headerlink" title="Fast Index Creation"></a>Fast Index Creation</h4><p>MySQL 5.5 版本之前（不包括 5.5）存在的一个普遍被人诟病的问题是 MySQL 数据库对于索引的添加或者删除的这类 DDL 操作，MySQL 数据库的操作过程是：</p>
<ul>
<li>首先创建一张新的临时表，表结构为通过命令 ALTER TABLE 新定义的结构。</li>
<li>然后把原表中数据导入到临时表。</li>
<li>接着删除原表。</li>
<li>最后把临时表重名为原来的表名。</li>
</ul>
<p>可以发现，若用户对一张大表进行索引的添加和删除操作，那么会花费很长的时间。更关键的是，若有大量事务需要访问正在被修改的表，这意味着数据库服务不可用。</p>
<p><strong>InnoDB</strong> 存储引擎从 <strong>InnoDB 1.0.x</strong> 版本开始支持一种称为 <strong>Fast Index Creation（快速索引创建）</strong> 的索引创建方式——简称 <strong>FIC</strong>。</p>
<p>对于辅助索引的创建，InnoDB 存储引擎会对创建索引的表加上一个 <strong>S 锁</strong>。在创建的过程中，不需要重建表，因此速度较之前提高很多，并且数据库的可用性也得到了提高。<br> 删除辅助索引操作就更简单了，InnoDB 存储引擎只需更新内部视图，并将辅助索引的空间标记为可用，同时触发 MySQL 数据库内部视图上对该索引定义即可以。</p>
<p>这里需要特别注意的是，临时表的创建路径是通过参数 tmpdir 进行设置的。用户必须保证 tmpdir 有足够的空间可以存放临时表，否则会导致创建索引失败。</p>
<p>由于 FIC 在索引的创建中对表加上了 S 锁，因此在创建的过程中只能对该表进行 <strong>读操作</strong>，若有大量的事务需要对目标表进行写操作，那么数据库的服务同样不可用。此外，FIC 方法只限用于 <strong>辅助索引</strong>，对于主键的创建和删除同样需要重建一张表。</p>
<h4 id="Online-Schema-Change"><a href="#Online-Schema-Change" class="headerlink" title="Online Schema Change"></a>Online Schema Change</h4><p>Online Schema Change（OSC）是一种用于 <strong>在线执行 MySQL DDL 操作</strong> 的技术，最早由 Facebook 推出并开源，旨在解决传统 DDL 操作期间数据库不可用的问题。通过 OSC，用户可以在 <strong>不中断业务访问的前提下</strong> 对表结构进行修改，如添加索引、修改字段等。</p>
<p>其核心思想是通过复制原表结构创建一张临时表，并在数据迁移和结构变更过程中，借助触发器记录原表的变更操作（DML）。在数据导入和变更同步完成后，再将原表与新表进行原子性换名操作，从而实现无缝切换。</p>
<h4 id="Online-DDL"><a href="#Online-DDL" class="headerlink" title="Online DDL"></a>Online DDL</h4><p>虽然 FIC 可以让 InnoDB 存储引擎避免创建临时表，从而提高索引创建的效率，但正如前面章节所说的，索引创建时会阻塞表上的 DML 操作。OSC 虽然解决了上述的部分问题，但还是有很大的局限性。</p>
<p>MySQL 从 5.6 版本开始支持 <strong>Online DDL（在线数据定义）</strong> 操作，其允许在辅助索引创建的同时，还允许其他诸如 INSERT、UPDATE、DELETE 这类 DML 操作，这极大地提高了 MySQL 数据库在生产环境中的可用性。</p>
<p>此外，不仅是辅助索引，以下几类 DDL 操作都可以通过“在线”的方式进行操作：</p>
<ul>
<li><p>辅助索引的创建与删除</p>
</li>
<li><p>改变自增长值</p>
</li>
<li><p>添加或删除外键约束</p>
</li>
<li><p>列的重命名</p>
</li>
</ul>
<p>通过新的 <code>ALTER TABLE</code> 语法，用户可以选择索引的创建方式：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER TABLE</span> tbl_name</span><br><span class="line"><span class="keyword">ADD</span> [INDEX<span class="operator">|</span>KEY] [index_name]</span><br><span class="line">[index_type] (index_col_name,...) [index_option] ...</span><br><span class="line">ALGORITHM [<span class="operator">=</span>] &#123;<span class="keyword">DEFAULT</span><span class="operator">|</span>INPLACE<span class="operator">|</span><span class="keyword">COPY</span>&#125;</span><br><span class="line">LOCK [<span class="operator">=</span>] &#123;<span class="keyword">DEFAULT</span><span class="operator">|</span><span class="keyword">NONE</span><span class="operator">|</span>SHARED<span class="operator">|</span>EXCLUSIVE&#125;</span><br></pre></td></tr></table></figure>

<p><strong>ALGORITHM</strong> 指定了创建或删除索引的算法：</p>
<ul>
<li>COPY 表示按 MySQL 5.1 版本之前的工作模式，即创建临时表的方式。</li>
<li>INPLACE 表示索引创建或删除操作不需要创建临时表。</li>
<li>DEFAULT 表示根据参数 <code>old_alter_table</code> 判断是否使用 INPLACE 或 COPY 算法，默认值为 OFF，即采用 INPLACE 方式。</li>
</ul>
<p>LOCK 部分表示在创建或删除索引时对表加锁的情况，可选值包括：</p>
<ol>
<li>**NONE：**执行索引创建或删除操作时，对目标表不添加任何锁，即事务仍然可以进行读写操作，不会受到阻塞。因此该模式可以获得最大的并发度。</li>
<li>**SHARE：**与 FIC 类似，执行索引创建或删除操作时，对目标表加上一个 S 锁。对于读操作不影响，但会阻塞写操作。</li>
<li>**EXCLUSIVE：**执行索引创建或删除操作时，对目标表加上一个 X 锁。此时所有事务都不能进行，等同于 COPY 方式运行时的状态，但不需要创建临时表。</li>
<li>**DEFAULT：**默认模式下，系统会判断当前操作是否可以使用 NONE 模式，若不能，则判断是否可以使用 SHARE，最后才判断是否可以使用 EXCLUSIVE 模式。DEFAULT 会根据当前事务的最大并发性来自动选择 DDL 执行的锁定模式。</li>
</ol>
<p>InnoDB 存储引擎在执行 Online DDL 的过程中，会将 INSERT、UPDATE、DELETE 等 DML 操作的日志写入一个缓冲区，待索引创建完成后再将这些日志应用到表上，以此保证数据一致性。</p>
<p>这个缓冲区的大小由参数 <code>innodb_online_alter_log_max_size</code> 控制，默认值为<strong>128MB</strong>。若在创建过程中遇到大量写事务，而缓冲区不够，会报错：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Error: 1799 SQLSTATE: HY000 (ER_INNODB_ONLINE_LOG_TOO_BIG)</span><br><span class="line"></span><br><span class="line">Message: Creating index &#x27;idx_aaa&#x27; required more than &#x27;innodb_online_alter_log_max_size&#x27; bytes of modification log. Please try again.</span><br></pre></td></tr></table></figure>

<p>为避免该错误，可通过调整 <code>innodb_online_alter_log_max_size</code> 获取更大的日志缓冲空间。此外，也可以设置 <code>ALTER TABLE 的 LOCK = SHARE</code> 模式，以避免记录过多的 DML 日志。</p>
<p>需要特别注意的是，<strong>在 Online DDL 结束后，MySQL 会通过重放日志达到数据最终一致性</strong>。因此在索引创建过程中，SQL 优化器不会选择正在创建的索引。</p>
<h2 id="Cardinality"><a href="#Cardinality" class="headerlink" title="Cardinality"></a>Cardinality</h2><p>概念：Cardinality ≈ 列中不同值的数量 → 反映列的选择性。</p>
<p>判断索引价值</p>
<ul>
<li><p>高选择性（Cardinality ≈ 表行数）：建 B+ 树索引，能显著加速查询。</p>
</li>
<li><p>低选择性（取值极少，如性别、地区）：索引作用有限，通常不建。</p>
</li>
</ul>
<p>衡量方法：SHOW INDEX 查看 Cardinality；用 Cardinality &#x2F; 总行数 估算选择性。</p>
<p>注意：Cardinality 仅是估值，可能不精确，仍需结合实际查询频率和过滤比例综合判断。</p>
<h3 id="InnoDB-存储引擎的-Cardinality-统计"><a href="#InnoDB-存储引擎的-Cardinality-统计" class="headerlink" title="InnoDB 存储引擎的 Cardinality 统计"></a>InnoDB 存储引擎的 Cardinality 统计</h3><p>InnoDB 不会在每次索引变动时都重新计算 Cardinality，而是通过采样（Sample）方式周期性更新，以避免频繁统计带来的性能开销。更新时机主要有两个条件：</p>
<ol>
<li><p>表中已有数据发生变化占比 ≥ 1&#x2F;16</p>
<ol>
<li>上次统计后，若有至少六分之一的数据被插入或删除，则触发 Cardinality 重新计算。 </li>
<li>目的是：当表数据量大幅变化时，统计结果才会显著偏离实际。</li>
</ol>
</li>
<li><p><code>stat_modified_counter &gt; 2,000,000,000</code> </p>
<ol>
<li>InnoDB 内部维护一个计数器 stat_modified_counter，用于记录自上次索引统计（Cardinality 更新）以来，对表中<strong>单行数据</strong>执行 INSERT&#x2F;UPDATE 之类操作的累计次数；</li>
<li>若对某行数据的更新非常频繁——即使该表总行数未增减，但同一行被多次修改，也会触发 Cardinality 更新； </li>
<li>当 stat_modified_counter 累积值超过 20 亿，则认为存量数据“实质”发生变化，从而重新采样计算。</li>
</ol>
</li>
</ol>
<p>这种双重策略保证在数据量变化大或单行更新极其频繁时，InnoDB 能及时刷新索引选择性估计；平时不会因频繁 INSERT&#x2F;UPDATE 而频繁统计，以降低系统负担。 </p>
<p>InnoDB 通过对 B+ 树叶子页（Leaf Page）进行随机采样，估算索引的 Cardinality 值（不保证精确）。默认采样 8 个叶子页，步骤如下：</p>
<ol>
<li>获取叶子页总数：设定为 A，即 B+ 树索引中叶子节点的总数量。</li>
<li>随机选取 8 个叶子节点：对这 8 个数据页，分别统计每页中不同记录的个数，记为 P1、P2、…、P8。</li>
<li>计算估算值：<code>Cardinality ≈ (P1 + P2 + … + P8) × A / 8</code>。</li>
</ol>
<p>每次采样都可能选到不同的 8 个叶子页，故同一索引的 Cardinality 值会有所波动。也就是说，这是一个估算值，并非精准统计。</p>
<p>当表的叶子页数 ≤ 8 时，InnoDB 默认会对所有叶子页进行采样（即采样页数 ≥ 表叶子页数）。这意味着每次执行索引统计，选到的都是相同的页，导致观测到的 Cardinality 值始终一致。</p>
<p>InnoDB 采样配置</p>
<ol>
<li><p><code>innodb_stats_sample_pages</code></p>
<p>用途：设置每次计算 Cardinality 时要采样的叶子页数量。</p>
<p>默认值：8。</p>
<p>如果将该值调小，采样精度会下降；调大则统计开销增加。</p>
</li>
<li><p><code>innodb_stats_method</code><br>控制统计时对索引列中 NULL 值的处理方式，可选取：</p>
<ul>
<li><p>nulls_equal（默认）：将所有 NULL 视为相同值。</p>
</li>
<li><p>nulls_unequal：将不同 NULL 视为不同值。</p>
</li>
<li><p>nulls_ignored：完全忽略 NULL 记录，不计入不同值。</p>
</li>
</ul>
</li>
</ol>
<p>示例<br>针对某页记录：NULL, NULL, 1, 2, 2, 3, 3, 3</p>
<ul>
<li>nulls_equal → 视为 {NULL, 1, 2, 3}, Cardinality &#x3D; 4</li>
<li>nulls_unequal → 视为 {NULL₁, NULL₂, 1, 2, 3}, Cardinality &#x3D; 5</li>
<li>nulls_ignored → 只计 {1, 2, 3}, Cardinality &#x3D; 3</li>
</ul>
<p>当执行 SQL 语句 <code>ANALYZE TABLE</code>、<code>SHOW TABLE STATUS</code>、<code>SHOW INDEX</code> 以及访问 INFORMATION_SCHEMA 架构下的表 TABLES 和 STATISTICS 时，会导致 InnoDB 存储引擎去重新计算索引的 Cardinality 值。若表中的数据量非常大，并且表中存在多个辅助索引时，执行上述这些操作可能会非常慢。虽然用户可能并不希望去更新 Cardinality 值。</p>
<p>Cardinality 的设置参数如下：</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><strong>innodb_stats_persistent</strong></td>
<td>是否将命令 <code>ANALYZE TABLE</code> 计算得到的 Cardinality 值存放到磁盘上。<br>若是，则这样做的好处是可以减少重新计算每个索引的 Cardinality 值，例如当 MySQL 数据库重启时。此外，用户也可以通过命令 <code>CREATE TABLE</code> 和 <code>ALTER TABLE</code> 的选项 <code>STATS_PERSISTENT</code> 来对每张表进行控制。<br>默认值：OFF</td>
</tr>
<tr>
<td><strong>innodb_stats_on_metadata</strong></td>
<td>当通过命令 <code>SHOW TABLE STATUS</code>、<code>SHOW INDEX</code> 及访问 <code>INFORMATION_SCHEMA</code> 架构下的表 <code>TABLES</code> 和 <code>STATISTICS</code> 时，是否需要重新计算索引的 Cardinality 值。<br>默认值：OFF</td>
</tr>
<tr>
<td><strong>innodb_stats_persistent_sample_pages</strong></td>
<td>若参数 <code>innodb_stats_persistent</code> 设置为 ON，该参数表示 <code>ANALYZE TABLE</code> 更新 Cardinality 值时每次采样页的数量。<br>默认值：20</td>
</tr>
<tr>
<td><strong>innodb_stats_transient_sample_pages</strong></td>
<td>该参数用来取代之前版本的参数 <code>innodb_stats_sample_pages</code>，表示每次采样页的数量。<br>默认值：8</td>
</tr>
</tbody></table>
<p>最后两个参数的区别：</p>
<p><code>persistent_sample_pages</code>：针对持久化统计（<code>ANALYZE TABLE</code> 等）时使用，采样页数较多以提高持久化统计精度。</p>
<p><code>transient_sample_pages</code>：针对临时统计（<code>SHOW INDEX</code>、<code>SHOW TABLE STATUS</code>、<code>INFORMATION_SCHEMA</code> 查询、或 <code>innodb_stats_persistent=OFF</code> 时的抽样）时使用，采样页数较少以减少临时统计的开销。</p>
<h2 id="B-树索引的使用"><a href="#B-树索引的使用" class="headerlink" title="B+ 树索引的使用"></a>B+ 树索引的使用</h2><p>OLTP（联机事务处理）场景下，单次查询通常只访问非常少量的记录（往往 ≤ 10 条，有时甚至只取 1 条）。此时建立的 B+ 树索引主要用于通过主键或少量条件快速定位对应记录。只有当索引能够显著减少 IO、提高查询效率时才有意义，否则即使创建了索引，优化器也可能绕过直接全表扫描。</p>
<p>OLAP（联机分析处理）场景下，查询往往涉及对表中大量数据的聚合与统计，面向决策支持（如按月统计销售额、环比增长等）。此类查询关注宏观视角，索引设计应基于整体分析需求，而非针对单条记录检索。一般情况下，不会对诸如“姓名”等仅偶尔单独查询的字段建立索引；但常见做法是对用作分区或筛选条件的<strong>时间字段</strong>建索引，因为大多数统计都是基于时间维度进行过滤。<br>在多表联接（JOIN）操作中，若使用 Hash Join 等算法，索引的重要性会相对降低，需要结合具体执行计划来权衡是否添加索引。</p>
<p>因此，索引添加策略需 Think Different，结合实际查询特点（选择性、扫描量、计算开销）和执行计划采样结果。</p>
<h3 id="联合索引"><a href="#联合索引" class="headerlink" title="联合索引"></a>联合索引</h3><p>单列索引：一个索引只包含单个列。</p>
<p>联合索引：一个索引包含多个列。</p>
<p>以下代码创建了一张 t 表，并且索引 <code>idx_a_b</code> 是联合索引，联合的列为 <code>(a, b)</code>。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> t (</span><br><span class="line">  a <span class="type">INT</span>,</span><br><span class="line">  b <span class="type">INT</span>,</span><br><span class="line">  <span class="keyword">PRIMARY KEY</span> (a),</span><br><span class="line">  KEY idx_a_b (a, b)</span><br><span class="line">) ENGINE<span class="operator">=</span>INNODB;</span><br></pre></td></tr></table></figure>

<p>该表对应的联合索引结构如下（同样省去叶节点之间的指针）：</p>
<p><img src="/../../images/MySQL/mysql_index_multi.drawio.png" alt="img"></p>
<p>因此，对于查询 <code>SELECT * FROM TABLE WHERE a=xxx and b=xxx</code>，显然是可以使用 <code>(a, b)</code> 这个联合索引的。对于单个 a 列查询 <code>SELECT * FROM TABLE WHERE a=xxx</code>，也可以使用这个 <code>(a, b)</code> 索引。但对于 b 列的查询 <code>SELECT * FROM TABLE WHERE b=xxx</code>，则不可以使用这棵 B+ 树索引。可以发现叶子节点上的 b 值为 1、2、1、4、1、2，显然不是排序的，因此对于 b 列的查询使用不到 <code>(a, b)</code> 的索引。</p>
<p>联合索引的第二个好处是已经对第二个键值进行了排序处理。例如，在很多情况下应用程序都需要查询某个用户的购物情况，并按照时间进行排序，最后取出最近三次的购买记录，这时使用联合索引可以避免多一次的排序操作，因为索引本身在叶子节点已经排好了。</p>
<p>在业务场景中，如果存在多个查询条件，考虑针对查询字段建立索引时，建议建立联合索引，而非单列索引。</p>
<p>多条件联合查询时，MySQL 优化器会评估哪个字段的索引效率更高并且选择对应索引完成本次查询。</p>
<h3 id="覆盖索引"><a href="#覆盖索引" class="headerlink" title="覆盖索引"></a>覆盖索引</h3><p>在 InnoDB 中，覆盖索引（Covering Index）指的是查询只访问辅助索引就能获取所需字段的数据，不需要回表到主键索引（聚集索引）中再取数据。</p>
<p>此外，统计查询也能利用覆盖索引：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> buy_log (</span><br><span class="line">  userid <span class="type">INT</span> UNSIGNED <span class="keyword">NOT NULL</span>,</span><br><span class="line">  buy_date <span class="type">DATE</span></span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="keyword">FROM</span> buy_log;</span><br></pre></td></tr></table></figure>

<p>对于这个 SQL 语句，InnoDB 并不会选择通过查询聚集索引来进行统计，因为 <code>buy_log</code> 表上还有辅助索引，而辅助索引远小于聚集索引，这有助于减少 I&#x2F;O 操作。</p>
<p>而且，对于以下 SQL 语句：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="keyword">FROM</span> buy_log</span><br><span class="line"><span class="keyword">WHERE</span> buy_date <span class="operator">&gt;=</span> <span class="string">&#x27;2011-01-01&#x27;</span> <span class="keyword">AND</span> buy_date <span class="operator">&lt;</span> <span class="string">&#x27;2011-02-01&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>即使查询条件中只用到联合索引的第二列 <code>buy_date</code>，但因为查询是统计操作，且能完全由索引提供数据，优化器依然会选择 <code>(userid, buy_date)</code> 联合索引作为覆盖索引使用。</p>
<h3 id="前缀索引"><a href="#前缀索引" class="headerlink" title="前缀索引"></a>前缀索引</h3><p>当字段类型为 varchar，text 等时，有时候需要索引很长的字符串，这会让索引变得很大，查询时消费大量的磁盘 I&#x2F;O。因此我们可对字符串的<strong>前缀</strong>建立索引，可极大节省索引空间，提高索引效率。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> index idx_xxx <span class="keyword">on</span> table_name(column_name(n));</span><br></pre></td></tr></table></figure>

<p>前缀长度选择：根据索引的选择性（和区分度类似）来决定，选择性是指不重复的索引值和数据表的记录总数的比值，索引选择性越高则查询效率越高（选择性最高为 1）。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="built_in">count</span>(<span class="keyword">distinct</span> email) <span class="operator">/</span> <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">from</span> table_name;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> <span class="built_in">count</span>(<span class="keyword">distinct</span> <span class="built_in">substring</span>(email, <span class="keyword">start</span>, <span class="keyword">end</span>)) <span class="operator">/</span> <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">from</span> table_name;</span><br></pre></td></tr></table></figure>

<p>查询流程</p>
<ol>
<li>构建聚集索引和 email 指定长度的前缀索引。</li>
<li>获取 where 后的条件查询字符串的指定长度的前缀，在对应 email 的索引中匹配获取对应行的 id，回表查询获取完整行。</li>
<li>比较该行中的 email 字符串是否等于查询字符串；如果是，则返回结果，之后查询 B+Tree 中下一个元素是否匹配 email 前缀，重复操作。</li>
<li>组装数据。</li>
</ol>
<h3 id="优化器选择不使用索引的情况"><a href="#优化器选择不使用索引的情况" class="headerlink" title="优化器选择不使用索引的情况"></a>优化器选择不使用索引的情况</h3><p>在某些场景下，即使有可用索引，执行 EXPLAIN 会发现优化器 没有选择索引，而是采用了全表扫描（table scan）或聚集索引扫描（PRIMARY key scan），而不是使用辅助索引。</p>
<p>查询语句如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> orderdetails <span class="keyword">WHERE</span> orderid <span class="operator">&gt;</span> <span class="number">10000</span> <span class="keyword">AND</span> orderid <span class="operator">&lt;</span> <span class="number">102000</span>;</span><br></pre></td></tr></table></figure>

<p>该语句选择扫描聚集索引，也就是全表扫描。</p>
<p>原因分析</p>
<ol>
<li>索引无法覆盖查询字段<ul>
<li>由于 <code>SELECT *</code> 需要返回整行记录，而 OrderID 是辅助索引，无法覆盖所有字段，导致必须回表。</li>
<li>回表的过程需要通过主键访问聚集索引数据页，这会产生额外的 I&#x2F;O。</li>
</ul>
</li>
<li>顺序读 vs 随机读<ul>
<li>聚集索引在磁盘上是物理顺序存储的，直接扫描比辅助索引 + 回表更高效（尤其当命中率低时）。</li>
<li>特别是在机械硬盘环境下，顺序读（聚集索引）性能远优于多次随机读（回表）。</li>
</ul>
</li>
<li>数据访问比例高时<ul>
<li>当查询返回的数据行占总行数较大（例如 &gt;20%）时，优化器认为直接顺序扫描整张表更快。</li>
</ul>
</li>
</ol>
<p>对于机械硬盘来说，顺序读取（聚集索引或全表扫描）远快于随机读（辅助索引 + 回表）。因此，当查询返回的行数占表的较大比例（≈20％ 或更高）时，优化器往往选择全表扫描，而不是使用辅助索引。</p>
<p>如果底层存储是固态硬盘（SSD），随机读性能就足够高，且对性能的影响较小，我们可以强制使用辅助索引来减少扫描行数。</p>
<p><code>USE INDEX</code> 只是告诉优化器可以选择该索引，但实际上优化器还是会根据自己的判断进行选择。</p>
<p><code>FORCE INDEX</code> 则强制优化器必须使用该索引。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">table</span> use index(idx) <span class="keyword">where</span> ...;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">table</span> ignore index(idx) <span class="keyword">where</span> ...;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">table</span> force index(idx) <span class="keyword">where</span> ...;</span><br></pre></td></tr></table></figure>

<h3 id="Multi-Range-Read-MRR-优化"><a href="#Multi-Range-Read-MRR-优化" class="headerlink" title="Multi-Range Read (MRR) 优化"></a>Multi-Range Read (MRR) 优化</h3><p>从 MySQL 5.6.0 开始，InnoDB 和 MyISAM 存储引擎支持 MRR（多范围读取）优化。</p>
<p>目标：尽可能减少磁盘的随机读，将随机访问转换为相对顺序的访问，以提升 I&#x2F;O 密集型查询的性能。</p>
<p>适用场景：对索引范围（range）、引用（ref）或等值引用（<code>eq_ref</code>）类型查询，尤其是在需要根据辅助索引快速定位大量匹配行，然后回表查数据的场景。</p>
<p>MRR 优化的几个好处：</p>
<p><strong>使数据访问变得更顺序</strong></p>
<ul>
<li><p>首先通过辅助索引找出所有符合条件的索引键值，把它们缓存在内存里（已经是按索引顺序排列的）。</p>
</li>
<li><p>然后按照主键（或聚簇索引）顺序对这些键值进行排序，最后再一次性按排好序的顺序访问实际数据页，从而将随机 I&#x2F;O 转为顺序 I&#x2F;O。</p>
</li>
</ul>
<p><strong>减少缓冲池中页被置换的次数</strong></p>
<ul>
<li>由于访问顺序更可预测，针对热点数据页的重复访问更集中，降低了缓存页被逐出后又立刻被读回的情况。</li>
</ul>
<p><strong>批量处理对键值的查询操作</strong></p>
<ul>
<li>将多个单独的索引查找合并成一次批量处理，更好地利用缓存和预取，提高吞吐量。</li>
</ul>
<p>MRR 的工作流程（以 InnoDB 和 MyISAM 为例）</p>
<ol>
<li>收集辅助索引键值<ul>
<li>执行范围或引用类型的索引查找时，先把所有满足条件的辅助索引键值（包含对应的 RowID 或主键）一次性读到一个临时缓冲区中。此时缓冲区中的键值已经是按辅助索引顺序排列的。</li>
</ul>
</li>
<li>对键值进行排序<ul>
<li>根据读到的所有主键（RowID）值，对缓冲区内记录按主键顺序排序（这一步把索引顺序转换为主键顺序）。</li>
</ul>
</li>
<li>按主键顺序批量访问数据页<ul>
<li>根据排好序的主键顺序依次访问 InnoDB&#x2F; MyISAM 数据文件，从而尽可能采用顺序读，减少随机 I&#x2F;O。</li>
</ul>
</li>
<li>注意缓冲池大小的影响<ul>
<li>如果 InnoDB 或 MyISAM 的缓冲池&#x2F;缓存（Buffer Pool &#x2F; Key Cache）足够大，可以一次性容纳整个表或者大部分热数据页，则 MRR 优化效果最明显。</li>
<li>若缓冲池不足以存放大量页，那么在批量读回过程中仍可能引起页被换出和换入，导致性能下降。</li>
</ul>
</li>
</ol>
<p>MRR 还可以将 <strong>复合索引</strong>（联合索引）上的多列范围查询拆分为一系列更细粒度的“键值对”，并对它们批量执行查询，从而在拆分过程中进一步“过滤”掉不符合条件的记录，避免不必要的回表。</p>
<p>假设 t 表有联合索引 <code>(key_part1, key_part2)</code>，当执行以下查询时：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> t</span><br><span class="line"><span class="keyword">WHERE</span> key_part1 <span class="operator">&gt;=</span> <span class="number">1000</span></span><br><span class="line"><span class="keyword">AND</span> key_part1 <span class="operator">&lt;</span> <span class="number">2000</span></span><br><span class="line"><span class="keyword">AND</span> key_part2 <span class="operator">=</span> <span class="number">10000</span>;</span><br></pre></td></tr></table></figure>

<p><strong>若不启用 MRR</strong>，优化器会先做一个 <strong>范围（Range）索引扫描</strong>：</p>
<ol>
<li>从联合索引按照 <code>key_part1 &gt;= 1000 AND key_part1 &lt; 2000</code> 条件，扫描出所有满足第一个条件的叶子节点记录，无视 <code>key_part2</code> 是否等于 10000；</li>
<li>读出这些记录后，再在应用层对 <code>key_part2 = 10000</code> 做过滤。<br> 这种做法可能会将大量 <code>key_part2 ≠ 10000</code> 的行读到缓冲区，却最终被丢弃，导致“无用 I&#x2F;O”。</li>
</ol>
<p><strong>若启用 MRR</strong>，优化器会把原来的查询拆分成一系列“点查”——也就是把范围 <code>[1000, 2000)</code> 细分为多个 <code>(key_part1, key_part2)</code> 对，例如 <code>(1000, 10000)</code>、<code>(1001, 10000)</code>、<code>(1002, 10000)</code> … <code>(1999, 10000)</code>；</p>
<ol>
<li>这些拆分出的 <code>(key_part1, key_part2)</code> 对本质上是更小的等值查询或等值范围查询的组合；</li>
<li>引擎对每个 <code>(key_part1, key_part2)</code> 直接通过索引查找，而不是先把所有 <code>key_part1</code> 的记录读出再过滤 <code>key_part2</code>；</li>
<li>最终在索引页上就能剪掉那些 <code>key_part2 ≠ 10000</code> 的记录，不会将它们读出到排序&#x2F;回表阶段；</li>
<li>这样做等价于把先按 <code>key_part1</code> 范围 → 再过滤 <code>key_part2</code> 改成先将范围拆为 <code>(key_part1, key_part2)</code> → 直接点查，避免无用读。</li>
</ol>
<h3 id="Index-Condition-Pushdown（索引条件下推）"><a href="#Index-Condition-Pushdown（索引条件下推）" class="headerlink" title="Index Condition Pushdown（索引条件下推）"></a>Index Condition Pushdown（索引条件下推）</h3><p>MySQL 数据库会在取出索引的同时判断是否可以进行 WHERE 条件的过滤，也就是将 WHERE 的部分过滤操作放在了存储引擎层。在某些查询下，可以大大减少上层 SQL 层对记录的索取，从而提高数据库的整体性能。</p>
<p>Index Condition Pushdown 优化支持 range、ref、<code>eq_ref</code>、<code>ref_or_null</code> 类型的查询，当前支持 MyISAM 和 InnoDB 存储引擎。当优化器选择 Index Condition Pushdown 优化时，可在执行计划的 Extra 列看到 Using index condition 提示。</p>
<p>假设某张表有联合索引 <code>(zip_code, last_name, first_name)</code>，并且查询语句如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> people</span><br><span class="line"><span class="keyword">WHERE</span> zipcode <span class="operator">=</span> <span class="string">&#x27;95054&#x27;</span></span><br><span class="line"><span class="keyword">AND</span> lastname <span class="keyword">LIKE</span> <span class="string">&#x27;%etrunia%&#x27;</span></span><br><span class="line"><span class="keyword">AND</span> address <span class="keyword">LIKE</span> <span class="string">&#x27;%Main Street%&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>对于上述语句，MySQL 数据库可以通过索引定位 <code>zipcode = &#39;95054&#39;</code> 的记录，但是索引对 WHERE 条件的 <code>lastname LIKE &#39;%etrunia%&#39;</code> 和 <code>address LIKE &#39;%Main Street%&#39;</code> 没有任何帮助。若不支持 Index Condition Pushdown 优化，则数据库需要先通过索引取出所有 <code>zipcode = &#39;95054&#39;</code> 的记录，然后再对这部分记录执行 <code>lastname LIKE &#39;%etrunia%&#39; AND address LIKE &#39;%Main Street%&#39;</code> 的过滤，才能最终得到结果。</p>
<p>若支持 Index Condition Pushdown 优化，则在索引扫描阶段，MySQL 存储引擎会先判断 <code>zipcode = &#39;95054&#39;</code> 这一部分（因为这是索引的第一列条件），然后在“取出”符合该索引前缀的行时，立即在存储引擎层对 <code>lastname LIKE &#39;%etrunia%&#39; AND address LIKE &#39;%Main Street%&#39;</code> 这两个条件进行过滤，只把同时满足三个条件的记录交给上层 SQL 层做最终读取。这样就极大地减少了上层 SQL 层对行的 fetch 次数，从而提高查询效率。当然，WHERE 中被下推的条件必须是“索引范围能够覆盖到”的列，否则无法下推。例如 <code>lastname LIKE &#39;%abc%&#39; 或者 address LIKE &#39;%xyz%&#39;</code> 带有前缀通配符（前面有 %），在大多数情况下并不属于索引可下推的范围；只有当索引是覆盖该列并且能够使用“范围扫描”或“等值比较”时，条件下推才有效。</p>
<h2 id="InnoDB-中的哈希算法"><a href="#InnoDB-中的哈希算法" class="headerlink" title="InnoDB 中的哈希算法"></a>InnoDB 中的哈希算法</h2><p><strong>哈希表基本结构与冲突解决</strong></p>
<ul>
<li>InnoDB 在缓冲池中维护一个哈希表，用于物理页号 → 缓冲池页地址的快速映射。</li>
<li>哈希冲突时采用链表方式：每个缓冲池页有一个指向同一哈希值下链上下一个页的指针，形成冲突链。</li>
</ul>
<p><strong>哈希函数：除法散列法（Division Method）</strong></p>
<ul>
<li>InnoDB 选取的哈希函数为 <strong>除法散列</strong>，即：<br>$hash_value  &#x3D;  K   mod   m$ 其中，<ul>
<li>K 是查询页标识的整数键；</li>
<li>m 是哈希表大小（槽位数）。</li>
</ul>
</li>
<li>为了尽量均匀分布并减少冲突，InnoDB 通常将 m 选为略大于 <code>缓冲池页总数 × 2</code> 的<strong>质数</strong>。<ul>
<li>例如，若 <code>innodb_buffer_pool_size = 10 MB</code>，则缓冲池中总页数约为 $10MB÷16KB&#x3D;640$ 页。</li>
<li>按 2 倍页数原则，需要 $640×2&#x3D;1280$ 个槽位，但 1280 不是质数，于是取下一个比 1280 稍大的质数 1399 作为哈希表槽数。</li>
</ul>
</li>
</ul>
<p><strong>构造查询键 K</strong></p>
<ul>
<li>InnoDB 中，每个页都有两个重要标识：<ol>
<li><strong><code>space_id</code></strong>：表示该页所属的表空间（tablespace）编号；</li>
<li><strong><code>offset</code></strong>：表示该页在表空间内的偏移量（即第几个 16 KB 页）。</li>
</ol>
</li>
<li>InnoDB 将这两个值合并成一个整数键 K，其计算公式通常为：$K  &#x3D;  (space_id  ≪  20)  +  offset$。</li>
<li>得到的 K 用于与哈希表槽数 m 做除法取余运算，确定该页在哈希表中对应的槽。</li>
</ul>
<h3 id="哈希索引"><a href="#哈希索引" class="headerlink" title="哈希索引"></a>哈希索引</h3><p><img src="/../../images/MySQL/mysql_index_hash.drawio.png" alt="img"></p>
<p>该索引采用哈希算法把键值换算成新的 hash 值，映射到对应的位置上，然后存储在 hash 表中。</p>
<ul>
<li>特点<ul>
<li>只能用于对等比较（&#x3D;，in），不支持范围查询（between，&gt;，&lt;，…）；</li>
<li>无法利用索引完成排序操作；</li>
<li>查询效率高，通常只需要一次索引就可以了，效率通常要高于 B+Tree 索引（不发生 hash 冲突的情况下）。</li>
</ul>
</li>
<li>存储引擎支持<ul>
<li>支持 hash 索引的是 Memory 和 NDB 存储引擎，而 InnoDB 中具有<strong>自适应 hash 索引</strong>。</li>
</ul>
</li>
</ul>
<p><strong>Hash 索引和 B+ 树索引的区别</strong></p>
<ol>
<li>B+ 树索引可以进行范围查询，Hash 索引不能。</li>
<li>B+ 树索引支持联合索引的最左侧原则，Hash 索引不支持。</li>
<li>B+ 树索引支持 order by 排序，Hash 索引不支持。</li>
<li>B+ 树使用 like 进行模糊查询的时候，LIKE ‘abc%’ 的话可以起到索引优化的作用，Hash 索引无法进行模糊查询。</li>
<li>Hash 索引在等值查询上比 B+ 树索引效率更高。</li>
</ol>
<h3 id="自适应哈希索引"><a href="#自适应哈希索引" class="headerlink" title="自适应哈希索引"></a>自适应哈希索引</h3><p>自适应哈希索引（Adaptive Hash Index，AHI）是 <strong>InnoDB 存储引擎在运行时自动创建的一种轻量级哈希结构</strong>，用于加速对 B+ 树叶子页中热点记录的等值查找。InnoDB 会监测查询模式，一旦检测到某个叶子页或某条索引项的访问频率过高，便在 Buffer Pool 中为该叶子页构造哈希表节点，使后续对该页的等值查找可以通过哈希函数直接定位，而无需再遍历 B+ 树路径。</p>
<p><strong>适用场景</strong></p>
<ul>
<li>等值查询：AHI 仅对形如 <code>SELECT * FROM table WHERE indexed_col = constant</code> 的等值匹配操作有效。如果是范围查询（BETWEEN、&gt;, &lt; 等）或排序（ORDER BY）、模糊匹配（LIKE ‘%…%’），则不能使用 AHI，只能回退到常规的 B+ 树扫描或其他索引操作。</li>
<li>热点数据页：在大表中，如果某个 B+ 树叶子页承载了大量相同或相近的等值访问（例如同一个二级索引项被频繁查询），AHI 能极大减少 B+ 树遍历的层级开销，将随机 I&#x2F;O 降低为直接在内存哈希表查找。</li>
</ul>
<h2 id="全文检索"><a href="#全文检索" class="headerlink" title="全文检索"></a>全文检索</h2><p>MySQL 的全文检索（Full-Text Search）功能主要基于倒排索引实现，在 MyISAM 和 InnoDB 存储引擎中均提供了不同的支持方式。其核心原理是在数据写入时将文本字段拆分成词汇单元，并建立一个词–文档或词–行号的映射表，从而使得在查询时能够快速检索包含指定关键词的记录。虽然 MySQL 的全文检索功能对于轻量级应用已经十分实用，但与专业搜索引擎（如 Lucene、Solr、Elasticsearch 等）相比，功能较为基础。</p>
<h2 id="创建索引的注意点"><a href="#创建索引的注意点" class="headerlink" title="创建索引的注意点"></a>创建索引的注意点</h2><ul>
<li>使用合适的列作为索引<ul>
<li>经常作为查询条件（WHERE 子句）、排序条件（ORDER BY 子句）、分组条件（GROUP BY 子句）的列是建立索引的好候选。</li>
<li>区分度低（唯一值比例低）的字段，例如性别，不要建索引。</li>
<li>频繁更新的字段，不要作为主键或者索引。</li>
<li>不建议用无序的值(例如身份证、UUID )作为索引，当主键具有不确定性，会造成叶子节点频繁分裂，出现磁盘存储的碎片化。</li>
</ul>
</li>
<li>避免过多的索引<ul>
<li>每个索引都需要占用额外的磁盘空间。</li>
<li>更新表（INSERT、UPDATE、DELETE 操作）时，所有的索引都需要被更新。</li>
<li>维护索引文件需要成本；还会导致页分裂，IO 次数增多。</li>
</ul>
</li>
<li>利用前缀索引和索引列的顺序<ul>
<li>对于字符串类型的列，可以考虑使用前缀索引来减少索引大小。</li>
<li>在创建复合索引时，应该根据查询条件将最常用作过滤条件的列放在前面。</li>
</ul>
</li>
</ul>
<h2 id="使用索引的注意点"><a href="#使用索引的注意点" class="headerlink" title="使用索引的注意点"></a>使用索引的注意点</h2><ul>
<li>最左前缀法则<ul>
<li>如果索引了多列（联合索引），要遵循最左前缀法则。最左前缀法则指的是查询从索引的最左列开始，并且不跳过索引中的列。如果跳过了某一列，索引将部分失效（后面的字段索引失效）。</li>
</ul>
</li>
<li>范围查询<ul>
<li>联合索引中出现范围查询（&gt;, &lt;），范围查询右侧的列索引失效。因为范围查询会存在一次性获取大量符合条件的指针，这些指针指向 B+ 树中的子节点。这些子节点中都可能会包含右侧的列索引键，因此无法使用索引。<strong>规避方法：业务允许的情况下，使用 &gt;&#x3D;, &lt;&#x3D;。</strong></li>
</ul>
</li>
<li>索引列运算：在索引列上进行运算操作（各种函数），索引将失效。</li>
<li>字符串不加引号：使用字符串类型字段时，不加引号（会造成<strong>隐式类型转换</strong>），索引将失效。</li>
<li>模糊查询：如果仅仅是尾部模糊匹配，索引不会失效，如果是<strong>头部模糊匹配</strong>，索引失效。因为索引无法确定开头部分是什么内容。</li>
<li>or 连接的条件：用 or 分割开的条件，如果 or 前面的条件中的列有索引，而后面的列中没有索引，那么涉及的索引都不会被用到。</li>
<li>数据分布的影响<ul>
<li>如果 MySQL 评估使用索引比全表更慢，则不使用索引。</li>
<li>如果某个数据占比小，那么使用索引；否则，使用全表查询。</li>
</ul>
</li>
</ul>
<h2 id="索引设计原则"><a href="#索引设计原则" class="headerlink" title="索引设计原则"></a>索引设计原则</h2><ol>
<li>数据量较大（数据行超过 1M 条），查询操作频繁的表建立索引。</li>
<li>经常作为查询条件（where），排序（order by），分组（group by）操作的字段建立索引。</li>
<li>区分度高的列建立索引（区分度高，索引效率高）。</li>
<li>长字符串、大文本字段建立前缀索引。</li>
<li>尽量使用联合索引（覆盖索引），减少单列索引，避免回表。</li>
<li>控制索引数量，维护大量索引代价高。</li>
<li>如果索引列不能存储 NULL 值，请对其使用 NOT NULL 约束（方便优化器确定哪个索引更高效）。</li>
</ol>
<h2 id="索引失效的情况"><a href="#索引失效的情况" class="headerlink" title="索引失效的情况"></a>索引失效的情况</h2><ul>
<li>在索引列上<strong>使用函数或表达式</strong>，索引可能无法使用，因为数据库无法预先计算出函数或表达式的结果。例如：<code>SELECT * FROM table_name WHERE YEAR(date_column) = 2021</code>。</li>
<li>使用<strong>不等于（&lt;&gt;）或者 NOT 操作</strong>通常会使索引失效，因为它们会扫描全表。</li>
<li>如果 LIKE 的模式串是<strong>以“%”或者“_”开头的</strong>，那么索引也无法使用。例如：<code>SELECT * FROM table_name WHERE column LIKE &#39;%abc&#39;</code>。</li>
<li>如果查询条件中使用了 <strong>OR</strong>，并且 OR 两边的条件分别涉及不同的索引，那么这些索引可能都无法使用。</li>
<li>如果 MySQL 估计使用全表扫描比使用索引更快时（通常是小表或者大部分行都满足 WHERE 子句），也不会使用索引。</li>
<li>联合索引不满足最左前缀原则时，索引会失效。</li>
</ul>
<p><strong>百万级别以上的数据如何删除？</strong></p>
<p>先删除索引，然后删除其中的无用数据，删除完成后重新创建索引。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN,en">
    <link itemprop="mainEntityOfPage" href="https://yihangwe.github.io/MySQL/2024/10/28/MySQL/%E6%96%87%E4%BB%B6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yihang Wei">
      <meta itemprop="description" content="聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EthanWeee">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/MySQL/2024/10/28/MySQL/%E6%96%87%E4%BB%B6/" class="post-title-link" itemprop="url">文件</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-10-28 00:00:00" itemprop="dateCreated datePublished" datetime="2024-10-28T00:00:00-07:00">2024-10-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-06-18 22:18:27" itemprop="dateModified" datetime="2025-06-18T22:18:27-07:00">2025-06-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MySQL/" itemprop="url" rel="index"><span itemprop="name">MySQL</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>MySQL 数据库和 InnoDB 存储引擎表的各种类型文件如下：</p>
<p><strong>参数文件</strong>：告诉 MySQL 实例启动时在哪里可以找到数据库文件，并且指定某些初始化参数，这些参数定义了某种内存结构的大小等设置，还会介绍各种参数的类型。</p>
<p><strong>日志文件</strong>：用来记录 MySQL 实例对某种条件做出响应时写入的文件，如错误日志文件、二进制日志文件、慢查询日志文件、查询日志文件等。</p>
<p><strong>socket 文件</strong>：当用 UNIX 域套接字方式进行连接时需要的文件。</p>
<p><strong>pid 文件</strong>：MySQL 实例的进程 ID 文件。</p>
<p><strong>MySQL 表结构文件</strong>：用来存放 MySQL 表结构定义文件。</p>
<p><strong>存储引擎文件</strong>：由于 MySQL 表存储引擎的关系，每个存储引擎都会有自己的文件来保存各种数据。这些存储引擎真正存储了记录和索引等数据。本章主要介绍与 InnoDB 有关的存储引擎文件。</p>
<h2 id="参数文件"><a href="#参数文件" class="headerlink" title="参数文件"></a>参数文件</h2><p>当 MySQL 实例启动时，数据库会先去读一个配置参数文件，用来寻找数据库的各种文件所在位置以及指定某些初始化参数，这些参数通常定义了某种内存结构有多大等。在默认情况下，MySQL 实例会按照一定的顺序在指定的位置进行读取，用户只需通过命令 mysql –help | grep my.cnf 来寻找即可。</p>
<p>MySQL 实例可以不需要参数文件，这时所有的参数值取决于编译 MySQL 时指定的默认值和源代码中指定参数的默认值。但是，如果 MySQL 实例在默认的数据库库目录下找不到 mysql 系统数据库，则启动同样会失败。</p>
<h3 id="参数类型"><a href="#参数类型" class="headerlink" title="参数类型"></a>参数类型</h3><p>MySQL 数据库中的参数可以分为两类：</p>
<ul>
<li>动态（dynamic）参数</li>
<li>静态（static）参数</li>
</ul>
<p>动态参数意味着可以在 MySQL 实例运行中进行更改，静态参数说明在整个实例生命周期内都不得进行更改，就好像是只读（read only）的。可以通过 SET 命令对动态参数值进行修改，SET 的语法如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SET</span></span><br><span class="line">[<span class="keyword">GLOBAL</span> <span class="operator">|</span> SESSION] system_var_name <span class="operator">=</span> expr</span><br><span class="line"><span class="operator">|</span> [@<span class="variable">@GLOBAL</span>. <span class="operator">|</span> @<span class="variable">@SESSION</span>.] system_var_name <span class="operator">=</span> expr;</span><br></pre></td></tr></table></figure>

<p>这里可以看到 GLOBAL 和 SESSION 关键字，它们表明该参数的修改是基于当前会话还是整个实例的生命周期。有些动态参数只能在会话中进行修改，如 autocommit；而有些参数修改完后，在整个实例生命周期中都会生效，如 <code>binlog_cache_size</code>；而有些参数既可以在会话中又可以在整个实例的生命周期内生效，如 <code>read_buffer_size</code>。</p>
<p>对变量的全局值进行了修改，在这次的实例生命周期内都有有效，但 MySQL 实例本身并不会对参数文件中的该值进行修改。也就是说，在下次启动时 MySQL 实例还是会读取参数文件。若想在数据库实例下一次启动时该参数还是保留为当前修改的值，那么用户必须去修改参数文件。</p>
<h2 id="日志文件"><a href="#日志文件" class="headerlink" title="日志文件"></a>日志文件</h2><p>MySQL 中常见的日志文件有：</p>
<ul>
<li>错误日志</li>
<li>二进制日志</li>
<li>慢查询日志</li>
<li>查询日志</li>
</ul>
<h3 id="错误日志"><a href="#错误日志" class="headerlink" title="错误日志"></a>错误日志</h3><p>错误日志文件对 MySQL 的启动、运行、关闭过程进行了记录。用户在遇到问题时应该首先查看该文件以便定位问题。该文件不仅记录了所有的错误信息，也记录一些警告信息或正确的信息。用户可以通过命令 SHOW VARIABLES LIKE ‘log_error’ 来定位该文件。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[mysql]<span class="operator">&gt;</span> <span class="keyword">show</span> variables <span class="keyword">like</span> <span class="string">&#x27;log_error&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="operator">|</span> Variable_name <span class="operator">|</span> <span class="keyword">Value</span>              <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="comment">------------- | ------------------ |</span></span><br><span class="line"><span class="operator">|</span> log_error     <span class="operator">|</span> .<span class="operator">/</span>Yihang.local.err <span class="operator">|</span></span><br><span class="line"></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.07</span> sec)</span><br></pre></td></tr></table></figure>

<h3 id="慢查询日志"><a href="#慢查询日志" class="headerlink" title="慢查询日志"></a>慢查询日志</h3><p>慢查询日志（slow log）可帮助用户定位可能存在问题的 SQL 语句，从而进行 SQL 语句层面的优化。例如，可以在 MySQL 启动时设一个阈值，将运行时间超过该值的所有 SQL 语句都记录到慢查询日志文件中。用户每天或每过一段时间对其进行检查，确认是否有 SQL 语句需要进行优化。该阈值可以通过参数 <code>long_query_time</code> 来设置，默认值为 10，代表 10 秒。</p>
<p>这里有两点需要注意。首先，设置 <code>long_query_time</code> 这个阈值后，MySQL 数据库会记录运行时间<strong>超过</strong>该值的所有 SQL 语句，但运行时间<strong>正好等于</strong> <code>long_query_time</code> 的情况并不会被记录。也就是说，在源代码中判断的是大于 <code>long_query_time</code>，而非大于等于。</p>
<p>其次，从 MySQL 5.1 开始，<code>long_query_time</code> 开始以<strong>微秒</strong>记录 SQL 语句运行的时间，此前仅用秒为单位记录。而这样可以更精确地记录 SQL 的运行时间。对用户来说，一条 SQL 语句运行 0.5 秒和 0.05 秒是非常不同的，前者可能已经进行了表扫描，后者可能只是进行了索引查找。</p>
<p>另一个和慢查询日志有关的参数是 <code>log_queries_not_using_indexes</code>，如果运行的 SQL 语句没有使用索引，则 MySQL 同样会将这条 SQL 语句记录到慢查询日志文件。</p>
<p>MySQL 5.6.5 版本开始新增了一个参数 <code>log_throttle_queries_not_using_indexes</code>，用来表示每分钟允许记录到 slow log 的且未使用索引的 SQL 语句的最大次数。该参数默认值为 0，表示没有限制。在生产环境下，如果有大量未使用索引的查询，此类 SQL 会频繁地被记录到 slow log，从而导致日志文件持续膨胀。</p>
<p>用户可以通过慢查询日志找出有问题的 SQL 语句并进行优化。然而，随着 MySQL 服务器运行时间的增加，可能会有越来越多的查询被记录到慢查询日志，此时直接阅读日志文件就显得不够直观。MySQL 提供的 mysqldumpslow 工具可以很好地帮助 DBA 对慢查询日志进行汇总和分析。</p>
<p>MySQL 5.1 开始可以将慢查询的日志记录放入一张表中，这使得用户的查询更加方便和直观。</p>
<p>InnoSQL 版本加强了对于 SQL 语句的捕获方式。在原版 MySQL 的基础上在 slow log 中增加了对逻辑读取（logical reads）和物理读取（physical reads）的统计。这里的物理读取是指从磁盘进行 IO 读取的次数，逻辑读取包含所有的读取，不管是磁盘还是缓冲池。</p>
<p>用户可以通过额外的参数 <code>long_query_io</code> 将超过指定逻辑 IO 次数的 SQL 语句记录到 slow log 中。该值默认为 100，即表示对于逻辑读取次数大于 100 的 SQL 语句，记录到 slow log 中。</p>
<h3 id="查询日志"><a href="#查询日志" class="headerlink" title="查询日志"></a>查询日志</h3><p>查询日志记录了所有对 MySQL 数据库请求的信息，无论这些请求是否得到了正确的执行。默认文件名为：<code>&lt;主机名&gt;.log</code>。</p>
<h3 id="二进制日志"><a href="#二进制日志" class="headerlink" title="二进制日志"></a>二进制日志</h3><p>二进制日志（binary log）记录了对 MySQL 数据库执行更改的所有操作，但是不包括 SELECT 和 SHOW 这类操作，因为这类操作对数据本身并没有修改。然而，若操作本身并没有导致数据库发生变化，那么该操作可能也会写入二进制日志，但是这种情况只会发生在 <code>binlog_format</code> 参数的值为 ROW 的情况下。</p>
<p><strong>Statement-Based Logging (SBL)</strong> 下，<strong>所有</strong> DML&#x2F;DDL 语句均写入二进制日志，无论它们是否实际修改了任何行。</p>
<p><strong>Row-Based Logging (RBL)</strong> 下，只有<strong>真正产生行变更</strong>的事件才写入二进制日志；如果一条语句对零行生效，就<strong>不会</strong>产生相应的行事件。</p>
<p>如果用户想记录 SELECT 和 SHOW 操作，那只能使用查询日志，而不是二进制日志。此外，二进制日志还包括了执行数据库更改操作的时间等其他额外信息。总的来说，二进制日志主要有以下几种作用：</p>
<ul>
<li>恢复（recovery）：某些数据的恢复需要二进制日志，例如，在一个数据库全备文件恢复后，用户可以通过二进制日志进行 point-in-time 的恢复。</li>
<li>复制（replication）：其原理与恢复类似，通过复制和执行二进制日志使一台远程的 MySQL 数据库（一般称为 slave 或 standby）与一台 MySQL 数据库（一般称为 master 或 primary）进行实时同步。</li>
<li>审计（audit）：用户可以通过二进制日志中的信息进行审计，判断是否有对数据库进行注入的攻击。</li>
</ul>
<p>以下配置文件的参数影响着二进制日志记录的信息和行为：</p>
<ul>
<li><code>max_binlog_size</code> </li>
<li><code>binlog_cache_size</code> </li>
<li><code>sync_binlog</code> </li>
<li><code>binlog-do-db</code> </li>
<li><code>binlog-ignore-db</code> </li>
<li><code>log-slave-update</code> </li>
<li><code>binlog_format</code></li>
</ul>
<p>参数 <code>max_binlog_size</code> 指定了单个二进制日志文件的最大值，如果超过该值，则产生新的二进制日志文件，后缀名加 1，并记录到 .index 文件。从 MySQL 5.0 开始的默认值为 1073741824，代表 1 G（在之前版本中 <code>max_binlog_size</code> 默认大小为 1.1 G）。</p>
<p>当使用事务的存储引擎（如 InnoDB 存储引擎）时，所有未提交（uncommitted）的二进制日志会被记录到一个缓冲中去，等该事务提交（committed）时再将缓冲中的二进制日志写入二进制日志文件，而该缓冲的大小由 <code>binlog_cache_size</code> 决定，默认大小为 32K。此外，binlog_cache_size 是基于会话（session）的，也就是说，当一个线程开始一个事务时，MySQL 会自动分配一个大小为 <code>binlog_cache_size</code> 的缓冲，因此该值的设置需要相当小心，不能设置过大。当一个事务的记录大于设置的 <code>binlog_cache_size</code> 时，MySQL 会把缓冲中的日志写入一个临时文件中，因此该值又不能设置得过小。</p>
<p>在默认情况下，二进制日志并不是在每次写的时候同步到磁盘（用户可以理解为缓冲写）。因此，当数据库所在操作系统发生宕机时，可能会有最后一部分数据没有写入二进制日志文件中，这会给恢复和复制带来问题。参数 <code>sync_binlog=[N]</code> 表示每写缓冲多少次就同步到磁盘。如果将 N 设为 1，即 <code>sync_binlog=1</code> 表示采用同步写磁盘的方式来写二进制日志，这时写操作不再使用操作系统的缓冲来写二进制日志。<code>sync_binlog</code> 的默认值为 0，如果使用 InnoDB 存储引擎进行复制，并且想得到最大的高可用性，建议将该值设为 1。不过该值为 0 时，的确会对数据库的 I&#x2F;O 系统带来一定的影响。</p>
<p>但是，即使将 sync_binlog 设为 1，还是会有一种情况导致问题的发生。当使用 InnoDB 存储引擎时，在一个事务发出 COMMIT 动作之前，由于 <code>sync_binlog=1</code>，因此会将二进制日志立即写入磁盘。如果这时已经写入了二进制日志，但是提交还没有发生，并且此时发生了宕机，那么在 MySQL 数据库下次启动时，由于 COMMIT 操作并没有发生，这个事务会被回滚。但是二进制日志已经记录了该事务信息，不能被回滚。这个问题可以通过将参数 <code>innodb_support_xa</code> 设为 1 来解决，虽然 <code>innodb_support_xa</code> 与 XA 事务有关，但它同时也确保了二进制日志和 InnoDB 存储引擎数据文件的同步。</p>
<p>参数 <code>binlog-do-db</code> 和 <code>binlog-ignore-db</code> 表示需要写入或忽略写入哪些库的日志。默认为空，表示需要同步所有库的日志到二进制日志。</p>
<p>如果当前数据库是复制中的 slave 角色，则它不会将从 master 取得并执行的二进制日志写入自己的二进制日志文件中去。如果需要写入，要设置 <code>log-slave-update</code>。如果需要搭建 master⇒slave⇒slave 架构的复制，则必须设置该参数。</p>
<p><code>binlog_format</code> 参数十分重要，它影响了记录二进制日志的格式。在 MySQL 5.1 版本之前，没有这个参数，因此所有二进制日志文件的格式都是基于 SQL 语句（statement）级别的。同时，对于复制也有一定要求。例如在主服务器上运行 rand、uuid 等函数，或者使用触发器等操作，这些都可能会导致主从服务器上表中数据的不一致（not sync）。另一个影响是，你会发现 InnoDB 存储引擎的默认事务隔离级别是 REPEATABLE READ。这其实也是因为二进制日志文件格式的关系：如果使用 READ COMMITTED 的事务隔离级别，会出现类似“丢失更新”的现象，从而导致主从数据库上的数据不一致。具体细节如下：</p>
<p>存在表 t1，定义如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> t1 (</span><br><span class="line">   a <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>, </span><br><span class="line">   b <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>, </span><br><span class="line">   KEY a (a) </span><br><span class="line">  ) ENGINE<span class="operator">=</span>InnoDB <span class="keyword">DEFAULT</span> CHARSET<span class="operator">=</span>latin1; </span><br><span class="line"><span class="keyword">insert into</span> t1 <span class="keyword">values</span>(<span class="number">10</span>,<span class="number">2</span>),(<span class="number">20</span>,<span class="number">1</span>);</span><br></pre></td></tr></table></figure>

<p>接着开始执行两个事务的写操作：</p>
<table>
<thead>
<tr>
<th>时序</th>
<th>事务1</th>
<th>事务2</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>set session transaction isolation level read committed;</td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>set autocommit&#x3D;0;</td>
<td></td>
</tr>
<tr>
<td>3</td>
<td>UPDATE t1 SET a&#x3D;11 where b&#x3D;2;</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td></td>
<td>set session transaction isolation level read committed;</td>
</tr>
<tr>
<td>5</td>
<td></td>
<td>set autocommit&#x3D;0;</td>
</tr>
<tr>
<td>6</td>
<td></td>
<td>UPDATE t1 SET b&#x3D;2 where b&#x3D;1;</td>
</tr>
<tr>
<td>7</td>
<td></td>
<td>COMMIT;</td>
</tr>
<tr>
<td>8</td>
<td>COMMIT;</td>
<td></td>
</tr>
</tbody></table>
<p>以上两个事务执行之后，数据库里面的记录会变成（11，2）和（20，2）。</p>
<p>因为事务的隔离级别是 read committed，所以，事务 1 在更新时，只会对 b &#x3D; 2 这行加上行级锁，不会影响到事务 2 对 b &#x3D; 1 这行的写操作。</p>
<p>以上两个事务执行完成之后，会在 binlog 中记录两条记录，因为事务 2 先提交，所以 <code>UPDATE t1 SET b=2 where b=1;</code> 会被优先记录，然后再记录 <code>UPDATE t1 SET a=11 where b=2;</code>。</p>
<p>binlog 同步到备从库之后，SQL语句回放时，会先执行 <code>UPDATE t1 SET b=2 where b=1;</code>，再执行 <code>UPDATE t1 SET a=11 where b=2;</code>。</p>
<p>这时候，数据库中的数据就会变成（11，2）和（11，2）。这就导致主库和备库的数据不一致了！！！</p>
<p>为了避免这种问题的发生，MySQL 就把数据库的默认隔离级别设置成了 Repeatable Read。</p>
<p>因为 Repetable Read 下，MySQL 在更新数据的时候不仅对更新的行加行级锁，还会增加 gap lock。同样是上面的例子，在事务 2 执行的时候，因为事务 1 增加了 gap lock，就会导致事务执行被卡住，需要等事务 1 提交或者回滚后才能继续执行。</p>
<p>除了设置默认的隔离级别外，MySQL 还在当使用 STATEMENT 格式的 binlog 的情况下，禁止设置 READ COMMITTED 作为事务隔离级别。</p>
<p>MySQL 5.1 开始引入了 <code>binlog_format</code> 参数，该参数可设的值有：STATEMENT、ROW 和 MIXED。</p>
<p>(1) STATEMENT 格式：二进制日志文件记录的是日志的逻辑 SQL 语句。</p>
<p>(2) ROW 格式下，二进制日志记录的不再是简单的 SQL 语句了，而是记录表的行更改情况。同时，对上述提及的 STATEMENT 格式下复制的问题予以解决。从 MySQL 5.1 版本开始，如果设置了 <code>binlog_format</code> 为 ROW，可以将 InnoDB 的事务隔离级别设为 READ COMMITTED，以获得更好的并发性。</p>
<p>(3) MIXED 格式下，MySQL 默认采用 STATEMENT 格式进行二进制日志文件的记录，但是在一些情况下会使用 ROW 格式，可能的情况有：</p>
<ul>
<li>使用了 <code>UUID()</code>、<code>USER()</code>、<code>CURRENT_USER()</code>、<code>FOUND_ROWS()</code>、<code>ROW_COUNT()</code> 等不确定函数。</li>
<li>使用了 INSERT DELAY 语句。</li>
<li>使用了用户定义函数（UDF）。</li>
<li>使用了临时表（temporary table）。</li>
</ul>
<p><code>binlog_format</code> 是动态参数，因此可以在数据库运行环境下进行更改。当然，也可以将全局的 <code>binlog_format</code> 设置为想要的格式，不过通常这个操作会带来问题，运行时要确保更改后不会对复制带来影响。在通常情况下，我们将参数 <code>binlog_format</code> 设置为 ROW，这可以为数据库的恢复和复制带来更好的可靠性。但是不能忽略的一点是，这会带来二进制文件大小的增加，有些语句下的 ROW 格式可能需要更大的容量。也就是说将参数 <code>binlog_format</code> 设置为 ROW，会对磁盘空间要求有一定的增加。而由于复制是采用传输二进制日志方式实现的，因此复制的网络开销也有所增加。</p>
<p>二进制日志文件的文件格式为二进制（好像有点废话），不能像错误日志文件、慢查询日志文件那样用 cat、head、tail 等命令来看查看。要查看二进制日志文件的内容，必须通过 MySQL 提供的工具 mysqlbinlog。</p>
<p>示例：</p>
<p>执行的 SQL 为：<code>UPDATE users SET age = age + 1 WHERE id = 100;</code></p>
<p><code>binlog_format=STATEMENT</code> 时的 binlog 输出（可读）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># at 234</span><br><span class="line">#240523 15:00:01 server id 1 end_log_pos 345 Query  thread_id=7 exec_time=0 error_code=0</span><br><span class="line">SET TIMESTAMP=1716495601/*!*/;</span><br><span class="line">UPDATE users SET age = age + 1 WHERE id = 100/*!*/;</span><br></pre></td></tr></table></figure>

<p><code>binlog_format=ROW</code> 时的 binlog 输出（不可读）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># at 456</span><br><span class="line">#240523 15:00:02 server id 1 end_log_pos 567 Table_map: `test`.`users` mapped to number 108</span><br><span class="line"># at 567</span><br><span class="line">#240523 15:00:02 server id 1 end_log_pos 678 Update_rows: table id 108 flags: STMT_END_F</span><br><span class="line">### UPDATE `test`.`users`</span><br><span class="line">### WHERE</span><br><span class="line">###  @1=100 /* id */</span><br><span class="line">###  @2=20 /* age (原值) */</span><br><span class="line">### SET</span><br><span class="line">###  @1=100</span><br><span class="line">###  @2=21 /* age (新值) */</span><br></pre></td></tr></table></figure>

<p>因此，在 ROW 格式下，binlog 中对于一个简单的更新操作记录了整个行额所有字段的更改信息。这也解释了为什么 ROW 格式下的 binlog 对磁盘空间要求有一定的增加。</p>
<h2 id="套接字文件"><a href="#套接字文件" class="headerlink" title="套接字文件"></a>套接字文件</h2><p>在 UNIX 系统下本地连接 MySQL 可以采用 UNIX 域套接字方式，这种方式需要一个套接字（socket）文件。套接字文件可由参数 socket 控制。一般在 <code>/tmp</code> 目录下，名为 <code>mysql.sock</code>。</p>
<h2 id="pid-文件"><a href="#pid-文件" class="headerlink" title="pid 文件"></a>pid 文件</h2><p>当 MySQL 实例启动时，会将自己的进程 ID 写入一个文件中——该文件即为 pid 文件并且可由参数 <code>pid_file</code> 控制，默认位于数据库目录下，文件名为主机名 <code>.pid</code>。</p>
<h2 id="表结构定义文件"><a href="#表结构定义文件" class="headerlink" title="表结构定义文件"></a>表结构定义文件</h2><p>因为 MySQL 插件式存储引擎的体系结构的关系，MySQL 数据的存储是根据表进行的，每个表都会有与之对应的文件。但不论表采用何种存储引擎，MySQL 都有一个以 <code>.frm</code> 为后缀名的文件，这个文件记录了该表的表结构定义。</p>
<p><code>.frm</code> 还用来存放视图的定义，如用户创建了一个 <code>v_a</code> 视图，那么对应地会产生一个 <code>v_a.frm</code> 文件，用来记录视图的定义。该文件是文本文件，可以直接使用 <code>cat</code> 命令进行查看。</p>
<h2 id="InnoDB-存储引擎文件"><a href="#InnoDB-存储引擎文件" class="headerlink" title="InnoDB 存储引擎文件"></a>InnoDB 存储引擎文件</h2><p>之前介绍的文件都是 MySQL 数据库本身的文件，和存储引擎无关。除了这些文件外，每个表存储引擎还有其自己独有的文件，包括重做日志文件、表空间文件。</p>
<h3 id="表空间文件"><a href="#表空间文件" class="headerlink" title="表空间文件"></a>表空间文件</h3><p>InnoDB 采用将存储的数据按表空间（tablespace）进行存放的设计。在默认配置下会有一个初始大小为 10MB，名为 ibdata1 的文件。该文件就是默认的表空间文件（tablespace file），用户可以通过参数 <code>innodb_data_file_path</code> 对其进行设置，格式如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">innodb_data_file_path=datafile_spec1[;datafile_spec2]...</span><br></pre></td></tr></table></figure>

<p>用户可以通过多个文件组成一个表空间，同时制定文件的属性，如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">innodb_data_file_path = /db/ibdata1:2000M;/dr2/db/ibdata2:2000M:autoextend</span><br></pre></td></tr></table></figure>

<p>这里将 <code>/db/ibdata1</code> 和 <code>/dr2/db/ibdata2</code> 两个文件用于组成表空间。若这两个文件位于不同的磁盘上，磁盘的负载可能被平均，因此可以提高数据库的整体性能。同时，两个文件的文件名后都跟了属性，表示文件 ibdata1 的大小为 2000MB，文件 ibdata2 的大小为 2000MB，如果用完了这 2000MB，该文件可以自动增长（autoextend）。</p>
<p>设置 <code>innodb_data_file_path</code> 参数后，所有基于 InnoDB 存储引擎的表的数据都会记录到该共享表空间中。若设置了参数 <code>innodb_file_per_table</code>，则用户可以将每个基于 InnoDB 存储引擎的表生成一个独立表空间。独立表空间的命名规则为：表名 <code>.ibd</code>。需要注意的是，这些单独的表空间文件仅存储该表的数据、索引和插入缓冲 BITMAP 等信息，其余信息还是存放在默认的表空间中。</p>
<p>下图展示了 InnoDB 对于文件的存储方式：</p>
<p><img src="/../../images/MySQL/mysql_tablespace.drawio.png" alt="img"></p>
<h3 id="Redo-日志文件"><a href="#Redo-日志文件" class="headerlink" title="Redo 日志文件"></a>Redo 日志文件</h3><p>在默认情况下，在 InnoDB 存储引擎的数据目录下会有两个名为 <code>ib_logfile0</code> 和 <code>ib_logfile1</code> 的文件。</p>
<p>当实例或介质失败时，重做日志文件就能派上用场。例如，数据库由于所在主机掉电导致实例失败，InnoDB 存储引擎会使用 Redo 日志恢复到掉电前的时刻，以此来保证数据的完整性。</p>
<p>每个 InnoDB 存储引擎至少有 1 个 Redo 日志文件组，每个文件组下至少有 2 个 Redo 日志文件，如默认的 <code>ib_logfile0</code> 和 <code>ib_logfile1</code>。为了得到更高的可靠性，用户可以设置多个镜像日志组，将不同的文件组放在不同的磁盘上，以此提高 Redo 日志的高可用性。在日志组中每个 Redo 日志文件的大小一致，并以循环写入的方式运行。InnoDB 存储引擎先写 Redo 日志文件 1，当达到文件的最后时，会切换至 Redo 日志文件 2，再当重做日志文件 2 也被写满时，会再切换到 Redo 日志文件 1 中。</p>
<p>下列参数影响着 Redo 日志文件的属性：</p>
<ul>
<li><code>innodb_log_file_size</code></li>
<li><code>innodb_log_files_in_group</code></li>
<li><code>innodb_mirrored_log_groups</code></li>
<li><code>innodb_log_group_home_dir</code></li>
</ul>
<p>参数 <code>innodb_log_file_size</code> 指定每个 Redo 日志文件的大小。在 InnoDB 1.2.x 版本之前，Redo 日志文件总的大小不得大于等于 4GB，而 1.2.x 版本将该限制扩大为了 512GB。</p>
<p>参数 <code>innodb_log_files_in_group</code> 指定了日志文件组中 Redo 日志文件的数量，默认为 2。</p>
<p>参数 <code>innodb_mirrored_log_groups</code> 指定了日志镜像文件组的数量，默认为 1，表示只有一个日志文件组，没有镜像。若磁盘本身已经做了高可用的方案，如磁盘阵列，那么可以不开启 Redo 日志镜像的功能。</p>
<p>最后，参数 <code>innodb_log_group_home_dir</code> 指定了日志文件组所在路径，默认为 <code>./</code>，表示在 MySQL 数据库的数据目录下。</p>
<p>Redo 日志文件的大小设置对于 InnoDB 存储引擎的性能有着非常大的影响。一方面 Redo 日志文件不能设置得太大，如果设置得很大，在恢复时可能需要很长的时间；另一方面又不能设置得太小了，否则可能导致一个事务的日志需要多次切换 Redo 日志文件。此外，Redo 日志文件太小会导致频繁地发生 async checkpoint，导致性能的抖动。因为，如果 Redo 日志文件大小超过最大容量则必须将缓冲池中脏页列表（flush list）中的部分脏数据写回磁盘，这时会导致用户线程的阻塞。</p>
<p>Redo 日志和二进制日志有什么区别？</p>
<p>首先，二进制日志会记录所有与 MySQL 数据库有关的日志记录，包括 InnoDB、MyISAM、Heap 等其他存储引擎的日志。而 InnoDB 存储引擎的 Redo 日志只记录有关该存储引擎本身的事务日志。</p>
<p>其次，记录的内容不同。无论用户将二进制日志文件记录的格式设为 STATEMENT 还是 ROW，又或者是 MIXED，其记录的都是关于一个事务的具体操作内容，即该日志是逻辑日志。而 InnoDB 存储引擎的 Redo 日志文件记录的是关于每个页（Page）的更改的物理情况。</p>
<p>此外，写入的时间也不同，二进制日志文件仅在事务提交前进行提交，即只写磁盘一次，不论这时该事务多大。而在事务进行的过程中，却不断有 Redo 日志条目（redo entry）被写入到 Redo 日志文件中。</p>
<p>Redo 日志条目的结构如下：</p>
<p><img src="/../../images/MySQL/mysql_redo_item.drawio.png" alt="img"></p>
<p>上图中 Redo 日志条目是由 4 个部分组成：</p>
<ul>
<li><code>redo_log_type</code> 占用 1 字节，表示重做日志的类型。</li>
<li><code>space</code> 表示表空间的 ID，但采用压缩的方式，因此占用的空间可能小于 4 字节。</li>
<li><code>page_no</code> 表示页的偏移量，同样采用压缩的方式。</li>
<li><code>redo_log_body</code> 表示每个重做日志的数据部分，恢复时需要调用相应的函数进行解析。</li>
</ul>
<p>写入重做日志文件的操作不是直接写，而是先写入一个重做日志缓冲中，然后按照一定的条件顺序地写入日志文件。下图是 Redo 日志的写入过程：</p>
<p><img src="/../../images/MySQL/mysql_redo_sync.drawio.png" alt="img"></p>
<p>从重做日志缓冲往磁盘写入时是按 512 字节，也就是一个扇区的大小进行写入。因为在传统的磁盘存储设备中，扇区是最小的物理写入单位。当操作系统或数据库系统请求写入数据时，磁盘控制器会确保整个扇区的数据要么被完整地写入，要么在发生故障（如断电）时不进行任何写入。这种机制确保了写入操作的原子性，即不会出现撕裂写（torn write）的情况，因此在重做日志的写入过程中不需要有 doublewrite。</p>
<p>前面提到了从日志缓冲写入磁盘上的重做日志文件是按一定条件进行的，那这些条件有哪些呢？我们知道在主线程中每秒会将重做日志缓冲写入磁盘的重做日志文件中，不论事务是否已经提交。另一个触发写磁盘的过程是由参数 <code>innodb_flush_log_at_trx_commit</code> 控制，表示在提交操作时，处理重做日志的方式。</p>
<p>参数 <code>innodb_flush_log_at_trx_commit</code> 的有效值有 0、1、2。</p>
<p>0 代表当提交事务时，并不将事务的重做日志写入磁盘上的日志文件，而是等待主线程每秒的刷新。1 和 2 不同的地方在于：</p>
<ul>
<li>1 表示在执行 commit 时将重做日志缓冲同步写到磁盘，即伴有 fsync 的调用。</li>
<li>2 表示将重做日志异步写到磁盘，即写到文件系统的缓存中。因此不能完全保证在执行 commit 时肯定会写入重做日志文件，只是有这个动作发生。</li>
</ul>
<p>因此为了保证事务的 ACID 中的持久性，<strong>必须将</strong> <strong><code>innodb_flush_log_at_trx_commit</code></strong> <strong>设置为 1</strong>，也就是每当有事务提交，就必须确保事务已经写入重做日志文件。那当数据库因为意外发生宕机时，可以通过重做日志文件恢复，并保证可以恢复已经提交的事务。</p>
<p>而将重做日志文件设置为 0 或 2，<strong>都有可能发生恢复时部分事务的丢失</strong>。不同之处在于，设置为 2 时，当 MySQL 数据库发生宕机而操作系统及服务器并没有发生宕机时，由于此时未写入磁盘的事务日志保存在文件系统缓存中，当恢复时同样能保证数据不丢失。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Yihang Wei</p>
  <div class="site-description" itemprop="description">聚焦于个人的学习与成长历程，旨在系统记录在后端开发、数据库等领域的探索与实践。</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">38</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        
  <div class="languages">
    <label class="lang-select-label">
      <i class="fa fa-language"></i>
      <span>简体中文</span>
      <i class="fa fa-angle-up" aria-hidden="true"></i>
    </label>
    <select class="lang-select" data-canonical="">
      
        <option value="zh-CN" data-href="/page/3/index.html" selected="">
          简体中文
        </option>
      
        <option value="en" data-href="/en/page/3/index.html" selected="">
          English
        </option>
      
    </select>
  </div>

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yihang Wei</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
<script src="https://cdn.jsdelivr.net/npm/darkmode-js@1.5.7/lib/darkmode-js.min.js"></script>

<script>
var options = {
  bottom: '50%',
  right: '32px',
  left: 'unset',
  time: '0.5s',
  mixColor: '#fff',
  backgroundColor: '#fff',
  buttonColorDark: '#100f2c',
  buttonColorLight: '#fff',
  saveInCookies: true,
  label: '明暗',
  autoMatchOsTheme: true
}
const darkmode = new Darkmode(options);
window.darkmode = darkmode;
darkmode.showWidget();
</script>

</body>
</html>
